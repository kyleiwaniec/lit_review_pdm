TY  - CHAP
AU  - Hasan, N.
AU  - Alam, M.
TI  - Envisaging Industrial Perspective Demand Response Using Machine Learning
PY  - 2022
T2  - Lecture Notes on Data Engineering and Communications Technologies
VL  - 90
SP  - 331
EP  - 342
DO  - 10.1007/978-981-16-6289-8_28
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122426631&doi=10.1007%2f978-981-16-6289-8_28&partnerID=40&md5=1a7595f051cd5e7a5ba51af2b5c5a7c0
AB  - The utilization of Internet of Things (IoT) sensors in industry which generates the data that is used in a variety of analytics for the acquisition of valuable information is characterised as Industrial Internet of Things (IIoT). In predictive analytics, the primary aspect is typically the kind of data provided by the sensors. Various kinds of data are collected while performing predictive modelling, for, e.g., area, season, energy, cost, etc. In this paper, a case study is presented, in which a dataset is used to examine the functioning of equipment and to analyse the demand and response of that equipment. The main aim of this paper is to employ various machine learning algorithms in order to devise of predictive models in industrial IoT environment using the dataset mentioned above. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
KW  - Demand response analytics
KW  - Industrial Internet
KW  - Wireless sensor network
KW  - Internet of things
KW  - Learning algorithms
KW  - Machine learning
KW  - Predictive analytics
KW  - Case-studies
KW  - Demand response
KW  - Demand response analytic
KW  - Energy cost
KW  - Industrial internet
KW  - Machine learning algorithms
KW  - Machine-learning
KW  - Predictive models
KW  - Wireless sensor networks
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Burghouts, G.J.
AU  - Hillerström, F.
AU  - Walraven, E.
AU  - van Bekkum, M.
AU  - Ruis, F.
AU  - Sijs, J.
AU  - van Mil, J.
AU  - Dijk, J.
AU  - Meijer, W.
TI  - Open-World Visual Reasoning by a Neuro-Symbolic Program of Zero-Shot Symbols
PY  - 2025
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 
VL  - 14892 LNCS
SP  - 62
EP  - 75
DO  - 10.1007/978-981-97-8702-9_5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219205229&doi=10.1007%2f978-981-97-8702-9_5&partnerID=40&md5=3ae83121ef335e18117b19039377a101
AB  - We consider the problem of finding spatial configurations of multiple objects in images, e.g., a mobile inspection robot is tasked to localize abandoned tools on the floor. We define the spatial configuration of objects by first-order logic in terms of relations and attributes. A neuro-symbolic program matches the logic formulas to probabilistic object proposals for the given image, provided by language-vision models by querying them for the symbols. This work is the first to combine neuro-symbolic programming (reasoning) and language-vision models (learning) to find spatial configurations of objects in images in an open world setting. We show the effectiveness by finding abandoned tools on floors and leaking pipes. We find that most prediction errors are due to biases in the language-vision model. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.
KW  - Knowledge Representation
KW  - Language-Vision Models
KW  - Neuro-Symbolic Programming
KW  - Open World Robotics
KW  - Zero-shot Models
KW  - Mobile robots
KW  - Probabilistic logics
KW  - Robot programming
KW  - Visual languages
KW  - Zero-shot learning
KW  - Knowledge-representation
KW  - Language-vision model
KW  - Neuro-symbolic programming
KW  - Open world
KW  - Open world robotic
KW  - Spatial configuration
KW  - Symbolic programming
KW  - Vision model
KW  - Visual reasoning
KW  - Zero-shot model
KW  - Knowledge representation
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Yan, R.
AU  - Ma, T.
AU  - Fokoue, A.
AU  - Chang, M.
AU  - Julius, A.
TI  - Neuro-symbolic Models for Interpretable Time Series Classification using Temporal Logic Description
PY  - 2022
T2  - Proceedings - IEEE International Conference on Data Mining, ICDM
VL  - 2022-November
SP  - 618
EP  - 627
DO  - 10.1109/ICDM54844.2022.00072
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147736516&doi=10.1109%2fICDM54844.2022.00072&partnerID=40&md5=3354b04651d0bc93bf9248f3b69c32f4
AB  - Most existing Time series classification (TSC) models lack interpretability and are difficult to inspect. Interpretable machine learning models can aid in discovering patterns in data as well as give easy-to-understand insights to domain specialists. In this study, we present Neuro-Symbolic Time Series Classification (NSTSC), a neuro-symbolic model that leverages signal temporal logic (STL) and neural network (NN) to accomplish TSC tasks using multi-view data representation and expresses the model as a human-readable, interpretable formula. In NSTSC, each neuron is linked to a symbolic expression, i.e., an STL (sub)formula. The output of NSTSC is thus interpretable as an STL formula akin to natural language, describing temporal and logical relations hidden in the data. We propose an NSTSC-based classifier that adopts a decision-tree approach to learn formula structures and accomplish a multiclass TSC task. The proposed smooth activation functions enable the model to be learned in an end-to-end fashion. We test NSTSC on a real-world wound healing dataset from mice and benchmark datasets from the UCR time-series repository, demonstrating that NSTSC achieves comparable performance with the state-of-the-art models. Furthermore, NSTSC can generate interpretable formulas that match domain knowledge.  © 2022 IEEE.
KW  - Benchmarking
KW  - Computer circuits
KW  - Decision trees
KW  - Mammals
KW  - Statistical tests
KW  - Time series
KW  - Classification models
KW  - Classification tasks
KW  - Data representations
KW  - Interpretability
KW  - Logic networks
KW  - Machine learning models
KW  - Multi-view datum
KW  - Neural-networks
KW  - Symbolic modeling
KW  - Time series classifications
KW  - Temporal logic
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Nasary, M.F.
AU  - Ibrahim, A.M.
AU  - Al Mahmud, S.
AU  - Shafie, A.A.
AU  - Mardzuki, M.I.
TI  - Optimizing Mobile Robot Navigation Through Neuro-Symbolic Fusion of Deep Deterministic Policy Gradient (DDPG) and Fuzzy Logic
PY  - 2024
T2  - Communications in Computer and Information Science
VL  - 2077 CCIS
SP  - 278
EP  - 292
DO  - 10.1007/978-3-031-59057-3_18
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194055874&doi=10.1007%2f978-3-031-59057-3_18&partnerID=40&md5=e5a28e62ab161a8dd9fa53f8454a897d
AB  - Mobile robot navigation has been a sector of great importance in the autonomous systems research arena for a while. For ensuring successful navigation in complex environments several rule-based traditional approaches have been employed previously which possess several drawbacks in terms of ensuring navigation and obstacle avoidance efficiency. Compared to them, reinforcement learning is a novel technique being assessed for this purpose lately. However, the constant reward values in reinforcement learning algorithms limits their performance capabilities. This study enhances the Deep Deterministic Policy Gradient (DDPG) algorithm by integrating fuzzy logic, creating a neuro-symbolic approach that imparts advanced reasoning capabilities to the mobile agents. The outcomes observed in the environment resembling real-world scenarios, highlighted remarkable performance improvements of the neuro-symbolic approach, displaying a success rate of 0.71% compared to 0.39%, an average path length of 35 m compared to 25 m, and an average execution time of 120 s compared to 97 s. The results suggest that the employed approach enhances the navigation performance in terms of obstacle avoidance success rate and path length, hence could be reliable for navigation purpose of mobile agents. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - DDPG
KW  - Fuzzy logic
KW  - Mobile robot navigation
KW  - Obstacle avoidance
KW  - Simulation
KW  - Air navigation
KW  - Computer circuits
KW  - Fuzzy inference
KW  - Learning algorithms
KW  - Mobile robots
KW  - Reinforcement learning
KW  - Complex environments
KW  - Deep deterministic policy gradient
KW  - Deterministics
KW  - Fuzzy-Logic
KW  - Mobile Robot Navigation
KW  - Obstacles avoidance
KW  - Policy gradient
KW  - Rule based
KW  - Simulation
KW  - Systems research
KW  - Mobile agents
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Khan, A.
AU  - Konig, T.
AU  - Hetznecker, A.
AU  - Greiner, T.
TI  - Enhanced Hybrid Neuro-Symbolic AI for External Magnetic Interference Classification in Magnetostrictive Position Sensors
PY  - 2025
T2  - IEEE Sensors Journal
VL  - 25
IS  - 5
SP  - 9121
EP  - 9129
DO  - 10.1109/JSEN.2025.3529660
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001062618&doi=10.1109%2fJSEN.2025.3529660&partnerID=40&md5=9dba293d1ddc89b33883d8dc20930f97
AB  - The growing use of sensors in both industrial and commercial settings demands sensors that are flexible, precise, and reliable. To meet these requirements, especially complex sensors should be able to detect anomalies and defects in both their environment and themselves and respond appropriately. Important examples of complex sensors are magnetostrictive position sensors (MPSs), which are used for high-precision distance and velocity measurements. These sensors work on the basis of time-of-flight (ToF) calculation for a structure-borne torsional wave generated through the interaction of an excitation pulse and a marker magnetic field within the sensor systems. The accuracy of these sensors is affected by external magnetic interference (EMI) which can interact with the structure-borne sound wave they generate. This study presents a novel solution using enhanced hybrid neuro-symbolic AI to classify the intensity of EMI directly from the received distance signal without the help of an additional sensor. This work is of significance for measurement in industrial environments where multiple sources of EMI can be present. © 2001-2012 IEEE.
KW  - Hybrid AI
KW  - magnetostrictive sensors
KW  - neural networks (NNs)
KW  - position sensors
KW  - symbolic AI
KW  - Acoustic wave velocity measurement
KW  - Acoustic waves
KW  - Hybrid sensors
KW  - Magnetostriction
KW  - Commercial settings
KW  - High-precision
KW  - Hybrid AI
KW  - Industrial settings
KW  - Magnetic interference
KW  - Magnetostrictive sensors
KW  - Neural-networks
KW  - Position sensors
KW  - Symbolic AI
KW  - Time-of flight
KW  - Magnetostrictive devices
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Arrotta, L.
AU  - Civitarese, G.
AU  - Bettini, C.
TI  - Knowledge Infusion for Context-Aware Sensor-Based Human Activity Recognition
PY  - 2022
T2  - Proceedings - 2022 IEEE International Conference on Smart Computing, SMARTCOMP 2022
SP  - 1
EP  - 8
DO  - 10.1109/SMARTCOMP55677.2022.00016
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136145298&doi=10.1109%2fSMARTCOMP55677.2022.00016&partnerID=40&md5=b0e5f9d2dca41db48e4c4c2493171737
AB  - Neuro-symbolic AI methods aim at integrating the capabilities of data-driven deep learning solutions with the ones of more traditional symbolic approaches. These techniques have been poorly explored in the sensor-based Human Activity Recognition (HAR) research field, even if they could lead to multiple benefits such as improving model interpretability and reducing the amount of labeled data that is necessary to reliably train the model. In this paper, we propose DUSTIN, a novel knowledge infusion approach for sensor-based HAR. DUSTIN concatenates the features automatically extracted by a CNN model from raw sensor data and high-level context data with the ones inferred by a knowledge-based reasoner. In particular, the symbolic features encode common-sense knowledge about the activities which are consistent with the context of the user, and they are infused within the model before the classification layer. We experimentally evaluated DUSTIN on a HAR dataset of mobile devices sensor data that includes 14 different activities performed by 26 users. Our results show that DUSTIN outperforms state-of-the-art neuro-symbolic approaches, with the advantage of requiring a limited amount of training data and training epochs to reach satisfying recognition rates.  © 2022 IEEE.
KW  - activity recognition
KW  - knowledge infusion
KW  - neuro-symbolic AI
KW  - Knowledge based systems
KW  - Pattern recognition
KW  - Activity recognition
KW  - Context-Aware
KW  - Data driven
KW  - Human activity recognition
KW  - Interpretability
KW  - Knowledge infusion
KW  - Labeled data
KW  - Neuro-symbolic AI
KW  - Research fields
KW  - Sensors data
KW  - Deep learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - CONF
AU  - Sakor, A.
AU  - Brunet, M.
AU  - Iglesias, E.
AU  - Rivas, A.
AU  - Rohde, P.D.
AU  - Kraft, A.
AU  - Vidal, M.-E.
TI  - Integrating Knowledge Graphs and Neuro-Symbolic AI: LDM Enables FAIR and Federated Research Data Management
PY  - 2025
T2  - WSDM 2025 - Proceedings of the 18th ACM International Conference on Web Search and Data Mining
SP  - 1044
EP  - 1047
DO  - 10.1145/3701551.3704125
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001674633&doi=10.1145%2f3701551.3704125&partnerID=40&md5=05c395e36b21cdb79938c146bd03399d
AB  - Managing research digital objects (RDOs) in compliance with FAIR principles is crucial for ensuring accessibility, interoperability, and reusability across scientific domains. The Leibniz Data Manager (LDM) is a state-of-the-art framework that integrates Knowledge Graphs (KGs) and Neuro-Symbolic AI, combining the reasoning power of Large Language Models (LLMs) with structured metadata. LDM supports the management and enhancement of RDOs through entity linking, connecting datasets to external KGs like Wikidata and the Open Research Knowledge Graph (ORKG). Additionally, LDM offers federated query processing across KGs, enabling users to explore related papers, datasets, and resources through natural language questions. This demo showcases LDM's capabilities to explore RDOs, compare existing datasets, and extend metadata. By blending Neuro-Symbolic AI with FAIR and federated research data management, LDM offers a powerful tool for accelerating data-driven discovery in science. LDM is publicly accessible at https://service.tib.eu/ldmservice/. © 2025 Copyright held by the owner/author(s).
KW  - Data Science
KW  - Digital Repositories
KW  - Federated Search
KW  - Data Science
KW  - Information management
KW  - Query languages
KW  - Query processing
KW  - Research and development management
KW  - Reusability
KW  - Structured Query Language
KW  - Digital Objects
KW  - Digital repository
KW  - External knowledge
KW  - Federated search
KW  - Knowledge graphs
KW  - Language model
KW  - Power
KW  - Research data managements
KW  - State of the art
KW  - Structured metadatas
KW  - Knowledge graph
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Huang, W.
AU  - Rezvani, A.
AU  - Chen, H.
AU  - Ni, Y.
AU  - Yun, S.
AU  - Jeong, S.
AU  - Zhang, G.
AU  - Imani, M.
TI  - Intelligent Sensing Framework: Near-Sensor Machine Learning for Efficient Data Transmission
PY  - 2024
T2  - IEEE Sensors Journal
VL  - 24
IS  - 21
SP  - 35858
EP  - 35871
DO  - 10.1109/JSEN.2024.3440988
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201612322&doi=10.1109%2fJSEN.2024.3440988&partnerID=40&md5=df3c14a1fd3a61b7e2e324d9e57d149d
AB  - Applications in the Internet of Things (IoT) utilize machine learning (ML) to analyze sensor-generated data. However, a major challenge lies in the lack of targeted intelligence in current sensing systems, leading to vast data generation and increased computational and communication costs. To address this challenge, we propose a novel sensing framework to equip sensing systems with intelligent data transmission capabilities by integrating a highly efficient ML model placed near the sensor. This model provides prompt feedback for the sensing system to transmit only valuable data while discarding irrelevant information by regulating the frequency of data transmission. The near-sensor model is quantized and optimized for real-time sensor control. To enhance the framework's performance, the training process is customized, and a 'lazy' sensor deactivation strategy utilizing temporal information is introduced. The suggested framework is orthogonal to other IoT frameworks and can be considered as a plug-in for selective data transmission. The framework is implemented, encompassing both software and hardware components. The experiments demonstrate that the framework utilizing the suggested module achieves over 85% system efficiency in terms of energy consumption and storage, with negligible impact on performance. This framework has the potential to significantly reduce data output from sensors, benefiting a wide range of IoT applications.  © 2001-2012 IEEE.
KW  - Energy efficiency
KW  - intelligent sensing
KW  - Internet of Things (IoT)
KW  - machine learning (ML)
KW  - near-sensor computing
KW  - Intelligent systems
KW  - Network security
KW  - Computational modelling
KW  - Data-transmission
KW  - Energy
KW  - Features extraction
KW  - Intelligent sensing
KW  - Intelligent sensors
KW  - Machine-learning
KW  - Near-sensor computing
KW  - Sensing systems
KW  - Sensor computing
KW  - Adversarial machine learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Siyaev, A.
AU  - Jo, G.-S.
TI  - Neuro-Symbolic Speech Understanding in Aircraft Maintenance Metaverse
PY  - 2021
T2  - IEEE Access
VL  - 9
SP  - 154484
EP  - 154499
DO  - 10.1109/ACCESS.2021.3128616
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120497485&doi=10.1109%2fACCESS.2021.3128616&partnerID=40&md5=cb3b6bf8a193bd6cebf47085842f7801
AB  - In the emerging world of metaverses, it is essential for speech communication systems to be aware of context to interact with virtual assets in the 3D world. This paper proposes the metaverse for aircraft maintenance training and education of Boeing-737, supplied with legacy manuals, 3D models, 3D simulators, and aircraft maintenance knowledge. Furthermore, to navigate and control operational flow in the metaverse, which is strictly followed by maintenance manuals, the context-aware speech understanding module Neuro-Symbolic Speech Executor (NSSE) is presented. Unlike conventional speech recognition methods, NSSE applies Neuro-Symbolic AI, which combines neural networks and traditional symbolic reasoning, to understand users' requests and reply based on context and aircraft-specific knowledge. NSSE is developed with an industrially flexible approach by applying only synthetic data for training. Nevertheless, the evaluation process performed with various automatic speech recognition metrics on real users' data showed sustainable results with an average accuracy of 94.7%, Word Error Rate (WER) of 7.5%, and the generalization ability to handle speech requests of users with the non-native pronunciation. The proposed Aircraft Maintenance Metaverse is a cheap and scalable solution for aviation colleges since it replaces expensive physical aircraft with virtual one that can be easily modified and updated. Moreover, the Neuro-Symbolic Speech Executor, playing the role of field expert, provides technical guidance and all the resources to facilitate effective training and education of aircraft maintenance.  © 2013 IEEE.
KW  - Aircraft maintenance education
KW  - Boeing-737
KW  - deep learning
KW  - industry 40
KW  - metaverse
KW  - mixed reality
KW  - neuro-symbolic AI
KW  - smart glasses
KW  - speech recognition
KW  - transformer
KW  - Air navigation
KW  - Deep learning
KW  - Maintenance
KW  - Mixed reality
KW  - Speech
KW  - Training aircraft
KW  - Aircraft maintenance
KW  - Aircraft maintenance education
KW  - Boeing 737
KW  - Deep learning
KW  - Industry 40
KW  - Metaverses
KW  - Mixed reality
KW  - Neuro-symbolic AI
KW  - Smart glass
KW  - Transformer
KW  - Speech recognition
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 90
ER  -

TY  - JOUR
AU  - Kalutharage, C.S.
AU  - Liu, X.
AU  - Chrysoulas, C.
TI  - Neurosymbolic learning and domain knowledge-driven explainable AI for enhanced IoT network attack detection and response
PY  - 2025
T2  - Computers and Security
VL  - 151
C7  - 104318
DO  - 10.1016/j.cose.2025.104318
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214903984&doi=10.1016%2fj.cose.2025.104318&partnerID=40&md5=e3484def89a21fc4460610cb0c5f70e3
AB  - In the dynamic landscape of network security, where cyberattacks continuously evolve, robust and adaptive detection mechanisms are essential, particularly for safeguarding Internet of Things (IoT) networks. This paper introduces an advanced anomaly detection model that utilizes Artificial Intelligence (AI) to identify network anomalies based on traffic features, explaining the most influential factors behind each detected anomaly. The model integrates domain knowledge stored in a knowledge graph to verify whether the detected anomaly constitutes a legitimate attack. Upon validation, the model identifies which core cybersecurity principles—Confidentiality, Integrity, or Availability (CIA)—are violated by mapping influential feature values. This is followed by an alignment with the MITRE ATT&CK framework to provide insights into potential attack tactics, techniques, and intelligence-driven countermeasures. By leveraging explainable AI (XAI) and incorporating expert domain knowledge, our approach bridges the gap between complex AI predictions and human-understandable decision-making, thereby enhancing both detection accuracy and result interpretability. This transparency facilitates faster responses and real-time decision-making while improving adaptability to new, unseen cyber threats. Our evaluation on network traffic datasets demonstrates that the model not only excels in detecting and explaining anomalies but also achieves an overall detection accuracy of 0.97 with the integration of domain knowledge for attack legitimacy. Furthermore, it provides 100% accuracy for threat intelligence based on the MITRE ATT&CK framework, ensuring that security measures are verifiable, actionable, and ultimately strengthen IoT environment defenses by delivering real-time threat intelligence and responses, thus minimizing human response time. © 2025 The Authors
KW  - Attack detection
KW  - Expert knowledge
KW  - Explainable artificial intelligence
KW  - Neurosymbolic learning
KW  - Threat intelligence
KW  - Cyber attacks
KW  - Network security
KW  - Attack detection
KW  - Cyber-attacks
KW  - Detection accuracy
KW  - Domain knowledge
KW  - Expert knowledge
KW  - Explainable artificial intelligence
KW  - Network attack
KW  - Networks security
KW  - Neurosymbolic learning
KW  - Threat intelligence
KW  - Domain Knowledge
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Cominelli, M.
AU  - Gringoli, F.
AU  - Kaplan, L.M.
AU  - Srivastava, M.B.
AU  - Bihl, T.
AU  - Blasch, E.P.
AU  - Iyer, N.
AU  - Cerutti, F.
TI  - Neuro-Symbolic Fusion of Wi-Fi Sensing Data for Passive Radar with Inter-Modal Knowledge Transfer
PY  - 2024
T2  - FUSION 2024 - 27th International Conference on Information Fusion
DO  - 10.23919/FUSION59988.2024.10706320
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207697009&doi=10.23919%2fFUSION59988.2024.10706320&partnerID=40&md5=6317d6a8a329a043b2c240be5219308a
AB  - Wi-Fi devices, akin to passive radars, can discern human activities within indoor settings due to the human body's interaction with electromagnetic signals. Current Wi-Fi sensing applications predominantly employ data-driven learning techniques to associate the fluctuations in the physical properties of the communication channel with the human activity causing them. However, these techniques often lack the desired flexibility and transparency. This paper introduces DeepProbHAR, a neuro-symbolic architecture for Wi-Fi sensing, providing initial evidence that Wi-Fi signals can differentiate between simple movements, such as leg or arm movements, which are integral to human activities like running or walking. The neuro-symbolic approach affords gathering such evidence without needing additional specialised data collection or labelling. The training of DeepProbHAR is facilitated by declarative domain knowledge obtained from a camera feed and by fusing signals from various antennas of the Wi-Fi receivers. DeepProbHAR achieves results comparable to the state-of-the-art in human activity recognition. Moreover, as a by-product of the learning process, DeepProbHAR generates specialised classifiers for simple movements that match the accuracy of models trained on finely labelled datasets, which would be particularly costly. © 2024 ISIF.
KW  - data fusion
KW  - neuro-symbolic AI
KW  - Wi-Fi sensing
KW  - Data acquisition
KW  - Image analysis
KW  - Image segmentation
KW  - Information fusion
KW  - Network security
KW  - Sensor data fusion
KW  - Steganography
KW  - Electromagnetic signals
KW  - Human activities
KW  - Human bodies
KW  - Knowledge transfer
KW  - Neuro-symbolic AI
KW  - Passive radars
KW  - Sensing data
KW  - Simple++
KW  - WI - FI
KW  - Wi-fi sensing
KW  - Data transfer
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Wu, M.
AU  - Chen, B.
AU  - Zhu, S.
AU  - Zheng, B.
AU  - Peng, W.
AU  - Zhang, M.
TI  - Neuro-symbolic recommendation model based on logic query
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 284
C7  - 111311
DO  - 10.1016/j.knosys.2023.111311
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183707157&doi=10.1016%2fj.knosys.2023.111311&partnerID=40&md5=5869b34ce20fba4fbca0b75ae5733b01
AB  - Recommendation systems assist users in finding items that are relevant to them. However, recommendation is not only an inductive statistics problem using data; it is also a cognitive task of reasoning decisions based on knowledge extracted from information. Hence, a logic system can naturally be incorporated for reasoning in a recommendation task. Although logic-based hard-rule approaches can provide a powerful reasoning ability, they struggle to cope with inconsistent and incomplete knowledge in real-world tasks, especially for complex tasks such as recommendation. To address these issues, we propose a neuro-symbolic recommendation model, which transforms user history interactions into a logic expression and then transforms the recommendation prediction into a query task based on this logic expression. The logic expressions are then computed based on the modular logic operations of the neural network. We also construct an implicit logic encoder to reasonably reduce the complexity of the logic computation. Finally, a user's interest items can be queried in the vector space based on the computation results. Experiments on three well-known datasets verified that the proposed method outperforms state of the art shallow, deep, session, and reasoning models. © 2023 Elsevier B.V.
KW  - Cognitive reasoning
KW  - Logic system
KW  - Neuro-symbolic
KW  - Recommendation systems
KW  - Cognitive systems
KW  - Complex networks
KW  - Computer circuits
KW  - Vector spaces
KW  - Cognitive reasoning
KW  - Cognitive task
KW  - Decision-based
KW  - Incomplete knowledge
KW  - Logic expressions
KW  - Logic systems
KW  - Model-based OPC
KW  - Neuro-symbolic
KW  - Real-world task
KW  - Reasoning ability
KW  - Recommender systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Gu, J.
AU  - Gall, H.
TI  - Towards Top-Down Automated Development in Limited Scopes: A Neuro-Symbolic Framework from Expressibles to Executables
PY  - 2023
T2  - ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering
SP  - 2072
EP  - 2076
DO  - 10.1145/3611643.3613076
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180553293&doi=10.1145%2f3611643.3613076&partnerID=40&md5=79d1f4395f512e918e80bc6b8ff0d63a
AB  - Deep code generation is a topic of deep learning for software engineering (DL4SE), which adopts neural models to generate code for the intended functions. Since end-to-end neural methods lack domain knowledge and software hierarchy awareness, they tend to perform poorly w.r.t project-level tasks. To systematically explore the potential improvements of code generation, we let it participate in the whole top-down development from expressibles to executables, which is possible in limited scopes. In the process, it benefits from massive samples, features, and knowledge. As the foundation, we suggest building a taxonomy on code data, namely code taxonomy, leveraging the categorization of code information. Moreover, we introduce a three-layer semantic pyramid (SP) to associate text data and code data. It identifies the information of different abstraction levels, and thus introduces the domain knowledge on development and reveals the hierarchy of software. Furthermore, we propose a semantic pyramid framework (SPF) as the approach, focusing on software of high modularity and low complexity. SPF divides the code generation process into stages and reserves spots for potential interactions. In addition, we conceived preliminary applications in software development to confirm the neuro-symbolic framework. © 2023 ACM.
KW  - code generation
KW  - deep learning
KW  - frame semantics
KW  - knowledge graph
KW  - program representation
KW  - requirement elicitation
KW  - software analytics
KW  - Application programs
KW  - Codes (symbols)
KW  - Deep learning
KW  - Domain Knowledge
KW  - Knowledge graph
KW  - Software design
KW  - Taxonomies
KW  - Codegeneration
KW  - Deep learning
KW  - Domain knowledge
KW  - Executables
KW  - Frame semantics
KW  - Knowledge graphs
KW  - Program representations
KW  - Requirements elicitation
KW  - Software analytic
KW  - Topdown
KW  - Semantics
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Munir, M.S.
AU  - Kim, K.T.
AU  - Adhikary, A.
AU  - Saad, W.
AU  - Shetty, S.
AU  - Park, S.-B.
AU  - Hong, C.S.
TI  - Neuro-Symbolic Explainable Artificial Intelligence Twin for Zero-Touch IoE in Wireless Network
PY  - 2023
T2  - IEEE Internet of Things Journal
VL  - 10
IS  - 24
SP  - 22451
EP  - 22468
DO  - 10.1109/JIOT.2023.3303713
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167778701&doi=10.1109%2fJIOT.2023.3303713&partnerID=40&md5=96bca2f2780447b267f574e38a8a56bd
AB  - Explainable artificial intelligence (XAI) twin systems will be a fundamental enabler of zero-touch network and service management (ZSM) for sixth-generation (6G) wireless networks. Thus, a reliable XAI twin system becomes essential to discretizing the physical behavior of the Internet of Everything (IoE) and identifying the reasons behind that behavior for enabling ZSM. To address the challenges of extensible, modular, and stateless management functions in ZSM, a novel neuro-symbolic XAI twin framework is proposed that to enable trustworthy ZSM for a wireless IoE. The proposed neuro-symbolic XAI twin framework consists of two learning systems: 1) implicit learner that acts as an unconscious learner in physical space and 2) explicit leaner that can exploit symbolic reasoning based on implicit learner decisions and prior evidence. The physical space of the XAI twin executes a neural-network-driven multivariate regression to capture the time-dependent wireless IoE environment while determining unconscious decisions of IoE service aggregation, such as uplink, downlink, and service provisioning. Subsequently, the virtual space of the XAI twin constructs a directed acyclic graph (DAG)-based Bayesian network that can infer a symbolic reasoning score over unconscious decisions through a first-order probabilistic language model. Furthermore, a Bayesian multiarm bandit-based learning problem is proposed for reducing the gap between the expected explained score and the current obtained score of the proposed neuro-symbolic XAI twin. Experimental results show that the proposed neuro-symbolic XAI twin can achieve around 96.26% accuracy while guaranteeing from 18% to 44% more trust score in terms of reasoning and closed-loop automation. © 2014 IEEE.
KW  - Declarative semantics
KW  - explainable artificial intelligence (XAI)
KW  - Internet of Everything (IoE)
KW  - neuro-symbolic XAI
KW  - trustworthy artificial intelligence (AI)
KW  - zero-touch network and service management (ZSM)
KW  - 5G mobile communication systems
KW  - Artificial intelligence
KW  - Bayesian networks
KW  - Directed graphs
KW  - Internet of Everything
KW  - Internet of things
KW  - Learning systems
KW  - Regression analysis
KW  - Semantic Web
KW  - Semantics
KW  - Bayes method
KW  - Cognition
KW  - Declarative semantics
KW  - Explainable artificial intelligence (XAI)
KW  - Internet of everything
KW  - Network and service managements
KW  - Neuro-symbolic explainable artificial intelligence
KW  - Trustworthy AI
KW  - Uplink
KW  - Zero-touch network and service management
KW  - Wireless networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 12
ER  -

TY  - CONF
AU  - Mangal, A.
AU  - Vyas, T.
AU  - Gupta, R.
AU  - Tanwar, S.
AU  - Shahinzadeh, H.
TI  - Neurosymbolic AI-based Framework for Sports Ball Identification Concerning Toddlers
PY  - 2024
T2  - 2024 20th CSI International Symposium on Artificial Intelligence and Signal Processing, AISP 2024
DO  - 10.1109/AISP61396.2024.10475201
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190359385&doi=10.1109%2fAISP61396.2024.10475201&partnerID=40&md5=d83866f0946a5d0edcad3e556c9c1ee1
AB  - In today's digital world, a vast amount of unstructured data is generated, primarily consisting of images and videos. Extracting meaningful information from these visuals is crucial for effective retrieval. Among the various fields where these images play a role, sports are essential in everyone's life. This article introduces a system aimed at helping toddlers effortlessly understand sports balls. The proposed framework establishes a classification system for sports images, considering factors such as ball size, color, direction, dimension, and other vital details. Our approach uses object detection and image processing techniques to classify various sports balls, including cricket balls, basketball, volleyball, tennis balls, and football. To determine their positions and provide relevant information, we implemented the neuro-symbolic ai framework (NSAI) to provide symbolic reasoning question-answer capabilities to classify balls.  © 2024 IEEE.
KW  - Image Processing
KW  - Inference
KW  - Machine Learning
KW  - Neuro-Symbolic AI
KW  - Object detection
KW  - OpenCV
KW  - Performance
KW  - Question-Answer
KW  - Classification (of information)
KW  - Computer vision
KW  - Machine learning
KW  - Object detection
KW  - Object recognition
KW  - Digital world
KW  - Images processing
KW  - Inference
KW  - Machine-learning
KW  - Neuro-symbolic AI
KW  - Objects detection
KW  - Opencv
KW  - Performance
KW  - Question-answer
KW  - Sports balls
KW  - Sports
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Keber, M.
AU  - Grubišić, I.
AU  - Barešić, A.
AU  - Jović, A.
TI  - A Review on Neuro-symbolic AI Improvements to Natural Language Processing
PY  - 2024
T2  - 2024 47th ICT and Electronics Convention, MIPRO 2024 - Proceedings
SP  - 66
EP  - 72
DO  - 10.1109/MIPRO60963.2024.10569741
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198223856&doi=10.1109%2fMIPRO60963.2024.10569741&partnerID=40&md5=bac7767c83990e24577e7adba3a53aa3
AB  - Symbolic artificial intelligence (AI) reflects the domain knowledge of experts and adheres to the logic of the subject area, rules, or any relations between entities. Connectionist (neuro) approaches based on artificial neural networks are excellent for extracting abstract features, contextualizing, and embedding interactions between features. When connectionist and symbolic approaches are properly aligned in a model, they benefit from complementary strengths; the combination is referred to as a hybrid or neuro-symbolic artificial intelligence (NSAI) model. The advantages that NSAI brings to the field of natural language processing (NLP) have received little attention from researchers in recent years. Therefore, in this review, we focus on the impact of neuro-symbolic approaches for NLP tasks, i.e. text classification, information extraction, machine translation, and language understanding. Relevant research articles from Scopus, Web of Science, and Google Scholar were carefully examined using appropriate keywords in the period from 2019 to 2024. The review aims to show the types of NSAI systems, identify the motivation for using NSAI, evaluate the use of additional annotations for content description, and briefly describe how the neuro-symbolic connection improves the methodology and enables trustworthy and explainable AI systems in current NLP research. The review also highlights areas of application and improvements achieved by NSAI approaches in benchmarks.  © 2024 IEEE.
KW  - deep learning
KW  - knowledge representation
KW  - natural language processing
KW  - neuro-symbolic artificial intelligence
KW  - Abstracting
KW  - Benchmarking
KW  - Classification (of information)
KW  - Deep learning
KW  - Domain Knowledge
KW  - Natural language processing systems
KW  - Neural networks
KW  - Text processing
KW  - Artificial intelligence systems
KW  - Deep learning
KW  - Domain knowledge
KW  - Embeddings
KW  - Intelligence models
KW  - Knowledge-representation
KW  - Language processing
KW  - Natural language processing
KW  - Natural languages
KW  - Neuro-symbolic artificial intelligence
KW  - Knowledge representation
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Sowiński, P.
AU  - Lacalle, I.
AU  - Vaño, R.
AU  - Palau, C.E.
AU  - Ganzha, M.
AU  - Paprzycki, M.
TI  - Overview of Current Challenges in Multi-architecture Software Engineering and a Vision for the Future
PY  - 2025
T2  - Lecture Notes in Computer Science
VL  - 15546 LNCS
SP  - 74
EP  - 94
DO  - 10.1007/978-3-031-86193-2_5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002562625&doi=10.1007%2f978-3-031-86193-2_5&partnerID=40&md5=758081b5d1651b16d0a2a1d29b93f5f2
AB  - The landscape of computing technologies is changing rapidly, straining existing software engineering practices and tools. The growing need to produce and maintain increasingly complex multi-architecture applications makes it crucial to effectively accelerate and automate software engineering processes. At the same time, artificial intelligence (AI) tools are expected to work hand-in-hand with human developers. Therefore, it becomes critical to model the software accurately, so that the AI and humans can share a common understanding of the problem. In this contribution, firstly, an in-depth overview of these interconnected challenges faced by modern software engineering is presented. Secondly, to tackle them, a novel architecture based on the emerging WebAssembly technology and the latest advancements in neuro-symbolic AI, autonomy, and knowledge graphs is proposed. The presented system architecture is based on the concept of dynamic, knowledge graph-based WebAssembly Twins, which model the software throughout all stages of its lifecycle. The resulting systems are to possess advanced autonomous capabilities, with full transparency and controllability by the end user. The concept takes a leap beyond the current software engineering approaches, addressing some of the most urgent issues in the field. Finally, the efforts towards realizing the proposed approach, as well as future research directions, are summarized. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
KW  - Autonomy
KW  - Knowledge graphs
KW  - Multi-architecture software
KW  - Overview
KW  - Software engineering
KW  - Software engineering automation
KW  - WebAssembly
KW  - Application programs
KW  - Computer aided software engineering
KW  - Life cycle
KW  - Software architecture
KW  - 'current
KW  - Autonomy
KW  - Computing technology
KW  - Engineering automation
KW  - Knowledge graphs
KW  - Multi-architecture software
KW  - Overview
KW  - Software engineering automation
KW  - Software engineering tools
KW  - Webassembly
KW  - Knowledge graph
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Kong, Y.
AU  - Guo, J.
AU  - Ren, L.
AU  - Kang, G.
AU  - Wang, Y.
AU  - Lu, J.
TI  - DADN: A Dynamic Anomaly Detection Network for Multivariate Time Series Data of the Industrial Internet of Things
PY  - 2025
T2  - IEEE Transactions on Industrial Informatics
C7  - 0b00006493f2c2d9
DO  - 10.1109/TII.2025.3563540
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006636275&doi=10.1109%2fTII.2025.3563540&partnerID=40&md5=8e661a0de3232f85f17a3f99fec07a72
AB  - Industrial Internet of Things (IIoT) faces significant security challenges such as data privacy and vulnerabilities. Unsupervised anomaly detection aims to identify abnormal patterns by monitoring multivariate time series data of IIoT without anomaly annotation. Previous deep-learning-based methods have high-computation cost, which hinders their deployment in edge devices. In this article, we propose a dynamic anomaly detection network (DADN), which introduces a dynamic anomaly detection mechanism to enable efficient inference. Specifically, a bilateral early-exit mechanism is designed so that each sample can dynamically exit at a certain layer during the forward process to support the anomaly judgement, and the layer where sample exits is adaptively determined at the inference stage. Experimental results show that DADN significantly reduces computational costs and enhances F1 scores in industrial anomaly-detection benchmarks, as shown by a 58.22% decrease in GFLOPS on the SWAT dataset, outperforming previous representative method (anomaly transformer). © 2005-2012 IEEE.
KW  - Anomaly detection
KW  - data-driven industrial intelligence
KW  - dynamic neural network
KW  - industrial cyber physical system (CPS) security
KW  - industrial Internet of Things (IIoT)
KW  - Deep neural networks
KW  - Sensitive data
KW  - Anomaly detection
KW  - Cyber-physical system securities
KW  - Data driven
KW  - Data-driven industrial intelligence
KW  - Detection networks
KW  - Dynamic anomaly detections
KW  - Dynamic neural networks
KW  - Industrial cybe physical system  security
KW  - Industrial internet of thing
KW  - Multivariate time series
KW  - Anomaly detection
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Nawaz, U.
AU  - Anees-ur-Rahaman, M.
AU  - Saeed, Z.
TI  - A review of neuro-symbolic AI integrating reasoning and learning for advanced cognitive systems
PY  - 2025
T2  - Intelligent Systems with Applications
VL  - 26
C7  - 200541
DO  - 10.1016/j.iswa.2025.200541
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007106617&doi=10.1016%2fj.iswa.2025.200541&partnerID=40&md5=54c2f86fc3fd188a36f5104c1b42a7c6
AB  - Neuro-symbolic AI represents the convergence of two principal paradigms in artificial intelligence: neural networks, which are efficient in data-driven learning, and symbolic reasoning, which offers explainability and logical inference. This hybrid methodology combines the adaptability of neural networks with symbolic AI's interpretability and formal reasoning abilities, which provide a practical framework for advanced cognitive systems. This paper analyzes the present condition of neuro-symbolic AI, emphasizing essential techniques that combine reasoning and learning. We explore models such as Logic Tensor Networks, Differentiable Logic Programs, and Neural Theorem Provers. The study analyzes their impact on the advancement of cognitive systems in natural language processing, robotics, and decision-making. The paper examines the challenges faced by neuro-symbolic AI, such as scalability, integration with multimodal data, and maintaining interpretability without compromising efficiency. By evaluating the strengths and weaknesses of many methodologies, we comprehensively understand the field's development and its potential to revolutionize intelligent systems. In addition, we identify emerging research areas, including the incorporation of ethical frameworks and the development of adaptive dynamic neuro-symbolic systems that respond in real-time. This review aims to guide future research by providing insights into the potential of neuro-symbolic AI to influence the development of the next generation of intelligent, explainable, and adaptive systems. © 2025
KW  - Condition
KW  - Data driven
KW  - Formal reasoning
KW  - Hybrid methodologies
KW  - Interpretability
KW  - Logical inference
KW  - Neural-networks
KW  - Paper analysis
KW  - Reasoning ability
KW  - Symbolic reasoning
KW  - Natural language processing systems
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Jain, A.
AU  - Kondapally, A.R.
AU  - Yamada, K.
AU  - Yanaka, H.
TI  - Neuro-Symbolic Reasoning for Multimodal Referring Expression Comprehension in HMI Systems
PY  - 2024
T2  - New Generation Computing
VL  - 42
IS  - 4
SP  - 579
EP  - 598
DO  - 10.1007/s00354-024-00243-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185111766&doi=10.1007%2fs00354-024-00243-8&partnerID=40&md5=11aea793523eb72cd189fd89f01fa90f
AB  - Conventional Human–Machine Interaction (HMI) interfaces have predominantly relied on GUI and voice commands. However, natural human communication also consists of non-verbal communication, including hand gestures like pointing. Thus, recent works in HMI systems have tried to incorporate pointing gestures as an input, making significant progress in recognizing and integrating them with voice commands. However, existing approaches often treat these input modalities independently, limiting their capacity to handle complex multimodal instructions requiring intricate reasoning of language and gestures. On the other hand, multimodal tasks requiring complex reasoning are being challenged in the language and vision domain, but these typically do not include gestures like pointing. To bridge this gap, we explore one of the challenging multimodal tasks, called Referring Expression Comprehension (REC), within multimodal HMI systems incorporating pointing gestures. We present a virtual setup in which a robot shares an environment with a user and is tasked with identifying objects based on the user’s language and gestural instructions. Furthermore, to address this challenge, we propose a hybrid neuro-symbolic model combining deep learning’s versatility with symbolic reasoning’s interpretability. Our contributions include a challenging multimodal REC dataset for HMI systems, an interpretable neuro-symbolic model, and an assessment of its ability to generalize the reasoning to unseen environments, complemented by an in-depth qualitative analysis of the model’s inner workings. © The Author(s) 2024.
KW  - Human–machine interaction
KW  - Multimodal learning
KW  - Neuro-symbolic reasoning
KW  - Referring expression comprehension
KW  - Human machine interaction
KW  - Human machine interaction system
KW  - Multi-modal
KW  - Multi-modal learning
KW  - Neuro-symbolic reasoning
KW  - Pointing gestures
KW  - Referring expression comprehension
KW  - Referring expressions
KW  - Symbolic reasoning
KW  - Voice command
KW  - Deep learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Ramo, I.F.F.
AU  - Gianini, G.
AU  - Damiani, E.
TI  - Neuro-Symbolic AI for Sensor-based Human Performance Prediction: System Architectures and Applications
PY  - 2022
T2  - Proceedings of the 32nd European Safety and Reliability Conference, ESREL 2022 - Understanding and Managing Risk and Reliability for a Sustainable Future
SP  - 3210
EP  - 3217
DO  - 10.3850/978-981-18-5183-4_S33-01-310-cd
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192242836&doi=10.3850%2f978-981-18-5183-4_S33-01-310-cd&partnerID=40&md5=43a01ed2e2254f0c5264fdc316791be4
AB  - Recently, due to the rapid development of deep learning methods, there has been a growing interest in Neurosymbolic Artificial Intelligence, which takes advantage of both explicit symbolic knowledge and statistical subsymbolic neural knowledge representations. In sensor-based human performance prediction (HPP) for safety-critical applications, where maintaining optimal human and system performance is a major concern, neuro-symbolic AI systems can improve sensor-based HPP tasks in complex working settings. In this paper, we focus on the advantages of hybrid neuro-symbolic AI systems, present the outstanding challenges and propose possible solutions for HPP in the safety-critical application domain. © 2022 ESREL2022 Organizers. Published by Research Publishing, Singapore.
KW  - Artificial Intelligence
KW  - Artificial Neural Networks
KW  - Explicit Symbolic Knowledge
KW  - Human Performance Prediction
KW  - Neuro-Symbolic Systems
KW  - Safety-Critical Applications
KW  - Deep learning
KW  - Prediction models
KW  - AI systems
KW  - Explicit symbolic knowledge
KW  - Human performance
KW  - Human performance prediction
KW  - Neural-networks
KW  - Neuro-symbolic system
KW  - Performance prediction
KW  - Prediction systems
KW  - Safety critical applications
KW  - Symbolic knowledge
KW  - Knowledge representation
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Xing, P.
AU  - Lu, S.
AU  - Yu, H.
TI  - Federated Neuro-Symbolic Learning
PY  - 2024
T2  - Proceedings of Machine Learning Research
VL  - 235
SP  - 54635
EP  - 54655
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203847998&partnerID=40&md5=8c8dc6c4237a2901f7dc0f79f528ad19
AB  - Neuro-symbolic learning (NSL) models complex symbolic rule patterns into latent variable distributions by neural networks, which reduces rule search space and generates unseen rules to improve downstream task performance. Centralized NSL learning involves directly acquiring data from downstream tasks, which is not feasible for federated learning (FL). To address this limitation, we shift the focus from such a one-to-one interactive neuro-symbolic paradigm to one-to-many Federated Neuro-Symbolic Learning framework (FedNSL) with latent variables as the FL communication medium. Built on the basis of our novel reformulation of the NSL theory, FedNSL is capable of identifying and addressing rule distribution heterogeneity through a simple and effective Kullback-Leibler (KL) divergence constraint on rule distribution applicable under the FL setting. It further theoretically adjusts variational expectation maximization (V-EM) to reduce the rule search space across domains. This is the first incorporation of distribution-coupled bilevel optimization into FL. Extensive experiments based on both synthetic and real-world data demonstrate significant advantages of FedNSL compared to five state-of-the-art methods. It outperforms the best baseline by 17% and 29% in terms of unbalanced average training accuracy and unseen average testing accuracy, respectively. Copyright 2024 by the author(s)
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Neural network models
KW  - Down-stream
KW  - Latent variable
KW  - Learning frameworks
KW  - Learning models
KW  - Model complexes
KW  - Neural-networks
KW  - Rule search
KW  - Search spaces
KW  - Symbolic learning
KW  - Variable distribution
KW  - Federated learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Onchis, D.M.
AU  - Gillich, G.-R.
AU  - Hogea, E.
AU  - Tufisi, C.
TI  - Neuro-symbolic model for cantilever beams damage detection
PY  - 2023
T2  - Computers in Industry
VL  - 151
C7  - 103991
DO  - 10.1016/j.compind.2023.103991
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165532620&doi=10.1016%2fj.compind.2023.103991&partnerID=40&md5=c551aab50f8ce46689b29e5500a70cee
AB  - In the last decade, damage detection approaches swiftly changed from advanced signal processing methods to machine learning and especially deep learning models, to accurately and non-intrusively estimate the state of the beam structures. But as the deep learning models reached their peak performances, also their limitations in applicability and vulnerabilities were observed. One of the most important reason for the lack of trustworthiness in operational conditions is the absence of intrinsic explainability of the deep learning system, due to the encoding of the knowledge in tensor values and without the inclusion of logical constraints. In this paper, we propose a neuro-symbolic model for the detection of damages in cantilever beams based on a novel cognitive architecture in which we join the processing power of convolutional networks with the interactive control offered by queries realized through the inclusion of real logic directly into the model. The hybrid discriminative model is introduced under the name Logic Convolutional Neural Regressor and it is tested on a dataset of values of the relative natural frequency shifts of cantilever beams derived from an original mathematical relation. While the obtained results preserve all the predictive capabilities of deep learning models, the usage of three distances as predicates for satisfiability, makes the system more trustworthy and scalable for practical applications. Extensive numerical and laboratory experiments were performed, and they all demonstrated the superiority of the hybrid approach, which can open a new path for solving the damage detection problem. © 2023 Elsevier B.V.
KW  - Cantilever beams
KW  - Damage detection
KW  - Deep learning
KW  - Neuro-symbolic model
KW  - Real logic
KW  - Relative frequency shifts
KW  - Cantilever beams
KW  - Computer circuits
KW  - Convolution
KW  - Deep learning
KW  - Learning systems
KW  - Nanocantilevers
KW  - Signal processing
KW  - Beam damage
KW  - Deep learning
KW  - Detection approach
KW  - Frequency shift
KW  - Learning models
KW  - Neuro-symbolic model
KW  - Real logic
KW  - Relative frequencies
KW  - Relative frequency shift
KW  - Symbolic modeling
KW  - Damage detection
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - CONF
AU  - Stol, M.C.
AU  - Mileo, A.
TI  - IID Relaxation by Logical Expressivity: A Research Agenda for Fitting Logics to Neurosymbolic Requirements
PY  - 2024
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14980 LNAI
SP  - 3
EP  - 13
DO  - 10.1007/978-3-031-71170-1_1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204923526&doi=10.1007%2f978-3-031-71170-1_1&partnerID=40&md5=f411370d2544cd4f442fa0936ea93acf
AB  - Neurosymbolic background knowledge and the expressivity required of its logic can break Machine Learning assumptions about data Independence and Identical Distribution. In this position paper we propose to analyze IID relaxation in a hierarchy of logics that fit different use case requirements. We discuss the benefits of exploiting known data dependencies and distribution constraints for Neurosymbolic use cases and argue that the expressivity required for this knowledge has implications for the design of underlying ML routines. This opens a new research agenda with general questions about Neurosymbolic background knowledge and the expressivity required of its logic. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - Expressivity
KW  - Logic Fragments
KW  - Neurosymbolic
KW  - Non-IID
KW  - Background knowledge
KW  - Data dependencies
KW  - Data independence
KW  - Expressivity
KW  - Logic fragment
KW  - Machine-learning
KW  - Neurosymbolic
KW  - Non-IID
KW  - Position papers
KW  - Research agenda
KW  - Computer circuits
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Hagos, D.H.
AU  - Rawat, D.B.
TI  - Neuro-Symbolic AI for Military Applications
PY  - 2024
T2  - IEEE Transactions on Artificial Intelligence
VL  - 5
IS  - 12
SP  - 6012
EP  - 6026
DO  - 10.1109/TAI.2024.3444746
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201789493&doi=10.1109%2fTAI.2024.3444746&partnerID=40&md5=51d61385ce8c15c0339e4a0114610094
AB  - Artificial intelligence (AI) plays a significant role in enhancing the capabilities of defense systems, revolutionizing strategic decision-making, and shaping the future landscape of military operations. Neuro-Symbolic AI is an emerging approach that leverages and augments the strengths of neural networks and symbolic reasoning. These systems have the potential to be more impactful and flexible than traditional AI systems, making them well-suited for military applications. This article comprehensively explores the diverse dimensions and capabilities of Neuro-Symbolic AI, aiming to shed light on its potential applications in military contexts. We investigate its capacity to improve decision-making, automate complex intelligence analysis, and strengthen autonomous systems. We further explore its potential to solve complex tasks in various domains, in addition to its applications in military contexts. Through this exploration, we address ethical, strategic, and technical considerations crucial to the development and deployment of Neuro-Symbolic AI in military and civilian applications. Contributing to the growing body of research, this study represents a comprehensive exploration of the extensive possibilities offered by Neuro-Symbolic AI. © 2024 IEEE.
KW  - Artificial intelligence (AI)
KW  - cybersecurity
KW  - deep learning (DL)
KW  - explainable AI (XAI)
KW  - machine learning (ML)
KW  - military applications
KW  - Neuro-Symbolic
KW  - symbolic reasoning
KW  - Adversarial machine learning
KW  - Deep neural networks
KW  - Job analysis
KW  - Biological neural networks
KW  - Cognition
KW  - Cyber security
KW  - Decisions makings
KW  - Deep learning
KW  - Explainable artificial intelligence
KW  - Machine-learning
KW  - Neuro-symbolic
KW  - Symbol
KW  - Symbolic reasoning
KW  - Task analysis
KW  - Neurons
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Maree, M.
TI  - Quantifying Relational Exploration in Cultural Heritage Knowledge Graphs with LLMs: A Neuro-Symbolic Approach for Enhanced Knowledge Discovery
PY  - 2025
T2  - Data
VL  - 10
IS  - 4
C7  - 52
DO  - 10.3390/data10040052
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003465024&doi=10.3390%2fdata10040052&partnerID=40&md5=dc224f3c2290a783a937ad23d6367a92
AB  - This paper introduces a neuro-symbolic approach for relational exploration in cultural heritage knowledge graphs, exploiting Large Language Models (LLMs) for explanation generation and a mathematically grounded model to quantify the interestingness of relationships. We demonstrate the importance of the proposed interestingness measure through a quantitative analysis, highlighting its significant impact on system performance, particularly in terms of precision, recall, and F1-score. Utilizing the Wikidata Cultural Heritage Linked Open Data (WCH-LOD) dataset, our approach achieves a precision of 0.70, recall of 0.68, and an F1-score of 0.69, outperforming both graph-based (precision: 0.28, recall: 0.25, F1-score: 0.26) and knowledge-based (precision: 0.45, recall: 0.42, F1-score: 0.43) baselines. Furthermore, the proposed LLM-powered explanations exhibit better quality, as evidenced by higher BLEU (0.52), ROUGE-L (0.58), and METEOR (0.63) scores compared to baseline approaches. We further demonstrate a strong correlation (0.65) between the interestingness measure and the quality of generated explanations, validating its ability to guide the system towards more relevant discoveries. This system offers more effective exploration by achieving more diverse and human-interpretable relationship explanations compared to purely knowledge-based and graph-based methods, contributing to the knowledge-based systems field by providing a personalized and adaptable relational exploration framework. © 2025 by the author.
KW  - contextual relevance
KW  - cultural heritage
KW  - explainable AI (XAI)
KW  - interestingness score
KW  - knowledge graphs
KW  - large language models (LLMs)
KW  - neuro-symbolic AI
KW  - personalized explanation
KW  - Contextual relevance
KW  - Cultural heritages
KW  - Explainable AI (XAI)
KW  - Interestingness
KW  - Interestingness score
KW  - Knowledge graphs
KW  - Language model
KW  - Large language model
KW  - Neuro-symbolic AI
KW  - Personalized explanation
KW  - Knowledge graph
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Jha, S.
AU  - Jha, S.K.
AU  - Velasquez, A.
TI  - Neuro-symbolic Generative AI Assistant for System Design
PY  - 2024
T2  - Proceedings - 2024 22nd ACM-IEEE International Symposium on Formal Methods and Models for System Design, MEMOCODE 2024
SP  - 75
EP  - 76
DO  - 10.1109/MEMOCODE63347.2024.00023
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211939497&doi=10.1109%2fMEMOCODE63347.2024.00023&partnerID=40&md5=cc37180dc588d892c645a59bcc1eb549
AB  - The design of complex cyber-physical systems involves balancing multiple, often conflicting performance objectives. In practice, some design requirements remain implicit, embedded in the intuition and expertise of seasoned designers who have worked on similar systems for years. These designers rely on their experience to explore a limited set of promising design candidates, evaluating or simulating them with detailed but computationally slow scientific models. The typical goal is to produce a diverse array of high-performing configurations that offer flexibility in trade-offs and avoid premature commitment to a specific design. In this invited talk, we describe an AI assistant that leverages neuro-symbolic machine learning to automate parts of the system design process. Our approach extends oracle-guided inductive synthesis by integrating a hierarchy of oracles, ranging from slow, detailed scientific models to faster but lower-fidelity deep neural network surrogates and symbolic rules. This approach accelerates design iterations, especially during early design phases. We employ deep generative models in the form of fine-Tuned large language models to learn the valid design space, followed by joint exploration and optimization across this learned manifold. This allows the generation of a diverse set of optimal designs based on specified performance objectives. © 2024 IEEE.
KW  - design space exploration
KW  - formal synthesis
KW  - generative ai
KW  - surrogate models
KW  - system design
KW  - Deep neural networks
KW  - Integrated circuit design
KW  - Learning systems
KW  - Optimal systems
KW  - Space applications
KW  - Cybe-physical systems
KW  - Cyber-physical systems
KW  - Design space exploration
KW  - Formal synthesis
KW  - Generative ai
KW  - Invited talk
KW  - Performance objective
KW  - Scientific modeling
KW  - Surrogate modeling
KW  - Trade off
KW  - Space research
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Lin, Y.
AU  - Lin, Y.
TI  - NSEA: A Resilient ERP Framework Integrating Quantum-Safe Cryptography and Neuro-Symbolic Reasoning for Industrial Adaptability
PY  - 2025
T2  - IEEE Access
VL  - 13
SP  - 77686
EP  - 77695
DO  - 10.1109/ACCESS.2025.3562739
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003441423&doi=10.1109%2fACCESS.2025.3562739&partnerID=40&md5=3029aa165143b13b04bfb6e7cb01929d
AB  - This study proposes a neurosymbolic ERP architecture (NSEA) incorporating post-quantum cryptographic protocols to enable real-time cybersecurity and adaptive operational optimization. NSEA integrates CRYSTALS-Kyber lattice-based post-quantum cryptography with temporal graph neural networks and symbolic rule engines to enhance cybersecurity, decision automation, and legacy system compatibility. On industrial IoT (IIoT) edge devices, Kyber-512 achieves sub- 5 μs encryption latency and mitigates 72% of phishing attacks through dynamic response mechanisms. In demand forecasting tasks, the hybrid reasoning model reduced mean absolute percentage error (MAPE) to 6.8% and resolved 89% of inventory stockout alerts within 15 minutes. Field validation in air conditioning and automotive supply chains demonstrated a 63.4% improvement in disruption recovery time and a 62.9% reduction in logistics cost overruns, compared to baseline systems. A resilience metric based on Kolmogorov-Sinai entropy (DRE = 0.81±0.05 ) quantifies the system’s robustness under simultaneous cyber and operational stress. Backward compatibility testing showed 92% schema alignment with legacy ERP modules through API translation, enabling a low-risk migration path. NSEA offers a unified and future-proof ERP solution that integrates security, intelligence, and interoperability in complex industrial environments. © 2013 IEEE.
KW  - dynamic resilience
KW  - Enterprise resource planning systems
KW  - Industrial Internet of Things
KW  - neuro-symbolic artificial intelligence
KW  - quantum cryptography
KW  - secure ERP architectures
KW  - Competition
KW  - Critical path analysis
KW  - Enterprise resource planning
KW  - Resource valuation
KW  - Supply chains
KW  - Trigeneration plant
KW  - Dynamic resilience
KW  - Enterprise resource planning systems
KW  - Enterprise resources planning
KW  - ERP architecture
KW  - Industrial internet of thing
KW  - Neuro-symbolic artificial intelligence
KW  - Planning framework
KW  - Secure enterprise
KW  - Secure enterprise resource planning architecture
KW  - Symbolic reasoning
KW  - Cost reduction
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Waltersdorfer, L.
AU  - Breit, A.
AU  - Ekaputra, F.J.
AU  - Sabou, M.
AU  - Ekelhart, A.
AU  - Iana, A.
AU  - Paulheim, H.
AU  - Portisch, J.
AU  - Revenko, A.
AU  - ten Teije, A.
AU  - van Harmelen, F.
TI  - Semantic web machine learning systems: An analysis of system patterns
PY  - 2023
T2  - Compendium of Neurosymbolic Artificial Intelligence
SP  - 77
EP  - 99
DO  - 10.3233/FAIA230136
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172821357&doi=10.3233%2fFAIA230136&partnerID=40&md5=4ef52da9b231fc456991488e8911a7b3
AB  - In line with the general trend in artificial intelligence research to create intelligent systems that combine learning and symbolic techniques (a.k.a. neuro-symbolic systems), a new sub-area has emerged that focuses on combining machine learning (ML) components with techniques developed by the SemanticWeb (SW) community - SemanticWeb Machine Learning (SWeML for short). Due to the rapid growth of this area and its impact on several communities in the last two decades, there is a need to better understand the space of these SWeML Systems, their characteristics, and trends. Of particular interest are the emerging variations of processing patterns used in these systems in terms of their inputs/outputs and the order of the processing units. While several such neuro-symbolic system patterns were identified previously from a large number of papers, there is currently no insight into their adoption in the field, e.g., about the completeness of the introduced system patterns, or about their usage frequency. To fill that gap, we performed a systematic study and analyzed nearly 500 papers published in the last decade in this area, where we focused on evaluating the type and frequency of such system patterns. Overall we discovered 41 different system patterns, which we categorized into six pattern types. In this chapter we detail these pattern types, exemplify their use in concrete papers and discuss their characteristics in terms of their semantic and machine learning modules. © 2023 The authors and IOS Press. All rights reserved.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Saha, S.S.
AU  - Sandha, S.S.
AU  - Aggarwal, M.
AU  - Wang, B.
AU  - Han, L.
AU  - de Gortari Briseno, J.
AU  - Srivastava, M.
TI  - TinyNS: Platform-aware Neurosymbolic Auto Tiny Machine Learning
PY  - 2024
T2  - ACM Transactions on Embedded Computing Systems
VL  - 23
IS  - 3
C7  - 43
DO  - 10.1145/3603171
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194167573&doi=10.1145%2f3603171&partnerID=40&md5=915332eac8785aff4c74ef3e93fd1b9b
AB  - Machine learning at the extreme edge has enabled a plethora of intelligent, time-critical, and remote applications. However, deploying interpretable artificial intelligence systems that can perform high-level symbolic reasoning and satisfy the underlying system rules and physics within the tight platform resource constraints is challenging. In this article, we introduce TinyNS, the first platform-aware neurosymbolic architecture search framework for joint optimization of symbolic and neural operators. TinyNS provides recipes and parsers to automatically write microcontroller code for five types of neurosymbolic models, combining the context awareness and integrity of symbolic techniques with the robustness and performance of machine learning models. TinyNS uses a fast, gradient-free, black-box Bayesian optimizer over discontinuous, conditional, numeric, and categorical search spaces to find the best synergy of symbolic code and neural networks within the hardware resource budget. To guarantee deployability, TinyNS talks to the target hardware during the optimization process. We showcase the utility of TinyNS by deploying microcontroller-class neurosymbolic models through several case studies. In all use cases, TinyNS outperforms purely neural or purely symbolic approaches while guaranteeing execution on real hardware. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
KW  - AutoML
KW  - bayesian
KW  - neural architecture search
KW  - Neurosymbolic
KW  - platform-aware
KW  - TinyML
KW  - Bayesian networks
KW  - Budget control
KW  - Machine learning
KW  - Microcontrollers
KW  - Network architecture
KW  - Automl
KW  - Bayesian
KW  - Machine-learning
KW  - Neural architecture search
KW  - Neural architectures
KW  - Neurosymbolic
KW  - Platform-aware
KW  - Remote applications
KW  - Time-critical applications
KW  - Tinyml
KW  - Codes (symbols)
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Manigrasso, F.
AU  - Morra, L.
AU  - Lamberti, F.
TI  - Fuzzy Logic Visual Network (FLVN): A Neuro-Symbolic Approach for Visual Features Matching
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14234 LNCS
SP  - 456
EP  - 467
DO  - 10.1007/978-3-031-43153-1_38
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173579175&doi=10.1007%2f978-3-031-43153-1_38&partnerID=40&md5=5d18750d64aacede50414d575eca6cc1
AB  - Neuro-symbolic integration aims at harnessing the power of symbolic knowledge representation combined with the learning capabilities of deep neural networks. In particular, Logic Tensor Networks (LTNs) allow to incorporate background knowledge in the form of logical axioms by grounding a first order logic language as differentiable operations between real tensors. Yet, few studies have investigated the potential benefits of this approach to improve zero-shot learning (ZSL) classification. In this study, we present the Fuzzy Logic Visual Network (FLVN) that formulates the task of learning a visual-semantic embedding space within a neuro-symbolic LTN framework. FLVN incorporates prior knowledge in the form of class hierarchies (classes and macro-classes) along with robust high-level inductive biases. The latter allow, for instance, to handle exceptions in class-level attributes, and to enforce similarity between images of the same class, preventing premature overfitting to seen classes and improving overall performance. FLVN reaches state of the art performance on the Generalized ZSL (GZSL) benchmarks AWA2 and CUB, improving by 1.3% and 3%, respectively. Overall, it achieves competitive performance to recent ZSL methods with less computational overhead. FLVN is available at https://gitlab.com/grains2/flvn. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.
KW  - Logic Tensor Networks
KW  - NeuroSymbolic AI
KW  - Zero shot learning
KW  - Benchmarking
KW  - Computer circuits
KW  - Deep neural networks
KW  - Image enhancement
KW  - Knowledge representation
KW  - Semantics
KW  - Tensors
KW  - Zero-shot learning
KW  - Background knowledge
KW  - Fuzzy-Logic
KW  - Knowledge-representation
KW  - Learning capabilities
KW  - Logic tensor network
KW  - Neurosymbolic AI
KW  - Power
KW  - Symbolic integration
KW  - Symbolic knowledge
KW  - Visual feature matching
KW  - Fuzzy logic
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Bellodi, E.
AU  - Bertozzi, D.
AU  - Bizzarri, A.
AU  - Favalli, M.
AU  - Fraccaroli, M.
AU  - Zese, R.
TI  - Efficient Resource-Aware Neural Architecture Search with a Neuro-Symbolic Approach
PY  - 2023
T2  - Proceedings - 2023 16th IEEE International Symposium on Embedded Multicore/Many-Core Systems-on-Chip, MCSoC 2023
SP  - 171
EP  - 178
DO  - 10.1109/MCSoC60832.2023.00034
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184663557&doi=10.1109%2fMCSoC60832.2023.00034&partnerID=40&md5=b40905afa75343f0399a5dce73aff3d0
AB  - Hardware-aware Neural Architectural Search (NAS) is gaining momentum to enable the deployment of deep learning on edge devices with limited computing capabilities. Incorporating device-related objectives such as affordable floating point operations, latency, power, memory usage, etc. into the optimization process makes searching for the most efficient neural architecture more complicated, since both model accuracy and hardware cost should guide the search. The main concern with most state-of-the-art hardware-aware NAS strategies is that they propose for evaluation also trivially infeasible network models for the capabilities of the hardware platform at hand. Moreover, previously generated models are frequently not exploited to intelligently generate new ones, leading to prohibitive computational costs for practical relevance. This paper aims to boost the computational efficiency of hardware-aware NAS by means of a neuro-symbolic framework revolving around a Probabilistic Inductive Logic Programming module to define and exploit a set of symbolic rules. This component learns and refines the probabilities associated with the rules, allowing the framework to adapt and improve over time, thus quickly narrowing down the search space toward the most promising neural architectures. © 2023 IEEE.
KW  - architecture search
KW  - neural network hardware accelerators
KW  - neural networks
KW  - probabilistic logic programming
KW  - Computer circuits
KW  - Computing power
KW  - Deep learning
KW  - Digital arithmetic
KW  - Inductive logic programming (ILP)
KW  - Network architecture
KW  - Neural networks
KW  - Probabilistic logics
KW  - Architecture search
KW  - Computing capability
KW  - Gaining momentum
KW  - Hardware accelerators
KW  - Neural architectures
KW  - Neural network hardware
KW  - Neural network hardware accelerator
KW  - Neural-networks
KW  - Probabilistic logic programming
KW  - Resource aware
KW  - Computational efficiency
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Dineshkumar, P.
AU  - Geetha, K.
AU  - Rajan, C.
TI  - Proactive Resilient Adaptive Sensor Node Management with Neuro-Symbolic Systems for Optimized Coverage Efficiency in the Mission-Critical Applications
PY  - 2025
T2  - ECS Journal of Solid State Science and Technology
VL  - 14
IS  - 1
C7  - 017008
DO  - 10.1149/2162-8777/ada999
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218944172&doi=10.1149%2f2162-8777%2fada999&partnerID=40&md5=493d2c877c99c27742cc7f43036998f4
AB  - Wireless sensor networks (WSNs) play a critical role in applications such as wildlife monitoring, disaster recovery, and precision agriculture, where continuous coverage and longevity are paramount amidst dynamic environmental challenges. To address these demands, the cellular adaptive energy forecasting and coverage optimization (CAEFCO) framework integrates localized neuro-symbolic energy forecasting (LNS-EF), a novel concept that combines symbolic reasoning with neural network learning directly on sensor nodes. LNS-EF enables nodes to not only predict energy depletion based on past consumption patterns and environmental factors but also incorporate rule-based contextual reasoning for enhanced decision-making. Alongside this, CAEFCO employs an anomaly detection module that identifies disruptions, such as sensor damage or environmental interference, allowing real-time task redistribution. This dual approach ensures seamless task reallocation while extending network lifetime. CAEFCO’s proactive methodology demonstrates a 97% reduction in data loss and an 85% improvement in network longevity, offering a breakthrough in the resilience and sustainability of WSNs in mission-critical and harsh environments. © 2025 The Electrochemical Society (“ECS”). Published on behalf of ECS by IOP Publishing Limited. All rights, including for text and data mining, AI training, and similar technologies, are reserved.
KW  - forecasting
KW  - network longevity
KW  - neural network
KW  - optimization
KW  - symbolic reasoning
KW  - Cellular neural networks
KW  - Cellulars
KW  - Coverage optimizations
KW  - Energy forecasting
KW  - Localised
KW  - Network longevity
KW  - Neural-networks
KW  - Optimisations
KW  - Sensors network
KW  - Symbolic reasoning
KW  - Wireless sensor
KW  - Sensor nodes
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Pei, J.
AU  - Li, J.
AU  - Song, Z.
AU  - Dabel, M.M.A.
AU  - Alenazi, M.J.F.
AU  - Zhang, S.
AU  - Bashir, A.K.
TI  - Neuro-VAE-Symbolic Dynamic Traffic Management
PY  - 2025
T2  - IEEE Transactions on Intelligent Transportation Systems
DO  - 10.1109/TITS.2025.3571210
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007297822&doi=10.1109%2fTITS.2025.3571210&partnerID=40&md5=219f5601d75f1ef76ff207c2dbf189de
AB  - Modern traffic management must balance the ability to predict complex, non-stationary flow patterns with the strict enforcement of safety and legal constraints (e.g., minimum pedestrian intervals, maximum cycle lengths). While generative models such as Variational Autoencoders (VAEs) can effectively capture traffic dynamics, purely data-driven approaches often fail to respect domain-specific rules. We propose a Neuro-VAE-Symbolic framework that combines the flexibility of VAE-based generation with the rule-enforcing capability of symbolic reasoning. By projecting raw neural outputs onto a feasible action space defined by traffic regulations, our method ensures both adaptability to dynamic demand and strict constraint compliance. Experiments on benchmark datasets show that our method reduces average waiting time by up to 15%, cuts queue lengths by 10–20%, and increases throughput by 5–8%, all while maintaining near-zero rule violations. These results demonstrate that neuro-symbolic integration enables high-fidelity traffic scenario generation alongside reliable, regulation-abiding decision-making, offering a robust solution for dynamic urban traffic control. © 2000-2011 IEEE.
KW  - Dynamic traffic management
KW  - neuro-symbolic AI
KW  - VAE
KW  - Crime
KW  - Information management
KW  - Risk perception
KW  - Variational techniques
KW  - Auto encoders
KW  - Cycle length
KW  - Dynamic traffic management
KW  - Legal constraint
KW  - Neuro-symbolic AI
KW  - Non-stationary flows
KW  - Safety constraint
KW  - Symbolic Dynamics
KW  - Traffic management
KW  - Variational autoencoder
KW  - Highway administration
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Kalutharage, C.S.
AU  - Liu, X.
AU  - Chrysoulas, C.
AU  - Bamgboye, O.
TI  - Neurosymbolic Learning in the XAI Framework for Enhanced Cyberattack Detection with Expert Knowledge Integration
PY  - 2024
T2  - IFIP Advances in Information and Communication Technology
VL  - 710
SP  - 236
EP  - 249
DO  - 10.1007/978-3-031-65175-5_17
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200739116&doi=10.1007%2f978-3-031-65175-5_17&partnerID=40&md5=2f0a172334e7f998521ed76e0a89fdf5
AB  - The perpetual evolution of cyberattacks, especially in the realm of Internet of Things (IoT) networks, necessitates advanced, adaptive, and intelligent defence mechanisms. The integration of expert knowledge can drastically enhance the efficacy of IoT network attack detection systems by enabling them to leverage domain-specific insights. This paper introduces a novel approach by applying Neurosymbolic Learning within the Explainable Artificial Intelligence (XAI) framework to enhance the detection of IoT network attacks while ensuring interpretability and transparency in decision-making. Neurosymbolic Learning synergizes symbolic AI, which excels in handling structured knowledge and providing explainability, with neural networks, known for their prowess in learning from data. Our proposed model utilizes expert knowledge in the form of rules and heuristics, integrating them into a learning mechanism to enhance its predictive capabilities and facilitate the incorporation of domain-specific insights into the learning process. The XAI framework is deployed to ensure that the predictive model is not a “black box”, providing clear, understandable explanations for its predictions, thereby augmenting trust and facilitating further enhancement by domain experts. Through rigorous evaluation against benchmark IoT network attack datasets, our model demonstrates superior detection performance compared to prevailing models, along with enhanced explainability and the successful incorporation of expert knowledge into the adaptive learning process. The proposed approach not only fortifies the security mechanisms against network attacks in IoT environments but also ensures that the knowledge discovery and decision-making processes are transparent, interpretable, and verifiable by human experts. © IFIP International Federation for Information Processing 2024.
KW  - Attack detection
KW  - Expert knowledge
KW  - Explainable artificial intelligence
KW  - Neurosymbolic learning
KW  - Artificial intelligence
KW  - Benchmarking
KW  - Computer crime
KW  - Decision making
KW  - Knowledge management
KW  - Learning systems
KW  - Attack detection
KW  - Cyber-attacks
KW  - Cyberattack detection
KW  - Defence mechanisms
KW  - Domain specific
KW  - Expert knowledge
KW  - Explainable artificial intelligence
KW  - Knowledge integration
KW  - Network attack
KW  - Neurosymbolic learning
KW  - Internet of things
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Shilov, N.
AU  - Ponomarev, A.
AU  - Smirnov, A.
TI  - THE ANALYSIS OF ONTOLOGY-BASED NEURO-SYMBOLIC INTELLIGENCE METHODS FOR COLLABORATIVE DECISION SUPPORT
ST  - АНАЛИЗ МЕТОДОВ ОНТОЛОГО-ОРИЕНТИРОВАННОГО НЕЙРО-СИМВОЛИЧЕСКОГО ИНТЕЛЛЕКТА ПРИ КОЛЛАБОРАТИВНОЙ ПОДДЕРЖКЕ ПРИНЯТИЯ РЕШЕНИЙ
PY  - 2023
T2  - Informatics and Automation
VL  - 22
IS  - 3
SP  - 576
EP  - 615
DO  - 10.15622/ia.22.3.4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164379135&doi=10.15622%2fia.22.3.4&partnerID=40&md5=896f594f554cc770746a83fc1b373cbe
AB  - The neural network approach to AI, which has become especially widespread in the last decade, has two significant limitations – training of a neural network, as a rule, requires a very large number of samples (not always available), and the resulting models often are not well interpretable, which can reduce their credibility. The use of symbols as the basis of collaborative processes, on the one hand, and the proliferation of neural network AI, on the other hand, necessitate the synthesis of neural network and symbolic paradigms in relation to the creation of collaborative decision support systems. The article presents the results of an analytical review in the field of ontology-oriented neuro-symbolic artificial intelligence with an emphasis on solving problems of knowledge exchange during collaborative decision support. Specifically, the review attempts to answer two questions: 1. how symbolic knowledge, represented as an ontology, can be used to improve AI agents operating on the basis of neural networks (knowledge transfer from a person to AI agents); 2. how symbolic knowledge, represented as an ontology, can be used to interpret decisions made by AI agents and explain these decisions (transfer of knowledge from an AI agent to a person). As a result of the review, recommendations were formulated on the choice of methods for introducing symbolic knowledge into neural network models, and promising areas of ontology-oriented methods for explaining neural networks were identified. © 2023 Messenger of Anesthesiology and Resuscitation. All rights reserved.
KW  - deep learning
KW  - domain knowledge
KW  - explainable AI
KW  - machine learning
KW  - neuro-symbolic AI
KW  - ontology
KW  - XAI
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Rawat, D.B.
TI  - Towards Neuro-Symbolic AI for Assured and Trustworthy Human-Autonomy Teaming
PY  - 2023
T2  - Proceedings - 2023 5th IEEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications, TPS-ISA 2023
SP  - 177
EP  - 179
DO  - 10.1109/TPS-ISA58951.2023.00030
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186499693&doi=10.1109%2fTPS-ISA58951.2023.00030&partnerID=40&md5=c9064595e43f9e9464f07b14706437a4
AB  - Despite the tremendous impact and potential of Artificial Intelligence (AI) for civilian and military applications, it has reached an impasse as learning and reasoning work well for certain applications and it generally suffers from a number of challenges such as hidden biases and causality. Next, 'symbolic' AI (not as efficient as 'sub-symbolic' AI), offers transparency, explainability, verifiability and trustworthiness. To address these limitations, neuro-symbolic AI has been emerged as a new AI field that combines efficiency of 'sub-symbolic' AI with the assurance and transparency of 'symbolic' AI. Furthermore, AI (that suffers from aforementioned challenges) will remain inadequate for operating independently in contested, unpredictable and complex multi-domain battlefield (MDB) environment for the foreseeable future and the AI enabled autonomous systems will require human in the loop to complete the mission in such a contested environment. Moreover, in order to successfully integrate AI enabled autonomous systems into military operations, military operators need to have assurance that these systems will perform as expected and in a safe manner. Most importantly, Human-Autonomy Teaming (HAT) for shared learning and understanding and joint reasoning is crucial to assist operations across military domains (space, air, land, maritime, and cyber) at combat speed with high assurance and trust. In this paper, we present a rough guide to key research challenges and perspectives of neuro symbolic AI for assured and trustworthy HAT.  © 2023 IEEE.
KW  - ABMS
KW  - Artificial Intelligence
KW  - Assured AI
KW  - HAT
KW  - Human Autonomy Teaming
KW  - Human Machine Teaming
KW  - Human-AI Teaming
KW  - MDB
KW  - MDO
KW  - Neuro Symbolic AI
KW  - Tactical autonomy
KW  - TEV/V
KW  - Trustworthy AI
KW  - Artificial intelligence
KW  - Military applications
KW  - Military operations
KW  - ABMS
KW  - Assured artificial intelligence
KW  - Human autonomy teaming
KW  - Human machine teaming
KW  - Human-artificial intelligence teaming
KW  - Human-autonomy teaming
KW  - Human-machine
KW  - MDO
KW  - Multi-domain battlefield
KW  - Multi-domains
KW  - Neuro symbolic artificial intelligence
KW  - Tactical autonomy
KW  - Tacticals
KW  - TEV/V
KW  - Trustworthy artificial intelligence
KW  - Transparency
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Smirnov, A.V.
AU  - Ponomarev, A.V.
AU  - Shilov, N.G.
AU  - Levashova, T.V.
TI  - Collaborative Decision Support Systems Based on Neuro-Symbolic Artificial Intelligence: Problems and Generalized Conceptual Model
PY  - 2023
T2  - Scientific and Technical Information Processing
VL  - 50
IS  - 6
SP  - 635
EP  - 645
DO  - 10.3103/S0147688223060151
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187195765&doi=10.3103%2fS0147688223060151&partnerID=40&md5=e507f2e22bd527c9b0caa370d65e3614
AB  - The development of artificial intelligence technologies and the growing complexity of decision-making when managing complex dynamic systems necessitate the joint work of humans and artificial intelligence, including as part of teams of heterogeneous participants (for example, experts and agents operating with artificial intelligence). The paper discusses the requirements for collaborative human-machine decision support systems and the problems that can arise during their creation. The methods of neuro-symbolic artificial intelligence can help resolve some of these problems. An analysis of modern results in the field of ontology-oriented neuro-symbolic artificial intelligence is carried out, primarily intended to explain neural network models using ontologies and symbolic knowledge to improve the efficiency of neural network models. A conceptual model of a collaborative human-machine decision support system based on ontology-oriented neuro-symbolic intelligence is proposed. © Allerton Press, Inc. 2023.
KW  - collaborative systems
KW  - decision support systems
KW  - neuro-symbolic intelligence
KW  - Artificial intelligence
KW  - Complex networks
KW  - Decision making
KW  - Ontology
KW  - Artificial intelligence technologies
KW  - Collaborative decisions
KW  - Collaborative systems
KW  - Conceptual model
KW  - Decisions makings
KW  - Human-machine
KW  - Machine decisions
KW  - Neural network model
KW  - Neuro-symbolic intelligence
KW  - Ontology's
KW  - Decision support systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CHAP
AU  - Liu, X.
AU  - Lu, Z.
AU  - Mou, L.
TI  - Weakly supervised reasoning by neuro-symbolic approaches
PY  - 2023
T2  - Compendium of Neurosymbolic Artificial Intelligence
SP  - 665
EP  - 692
DO  - 10.3233/FAIA230162
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172818692&doi=10.3233%2fFAIA230162&partnerID=40&md5=73b98be8d43f120e6f0e5e7e01e464fa
AB  - Deep learning has largely improved the performance of various natural language processing (NLP) tasks. However, most deep learning models are black-box machinery, and lack explicit interpretation. In this chapter, we will introduce our recent progress on neuro-symbolic approaches to NLP, which combines different schools of AI, namely, symbolism and connectionism. Generally, we will design a neural system with symbolic latent structures for an NLP task, and apply reinforcement learning or its relaxation to perform weakly supervised reasoning in the downstream task. Our framework has been successfully applied to various tasks, including table query reasoning, syntactic structure reasoning, information extraction reasoning, and rule reasoning. For each application, we will introduce the background, our approach, and experimental results. © 2023 The authors and IOS Press. All rights reserved.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - De Vito, G.
AU  - Palomba, F.
AU  - Ferrucci, F.
TI  - The role of Large Language Models in addressing IoT challenges: A systematic literature review
PY  - 2025
T2  - Future Generation Computer Systems
VL  - 171
C7  - 107829
DO  - 10.1016/j.future.2025.107829
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002636788&doi=10.1016%2fj.future.2025.107829&partnerID=40&md5=ecdd9e64054c6c300969c5cc1a7a2c09
AB  - The Internet of Things (IoT) has revolutionized various sectors by enabling devices to communicate and interact seamlessly. However, developing IoT applications has data management, security, and interoperability challenges. Large Language Models (LLMs) have shown promise in addressing these challenges due to their advanced language processing capabilities. This Systematic Literature Review assesses the role of LLMs in addressing IoT challenges, exploring the strategies, hardware, and software configurations used, and identifying directions for future research. We extensively searched databases like Scopus, IEEE Xplore, and ACM Digital Library, initially screening 1419 studies and identifying an additional 1167 through snowballing, ultimately focusing on 55 relevant papers. The findings reveal LLMs’ potential to address key IoT challenges such as security and scalability. However, they also highlight significant obstacles, including high computational demands and the complexities of training and tuning these models. Future research should aim to develop methods to reduce the computational requirements of LLMs, improve training datasets, simplify implementation processes, and explore the ethical and privacy implications of using LLMs in IoT applications. © 2025 Elsevier B.V.
KW  - Internet-of-Things
KW  - Large Language Models
KW  - Systematic literature reviews
KW  - Computational demands
KW  - Hardware and software
KW  - Hardware configurations
KW  - Language model
KW  - Language processing
KW  - Large language model
KW  - Model potential
KW  - Processing capability
KW  - Software configuration
KW  - Systematic literature review
KW  - Information management
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Zhang, C.
AU  - Zou, H.
AU  - Lasaulce, S.
AU  - Saad, W.
AU  - Kountouris, M.
AU  - Bennis, M.
TI  - Goal-Oriented Communications for the IoT and Application to Data Compression
PY  - 2022
T2  - IEEE Internet of Things Magazine
VL  - 5
IS  - 4
SP  - 58
EP  - 63
DO  - 10.1109/IOTM.001.2200177
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143704804&doi=10.1109%2fIOTM.001.2200177&partnerID=40&md5=ef4727294f997f2dddb43dd5e1512c0a
AB  - Internet of Things (IoT) devices will play an important role in emerging applications, since their sensing, actuation, processing, and wireless communication capabilities stimulate data collection, transmission and decision processes of smart applications. However, new challenges arise from the widespread popularity of IoT devices, including the need for processing more complicated data structures and high dimensional data/signals. The unprecedented volume, heterogeneity, and velocity of IoT data calls for a communication paradigm shift from a search for accuracy or fidelity to semantics extraction and goal accomplishment. In this paper, we provide a partial but insightful overview of recent research efforts in this newly formed area of goal-oriented (GO) and semantic communications, focusing on the problem of GO data compression for IoT applications. © 2018 IEEE.
KW  - Clustering algorithms
KW  - Data compression
KW  - Semantics
KW  - Data collection process
KW  - Data decision
KW  - Data signals
KW  - Data-transmission
KW  - Decision process
KW  - Emerging applications
KW  - Goal-oriented communication
KW  - High dimensional data
KW  - Smart applications
KW  - Wireless communication capabilities
KW  - Internet of things
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 23
ER  -

TY  - JOUR
AU  - Prentzas, J.
AU  - Hatzilygeroudis, I.
TI  - Neurules and connectionist expert systems: Unexplored neuro-symbolic reasoning aspects
PY  - 2021
T2  - Intelligent Decision Technologies
VL  - 15
IS  - 4
SP  - 761
EP  - 777
DO  - 10.3233/IDT-210211
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123921480&doi=10.3233%2fIDT-210211&partnerID=40&md5=ea39997cf85c921a084ec6d4900bb99b
AB  - Neuro-symbolic approaches combine neural and symbolic methods. This paper explores aspects regarding the reasoning mechanisms of two neuro-symbolic approaches, that is, neurules and connectionist expert systems. Both provide reasoning and explanation facilities. Neurules are a type of neuro-symbolic rules tightly integrating the neural and symbolic components, giving pre-eminence to the symbolic component. Connectionist expert systems give pre-eminence to the connectionist component. This paper explores reasoning aspects about neurules and connectionist expert systems that have not been previously addressed. As far as neurules are concerned, an aspect playing a role in conflict resolution (i.e., order of neurules) is explored. Experimental results show an improvement in reasoning efficiency. As far as connectionist expert systems are concerned, variations of the reasoning mechanism are explored. Experimental results are presented for them as well showing that one of the variations generally performs better than the others. © 2021 - IOS Press. All rights reserved.
KW  - Combinations of intelligent methods
KW  - explainable Artificial Intelligence
KW  - hybrid expert systems
KW  - hybrid intelligent systems
KW  - neuro-symbolic approaches
KW  - reasoning
KW  - Expert systems
KW  - Combination of intelligent method
KW  - Connectionist expert system
KW  - Explainable artificial intelligence
KW  - Hybrid expert system
KW  - Hybrid intelligent system
KW  - Intelligent method
KW  - Neuro-symbolic approach
KW  - Reasoning
KW  - Reasoning mechanism
KW  - Symbolic reasoning
KW  - Intelligent systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Junaid Khan, M.
AU  - Masood Siddiqui, A.
AU  - Saeed Khan, H.
AU  - Akram, F.
AU  - Jaleed Khan, M.
TI  - MuRelSGG: Multimodal Relationship Prediction for Neurosymbolic Scene Graph Generation
PY  - 2025
T2  - IEEE Access
VL  - 13
SP  - 47042
EP  - 47054
DO  - 10.1109/ACCESS.2025.3551267
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001076017&doi=10.1109%2fACCESS.2025.3551267&partnerID=40&md5=6bdcba3b91b820f659e351a27bfa5969
AB  - Neurosymbolic Scene Graph Generation (SGG) is a promising approach that jointly leverages the perception capabilities of deep neural networks and the reasoning capabilities of symbolic techniques for scene understanding and visual reasoning. SGG systematically captures semantic components, including objects and their relationships, in images, enabling structured representations of visual data. However, existing SGG methods exhibit constrained accuracy and limited expressiveness, particularly in long-tail relationship prediction. To address these limitations, we present MuRelSGG, a novel neurosymbolic SGG framework that integrates a Transformer-based multimodal relationship prediction pipeline with common sense knowledge enrichment. This synergistic combination encapsulates global context, long-range dependencies, and complex object interactions to enhance relationship prediction in SGG. The proposed neurosymbolic architecture begins with object detection via Faster R-CNN, followed by a cascade of Multi-Head Attention Transformers (M-HAT) and Vision Transformers (ViT) for relationship prediction. Subsequently, CSKG enrichment refines and augments visual relationships, improving both accuracy and expressiveness. We conduct extensive evaluations on both the Visual Genome (VG) and GQA datasets to assess performance and generalizability. MuRelSGG achieves substantial gains in recall rates (VG: R@ 100=43.2 , mR@ 100=14.9 ; GQA: R@ 100=42.1 ), outperforming state-of-the-art SGG techniques. Ablation studies confirm the critical contributions of M-HAT, ViT, linguistic features, CSKG enrichment and embedding similarity thresholds, demonstrating the effectiveness of structured knowledge integration for long-tail relationship prediction. These findings underscore the potential of combining deep learning architectures with structured knowledge bases to advance visual scene representation and reasoning. © 2013 IEEE.
KW  - Common sense knowledge
KW  - neurosymbolic integration
KW  - scene graph
KW  - scene understanding
KW  - visual reasoning
KW  - Data encapsulation
KW  - Deep neural networks
KW  - Graph neural networks
KW  - Knowledge graph
KW  - Commonsense knowledge
KW  - Graph generation
KW  - Long tail
KW  - Multi-modal
KW  - Neurosymbolic integration
KW  - Perception capability
KW  - Scene understanding
KW  - Scene-graphs
KW  - Structured knowledge
KW  - Visual reasoning
KW  - Semantics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Arrotta, L.
AU  - Civitarese, G.
AU  - Bettini, C.
TI  - Probabilistic knowledge infusion through symbolic features for context-aware activity recognition
PY  - 2023
T2  - Pervasive and Mobile Computing
VL  - 91
C7  - 101780
DO  - 10.1016/j.pmcj.2023.101780
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150454528&doi=10.1016%2fj.pmcj.2023.101780&partnerID=40&md5=2740b0c5cbb15f4f3192ee6d3fe60763
AB  - In the general machine learning domain, solutions based on the integration of deep learning models with knowledge-based approaches are emerging. Indeed, such hybrid systems have the advantage of improving the recognition rate and the model's interpretability. At the same time, they require a significantly reduced amount of labeled data to reliably train the model. However, these techniques have been poorly explored in the sensor-based Human Activity Recognition (HAR) domain. The common-sense knowledge about activity execution can potentially improve purely data-driven approaches. While a few knowledge infusion approaches have been proposed for HAR, they rely on rigid logic formalisms that do not take into account uncertainty. In this paper, we propose P-NIMBUS, a novel knowledge infusion approach for sensor-based HAR that relies on probabilistic reasoning. A probabilistic ontology is in charge of computing symbolic features that are combined with the features automatically extracted by a CNN model from raw sensor data and high-level context data. In particular, the symbolic features encode probabilistic common-sense knowledge about the activities consistent with the user's surrounding context. These features are infused within the model before the classification layer. We experimentally evaluated P-NIMBUS on a HAR dataset of mobile devices sensor data that includes 14 different activities performed by 25 users. Our results show that P-NIMBUS outperforms state-of-the-art neuro-symbolic approaches, with the advantage of requiring a limited amount of training data to reach satisfying recognition rates (i.e., more than 80% of F1-score with only 20% of labeled data). © 2023 Elsevier B.V.
KW  - Context-awareness
KW  - Human activity recognition
KW  - Neuro-symbolic
KW  - Computation theory
KW  - Deep learning
KW  - Knowledge based systems
KW  - Learning systems
KW  - Pattern recognition
KW  - Activity recognition
KW  - Commonsense knowledge
KW  - Context- awareness
KW  - Context-Aware
KW  - Human activity recognition
KW  - Labeled data
KW  - Neuro-symbolic
KW  - Probabilistic knowledge
KW  - Sensors data
KW  - Symbolic features
KW  - Hybrid systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Namasivayam, K.
AU  - Tuli, A.
AU  - Bindal, V.
AU  - Singh, H.
AU  - Singla, P.
AU  - Paul, R.
TI  - Learning to Recover from Plan Execution Errors during Robot Manipulation: A Neuro-symbolic Approach
PY  - 2024
T2  - IEEE International Conference on Intelligent Robots and Systems
SP  - 12632
EP  - 12639
DO  - 10.1109/IROS58592.2024.10801831
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216467897&doi=10.1109%2fIROS58592.2024.10801831&partnerID=40&md5=a2aa79f51eb3ca8f351f50ae2434b432
AB  - Automatically detecting and recovering from failures is an important but challenging problem for autonomous robots. Most of the recent work on learning to plan from demonstrations lacks the ability to detect and recover from errors in the absence of an explicit state representation and/or a (sub-) goal check function. We propose an approach (blending learning with symbolic search) for automated error discovery and recovery, without needing annotated data of failures. Central to our approach is a neuro-symbolic state representation, in the form of dense scene graph, structured based on the objects present within the environment. This enables efficient learning of the transition function and a discriminator that not only identifies failures but also localizes them facilitating fast re-planning via computation of heuristic distance function. We also present an anytime version of our algorithm, where instead of recovering to the last correct state, we search for a sub-goal in the original plan minimizing the total distance to the goal given a re-planning budget. Experiments on a physics simulator with a variety of simulated failures show the effectiveness of our approach compared to existing baselines, both in terms of efficiency as well as accuracy of our recovery mechanism. © 2024 IEEE.
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Heuristic programming
KW  - Robot learning
KW  - Robot programming
KW  - Blending learning
KW  - Execution errors
KW  - Explicit state
KW  - Plan execution
KW  - Re-planning
KW  - Robot manipulation
KW  - State representation
KW  - Subgoals
KW  - Symbolic search
KW  - Symbolic state
KW  - Budget control
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Bougzime, O.
AU  - Cruz, C.
AU  - André, J.-C.
AU  - Zhou, K.
AU  - Jerry Qi, H.
AU  - Demoly, F.
TI  - Neuro-symbolic artificial intelligence in accelerated design for 4D printing: Status, challenges, and perspectives
PY  - 2025
T2  - Materials and Design
VL  - 252
C7  - 113737
DO  - 10.1016/j.matdes.2025.113737
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219042880&doi=10.1016%2fj.matdes.2025.113737&partnerID=40&md5=487e529955aad96bb4419ecc0a42750a
AB  - 4D printing enables the creation of adaptive and reconfigurable devices by combining additive manufacturing with smart materials. This integration introduces challenges in designing printable, responsive materials and structures. Current research focuses on improving the responsiveness and mechanical performance of smart materials, but incremental advances often lack sufficient feedback for achieving specific properties, shapes, and performance targets. Inverse design has emerged as a strategy for determining material compositions and structural configurations to meet desired outputs, but its application remains limited to simple structures. Accelerating material and structural discovery is crucial for advancing 4D printing. Artificial intelligence (AI), especially machine learning (ML), offers promising solutions to address the complexity of 4D printing design. However, conventional AI approaches often lack logical reasoning, explainability, and interpretability. This review paper highlights recent achievements and challenges in 4D printing design and introduces neuro-symbolic AI as a promising approach. By combining ML's learning capabilities with the logical reasoning and semantic understanding of symbolic AI, this approach can enhance the exploration of advanced active materials and structures. The insights provided aim to guide future research toward optimizing 4D printing for broader applications and enhanced performance. © 2025 The Author(s)
KW  - 4D printing
KW  - Additive manufacturing
KW  - Inverse design
KW  - Machine learning
KW  - Neural network
KW  - Neuro-symbolic AI
KW  - Symbolic AI
KW  - Additives
KW  - Contrastive Learning
KW  - Inverse problems
KW  - 4d printing
KW  - Accelerated design
KW  - Adaptive devices
KW  - Inverse designs
KW  - Logical reasoning
KW  - Machine-learning
KW  - Neural-networks
KW  - Neuro-symbolic artificial intelligence
KW  - Printing designs
KW  - Symbolic artificial intelligence
KW  - Smart manufacturing
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Chandre, P.
AU  - Mahalle, P.
AU  - Shinde, G.
AU  - Shendkar, B.
AU  - Kashid, S.
TI  - Neuro-Symbolic AI: A Future of Tomorrow
PY  - 2025
T2  - ASEAN Journal on Science and Technology for Development
VL  - 42
IS  - 2
SP  - 187
EP  - 200
DO  - 10.61931/2224-9028.1620
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003053014&doi=10.61931%2f2224-9028.1620&partnerID=40&md5=74b6e3981bc3f4be01a896f47a95e0e8
AB  - “Neuro-Symbolic AI: A Future of Tomorrow” explores the convergence of neural learning and symbolic reasoning to advance artificial intelligence (AI) systems. Symbolic reasoning makes use of knowledge representation techniques and rule-based systems, whereas neural learning analyzes data using deep learning models. AI becomes more adept at fusing data-driven insights with deductive reasoning when these methods are integrated using hybrid models and differentiable reasoning techniques. Applications show enhanced diagnostic precision and decision-making skills in a variety of industries, including robotics, healthcare, and finance. To promote responsible AI development, regulatory frameworks and ethical principles address issues like bias and transparency. Future paths prioritize scalability and interdisciplinary collaboration for robust and ethical AI developments, and seek for flexible architectures that can adapt to new data and contexts. The potential of neuro-symbolic AI to revolutionize AI capabilities with wider applicability and ethical considerations is highlighted by this research. © 2025 The Authors.
KW  - Artificial intelligence
KW  - Ethical AI
KW  - Hybrid models
KW  - Neural learning
KW  - Neuro-Symbolic AI
KW  - Symbolic reasoning
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Pflueger, M.
AU  - Tena Cucala, D.J.
AU  - Kostylev, E.V.
TI  - GNNQ: A Neuro-Symbolic Approach to Query Answering over Incomplete Knowledge Graphs
PY  - 2022
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 13489 LNCS
SP  - 481
EP  - 497
DO  - 10.1007/978-3-031-19433-7_28
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141686209&doi=10.1007%2f978-3-031-19433-7_28&partnerID=40&md5=3e3b674b4d6054707fae2dd6cb608a21
AB  - Real-world knowledge graphs (KGs) are usually incomplete—that is, miss some facts representing valid information. So, when applied to such KGs, standard symbolic query engines fail to produce answers that are expected but not logically entailed by the KGs. To overcome this issue, state-of-the-art ML-based approaches first embed KGs and queries into a low-dimensional vector space, and then produce query answers based on the proximity of the candidate entity and the query embeddings in the embedding space. This allows embedding-based approaches to obtain expected answers that are not logically entailed. However, embedding-based approaches are not applicable in the inductive setting, where KG entities (i.e., constants) seen at runtime may differ from those seen during training. In this paper, we propose a novel neuro-symbolic approach to query answering over incomplete KGs applicable in the inductive setting. Our approach first symbolically augments the input KG with facts representing parts of the KG that match query fragments, and then applies a generalisation of the Relational Graph Convolutional Networks (RGCNs) to the augmented KG to produce the predicted query answers. We formally prove that, under reasonable assumptions, our approach can capture an approach based on vanilla RGCNs (and no KG augmentation) using a (often substantially) smaller number of layers. Finally, we empirically validate our theoretical findings by evaluating an implementation of our approach against the RGCN baseline on several dedicated benchmarks. © 2022, The Author(s).
KW  - Graph neural networks
KW  - Knowledge graphs
KW  - Neuro-symbolic AI
KW  - Query answering
KW  - Graph embeddings
KW  - Graph neural networks
KW  - Vector spaces
KW  - Convolutional networks
KW  - Embeddings
KW  - Graph neural networks
KW  - Incomplete knowledge
KW  - Knowledge graphs
KW  - Neuro-symbolic AI
KW  - Query answering
KW  - Real-world
KW  - Relational graph
KW  - World knowledge
KW  - Knowledge graph
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - JOUR
AU  - Acharya, K.
AU  - Raza, W.
AU  - Dourado, C.
AU  - Velasquez, A.
AU  - Song, H.H.
TI  - Neurosymbolic Reinforcement Learning and Planning: A Survey
PY  - 2024
T2  - IEEE Transactions on Artificial Intelligence
VL  - 5
IS  - 5
C7  - 10238788
SP  - 1939
EP  - 1953
DO  - 10.1109/TAI.2023.3311428
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171555510&doi=10.1109%2fTAI.2023.3311428&partnerID=40&md5=d2bb4ca05c8ab1e65d40a309ce1404f6
AB  - The area of neurosymbolic artificial intelligence (Neurosymbolic AI) is rapidly developing and has become a popular research topic, encompassing subfields, such as neurosymbolic deep learning and neurosymbolic reinforcement learning (Neurosymbolic RL). Compared with traditional learning methods, Neurosymbolic AI offers significant advantages by simplifying complexity and providing transparency and explainability. Reinforcement learning (RL), a long-standing artificial intelligence (AI) concept that mimics human behavior using rewards and punishment, is a fundamental component of Neurosymbolic RL, a recent integration of the two fields that has yielded promising results. The aim of this article is to contribute to the emerging field of Neurosymbolic RL by conducting a literature survey. Our evaluation focuses on the three components that constitute Neurosymbolic RL: neural, symbolic, and RL. We categorize works based on the role played by the neural and symbolic parts in RL, into three taxonomies: learning for reasoning, reasoning for learning, and learning-reasoning. These categories are further divided into subcategories based on their applications. Furthermore, we analyze the RL components of each research work, including the state space, action space, policy module, and RL algorithm. In addition, we identify research opportunities and challenges in various applications within this dynamic field.  © 2023 IEEE.
KW  - Neurosymbolic
KW  - neurosymbolic reinforcement learning (Neurosymbolic RL)
KW  - reinforcement learning (RL)
KW  - Behavioral research
KW  - Deep learning
KW  - Reinforcement learning
KW  - Cognition
KW  - Heuristics algorithm
KW  - Neurosymbolic
KW  - Neurosymbolic reinforcement learning
KW  - Psychology
KW  - Reinforcement learnings
KW  - Reinforcement planning
KW  - Research topics
KW  - Heuristic algorithms
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 9
ER  -

TY  - JOUR
AU  - Roig Vilamala, M.
AU  - Xing, T.
AU  - Taylor, H.
AU  - Garcia, L.
AU  - Srivastava, M.
AU  - Kaplan, L.
AU  - Preece, A.
AU  - Kimmig, A.
AU  - Cerutti, F.
TI  - DeepProbCEP: A neuro-symbolic approach for complex event processing in adversarial settings
PY  - 2023
T2  - Expert Systems with Applications
VL  - 215
C7  - 119376
DO  - 10.1016/j.eswa.2022.119376
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144496844&doi=10.1016%2fj.eswa.2022.119376&partnerID=40&md5=1c3bdb22e30315dfb2611e590cbfd42b
AB  - Detecting complex events from subsymbolic data streams (such as images, audio recordings or videos) is a challenging problem, as traditional symbolic approaches cannot be used to process subsymbolic data, and neural-only approaches usually require larger amounts of training data than available. In this paper, we present DeepProbCEP, a Complex Event Processing (CEP) approach designed with four objectives: (i) allowing the use of subsymbolic data as an input, (ii) retaining flexibility and modularity in the definition of complex event rules, (iii) limiting the cost of obtaining training data and (iv) being robust against adversarial conditions. DeepProbCEP archives this by using a neuro-symbolic approach, which combines the neural and symbolic approaches to allow training with sparse data. This is made possible through the injection of human knowledge. In this paper, we demonstrate that DeepProbCEP outperforms other state-of-the-art approaches when training using sparse data. We also show that DeepProbCEP is robust in different adversarial settings. Finally, DeepProbCEP's flexibility is demonstrated by showing it can be used to process both images and audio as input. © 2022 The Authors
KW  - Complex Event Processing
KW  - Learning with sparse data
KW  - Neuro-symbolic architecture
KW  - Robustness
KW  - Complex event processing
KW  - Complex events
KW  - Data stream
KW  - Event Processing
KW  - Learning with sparse data
KW  - Neuro-symbolic architecture
KW  - Robustness
KW  - Sparse data
KW  - Sub-symbolic
KW  - Training data
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 12
ER  -

TY  - CONF
AU  - Arrotta, L.
AU  - Bettini, C.
AU  - Civitarese, G.
AU  - Fiori, M.
TI  - ContextGPT: Infusing LLMs Knowledge into Neuro-Symbolic Activity Recognition Models
PY  - 2024
T2  - Proceedings - 2024 IEEE International Conference on Smart Computing, SMARTCOMP 2024
SP  - 55
EP  - 62
DO  - 10.1109/SMARTCOMP61445.2024.00029
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199931500&doi=10.1109%2fSMARTCOMP61445.2024.00029&partnerID=40&md5=61f9d3524e57d14e5b6829ff6c0b2591
AB  - Context-aware Human Activity Recognition (HAR) is a hot research area in mobile computing, and the most effective solutions in the literature are based on supervised deep learning models. However, the actual deployment of these systems is limited by the scarcity of labeled data that is required for training. Neuro-Symbolic AI (NeSy) provides an interesting research direction to mitigate this issue, by infusing common-sense knowledge about human activities and the contexts in which they can be performed into HAR deep learning classifiers. Existing NeSy methods for context-aware HAR rely on knowledge encoded in logic-based models (e.g., ontologies) whose design, implementation, and maintenance to capture new activities and contexts require significant human engineering efforts, technical knowledge, and domain expertise. Recent works show that pre-trained Large Language Models (LLMs) effectively encode common-sense knowledge about human activities. In this work, we propose ContextGPT: a novel prompt engineering approach to retrieve from LLMs common-sense knowledge about the relationship between human activities and the context in which they are performed. Unlike ontologies, ContextGPT requires limited human effort and expertise, while sharing similar privacy concerns if the reasoning is performed in the cloud. An extensive evaluation using two public datasets shows how a NeSy model obtained by infusing common-sense knowledge from ContextGPT is effective in data scarcity scenarios, leading to similar (and sometimes better) recognition rates than logic-based approaches with a fraction of the effort.  © 2024 IEEE.
KW  - context-awareness
KW  - human activity recognition
KW  - large language models
KW  - Computational linguistics
KW  - Learning systems
KW  - Ontology
KW  - Pattern recognition
KW  - Professional aspects
KW  - Activity recognition
KW  - Commonsense knowledge
KW  - Context- awareness
KW  - Context-Aware
KW  - Human activities
KW  - Human activity recognition
KW  - Language model
KW  - Large language model
KW  - Model knowledge
KW  - Ontology's
KW  - Deep learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Bhuyan, B.P.
AU  - Ramdane-Cherif, A.
AU  - Tomar, R.
AU  - Singh, T.P.
TI  - Neuro-symbolic artificial intelligence: a survey
PY  - 2024
T2  - Neural Computing and Applications
VL  - 36
IS  - 21
SP  - 12809
EP  - 12844
DO  - 10.1007/s00521-024-09960-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195277724&doi=10.1007%2fs00521-024-09960-z&partnerID=40&md5=75c719434666e05fa34cef51251561d1
AB  - The goal of the growing discipline of neuro-symbolic artificial intelligence (AI) is to develop AI systems with more human-like reasoning capabilities by combining symbolic reasoning with connectionist learning. We survey the literature on neuro-symbolic AI during the last two decades, including books, monographs, review papers, contribution pieces, opinion articles, foundational workshops/talks, and related PhD theses. Four main features of neuro-symbolic AI are discussed, including representation, learning, reasoning, and decision-making. Finally, we discuss the many applications of neuro-symbolic AI, including question answering, robotics, computer vision, healthcare, and more. Scalability, explainability, and ethical considerations are also covered, as well as other difficulties and limits of neuro-symbolic AI. This study summarizes the current state of the art in neuro-symbolic artificial intelligence. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.
KW  - Artificial intelligence
KW  - Knowledge representation and reasoning
KW  - Machine learning
KW  - Neural networks
KW  - Neuro-symbolic artificial intelligence
KW  - Spatial-temporal data
KW  - Decision making
KW  - Knowledge representation
KW  - Neural networks
KW  - Reviews
KW  - Artificial intelligence systems
KW  - Human like
KW  - Knowledge representation and reasoning
KW  - Machine-learning
KW  - Neural-networks
KW  - Neuro-symbolic artificial intelligence
KW  - Reasoning capabilities
KW  - Review papers
KW  - Spatial-temporal data
KW  - Symbolic reasoning
KW  - Machine learning
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 13
ER  -

TY  - CONF
AU  - Agiollo, A.
AU  - Omicini, A.
TI  - Measuring Trustworthiness in Neuro-Symbolic Integration
PY  - 2023
T2  - Proceedings of the 18th Conference on Computer Science and Intelligence Systems, FedCSIS 2023
SP  - 1
EP  - 10
DO  - 10.15439/2023F6019
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179180821&doi=10.15439%2f2023F6019&partnerID=40&md5=d0df6131e5c4949474832155b4f7754e
AB  - Neuro-symbolic integration of symbolic and subsymbolic techniques represents a fast-growing AI trend aimed at mitigating the issues of neural networks in terms of decision processes, reasoning, and interpretability. Several state-of-the-art neuro-symbolic approaches aim at improving performance, most of them focusing on proving their effectiveness in terms of raw predictive performance and/or reasoning capabilities. Meanwhile, few efforts have been devoted to increasing model trustworthiness, interpretability, and efficiency - mostly due to the complexity of measuring effectively improvements in terms of trustworthiness and interpretability. This is why here we analyse and discuss the need for ad-hoc trustworthiness metrics for neurosymbolic techniques. We focus on two popular paradigms mixing subsymbolic computation and symbolic knowledge, namely: (i) symbolic knowledge extraction (SKE), aimed at mapping subsymbolic models into human-interpretable knowledge bases; and (ii) symbolic knowledge injection (SKI), aimed at forcing subsymbolic models to adhere to a given symbolic knowledge. We first emphasise the need for assessing neuro-symbolic approaches from a trustworthiness perspective, highlighting the research challenges linked with this evaluation and the need for ad-hoc trust definitions. Then we summarise recent developments in SKE and SKI metrics focusing specifically on several trustworthiness pillars such as interpretability, efficiency, and robustness of neuro-symbolic methods. Finally, we highlight open research opportunities towards reliable and flexible trustworthiness metrics for neuro-symbolic integration.  © 2023 Polish Information Processing Society.
KW  - Information systems
KW  - Information use
KW  - Integration
KW  - Decision process
KW  - Improving performance
KW  - Interpretability
KW  - Knowledge extraction
KW  - Neural-networks
KW  - Process reasoning
KW  - State of the art
KW  - Sub-symbolic
KW  - Symbolic integration
KW  - Symbolic knowledge
KW  - Efficiency
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Khan, H.
AU  - Chaudhari, T.D.
AU  - Ramesh, J.V.N.
AU  - Kranthi, A.S.
AU  - Muniyandy, E.
AU  - Baker El-Ebiary, Y.A.
AU  - Devadhas, D.N.P.
TI  - Neuro-Symbolic Reinforcement Learning for Context-Aware Decision Making in Safe Autonomous Vehicles
PY  - 2025
T2  - International Journal of Advanced Computer Science and Applications
VL  - 16
IS  - 5
SP  - 599
EP  - 609
DO  - 10.14569/IJACSA.2025.0160558
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007901983&doi=10.14569%2fIJACSA.2025.0160558&partnerID=40&md5=07f93cd400d44bec926121bb965a6239
AB  - Autonomous vehicles need to be equipped with smart, understandable, and context-aware decision-making frameworks to drive safely within crowded environments. Current deep learning approaches tend to generalize poorly, lack transparency, and perform inadequately in dealing with uncertainty within dynamic city environments. Towards overcoming these deficiencies, this study suggests a new hybrid approach that combines Neuro-Symbolic reasoning with a Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) architecture, together with a Deep Q-Network (DQN) for learning through reinforcement. The model employs symbolic logic to enforce traffic regulations and infer context while relying on CNN for extracting spatial features and LSTM for extracting temporal dependencies in vehicle motion. The system is trained and tested using the Lyft Level 5 Motion Prediction dataset, which emulates varied and realistic driving scenarios in urban environments. Enforced on the Python platform, the new framework allows autonomous cars to generate rule-adherent, strong, and explainable choices under diverse driving scenarios. Neuro-symbolic combination is more robust for learning as well as explainability, whereas reinforcement improves long-term rewards regarding safety and efficiency. The experiment shows that the model provides high accuracy of 98% on scenario-based decision-making problems in contrast to classical deep learning models used in safety-critical routing. This work is advantageous to autonomous vehicle manufacturers, smart mobility system developers, and urban planners by providing a scalable, explainable, and reliable AI-based solution for future transportation systems. © (2025), (Science and Information Organization). All rights reserved.
KW  - Autonomous vehicles
KW  - CNN-LSTM architecture
KW  - context aware
KW  - Deep Q-Network (DQN)
KW  - neuro-symbolic learning
KW  - Automobile drivers
KW  - Behavioral research
KW  - Computation theory
KW  - Convolutional neural networks
KW  - Decision making
KW  - Deep neural networks
KW  - Intelligent systems
KW  - Long short-term memory
KW  - Memory architecture
KW  - Urban planning
KW  - Urban transportation
KW  - Autonomous Vehicles
KW  - Context-Aware
KW  - Context-aware decision makings
KW  - Convolutional neural network
KW  - Convolutional neural network-long short-term memory architecture
KW  - Deep Q-network
KW  - Neuro-symbolic learning
KW  - Reinforcement learnings
KW  - Short term memory
KW  - Symbolic learning
KW  - Autonomous vehicles
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Stephane, R.
AU  - Anthony, D.
AU  - Ana, R.
TI  - Neuro-symbolic approach for querying BIM models
PY  - 2023
T2  - Proceedings - 17th International Conference on Signal-Image Technology and Internet-Based Systems, SITIS 2023
SP  - 62
EP  - 69
DO  - 10.1109/SITIS61268.2023.00019
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190142716&doi=10.1109%2fSITIS61268.2023.00019&partnerID=40&md5=ae6e2ba4d4e0bb114e0883ab1e576e33
AB  - Integrating technologies like the Internet of Things (IoT) and artificial intelligence (AI) has transformed the smart building domain, enabling innovative services. The data gathered throughout a building's lifecycle, including construction and usage, create a comprehensive database for efficient management and improvement, mainly through Building Information Modelling (BIM). However, accessing and utilising these data can be challenging for users, as it often requires specialised query skills. Improving information accessibility involves intuitive and user-friendly query interfaces. Traditional approaches struggle to provide the flexibility and adaptability needed to keep up with evolving building information and user language expressions. To address these challenges, modern and scalable methods from symbolic and numeric artificial intelligence offer a solution. These systems can handle varying queries, adapt to changing data, and provide more user-friendly interactions, aligning better with user expectations in the industry.  © 2023 IEEE.
KW  - artificial intelligence
KW  - Building Information Modelling (BIM)
KW  - knowledge-based question answering (KBQA)
KW  - neuro-symbolic.
KW  - ontology
KW  - Architectural design
KW  - Information theory
KW  - Internet of things
KW  - Knowledge based systems
KW  - Life cycle
KW  - Query processing
KW  - Uncertainty analysis
KW  - Building information modeling
KW  - Building Information Modelling
KW  - Building life cycle
KW  - Integrating technology
KW  - Knowledge based
KW  - Knowledge-based question answering
KW  - Neuro-symbolic.
KW  - Ontology's
KW  - Question Answering
KW  - User friendly
KW  - Scalability
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Bizzarri, A.
AU  - Yu, C.-E.
AU  - Jalaian, B.
AU  - Riguzzi, F.
AU  - Bastian, N.D.
TI  - Neuro-Symbolic Integration for Open Set Recognition in Network Intrusion Detection
PY  - 2025
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 
VL  - 15450 LNAI
SP  - 50
EP  - 63
DO  - 10.1007/978-3-031-80607-0_5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215689753&doi=10.1007%2f978-3-031-80607-0_5&partnerID=40&md5=842ce861adaf6e84ddf5a517a3c70f43
AB  - Open Set Recognition (OSR) addresses the challenge of classifying inputs into known and unknown categories, a crucial task where labeling is often prohibitively expensive or incomplete. This is particularly vital in applications like Network Intrusion Detection Systems (NIDS), where OSR is used to identify novel, previously unknown attacks. We propose a neuro-symbolic integration approach that combines deep learning and symbolic methods, enhancing deep embedding for clustering with custom loss functions and leveraging XGBoost’s decision tree algorithms. Our methodology not only robustly addresses the identification of previously unknown attacks in NIDS but also effectively manages scenarios involving covariance shift. We demonstrate the efficacy of our approach through extensive experimentation, achieving an AUROC of 0.99 in both contexts. This paper presents a significant step forward in OSR for network intrusion detection by integrating deep and symbolic learning to handle unforeseen challenges in dynamic environments. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
KW  - Deep Embedding for Clustering
KW  - Network Intrusion Detection
KW  - Neuro-symbolic Integration
KW  - Open Set Recognition
KW  - XGBoost
KW  - Decision trees
KW  - Deep neural networks
KW  - Integration
KW  - Intrusion detection
KW  - Network embeddings
KW  - Clusterings
KW  - Deep embedding for clustering
KW  - Embeddings
KW  - Network intrusion detection
KW  - Network intrusion detection systems
KW  - Neuro-symbolic integration
KW  - Open set recognition
KW  - Symbolic integration
KW  - Unknown attacks
KW  - Xgboost
KW  - Network intrusion
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Cevallos M., J.F.
AU  - Rizzardi, A.
AU  - Sicari, S.
AU  - Porisini, A.C.
TI  - NERO: NEural algorithmic reasoning for zeRO-day attack detection in the IoT: A hybrid approach
PY  - 2024
T2  - Computers and Security
VL  - 142
C7  - 103898
DO  - 10.1016/j.cose.2024.103898
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193487491&doi=10.1016%2fj.cose.2024.103898&partnerID=40&md5=38dc5f0fd37d5ccda0f3f815959633c7
AB  - Anomaly detection approaches for network intrusion detection learn to identify deviations from normal behavior on a data-driven basis. However, current approaches strive to infer the degree of abnormality of out-of-distribution samples when these appertain to different zero-day attacks. Inspired by the successes of the neural algorithmic reasoning paradigm to leverage the generalization of rule-based behavior, this paper presents a deep learning strategy for solving zero-day network attack detection and categorization. Moreover, focusing on the particular scenario of the Internet of Things (IoT), the privacy preservation requirement may imply a low training data regime for any learning algorithm. To this respect, the presented framework uses metric-based meta-learning to achieve few-shot learning capabilities. The presented pipeline is called NERO, as it imports the encode-process-decode architecture from the NEural algorithmic reasoning blueprint to converge zeRO-day attack detection policies within constrained training data. © 2024 The Author(s)
KW  - Internet of things
KW  - Meta-learning
KW  - Network intrusion detection systems
KW  - Neural algorithmic reasoning
KW  - Anomaly detection
KW  - Deep learning
KW  - Internet of things
KW  - Intrusion detection
KW  - Learning algorithms
KW  - Learning systems
KW  - Algorithmic reasoning
KW  - Anomaly detection
KW  - Attack detection
KW  - Detection approach
KW  - Hybrid approach
KW  - Metalearning
KW  - Network intrusion detection systems
KW  - Neural algorithmic reasoning
KW  - Training data
KW  - Zero day attack
KW  - Zero-day attack
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 10
ER  -

TY  - CONF
AU  - Doula, A.
AU  - Yin, H.
AU  - Muhlhauser, M.
AU  - Guinea, A.S.
TI  - NeSyMoF: A Neuro-Symbolic Model for Motion Forecasting
PY  - 2024
T2  - IEEE International Conference on Intelligent Robots and Systems
SP  - 919
EP  - 926
DO  - 10.1109/IROS58592.2024.10801779
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216464133&doi=10.1109%2fIROS58592.2024.10801779&partnerID=40&md5=b429e6a5f479ab596a32c43f7007d357
AB  - Recent advancements in deep learning have significantly enhanced the development of efficient models for multi-modal path prediction within urban environments, offering approaches to navigate complex environments accurately. Despite their performance, models grounded in deep learning techniques frequently encounter challenges related to interpretability. This limitation not only hampers their practical application but also complicates the process of diagnosing and rectifying errors within these systems, which is a critical factor for ensuring reliability and safety in realworld deployments. In this paper we propose NeSyMoF, a Neuro-Symbolic model for Motion Forecasting, to address this critical gap by combining the predictive power of deep neural networks with the interpretable logic inherent in symbolic reasoning. Data processing in NeSyMoF involves extracting pertinent features from the agent's environment and channeling them into a neuro-symbolic reasoning module. The neurosymbolic reasoning module generates first-order logic rules that describe and condition the path prediction process, thereby providing clear explanations and intentions behind the forecasts of the model. We evaluate our model with the Argoverse benchmark for path forecasting, as it includes challenging driving situations, necessary to extensively evaluate our model. The results of our evaluation show that NeSyMoF outperforms state-of-the-art interpretable models for single-mode predictions while providing logic-based explanations for its forecasts, that articulate the reasoning behind predictions, making NeSyMoF more adapted for human-centric applications. © 2024 IEEE.
KW  - Contrastive Learning
KW  - Deep neural networks
KW  - Complex environments
KW  - Critical factors
KW  - Interpretability
KW  - Learning techniques
KW  - Multi-modal
KW  - Path prediction
KW  - Performance Modeling
KW  - Symbolic modeling
KW  - Symbolic reasoning
KW  - Urban environments
KW  - Prediction models
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Okamoto, L.
AU  - Parmar, P.
TI  - Hierarchical NeuroSymbolic Approach for Comprehensive and Explainable Action Quality Assessment
PY  - 2024
T2  - IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops
SP  - 3204
EP  - 3213
DO  - 10.1109/CVPRW63382.2024.00326
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206467647&doi=10.1109%2fCVPRW63382.2024.00326&partnerID=40&md5=a5ad765cd874525acef9c585c315a54c
AB  - Action quality assessment (AQA) applies computer vision to quantitatively assess the performance or execution of a human action. Current AQA approaches are end-to-end neural models, which lack transparency and tend to be biased because they are trained on subjective human judgements as ground-truth. To address these issues, we introduce a neuro-symbolic paradigm for AQA, which uses neural networks to abstract interpretable symbols from video data and makes quality assessments by applying rules to those symbols. We take diving as the case study. We found that domain experts prefer our system and find it more informative than purely neural approaches to AQA in diving. Our system also achieves state-of-the-art action recognition and temporal segmentation, and automatically generates a detailed report that breaks the dive down into its elements and provides objective scoring with visual evidence. As verified by a group of domain experts, this report may be used to assist judges in scoring, help train judges, and provide feedback to divers. Annotated training data and code: https://github.com/laurenok24/NSAQA. © 2024 IEEE.
KW  - action quality assessment
KW  - action recognition
KW  - AI Coach
KW  - AI Diving Coach
KW  - AI Diving Judge
KW  - AI Olympics Judge
KW  - explainable AI
KW  - fairness in AI
KW  - interpretable action analysis
KW  - interpretable action quality assessment
KW  - interpretable fine-grained action quality assessment
KW  - neuro-symbolic computer vision
KW  - neurosymbolic action assessment
KW  - neurosymbolic action scoring
KW  - neurosymbolic AI
KW  - neurosymbolic fine-grained action analysis
KW  - neurosymbolic fine-grained action quality assessment
KW  - neurosymbolic fine-grained action recogntion
KW  - neurosymbolic fine-grained action understanding
KW  - neurosymbolic skills assessment
KW  - neurosymbolic temporal segmentation
KW  - neurosymbolic video understanding
KW  - Olympics Scoring
KW  - representation learning
KW  - skills assessment
KW  - temporal segmentation
KW  - transparent AI
KW  - XAI
KW  - Personnel training
KW  - Action analysis
KW  - Action assessment
KW  - Action quality assessment
KW  - Action recognition
KW  - AI coach
KW  - AI diving coach
KW  - AI diving judge
KW  - AI olympic judge
KW  - Explainable AI
KW  - Fairness in AI
KW  - Fine grained
KW  - Interpretable action analyze
KW  - Interpretable action quality assessment
KW  - Interpretable fine-grained action quality assessment
KW  - Neuro-symbolic computer vision
KW  - Neurosymbolic action assessment
KW  - Neurosymbolic action scoring
KW  - Neurosymbolic AI
KW  - Neurosymbolic fine-grained action analyze
KW  - Neurosymbolic fine-grained action quality assessment
KW  - Neurosymbolic fine-grained action recogntion
KW  - Neurosymbolic fine-grained action understanding
KW  - Neurosymbolic skill assessment
KW  - Neurosymbolic temporal segmentation
KW  - Neurosymbolic video understanding
KW  - Olympic scoring
KW  - Olympics
KW  - Quality assessment
KW  - Representation learning
KW  - Skill assessment
KW  - Temporal segmentations
KW  - Transparent AI
KW  - Video understanding
KW  - XAI
KW  - Neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Himabindu, M.
AU  - Revathi, V.
AU  - Gupta, M.
AU  - Rana, A.
AU  - Chandra, P.K.
AU  - Abdulaali, H.S.
TI  - Neuro-Symbolic AI: Integrating Symbolic Reasoning with Deep Learning
PY  - 2023
T2  - 2023 10th IEEE Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering, UPCON 2023
SP  - 1587
EP  - 1592
DO  - 10.1109/UPCON59197.2023.10434380
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187374768&doi=10.1109%2fUPCON59197.2023.10434380&partnerID=40&md5=822d1718cbcdcda2f8a56400bf0fe932
AB  - Neuro-symbolic artificial intelligence (AI) stands at the frontier of machine learning by amalgamating the interpretability and structured knowledge representation of symbolic reasoning with the adaptive learning capabilities of deep neural networks. This paper presents a comprehensive framework for neuro-symbolic integration, outlining a harmonized architecture that leverages the strengths of both domains. The proposed system utilizes symbolic AI to impose structural constraints and inject domain knowledge into the learning process, enhancing the reasoning capabilities of deep learning models. Concurrently, it capitalizes on the proficiency of deep learning in handling high-dimensional, noisy data, enabling the symbolic components to operate beyond discrete, well-defined environments. The architecture is validated through a series of experiments demonstrating enhanced performance in tasks requiring complex reasoning, generalization, and knowledge transfer. The framework showcases a significant reduction in data dependency for model training, increased interpretability of the decision-making process, and robustness to noise and ambiguity. This integration marks a stride towards the development of AI systems with advanced cognitive abilities, akin to human-like understanding and reasoning. The paper concludes with a discussion on the implications of neuro-symbolic AI in advancing the field and its potential to transform future AI applications.  © 2023 IEEE.
KW  - Cognitive AI Systems
KW  - Deep Learning
KW  - Knowledge Representation
KW  - Neuro-symbolic AI
KW  - Symbolic Reasoning
KW  - Cognitive systems
KW  - Decision making
KW  - Deep neural networks
KW  - Domain Knowledge
KW  - Knowledge management
KW  - Learning systems
KW  - Network architecture
KW  - Adaptive learning
KW  - Artificial intelligence systems
KW  - Cognitive artificial intelligence system
KW  - Deep learning
KW  - Interpretability
KW  - Knowledge-representation
KW  - Machine-learning
KW  - Neuro-symbolic artificial intelligence
KW  - Structured knowledge
KW  - Symbolic reasoning
KW  - Knowledge representation
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Bein, L.
AU  - Pufahl, L.
TI  - Knowledge Graphs: A Key Technology for Explainable Knowledge-Aware Process Automation?
PY  - 2025
T2  - Lecture Notes in Business Information Processing
VL  - 534 LNBIP
SP  - 18
EP  - 30
DO  - 10.1007/978-3-031-78666-2_2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000450981&doi=10.1007%2f978-3-031-78666-2_2&partnerID=40&md5=3cc9da8e5cda33dcbfba2747cbbba8d8
AB  - Process automation is a key subfield of business process management. Recent advances in AI research promise to yield a new type of intelligent process automation that can support high-variability, flexible, knowledge-intensive processes previously hard to enhance with process automation. However, primarily proposed, subsymbolic deep learning approaches fail to reliably consider the complex knowledge inherent to these processes and provide adequate explanations for their decisions. Neuro-symbolic reasoning approaches based on knowledge graphs promise to address these challenges by allowing to holistically encode complex domain knowledge and to perform explainable reasoning thereupon. In this vision paper, we investigate the potential of knowledge graphs for intelligent process automation. Using tangible examples, we show how they can be used to enable explainable, knowledge-aware process automation, integrating a wide range of process knowledge. We show that such knowledge-aware process automation can contribute to addressing two current challenges of the BPM community: the automation of knowledge-intensive processes and the design of AI-augmented business process management systems. Finally, we discuss avenues for future research. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
KW  - Business Process Automation
KW  - Knowledge Graphs
KW  - Knowledge-intensive Processes
KW  - Neuro-symbolic AI
KW  - Enterprise resource management
KW  - Business Process
KW  - Business process automation
KW  - Intelligent process automation
KW  - Key technologies
KW  - Knowledge graphs
KW  - Knowledge intensive process
KW  - Neuro-symbolic AI
KW  - Process automation
KW  - Process management
KW  - Subfields
KW  - Knowledge graph
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Arrotta, L.
AU  - Civitarese, G.
AU  - Bettini, C.
TI  - Semantic Loss: A New Neuro-Symbolic Approach for Context-Aware Human Activity Recognition
PY  - 2024
T2  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 7
IS  - 4
C7  - 147
DO  - 10.1145/3631407
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182607385&doi=10.1145%2f3631407&partnerID=40&md5=43bfbd5959d2e27b106fd97245ede414
AB  - Deep Learning models are a standard solution for sensor-based Human Activity Recognition (HAR), but their deployment is often limited by labeled data scarcity and models' opacity. Neuro-Symbolic AI (NeSy) provides an interesting research direction to mitigate these issues by infusing knowledge about context information into HAR deep learning classifiers. However, existing NeSy methods for context-aware HAR require computationally expensive symbolic reasoners during classification, making them less suitable for deployment on resource-constrained devices (e.g., mobile devices). Additionally, NeSy approaches for context-aware HAR have never been evaluated on in-the-wild datasets, and their generalization capabilities in real-world scenarios are questionable. In this work, we propose a novel approach based on a semantic loss function that infuses knowledge constraints in the HAR model during the training phase, avoiding symbolic reasoning during classification. Our results on scripted and in-the-wild datasets show the impact of different semantic loss functions in outperforming a purely data-driven model. We also compare our solution with existing NeSy methods and analyze each approach's strengths and weaknesses. Our semantic loss remains the only NeSy solution that can be deployed as a single DNN without the need for symbolic reasoning modules, reaching recognition rates close (and better in some cases) to existing approaches.  © 2024 Owner/Author.
KW  - context-awareness
KW  - human activity recognition
KW  - knowledge infusion
KW  - knowledge-based reasoning
KW  - neuro-symbolic
KW  - Classification (of information)
KW  - Deep learning
KW  - Knowledge based systems
KW  - Learning systems
KW  - Pattern recognition
KW  - Context- awareness
KW  - Context-Aware
KW  - Human activity recognition
KW  - Knowledge infusion
KW  - Knowledge-based reasoning
KW  - Learning models
KW  - Loss functions
KW  - Neuro-symbolic
KW  - Standard solutions
KW  - Symbolic reasoning
KW  - Semantics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - CONF
AU  - Arabshahi, F.
AU  - Lee, J.
AU  - Gawarecki, M.
AU  - Mazaitis, K.
AU  - Azaria, A.
AU  - Mitchell, T.
TI  - Conversational Neuro-Symbolic Commonsense Reasoning
PY  - 2021
T2  - 35th AAAI Conference on Artificial Intelligence, AAAI 2021
VL  - 6A
SP  - 4902
EP  - 4911
DO  - 10.1609/aaai.v35i6.16623
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115876829&doi=10.1609%2faaai.v35i6.16623&partnerID=40&md5=d3dcb88461afcc63ba054fc932663f3e
AB  - In order for conversational AI systems to hold more natural and broad-ranging conversations, they will require much more commonsense, including the ability to identify unstated presumptions of their conversational partners. For example, in the command “If it snows at night then wake me up early because I don’t want to be late for work” the speaker relies on commonsense reasoning of the listener to infer the implicit presumption that they wish to be woken only if it snows enough to cause traffic slowdowns. We consider here the problem of understanding such imprecisely stated natural language commands given in the form of if-(state), then-(action), because-(goal) statements. More precisely, we consider the problem of identifying the unstated presumptions of the speaker that allow the requested action to achieve the desired goal from the given state (perhaps elaborated by making the implicit presumptions explicit). We release a benchmark data set for this task, collected from humans and annotated with commonsense presumptions. We present a neuro-symbolic theorem prover that extracts multi-hop reasoning chains, and apply it to this problem. Furthermore, to accommodate the reality that current AI commonsense systems lack full coverage, we also present an interactive conversational framework built on our neuro-symbolic system, that conversationally evokes commonsense knowledge from humans to complete its reasoning chains. Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.
KW  - Artificial intelligence
KW  - 'current
KW  - AI systems
KW  - Benchmark data
KW  - Commonsense reasoning
KW  - Conversational frameworks
KW  - Data set
KW  - Multi-hops
KW  - Natural languages
KW  - Neuro-symbolic system
KW  - Theorem provers
KW  - Snow
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 27
ER  -

TY  - CONF
AU  - Theodoropoulos, S.
AU  - Makridis, G.
AU  - Kyriazis, D.
AU  - Tsanakas, P.
TI  - Robust Novel Defect Detection with Neurosymbolic AI
PY  - 2024
T2  - IFIP Advances in Information and Communication Technology
VL  - 732 IFIP
SP  - 381
EP  - 396
DO  - 10.1007/978-3-031-71637-9_26
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204640045&doi=10.1007%2f978-3-031-71637-9_26&partnerID=40&md5=dde4f181e41f34344d3568a9fc177753
AB  - Detecting novel product defects whose classes have not been seen at all during training time, is an important aspect of practical automated visual inspection in manufacturing. Without proper handling it is possible that these unknown defects will remain unnoticed causing production quality to deteriorate. Collecting more and more defect data is also not a solution as defects occur rarely in production and the ramp-up time of the AI-driven quality inspector becomes significantly slower. Since traditional machine algorithms are not always designed for handling these challenges, this paper applies an innovative approach based on Neurosymbolic AI. Specifically, we use a Logic Tensor Network that expresses the outputs of an unsupervised out-of-distribution detector as symbolic rules and uses them to drive the training of a neural network classifier. The resulting algorithm shows improved results in comparison to other related methods, especially in terms of defect recall, meaning that few defects remain undetected even if completely novel. More specifically, it achieves similar or better recall scores than semi-supervised and unsupervised methods when handling novel defects, but significantly outperforms them in defects that were seen during training. Similarly, when compared to supervised methods, it maintains high performance on known defects but significantly improves on novel ones. These best-of-both-worlds results are illustrated through higher F1-scores in the majority of the test datasets of manufacturing products. © IFIP International Federation for Information Processing 2024.
KW  - artificial intelligence
KW  - Neurosymbolic AI
KW  - quality inspection
KW  - smart manufacturing
KW  - Data acquisition
KW  - Manufacturing data processing
KW  - Neural networks
KW  - Smart manufacturing
KW  - Automated visual inspection
KW  - Defect detection
KW  - Neurosymbolic AI
KW  - Product defects
KW  - Production quality
KW  - Quality inspection
KW  - Ramp up
KW  - Smart manufacturing
KW  - Training time
KW  - Up-time
KW  - Inspection
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Smirnov, A.
AU  - Ponomarev, A.
AU  - Shilov, N.
TI  - Collaborative Decision Support with Ontology-Based Neuro-Symbolic Artificial Intelligence: Challenges and Conceptual Model
PY  - 2023
T2  - Lecture Notes in Networks and Systems
VL  - 566 LNNS
SP  - 51
EP  - 59
DO  - 10.1007/978-3-031-19620-1_6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144523925&doi=10.1007%2f978-3-031-19620-1_6&partnerID=40&md5=273a0bf32c1fa47edd8459079557cba1
AB  - The development of artificial intelligence technologies and the growing complexity of decision-making in the management of modern production systems necessitate the collaboration of humans and AI, including teams of heterogeneous participants (for example, experts and agents operating on the basis of artificial intelligence). The paper discusses the tasks that have to be resolved to enable collaborative human-machine decision support systems and the main problems that arise during the creation of such systems. The analysis of modern results in the field of ontology-oriented neuro-symbolic artificial intelligence is carried out, primarily aimed at explaining neural network models using ontologies and at using symbolic knowledge to improve the efficiency of neural network models. A conceptual model of a collaborative human-machine decision support based on ontology-oriented neuro-symbolic artificial intelligence is proposed. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Collaborative systems
KW  - Decision support systems
KW  - Neuro-symbolic artificial intelligence
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Diallo, G.
TI  - Neuro-symbolic digital twins for precision and predictive public health
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3541
SP  - 17
EP  - 22
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177028341&partnerID=40&md5=2bdacb44a75b93c59dbe6e0aa2ddb32c
AB  - Public health prioritizes community medical conditions and population health factors. Promoting population health and preventing disease outbreaks and epidemics are the main goals. Targeting populations based on territorial factors, socio-economic and environmental determinants, and phenotypic profiles is essential for developing precise preventive or health promotion measures. Digital Twins (DTs) technology enables data acquisition, hypothesis generation, and in-silico experiments and comparisons. Thanks to Internet of Things and Artificial Intelligence, digital twins can collect a wider range of real-Time data from various sources in addition to traditional data sources like Electronic Health Records. Thus, comprehensive simulations of physical entities, their functionality, and their evolution can be created and maintained. This position paper proposes using DT technology, Public Health instruments, knowledge graphs, and AI to enable Precision and Predictive Public Health for population health. In particular, it introduces Neuro-symbolic DTs, which combine semantic reasoning supported by a knowledge graph, deep-learning s predictive power, and a DT s agility to simulate public health interventions in a virtual environment.  © 2023 Copyright for this paper by its authors.
KW  - Digital Twins
KW  - Knowledge Graphs
KW  - Neuro-symbolic AI
KW  - Precision Public Health
KW  - Data acquisition
KW  - Deep learning
KW  - Public health
KW  - Semantics
KW  - Technology transfer
KW  - Virtual reality
KW  - Disease outbreaks
KW  - Environmental determinants
KW  - Health factors
KW  - Health promotion
KW  - Knowledge graphs
KW  - Medical conditions
KW  - Neuro-symbolic AI
KW  - Population health
KW  - Precision public health
KW  - Socio-economics
KW  - Knowledge graph
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Capogrosso, L.
AU  - Mascolini, A.
AU  - Girella, F.
AU  - Skenderi, G.
AU  - Gaiardelli, S.
AU  - Dall'Ora, N.
AU  - Ponzio, F.
AU  - Fraccaroli, E.
AU  - Di Cataldo, S.
AU  - Vinco, S.
AU  - Macii, E.
AU  - Fummi, F.
AU  - Cristani, M.
TI  - Neuro-Symbolic Empowered Denoising Diffusion Probabilistic Models for Real-Time Anomaly Detection in Industry 4.0: Wild-And-Crazy-Idea Paper
PY  - 2023
T2  - Forum on Specification and Design Languages
VL  - 2023-September
DO  - 10.1109/FDL59689.2023.10272095
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175251860&doi=10.1109%2fFDL59689.2023.10272095&partnerID=40&md5=8597be2c8825fa9f3dca6d45d7706707
AB  - Industry 4.0 involves the integration of digital technologies, such as IoT, Big Data, and AI, into manufacturing and industrial processes to increase efficiency and productivity. As these technologies become more interconnected and interdependent, Industry 4.0 systems become more complex, which brings the difficulty of identifying and stopping anomalies that may cause disturbances in the manufacturing process. This paper aims to propose a diffusion-based model for real-Time anomaly prediction in Industry 4.0 processes. Using a neuro-symbolic approach, we integrate industrial ontologies in the model, thereby adding formal knowledge on smart manufacturing. Finally, we propose a simple yet effective way of distilling diffusion models through Random Fourier Features for deployment on an embedded system for direct integration into the manufacturing process. To the best of our knowledge, this approach has never been explored before. copy; 2023 IEEE. © 2023 IEEE Computer Society. All rights reserved.
KW  - Anomaly Detection
KW  - Diffusion Models
KW  - Industry 4.0
KW  - Knowledge Distillation
KW  - Neuro-symbolic AI
KW  - Detection
KW  - Diffusion
KW  - Distillation
KW  - Efficiency
KW  - Integration
KW  - Models
KW  - Paper Industry
KW  - Processes
KW  - Anomaly detection
KW  - Diffusion
KW  - Distillation
KW  - Anomaly detection
KW  - De-noising
KW  - Diffusion model
KW  - Digital technologies
KW  - Industrial processs
KW  - Knowledge distillation
KW  - Manufacturing process
KW  - Neuro-symbolic AI
KW  - Probabilistic models
KW  - Real-time anomaly detections
KW  - Industry 4.0
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - CONF
AU  - Maene, J.
AU  - Derkinderen, V.
AU  - De Raedt, L.
TI  - On the Hardness of Probabilistic Neurosymbolic Learning
PY  - 2024
T2  - Proceedings of Machine Learning Research
VL  - 235
SP  - 34203
EP  - 34218
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203816760&partnerID=40&md5=205a9ab1044a333e6ef43cd9de6149d7
AB  - The limitations of purely neural learning have sparked an interest in probabilistic neurosymbolic models, which combine neural networks with probabilistic logical reasoning. As these neurosymbolic models are trained with gradient descent, we study the complexity of differentiating probabilistic reasoning. We prove that although approximating these gradients is intractable in general, it becomes tractable during training. Furthermore, we introduce WeightME, an unbiased gradient estimator based on model sampling. Under mild assumptions, WeightME approximates the gradient with probabilistic guarantees using a logarithmic number of calls to a SAT solver. Lastly, we evaluate the necessity of these guarantees on the gradient. Our experiments indicate that the existing biased approximations indeed struggle to optimize even when exact solving is still feasible. Copyright 2024 by the author(s)
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Probabilistic logics
KW  - Biased approximation
KW  - Gradient estimator
KW  - Gradient-descent
KW  - Logical reasoning
KW  - Neural learning
KW  - Neural-networks
KW  - Probabilistic guarantees
KW  - Probabilistic reasoning
KW  - Probabilistics
KW  - SAT solvers
KW  - Neural network models
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Monaldini, A.
TI  - Neuro-Symbolic Approach for Tantrum Monitoring and Prevention in Individuals with Autism Spectrum Disorder: A Protocol for Virtual Agents
PY  - 2024
T2  - Frontiers in Artificial Intelligence and Applications 
VL  - 386
SP  - 394
EP  - 401
DO  - 10.3233/FAIA240213
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198725992&doi=10.3233%2fFAIA240213&partnerID=40&md5=2605f3486d5d0d3eb5bb78e7d404fd39
AB  - Autism Spectrum Disorder (ASD) poses unique challenges, with individuals often experiencing difficulties in emotional regulation, leading to disruptive behaviors such as tantrums. This research protocol outlines the development of an innovative system designed to monitor and prevent tantrums in individuals with ASD, employing a neuro-symbolic approach. The proposed system integrates neural networks and symbolic reasoning to improve understanding and prediction of tantrum episodes. Leveraging real-time physiological and behavioral data, collected through wearable devices and user input, the system employs machine learning algorithms to detect patterns indicative of imminent tantrum events. Furthermore, a symbolic reasoning system interprets these patterns, taking into account individualized factors. The outcomes of this study are anticipated to contribute valuable insights to the growing field of technology-assisted interventions for neurodevelopmental disorders. © 2024 The Authors.
KW  - Autism
KW  - Biosensing techniques
KW  - Human-AI interaction and collaboration
KW  - Integration of learning and reasoning
KW  - User modeling and personalisation
KW  - Diseases
KW  - E-learning
KW  - Learning systems
KW  - Machine learning
KW  - Virtual reality
KW  - Autism
KW  - Autism spectrum disorders
KW  - Biosensing technique
KW  - Human-AI interaction and collaboration
KW  - Integration of learning and reasoning
KW  - Personalizations
KW  - Symbolic reasoning
KW  - User modeling and personalization
KW  - User Modelling
KW  - Virtual agent
KW  - Learning algorithms
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Piran, F.J.
AU  - Chen, Z.
AU  - Imani, M.
AU  - Imani, F.
TI  - Privacy-Preserving Federated Learning with Differentially Private Hyperdimensional Computing
PY  - 2025
T2  - Computers and Electrical Engineering
VL  - 123
C7  - 110261
DO  - 10.1016/j.compeleceng.2025.110261
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000099792&doi=10.1016%2fj.compeleceng.2025.110261&partnerID=40&md5=1e6d03333646f675b741a3c1023142d9
AB  - Federated Learning (FL) has become a key method for preserving data privacy in Internet of Things (IoT) environments, as it trains Machine Learning (ML) models locally while transmitting only model updates. Despite this design, FL remains susceptible to threats such as model inversion and membership inference attacks, which can reveal private training data. Differential Privacy (DP) techniques are often introduced to mitigate these risks, but simply injecting DP noise into black-box ML models can compromise accuracy, particularly in dynamic IoT contexts, where continuous, lifelong learning leads to excessive noise accumulation. To address this challenge, we propose Federated HyperDimensional computing with Privacy-preserving (FedHDPrivacy), an eXplainable Artificial Intelligence (XAI) framework that integrates neuro-symbolic computing and DP. Unlike conventional approaches, FedHDPrivacy actively monitors the cumulative noise across learning rounds and adds only the additional noise required to satisfy privacy constraints. In a real-world application for monitoring manufacturing machining processes, FedHDPrivacy maintains high performance while surpassing standard FL frameworks — Federated Averaging (FedAvg), Federated Proximal (FedProx), Federated Normalized Averaging (FedNova), and Federated Optimization (FedOpt) — by up to 37%. Looking ahead, FedHDPrivacy offers a promising avenue for further enhancements, such as incorporating multimodal data fusion. © 2025 Elsevier Ltd
KW  - Differential Privacy
KW  - Explainable Artificial Intelligence
KW  - Federated Learning
KW  - Hyperdimensional Computing
KW  - Internet of Things
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Differential privacy
KW  - Black boxes
KW  - Differential privacies
KW  - Explainable artificial intelligence
KW  - Hyperdimensional computing
KW  - Inference attacks
KW  - Machine learning models
KW  - Model inversion
KW  - Model updates
KW  - Privacy preserving
KW  - Training data
KW  - Federated learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Grov, G.
AU  - Halvorsen, J.
AU  - Eckhoff, M.W.
AU  - Hansen, B.J.
AU  - Eian, M.
AU  - Mavroeidis, V.
TI  - On the Use of Neurosymbolic AI for Defending Against Cyber Attacks
PY  - 2024
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14979 LNAI
SP  - 119
EP  - 140
DO  - 10.1007/978-3-031-71167-1_7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204643431&doi=10.1007%2f978-3-031-71167-1_7&partnerID=40&md5=1584fbee22f86f772c78454c148b6a38
AB  - It is generally accepted that all cyber attacks cannot be prevented, creating a need for the ability to detect and respond to cyber attacks. Both connectionist and symbolic AI are currently being used to support such detection and response. In this paper, we make the case for combining them using neurosymbolic AI. We identify a set of challenges when using AI today and propose a set of neurosymbolic use cases we believe are both interesting research directions for the neurosymbolic AI community and can have an impact on the cyber security field. We demonstrate feasibility through two proof-of-concept experiments. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - AI
KW  - cyber security
KW  - incident detection and response
KW  - neurosymbolic AI
KW  - Anonymity
KW  - Network intrusion
KW  - Cyber security
KW  - Cyber-attacks
KW  - Incident detection
KW  - Incident response
KW  - Neurosymbolic AI
KW  - Proof of concept
KW  - Security fields
KW  - Cyber attacks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Apriceno, G.
AU  - Passerini, A.
AU  - Serafini, L.
TI  - A Neuro-Symbolic Approach for Real-World Event Recognition from Weak Supervision
PY  - 2022
T2  - Leibniz International Proceedings in Informatics, LIPIcs
VL  - 247
C7  - 12
DO  - 10.4230/LIPIcs.TIME.2022.12
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142651412&doi=10.4230%2fLIPIcs.TIME.2022.12&partnerID=40&md5=e523d482c6428d565cd3516a42238524
AB  - Events are structured entities involving different components (e.g, the participants, their roles etc.) and their relations. Structured events are typically defined in terms of (a subset of) simpler, atomic events and a set of temporal relation between them. Temporal Event Detection (TED) is the task of detecting structured and atomic events within data streams, most often text or video sequences, and has numerous applications, from video surveillance to sports analytics. Existing deep learning approaches solve TED task by implicitly learning the temporal correlations among events from data. As consequence, these approaches often fail in ensuring a consistent prediction in terms of the relationship between structured and atomic events. On the other hand, neuro-symbolic approaches have shown their capability to constrain the output of the neural networks to be consistent with respect to the background knowledge of the domain. In this paper, we propose a neuro-symbolic approach for TED in a real world scenario involving sports activities. We show how by incorporating simple knowledge involving the relative order of atomic events and constraints on their duration, the approach substantially outperforms a fully neural solution in terms of recognition accuracy, when little or even no supervision is available on the atomic events. © Gianluca Apriceno, Andrea Passerini, and Luciano Serafini.
KW  - neuro-symbolic integration
KW  - structured events
KW  - temporal event detection
KW  - Atoms
KW  - Deep learning
KW  - Security systems
KW  - Data stream
KW  - Event recognition
KW  - Events detection
KW  - Neuro-symbolic integration
KW  - Real-world
KW  - Simple++
KW  - Structured event
KW  - Symbolic integration
KW  - Temporal event detection
KW  - Temporal relation
KW  - Sports
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Lei, H.
AU  - Ge, Y.
AU  - Zhu, Q.
TI  - ADAPT: A Game-Theoretic and Neuro-Symbolic Framework for Automated Distributed Adaptive Penetration Testing
PY  - 2024
T2  - Proceedings - IEEE Military Communications Conference MILCOM
SP  - 7
EP  - 12
DO  - 10.1109/MILCOM61039.2024.10774038
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214563559&doi=10.1109%2fMILCOM61039.2024.10774038&partnerID=40&md5=70db234056907661f5adf80d0a506de1
AB  - The integration of AI into modern critical infrastructure systems, such as healthcare, has introduced new vulnerabilities that can significantly impact workflow, efficiency, and safety. Additionally, the increased connectivity has made traditional human-driven penetration testing insufficient for assessing risks and developing remediation strategies. Consequently, there is a pressing need for a distributed, adaptive, and efficient automated penetration testing framework that not only identifies vulnerabilities but also provides countermeasures to enhance security posture. This work presents ADAPT, a game-theoretic and neuro-symbolic framework for automated distributed adaptive penetration testing, specifically designed to address the unique cybersecurity challenges of AI-enabled healthcare infrastructure networks. We use a healthcare system case study to illustrate the methodologies within ADAPT. The proposed solution enables a learning-based risk assessment. Numerical experiments are used to demonstrate effective countermeasures against various tactical techniques employed by adversarial AI. © 2024 IEEE.
KW  - Artificial intelligence
KW  - Integration testing
KW  - Critical infrastructure systems
KW  - Cyber security
KW  - Game-theoretic
KW  - Healthcare infrastructure
KW  - Infrastructure networks
KW  - Penetration testing
KW  - Pressung
KW  - Remediation strategies
KW  - Testing framework
KW  - Work-flows
KW  - Risk assessment
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Onchis, D.
AU  - Istin, C.
AU  - Hogea, E.
TI  - A Neuro-Symbolic Classifier with Optimized Satisfiability for Monitoring Security Alerts in Network Traffic
PY  - 2022
T2  - Applied Sciences (Switzerland)
VL  - 12
IS  - 22
C7  - 11502
DO  - 10.3390/app122211502
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142537595&doi=10.3390%2fapp122211502&partnerID=40&md5=373374806b7169cb697cf7e309886920
AB  - We introduce in this paper a neuro-symbolic predictive model based on Logic Tensor Networks, capable of discriminating and at the same time of explaining the bad connections, called alerts or attacks, and the normal connections. The proposed classifier incorporates both the ability of deep neural networks to improve on their own through learning from experience and the interpretability of the results provided by the symbolic artificial intelligence approach. Compared to other existing solutions, we advance in the discovery of potential security breaches from a cognitive perspective. By introducing the reasoning in the model, our aim is to further reduce the human staff needed to deal with the cyber-threat hunting problem. To justify the need for shifting towards hybrid systems for this task, the design, the implementation, and the comparison of the dense neural network and the neuro-symbolic model is performed in detail. While in terms of standard accuracy, both models demonstrated similar precision, we further introduced for our model the concept of interactive accuracy as a way of querying the model results at any time coupled with deductive reasoning over data. By applying our model on the CIC-IDS2017 dataset, we reached an accuracy of 0.95, with levels of satisfiability around 0.85. Other advantages such as overfitting mitigation and scalability issues are also presented. © 2022 by the authors.
KW  - classifier
KW  - cognitive threat hunting
KW  - IT alerts
KW  - Logic Tensor Networks
KW  - neuro-symbolic model
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - CONF
AU  - Chandio, Y.
AU  - Khan, M.A.
AU  - Selialia, K.
AU  - Garcia, L.
AU  - Degol, J.
AU  - Anwar, F.M.
TI  - A Neurosymbolic Approach to Adaptive Feature Extraction in SLAM
PY  - 2024
T2  - IEEE International Conference on Intelligent Robots and Systems
SP  - 4941
EP  - 4948
DO  - 10.1109/IROS58592.2024.10802379
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216463398&doi=10.1109%2fIROS58592.2024.10802379&partnerID=40&md5=a6d00f8355fa34f5d11c5dfc9dfc5834
AB  - Autonomous robots, autonomous vehicles, and humans wearing mixed-reality headsets require accurate and reliable tracking services for safety-critical applications in dynamically changing real-world environments. However, the existing tracking approaches, such as Simultaneous Localization and Mapping (SLAM), do not adapt well to environmental changes and boundary conditions despite extensive manual tuning. On the other hand, while deep learning-based approaches can better adapt to environmental changes, they typically demand substantial data for training and often lack flexibility in adapting to new domains. To solve this problem, we propose leveraging the neurosymbolic program synthesis approach to construct adaptable SLAM pipelines that integrate the domain knowledge from traditional SLAM approaches while leveraging data to learn complex relationships. While the approach can synthesize end-to-end SLAM pipelines, we focus on synthesizing the feature extraction module. We first devise a domain-specific language (DSL) that can encapsulate domain knowledge on the essential attributes for feature extraction and the real-world performance of various feature extractors. Our neurosymbolic architecture then undertakes adaptive feature extraction, optimizing parameters via learning while employing symbolic reasoning to select the most suitable feature extractor. Our evaluations demonstrate that our approach, neurosymbolic Feature EXtraction (nFEX), yields higher-quality features. It also reduces the pose error observed for the state-of-the-art baseline feature extractors ORB and SIFT by up to 90% and up to 66%, respectively, thereby enhancing the system's efficiency and adaptability to novel environments. © 2024 IEEE.
KW  - Digital subscriber lines
KW  - Problem oriented languages
KW  - Robot applications
KW  - Robot programming
KW  - SLAM robotics
KW  - Adaptive feature extractions
KW  - Autonomous Vehicles
KW  - Domain knowledge
KW  - Environmental change
KW  - Feature extractor
KW  - Features extraction
KW  - Mixed reality
KW  - Safety critical applications
KW  - Simultaneous localization and mapping
KW  - Tracking services
KW  - Deep learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Ferreira, S.
AU  - Martins, A.
AU  - Costa, D.G.
AU  - Silva, I.
TI  - Integrating Textual Queries with AI-Based Object Detection: A Compositional Prompt-Guided Approach
PY  - 2025
T2  - Sensors
VL  - 25
IS  - 7
C7  - 2258
DO  - 10.3390/s25072258
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002468901&doi=10.3390%2fs25072258&partnerID=40&md5=d0698dc407a3641a1a1a273e9eec3ca2
AB  - While object detection and recognition have been extensively adopted by many applications in decision-making, new algorithms and methodologies have emerged to enhance the automatic identification of target objects. In particular, the rise of deep learning and language models has opened many possibilities in this area, although challenges in contextual query analysis and human interactions persist. This article presents a novel neuro-symbolic object detection framework that aligns object proposals with textual prompts using a deep learning module while enabling logical reasoning through a symbolic module. By integrating deep learning with symbolic reasoning, object detection and scene understanding are considerably enhanced, enabling complex, query-driven interactions. Using a synthetic 3D image dataset, the results demonstrate that this framework effectively generalizes to complex queries, combining simple attribute-based descriptions without explicit training on compound prompts. We present the numerical results and comprehensive discussions, highlighting the potential of our approach for emerging smart applications. © 2025 by the authors.
KW  - crossmodal reasoning
KW  - neuro-symbolic AI
KW  - prompt-guided object detection
KW  - query-driven recognition
KW  - visual-language alignment
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Deep learning
KW  - Query languages
KW  - Visual languages
KW  - Complex queries
KW  - Cross-modal
KW  - Crossmodal reasoning
KW  - Neuro-symbolic AI
KW  - Object detection and recognition
KW  - Objects detection
KW  - Prompt-guided object detection
KW  - Query-driven recognition
KW  - Textual query
KW  - Visual-language alignment
KW  - algorithm
KW  - article
KW  - decision making
KW  - deep learning
KW  - electric potential
KW  - human
KW  - language model
KW  - logical reasoning
KW  - reasoning
KW  - Structured Query Language
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Lu, Z.
AU  - Afridi, I.
AU  - Kang, H.J.
AU  - Ruchkin, I.
AU  - Zheng, X.
TI  - Surveying neuro-symbolic approaches for reliable artificial intelligence of things
PY  - 2024
T2  - Journal of Reliable Intelligent Environments
VL  - 10
IS  - 3
SP  - 257
EP  - 279
DO  - 10.1007/s40860-024-00231-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199550805&doi=10.1007%2fs40860-024-00231-1&partnerID=40&md5=a95b3e94ed90c433bc81fd5a2475e0aa
AB  - The integration of Artificial Intelligence (AI) with the Internet of Things (IoT), known as the Artificial Intelligence of Things (AIoT), enhances the devices’ processing and analysis capabilities and disrupts such sectors as healthcare, industry, and oil. However, AIoT’s complexity and scale are challenging for traditional machine learning (ML). Deep learning offers a solution but has limited testability, verifiability, and interpretability. In turn, the neuro-symbolic paradigm addresses these challenges by combining the robustness of symbolic AI with the flexibility of DL, enabling AI systems to reason, make decisions, and generalize knowledge from large datasets better. This paper reviews state-of-the-art DL models for IoT, identifies their limitations, and explores how neuro-symbolic methods can overcome them. It also discusses key challenges and research opportunities in enhancing AIoT reliability with neuro-symbolic approaches, including hard-coded symbolic AI, multimodal sensor data, biased interpretability, trading-off interpretability, and performance, complexity in integrating neural networks and symbolic AI, and ethical and societal challenges. © The Author(s) 2024.
KW  - AIoT
KW  - Interpretability
KW  - Neuro-symbolic
KW  - Testability
KW  - Verifiability
KW  - Complex networks
KW  - Internet of things
KW  - Large datasets
KW  - Analysis capabilities
KW  - Artificial intelligence of thing
KW  - Device analysis
KW  - Device processing
KW  - Healthcare industry
KW  - Interpretability
KW  - Neuro-symbolic
KW  - Processing capability
KW  - Testability
KW  - Verifiability
KW  - Deep learning
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 18
ER  -

TY  - CHAP
AU  - Waltersdorfer, L.
AU  - Breit, A.
AU  - Ekaputra, F.J.
AU  - Sabou, M.
AU  - Ekelhart, A.
AU  - Iana, A.
AU  - Paulheim, H.
AU  - Portisch, J.
AU  - Revenko, A.
AU  - Ten Teije, A.
AU  - Van Harmelen, F.
TI  - Semantic web machine learning systems: An analysis of system patterns
PY  - 2023
T2  - Frontiers in Artificial Intelligence and Applications
VL  - 369
SP  - 77
EP  - 99
DO  - 10.3233/FAIA230136
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171774325&doi=10.3233%2fFAIA230136&partnerID=40&md5=19eee17b61bca0cca5637dd0564e219c
AB  - In line with the general trend in artificial intelligence research to create intelligent systems that combine learning and symbolic techniques (a.k.a. neuro-symbolic systems), a new sub-Area has emerged that focuses on combining machine learning (ML) components with techniques developed by the Semantic Web (SW) community-Semantic Web Machine Learning (SWeML for short). Due to the rapid growth of this area and its impact on several communities in the last two decades, there is a need to better understand the space of these SWeML Systems, their characteristics, and trends. Of particular interest are the emerging variations of processing patterns used in these systems in terms of their inputs/outputs and the order of the processing units. While several such neuro-symbolic system patterns were identified previously from a large number of papers, there is currently no insight into their adoption in the field, e.g., about the completeness of the introduced system patterns, or about their usage frequency. To fill that gap, we performed a systematic study and analyzed nearly 500 papers published in the last decade in this area, where we focused on evaluating the type and frequency of such system patterns. Overall we discovered 41 different system patterns, which we categorized into six pattern types. In this chapter we detail these pattern types, exemplify their use in concrete papers and discuss their characteristics in terms of their semantic and machine learning modules. © 2023 The authors and IOS Press. All rights reserved.
KW  - Machine components
KW  - Machine learning
KW  - Paper
KW  - Semantic Web
KW  - Artificial intelligence research
KW  - General trends
KW  - Learning techniques
KW  - Machine learning systems
KW  - Machine-learning
KW  - Neuro-symbolic system
KW  - Semantic-Web
KW  - Sub-areas
KW  - Symbolic techniques
KW  - Web machines
KW  - Intelligent systems
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Kashikar, R.
TI  - Neuro-Symbolic AI for Self-Evolving Signal Processing in Autonomous Communication Systems
PY  - 2024
T2  - 2024 7th International Conference on Signal Processing and Information Security, ICSPIS 2024
DO  - 10.1109/ICSPIS63676.2024.10812626
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216711326&doi=10.1109%2fICSPIS63676.2024.10812626&partnerID=40&md5=1f57f3fa8543d6d2669b623f0285e556
AB  - The rapid advancement of autonomous systems demands highly adaptive and secure communication protocols. To address these challenges, we present a novel neuro-symbolic AI framework that enables real-time self-evolving signal processing in highly dynamic and security-sensitive autonomous communication systems. By integrating the strengths of neural networks in pattern recognition with the logical, adaptive decision-making capabilities of symbolic AI, the system autonomously optimizes communication protocols without human intervention. This approach leverages multi-scale convolutional neural networks (CNNs) for hierarchical signal feature extraction and uses symbolic AI for rule-based adaptation. Additionally, quantum key distribution (QKD) is employed to secure the evolving communication channels. Through comprehensive simulations, this system achieved a substantial improvement in signal-tonoise ratio (SNR) by 33% ± 2% and reduced bit error rate (BER) by 44% ± 3%, outperforming existing models. Furthermore, the proposed framework's ability to dynamically adapt to new environmental stimuli and secure communications in real time introduces a groundbreaking self-evolving communication system.  © 2024 IEEE.
KW  - Autonomous Communication
KW  - Autonomous Vehicles
KW  - Deep Learning
KW  - Neuro-Symbolic AI
KW  - Quantum Key Distribution (QKD)
KW  - Satellite Networks
KW  - Secure Communication
KW  - SelfEvolving Systems
KW  - Signal Processing
KW  - Symbolic Reasoning
KW  - Convolutional neural networks
KW  - Image analysis
KW  - Image annotation
KW  - Image coding
KW  - Image compression
KW  - Image thinning
KW  - Medium access control
KW  - Quantum communication
KW  - Secure communication
KW  - Autonomous communications
KW  - Autonomous Vehicles
KW  - Deep learning
KW  - Key distribution
KW  - Neuro-symbolic AI
KW  - Quantum key
KW  - Quantum key distribution
KW  - Satellite network
KW  - Selfevolving system
KW  - Signal-processing
KW  - Symbolic reasoning
KW  - Satellite communication systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Smirnova, A.
AU  - Yang, J.
AU  - Yang, D.
AU  - Cudre-Mauroux, P.
TI  - Nessy: A Neuro-Symbolic System for Label Noise Reduction
PY  - 2023
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 35
IS  - 8
SP  - 8300
EP  - 8311
DO  - 10.1109/TKDE.2022.3199570
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136846615&doi=10.1109%2fTKDE.2022.3199570&partnerID=40&md5=be66718dad5b645f7122320c77b5f9c9
AB  - Noisy labels represent one of the key issues in supervised machine learning. Existing work for label noise reduction mainly takes a probabilistic approach that infers true labels from data distributions in low-level feature spaces. Such an approach is not only limited by its capability to learn high-quality data representations, but also by the low predictive power of data distributions in inferring true classes. To address those problems, we introduce Nessy, a neuro-symbolic system that integrates deep probabilistic modeling and symbolic knowledge for label noise reduction. Our deep probabilistic model infers the true classes of data instances with noisy labels by exploiting data distributions in an underlying latent feature representation space. For data instances where inference is not reliable enough, Nessy extracts symbolic rules and ranks them according to several utility metrics. Top-ranking rules are injected into the deep probabilistic model via expectation regularization, i.e., via a posterior regularization term constraining the class distribution in the objective function. In a real deployment over multiple relation extraction tasks, we demonstrate that Nessy is able to significantly improve the state of the art, by 7% accuracy and 10.7% AUC on average.  © 1989-2012 IEEE.
KW  - deep probabilistic model
KW  - distant supervision
KW  - neuro-symbolic systems
KW  - Noise reduction
KW  - relation extraction
KW  - Data mining
KW  - Deep learning
KW  - Extraction
KW  - Noise abatement
KW  - Probabilistic logics
KW  - Supervised learning
KW  - Data distribution
KW  - Deep learning
KW  - Deep probabilistic model
KW  - Distant supervision
KW  - Features extraction
KW  - Neuro-symbolic system
KW  - Noise measurements
KW  - Probabilistic models
KW  - Relation extraction
KW  - Training data
KW  - Probability distributions
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CHAP
AU  - Bhuyan, B.P.
AU  - Ramdane-Cherif, A.
AU  - Singh, T.P.
AU  - Tomar, R.
TI  - Neuro-Symbolic Artificial Intelligence: Bridging Logic and Learning
PY  - 2025
T2  - Studies in Computational Intelligence
VL  - 1176
SP  - 1
EP  - 358
DO  - 10.1007/978-981-97-8171-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216218688&doi=10.1007%2f978-981-97-8171-3&partnerID=40&md5=c744792bbefef4148d6174c56e840dda
AB  - This book highlights and attempts to fill a crucial gap in the existing literature by providing a comprehensive exploration of the emerging field of neuro-symbolic AI. It introduces the concept of neuro-symbolic AI, highlighting its fusion of symbolic reasoning and machine learning. The book covers symbolic AI and knowledge representation, neural networks and deep learning, neuro-symbolic integration approaches, reasoning and inference techniques, applications in healthcare and robotics, as well as challenges and future directions. By combining the power of symbolic logic and knowledge representation with the flexibility of neural networks, neuro-symbolic AI offers the potential for more interpretable and trustworthy AI systems. This book is a valuable resource for researchers, practitioners, and students interested in understanding and applying neuro-symbolic AI.. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
KW  - Autonomous Systems
KW  - Computer Vision
KW  - Convolutional Neural Networks (CNNs)
KW  - Deep Learning (DL)
KW  - Long Short-Term Memory (LSTM) Networks
KW  - Machine Learning (ML)
KW  - Medical Diagnosis
KW  - Recurrent Neural Networks (RNNs)
KW  - Robotics
KW  - Symbolic Reasoning
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Jha, S.
AU  - Roy, A.
AU  - Cobb, A.
AU  - Berenbeim, A.
AU  - Bastian, N.D.
TI  - Challenges and Opportunities in Neuro-Symbolic Composition of Foundation Models
PY  - 2023
T2  - MILCOM 2023 - 2023 IEEE Military Communications Conference: Communications Supporting Military Operations in a Contested Environment
SP  - 156
EP  - 161
DO  - 10.1109/MILCOM58377.2023.10356344
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182389623&doi=10.1109%2fMILCOM58377.2023.10356344&partnerID=40&md5=296eef689ddc9a8500f849c606098743
AB  - Trustworthy, resilient, and interpretable artificial intelligence (AI) is essential for effective operation of the Internet of Things (IoT) in adversarial environments. Such a robust and interpretable AI is needed to improve tactical coordination through scalability, corroboration, and context-aware intelligence. It is crucial to have robust machine learning (ML) models with characteristics such as low-supervision adaptability, decision explanations, and adaptive inference. Pre-trained large language models (LLMs) and foundation models (FMs) address some of these challenges, but are unpredictable and cannot directly solve complex tasks in mission-critical scenarios. However, their generalization capabilities make them potential building blocks for high-assurance AI/ML systems that compose multiple FMs and LLMs. In this paper, we propose combining neural foundation models (FMs) using symbolic programs that results in a more effective AI for adversarial conditions. Neuro-symbolic composition of FMs to solve complex tasks requires interactive and unambiguous specification of the intent, task decomposition into subtasks that can be solved by individual FMs, program synthesis for composing FMs, and neuro-symbolic inference that schedules inference of different FMs and combines their results. We give examples of such neuro-symbolic programs using foundation models to solve visual question-answering tasks such as out-of-context detection. This position paper identifies the challenges and opportunities in the neuro-symbolic composition of the large language models and foundation models.  © 2023 IEEE.
KW  - Foundation Models
KW  - LLMs
KW  - Neuro-symbolic Learning
KW  - Artificial intelligence
KW  - Computational linguistics
KW  - Foundations
KW  - Internet of things
KW  - Adversarial environments
KW  - Complex task
KW  - Context-Aware
KW  - Foundation models
KW  - Language model
KW  - Large language model
KW  - Machine learning models
KW  - Neuro-symbolic learning
KW  - Symbolic learning
KW  - Tacticals
KW  - Learning systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Hazra, R.
AU  - De Raedt, L.
TI  - Deep Explainable Relational Reinforcement Learning: A Neuro-Symbolic Approach
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14172 LNAI
SP  - 213
EP  - 229
DO  - 10.1007/978-3-031-43421-1_13
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174441916&doi=10.1007%2f978-3-031-43421-1_13&partnerID=40&md5=e812aaa6e53fc6c37c0433d1b7d1b0a4
AB  - Despite its successes, Deep Reinforcement Learning (DRL) yields non-interpretable policies. Moreover, since DRL does not exploit symbolic relational representations, it has difficulties in coping with structural changes in its environment (such as increasing the number of objects). Meanwhile, Relational Reinforcement Learning inherits the relational representations from symbolic planning to learn reusable policies. However, it has so far been unable to scale up and exploit the power of deep neural networks. We propose Deep Explainable Relational Reinforcement Learning (DERRL), a framework that exploits the best of both – neural and symbolic worlds. By resorting to a neuro-symbolic approach, DERRL combines relational representations and constraints from symbolic planning with deep learning to extract interpretable policies. These policies are in the form of logical rules that explain why each decision (or action) is arrived at. Through several experiments, in setups like the Countdown Game, Blocks World, Gridworld, Traffic, and Mingrid, we show that the policies learned by DERRL are adaptable to varying configurations and environmental changes. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Deep Reinforcement Learning
KW  - Explainability
KW  - Neuro-Symbolic AI
KW  - Relational Reinforcement Learning
KW  - Deep neural networks
KW  - Deep reinforcement learning
KW  - Explainability
KW  - Learn+
KW  - Neuro-symbolic AI
KW  - Power
KW  - Reinforcement learnings
KW  - Relational reinforcement learning
KW  - Relational representations
KW  - Reusable policy
KW  - Scale-up
KW  - Reinforcement learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CHAP
AU  - Liu, X.
AU  - Lu, Z.
AU  - Mou, L.
TI  - Weakly supervised reasoning by neuro-symbolic approaches
PY  - 2023
T2  - Frontiers in Artificial Intelligence and Applications
VL  - 369
SP  - 665
EP  - 692
DO  - 10.3233/FAIA230162
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171803233&doi=10.3233%2fFAIA230162&partnerID=40&md5=cc632baf202e467d06bdced700d1ec5c
AB  - Deep learning has largely improved the performance of various natural language processing (NLP) tasks. However, most deep learning models are black-box machinery, and lack explicit interpretation. In this chapter, we will introduce our recent progress on neuro-symbolic approaches to NLP, which combines different schools of AI, namely, symbolism and connectionism. Generally, we will design a neural system with symbolic latent structures for an NLP task, and apply reinforcement learning or its relaxation to perform weakly supervised reasoning in the downstream task. Our framework has been successfully applied to various tasks, including table query reasoning, syntactic structure reasoning, information extraction reasoning, and rule reasoning. For each application, we will introduce the background, our approach, and experimental results. © 2023 The authors and IOS Press. All rights reserved.
KW  - Deep learning
KW  - Learning algorithms
KW  - Reinforcement learning
KW  - Supervised learning
KW  - Syntactics
KW  - Black boxes
KW  - Connectionism
KW  - Language processing
KW  - Latent structures
KW  - Learning models
KW  - Natural languages
KW  - Neural systems
KW  - Performance
KW  - Recent progress
KW  - Reinforcement learnings
KW  - Natural language processing systems
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Abdelzaher, T.
AU  - Bastian, N.D.
AU  - Jha, S.
AU  - Kaplan, L.
AU  - Srivastava, M.
AU  - Veeravalli, V.V.
TI  - Context-aware Collaborative Neuro-Symbolic Inference in IoBTs
PY  - 2022
T2  - Proceedings - IEEE Military Communications Conference MILCOM
VL  - 2022-November
SP  - 1053
EP  - 1058
DO  - 10.1109/MILCOM55135.2022.10017607
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147328720&doi=10.1109%2fMILCOM55135.2022.10017607&partnerID=40&md5=8e608e6e11cca6b1e23cada2619696e8
AB  - IoBTs must feature collaborative, context-aware, multi-modal fusion for real-time, robust decision-making in adversarial environments. The integration of machine learning (ML) models into IoBTs has been successful at solving these problems at a small scale (e.g., AiTR), but state-of-the-art ML models grow exponentially with increasing temporal and spatial scale of modeled phenomena, and can thus become brittle, untrustworthy, and vulnerable when interpreting large-scale tactical edge data. To address this challenge, we need to develop principles and methodologies for uncertainty-quantified neuro-symbolic ML, where learning and inference exploit symbolic knowledge and reasoning, in addition to, multi-modal and multi-vantage sensor data. The approach features integrated neuro-symbolic inference, where symbolic context is used by deep learning, and deep learning models provide atomic concepts for symbolic reasoning. The incorporation of high-level symbolic reasoning improves data efficiency during training and makes inference more robust, interpretable, and resource-efficient. In this paper, we identify the key challenges in developing context-aware collaborative neuro-symbolic inference in IoBTs and review some recent progress in addressing these gaps.  © 2022 IEEE.
KW  - Neuro-symbolic inference
KW  - robust learning
KW  - Deep learning
KW  - Learning systems
KW  - Adversarial environments
KW  - Context-Aware
KW  - Decisions makings
KW  - Machine learning models
KW  - Multi-modal fusion
KW  - Neuro-symbolic inference
KW  - Real- time
KW  - Robust decisions
KW  - Robust learning
KW  - Symbolic reasoning
KW  - Decision making
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CHAP
AU  - Di Maio, P.
TI  - Towards a Web Standard for Neuro-Symbolic Integration and Knowledge Representation Using Model Cards
PY  - 2023
T2  - Data Science with Semantic Technologies: New Trends and Future Developments
SP  - 173
EP  - 193
DO  - 10.1201/9781003310785-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190486302&doi=10.1201%2f9781003310785-9&partnerID=40&md5=db1ef741b2b381c1934806ae73c0e42c
AB  - Neural symbolic integration, in addition to its classical role in bridging symbolic and subsymbolic approaches in artificial intelligence (AI), can be leveraged to connect the shared conceptual structures in data science, the semantic web and AI, as well as to provide explicit and shared knowledge representation (KR) mechanisms to support the explainability, reliability and reproducibility of machine learning (ML). This chapter introduces and explains a novel approach to neuro-symbolic integration using a model card in the context of intelligent systems design, and presents for the first time a pragmatic approach to neuro-symbolism in AI using model cards. A systems development approach is undertaken and consideration is given to early efforts where unified languages and methods were first proposed to tackle disparate integration challenges in AI and where the relationship between knowledge representation and connectionism has been long researched. In addition to bridging symbolic and connectionist AI, integrated neuro-symbolic knowledge representation has a novel role bridging disparate but closely related knowledge domains, such as data science, semantic web and AI, considering advances in neuromorphic engineering. A model card is proposed to achieve integrated neural-symbolic knowledge representation across domains. Application scenarios in neuroscience are used to describe use cases showing how the model cards can be used. The chapter points to the development and publication of a possible web standard for neuro-symbolic integration using model cards. © 2023 CRC Press.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Sharma, N.
AU  - Aggarwal, R.K.
TI  - Ontology as a Tool to Enable Health Internet of Things Viable 5G Communication Networks
PY  - 2020
T2  - Ontology-Based Information Retrieval for Healthcare Systems
SP  - 293
EP  - 311
DO  - 10.1002/9781119641391.ch14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007264942&doi=10.1002%2f9781119641391.ch14&partnerID=40&md5=a6d931ffc1371a8a4fc4ae4cbdcb646d
AB  - This chapter is an attempt to review future IoT-based medicinal services frameworks to gather Medical Ontologies, which can be applied to generic frameworks. A few wearable or non-meddlesome sensors were exhibited and investigated, with a specific spotlight on those sensors which are observing indispensable signs of pulse, and blood oxygen levels. Emerging IoT technologies have revolutionized the communication system of the medical service industry. These advancements improve the perception of health by analyzing the variations of sampled data. IoT applications offer the open door for suppliers to have permeability to what occurs among patients’ visits and can give a few bits of knowledge into understanding medicine adherence, action levels, and essential signs. © 2020 Scrivener Publishing LLC.
KW  - Health internet of things
KW  - Health-care automation
KW  - Medical ontology
KW  - Remote health monitoring
KW  - Tele-health robotics
KW  - Biomedical engineering
KW  - mHealth
KW  - Oncology
KW  - Patient treatment
KW  - Communications networks
KW  - Generic frameworks
KW  - Health internet of thing
KW  - Health-care automation
KW  - Medical ontology
KW  - Ontology's
KW  - Remote health monitoring
KW  - Service framework
KW  - Tele-health robotic
KW  - Telehealth
KW  - Diseases
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Bohne, T.
AU  - Windler, A.-K.P.
AU  - Atzmueller, M.
TI  - A Neuro-Symbolic Approach for Anomaly Detection and Complex Fault Diagnosis Exemplified in the Automotive Domain
PY  - 2023
T2  - K-CAP 2023 - Proceedings of the 12th Knowledge Capture Conference 2023
SP  - 35
EP  - 43
DO  - 10.1145/3587259.3627546
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180370074&doi=10.1145%2f3587259.3627546&partnerID=40&md5=108e415d6020533cb9c2f12bef29cd50
AB  - This paper presents an iterative, hybrid neuro-symbolic approach for anomaly detection and complex fault diagnosis, enabling knowledge-based (symbolic) methods to complement (neural) machine learning methods and vice versa. We demonstrate an instantiation of this novel diagnosis system with applicability in a practically relevant real-world context, specifically the automotive domain. Explainability is indispensable for diagnosis and arises naturally in the system through the specific interplay of neural and symbolic methods. The presented architecture can be considered as a blueprint which is generally transferable to various diagnostic problems and domains. © 2023 ACM.
KW  - Anomaly Detection
KW  - Explainable AI
KW  - Fault Diagnosis
KW  - Knowledge Acquisition
KW  - Knowledge Representation
KW  - Neuro-Symbolic AI
KW  - Anomaly detection
KW  - Fault detection
KW  - Iterative methods
KW  - Knowledge acquisition
KW  - Knowledge representation
KW  - Learning systems
KW  - Anomaly detection
KW  - Automotive domains
KW  - Complex fault diagnosis
KW  - Explainable AI
KW  - Faults diagnosis
KW  - Knowledge based
KW  - Knowledge-representation
KW  - Machine learning methods
KW  - Neuro-symbolic AI
KW  - Symbolic methods
KW  - Failure analysis
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - An, Y.
AU  - Yu, F.R.
AU  - He, Y.
AU  - Li, J.
AU  - Chen, J.
AU  - Leung, V.C.M.
TI  - A Novel Internet of Things Web Attack Detection Architecture Based on the Combination of Symbolism and Connectionism AI
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 11
SP  - 19823
EP  - 19837
DO  - 10.1109/JIOT.2024.3369852
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186963836&doi=10.1109%2fJIOT.2024.3369852&partnerID=40&md5=2a61023e199958914405f1cd8cc7b3b5
AB  - The rapid advancement and wide application of the Internet of Things technology (IoT) have brought unprecedented convenience to people's production and life. A great number of devices are connected to the IoT network to provide various services for people, which also makes the IoT more vulnerable to various cyber attacks. This article designs a novel IoT Web attack detection architecture, which combines the powerful knowledge expression ability and high interpretability of symbolic artificial intelligence (AI) with the adaptive learning ability of connectionist AI to form a closed loop of knowledge embedding and extraction, effectively improve the detection ability of Web attacks. The architecture solves the 'black box' feature of deep learning models and can obtain knowledge from the trained detection model and add it to the training process of the new model to improve detection capabilities. It also uses the advantages of blockchain technology to realize intelligent sharing between different detection systems, solve the problem of difficult detection model updates and training data acquisition 'bottlenecks.' To better detect Web attacks, we propose a semi-supervised learning method based on an interpretable convolutional neural network (CNN) to reduce misjudgments during self-training and improve detection accuracy. Additionally, we propose a new feature method to extract the features of Web logs in IoT devices, which can help the system to detect Web attacks in IoT more quickly and accurately. Simulation results on two different data sets show that the proposed architecture and method can effectively detect Web attacks in IoT and reduce the false positive rate.  © 2014 IEEE.
KW  - Blockchain
KW  - connectionist artificial intelligence (AI)
KW  - Internet of Things (IoT)
KW  - semi-supervised learning
KW  - symbolic AI
KW  - Web attack
KW  - Data acquisition
KW  - Deep learning
KW  - Extraction
KW  - Feature extraction
KW  - Information services
KW  - Internet of things
KW  - Network architecture
KW  - Network security
KW  - Neural networks
KW  - Service oriented architecture (SOA)
KW  - Supervised learning
KW  - Block-chain
KW  - Connectionist artificial intelligence
KW  - Deep learning
KW  - Features extraction
KW  - Internet of thing
KW  - Semi-supervised learning
KW  - Soa (serviceoriented architecture)
KW  - Symbolic artificial intelligence
KW  - Web attacks
KW  - Blockchain
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Jha, S.
TI  - Lightning Talk: Trinity - Assured Neuro-symbolic Model Inspired by Hierarchical Predictive Coding
PY  - 2023
T2  - Proceedings - Design Automation Conference
VL  - 2023-July
DO  - 10.1109/DAC56929.2023.10247803
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173078158&doi=10.1109%2fDAC56929.2023.10247803&partnerID=40&md5=2db095574a2b7a2967cb0ae5a2516b80
AB  - This paper describes the core concepts and challenges in developing Trinity - a high-assurance neuro-symbolic approach to trustworthy and resilient machine learning for applications in open-world, contested, and rapidly-evolving environments. The two central concepts in Trinity are a neuro-symbolic factored world model that identifies entities, activities, and complex events, and the notion of surprise against this world model that is used for self-adaptation and learning, as well as runtime assurance. The world model is not derived purely as a bottom-up inference from sensors treating each observation as independent uncorrelated input; instead, we iteratively interleave bottom-up inference (conditioned on context) with top-down predictions and context identification using a three-layered hierarchical predictive processing (HPP) stack. Thus, the neuro-symbolic inference in Trinity is bidirectional - learning-based bottom-up pull that is uncertainty-driven and reasoning-based symbolic top-down push that is decision-driven. The progressively symbolic higher layers capture a larger context than the bottom layers finally culminating in the highest layer implemented using large language models. Any surprise arising from the mismatch between the top-down prediction and the bottom-up inference is used for the continual adaptation of Trinity. The inference in Trinity produces a factored temporal world model as the result of perception. The predictions are accompanied by a quantitative measure of surprise from the 3-layered HPP stack. This surprise corresponds to the confidence of the model in its current inference. The continuous monitoring and adaptation accompanied by risk analysis make Trinity robust to semantic adversarial perturbations and more efficiently generalizable to novelties. The hierarchical nature of Trinity also enables adaptation of the architecture to the available compute resources. © 2023 IEEE.
KW  - assurance
KW  - machine learning
KW  - predictive processing
KW  - robust learning
KW  - Forecasting
KW  - Risk analysis
KW  - Risk assessment
KW  - Semantics
KW  - Assurance
KW  - Bottom up
KW  - High assurance
KW  - Machine-learning
KW  - Predictive coding
KW  - Predictive processing
KW  - Robust learning
KW  - Symbolic modeling
KW  - Topdown
KW  - World model
KW  - Machine learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Khan, M.J.
AU  - Curry, E.
TI  - Neuro-symbolic visual reasoning for multimedia event processing: Overview, prospects and challenges
PY  - 2020
T2  - CEUR Workshop Proceedings
VL  - 2699
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097555378&partnerID=40&md5=15435877b68d1d5f376584964f90771e
AB  - Efficient multimedia event processing is a key enabler for real-time and complex decision making in streaming media. The need for expressive queries to detect high-level human-understandable spatial and temporal events in multimedia streams is inevitable due to the explosive growth of multimedia data in smart cities and internet. The recent work in stream reasoning, event processing and visual reasoning inspires the integration of visual and commonsense reasoning in multimedia event processing, which would improve and enhance multimedia event processing in terms of expressivity of event rules and queries. This can be achieved through careful integration of knowledge about entities, relations and rules from rich knowledge bases via reasoning over multimedia streams within an event processing engine. The prospects of neuro-symbolic visual reasoning within multimedia event processing are promising, however, there are several associated challenges that are highlighted in this paper. © 2020 CEUR-WS. All rights reserved.
KW  - Commonsense reasoning
KW  - Multimedia event processing
KW  - Spatiotemporal events
KW  - Video stream processing
KW  - Visual reasoning
KW  - Data streams
KW  - Decision making
KW  - Explosives detection
KW  - Knowledge management
KW  - Commonsense reasoning
KW  - Complex decision
KW  - Event-processing engine
KW  - Explosive growth
KW  - Integration of knowledge
KW  - Multimedia stream
KW  - Stream reasonings
KW  - Visual reasoning
KW  - Media streaming
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 8
ER  -

TY  - JOUR
AU  - Barbara, V.
AU  - Guarascio, M.
AU  - Leone, N.
AU  - Manco, G.
AU  - Quarta, A.
AU  - Ricca, F.
AU  - Ritacco, E.
TI  - Neuro-Symbolic AI for Compliance Checking of Electrical Control Panels
PY  - 2023
T2  - Theory and Practice of Logic Programming
VL  - 23
IS  - 4
SP  - 748
EP  - 764
DO  - 10.1017/S1471068423000170
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165047471&doi=10.1017%2fS1471068423000170&partnerID=40&md5=6cae53a1e14558f94be3a076291a2b37
AB  - Artificial Intelligence plays a main role in supporting and improving smart manufacturing and Industry 4.0, by enabling the automation of different types of tasks manually performed by domain experts. In particular, assessing the compliance of a product with the relative schematic is a time-consuming and prone-to-error process. In this paper, we address this problem in a specific industrial scenario. In particular, we define a Neuro-Symbolic approach for automating the compliance verification of the electrical control panels. Our approach is based on the combination of Deep Learning techniques with Answer Set Programming (ASP), and allows for identifying possible anomalies and errors in the final product even when a very limited amount of training data is available. The experiments conducted on a real test case provided by an Italian Company operating in electrical control panel production demonstrate the effectiveness of the proposed approach. © The Author(s), 2023. Published by Cambridge University Press.
KW  - answer set programming
KW  - automated quality control systems
KW  - computer vision
KW  - data scarcity
KW  - Compliance control
KW  - Computer control systems
KW  - Computer vision
KW  - Quality control
KW  - Answer set programming
KW  - Automated quality control system
KW  - Compliance checking
KW  - Control panels
KW  - Data scarcity
KW  - Domain experts
KW  - Electrical control
KW  - Error process
KW  - Quality control system
KW  - Smart manufacturing
KW  - Deep learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Verheyen, L.
AU  - Ekila, J.B.
AU  - Nevens, J.
AU  - Van Eecke, P.
AU  - Beuls, K.
TI  - Neuro-symbolic procedural semantics for explainable visual dialogue
PY  - 2025
T2  - PLOS ONE
VL  - 20
IS  - 5 May
C7  - e0323098
DO  - 10.1371/journal.pone.0323098
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006780710&doi=10.1371%2fjournal.pone.0323098&partnerID=40&md5=34399a5dea7d298796376a99b7075d0f
AB  - This paper introduces a novel approach to visual dialogue that is based on neuro-symbolic procedural semantics. The approach builds further on earlier work on procedural semantics for visual question answering and expands it with neuro-symbolic mechanisms that handle the challenges that are inherent to dialogue, in particular the incremental nature of the information that is conveyed. Concretely, we introduce (i) the use of a conversation memory as a data structure that explicitly and incrementally represents the information that is expressed during the subsequent turns of a dialogue, and (ii) the design of a neuro-symbolic procedural semantic representation that is grounded in both visual input and the conversation memory. We validate the methodology using the MNIST Dialog and CLEVR-Dialog benchmark challenges and achieve a question-level accuracy of 99.8% and 99.2% respectively. The methodology presented in this paper contributes to the growing body of research in artificial intelligence that tackles tasks that involve both low-level perception and high-level reasoning using a combination of neural and symbolic techniques. It thereby leads the way towards the development of conversational agents that will be able to hold more explainable, natural and coherent conversations with their human interlocutors. © 2025 Verheyen et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
KW  - Artificial Intelligence
KW  - Communication
KW  - Humans
KW  - Memory
KW  - Semantics
KW  - Article
KW  - artificial intelligence
KW  - conversation memory
KW  - human
KW  - memory
KW  - neuro symbolic procedural semantics
KW  - semantics
KW  - interpersonal communication
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Apriceno, G.
AU  - Erculiani, L.
AU  - Passerini, A.
TI  - A Neuro-Symbolic Approach for Non-Intrusive Load Monitoring
PY  - 2023
T2  - Frontiers in Artificial Intelligence and Applications
VL  - 372
SP  - 3175
EP  - 3181
DO  - 10.3233/FAIA230638
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175802717&doi=10.3233%2fFAIA230638&partnerID=40&md5=3e92e0d1c0d7a028f31be1cf632217c4
AB  - A requirement of Smart Grids is the ability to predict the energy consumption patterns of their users. In the residential domain, this is usually not feasible due to the inability of the grid to dialog with (legacy) domestic appliances. To overcome this issue Non Intrusive Load Monitoring (NILM) was introduced, a task in which a predictor is used to disaggregate household power consumption. Many of the newer approaches make use of Neural Networks to accomplish this task, due to their superior ability to detect patterns in temporal (thus sequential) data. These models unfortunately require a huge amount of data to achieve good performance, and have the tendency to overfit the training data, making them difficult to predict future consumptions. For these reasons, adapting them to optimally predict a (future) house's consumption requires expensive and often prohibitive data collection phases. We propose a solution in the form of a neuro-symbolic framework that refines neural network predictions via a constrained optimization problem modelling the characteristics of the appliances of a house. This combined approach achieves superior performance with respect to the neural network alone over two out of five appliances and comparable results for the remaining ones, without requiring further training data. © 2023 The Authors.
KW  - Constrained optimization
KW  - Electric load management
KW  - Electric power plant loads
KW  - Energy utilization
KW  - Forecasting
KW  - Smart power grids
KW  - Consumption patterns
KW  - Energy-consumption
KW  - Future consumption
KW  - Neural-networks
KW  - New approaches
KW  - Nonintrusive load monitoring
KW  - Performance
KW  - Sequential data
KW  - Smart grid
KW  - Training data
KW  - Domestic appliances
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Skvorc, T.
AU  - Lavrac, N.
AU  - Robnik-Sikonja, M.
TI  - NeSyChair: Automatic Conference Scheduling Combining Neuro-Symbolic Representations and Constrained Clustering
PY  - 2022
T2  - IEEE Access
VL  - 10
SP  - 10880
EP  - 10897
DO  - 10.1109/ACCESS.2022.3144932
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123711457&doi=10.1109%2fACCESS.2022.3144932&partnerID=40&md5=b9709fc2049b52ab0b37079915ca58ff
AB  - Creating the schedule for an academic conference is a time-consuming task. A typical conference schedule consists of sessions containing papers addressing the same research topic. To construct a schedule, conference papers must be grouped according to their research topic, and the obtained groups should fit the assigned time slots. This paper proposes an approach to automating the schedule-creation process. We use multilingual, neuro-symbolic paper representations and novel constrained clustering to group papers into clusters of predetermined size with the same topic fitting the schedule structure. In the process, we combine machine-learning, natural language processing, network analysis, and combinatorial optimization. We tested the components of the proposed approach on a newly created database of papers from six machine learning conferences, which were manually labeled by their research topics. The entire system was tested on two real-world conferences in a multilingual setting. The developed methodology is incorporated into an interactive automatic conference-scheduling system NeSyChair (Neuro-Symbolic Conference Chair), which can be used to create and improve conference schedules.  © 2013 IEEE.
KW  - Machine learning
KW  - natural language processing
KW  - optimization
KW  - supervised learning
KW  - unsupervised learning
KW  - Combinatorial optimization
KW  - Job analysis
KW  - Learning algorithms
KW  - Machine components
KW  - Machine learning
KW  - Natural language processing systems
KW  - Academic conferences
KW  - Conference papers
KW  - Constrained clustering
KW  - Features extraction
KW  - Optimisations
KW  - Research topics
KW  - Schedule
KW  - Symbolic representation
KW  - Task analysis
KW  - Time-consuming tasks
KW  - Scheduling
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Siyaev, A.
AU  - Valiev, D.
AU  - Jo, G.-S.
TI  - Interaction with Industrial Digital Twin Using Neuro-Symbolic Reasoning
PY  - 2023
T2  - Sensors
VL  - 23
IS  - 3
C7  - 1729
DO  - 10.3390/s23031729
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147895020&doi=10.3390%2fs23031729&partnerID=40&md5=b97cf12b13c087d972d23714fe00e025
AB  - Digital twins have revolutionized manufacturing and maintenance, allowing us to interact with virtual yet realistic representations of the physical world in simulations to identify potential problems or opportunities for improvement. However, traditional digital twins do not have the ability to communicate with humans using natural language, which limits their potential usefulness. Although conventional natural language processing methods have proven to be effective in solving certain tasks, neuro-symbolic AI offers a new approach that leads to more robust and versatile solutions. In this paper, we propose neuro-symbolic reasoning (NSR)—a fundamental method for interacting with 3D digital twins using natural language. The method understands user requests and contexts to manipulate 3D components of digital twins and is able to read maintenance manuals and implement installations and removal procedures autonomously. A practical neuro-symbolic dataset of machine-understandable manuals, 3D models, and user queries is collected to train the neuro-symbolic reasoning interaction mechanism. The evaluation demonstrates that NSR can execute user commands accurately, achieving 96.2% accuracy on test data. The proposed method has industrial importance since it provides the technology to perform maintenance procedures, request information from manuals, and serve as a tool to interact with complex virtual machinery using natural language. © 2023 by the authors.
KW  - aircraft maintenance education
KW  - artificial intelligence
KW  - Boeing 737
KW  - digital twin
KW  - Industry 4.0
KW  - internet of things
KW  - language understanding
KW  - neuro-symbolic AI
KW  - smart maintenance
KW  - Artificial Intelligence
KW  - Humans
KW  - Language
KW  - Natural Language Processing
KW  - Problem Solving
KW  - Technology
KW  - Aircraft
KW  - Artificial intelligence
KW  - E-learning
KW  - Industry 4.0
KW  - Learning algorithms
KW  - Maintenance
KW  - Natural language processing systems
KW  - Aircraft maintenance education
KW  - Boeing 737
KW  - Language processing
KW  - Language understanding
KW  - Natural languages
KW  - Neuro-symbolic AI
KW  - Physical world
KW  - Potential problems
KW  - Smart maintenance
KW  - Symbolic reasoning
KW  - artificial intelligence
KW  - human
KW  - language
KW  - natural language processing
KW  - problem solving
KW  - technology
KW  - Internet of things
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 14
ER  -

TY  - CONF
AU  - Ahlawat, P.
AU  - Rana, C.
TI  - A Hybrid Trusted Knowledge Infusion Recommendation System for IoT-Based Applications
PY  - 2023
T2  - Proceedings of International Conference on Contemporary Computing and Informatics, IC3I 2023
SP  - 973
EP  - 977
DO  - 10.1109/IC3I59117.2023.10397944
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185228155&doi=10.1109%2fIC3I59117.2023.10397944&partnerID=40&md5=f163c7bfb262c5101e57e94cd860342d
AB  - Technological evolutions always give substitute solutions for the betterment. In today's ubiquitous web-based informatic scenario, it is very difficult to poke the purposeful information. But Recommender Systems as information filtering systems do this very effectively and significantly. There is a wide range of recommender systems applicable in many divergent areas. Internet of Things (IoT) as a seamlessly integrated platform of cyber world and physical world contributing an important role in business world, public and private sectors, maintenance and security, researches, healthcare, manufacturing sector and transportations etc. In IoT also, Recommender Systems can be applied to feature personalized and favorites things or services to the customers. Machine learning techniques are more desirable IoT-based recommendations because they can put together the attributes like dynamicity, scalability, and trust in recommendation. In this paper, firstly we introduce IoT Recommender Systems and their contrast nature with the traditional recommendations. We also propose a new hybrid framework for IoT recommendations using a trusted knowledge infusion model. We end the paper with the discussions of the results.  © 2023 IEEE.
KW  - Internet of Things
KW  - IoT Recommender Systems
KW  - Knowledge Infusion
KW  - Machine Learning
KW  - Recommender System
KW  - Information filtering
KW  - Machine learning
KW  - Recommender systems
KW  - Divergents
KW  - Informatics
KW  - Information filtering system
KW  - Integrated platform
KW  - Internet of thing recommende system
KW  - Knowledge infusion
KW  - Machine-learning
KW  - Technological evolution
KW  - Ubiquitous Web
KW  - Web based
KW  - Internet of things
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Raza, M.A.
AU  - Malik, K.M.
AU  - Haq, I.U.
TI  - RuleBoost: A Neuro-Symbolic Framework for Robust Deepfake Detection
PY  - 2024
T2  - Proceedings - 2024 IEEE International Joint Conference on Biometrics, IJCB 2024
DO  - 10.1109/IJCB62174.2024.10744498
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211330244&doi=10.1109%2fIJCB62174.2024.10744498&partnerID=40&md5=6cc72242ce76b23a1e443af3deb5bd6d
AB  - The proliferation of user-friendly deepfake creation tools poses a serious challenge, demanding robust and adaptable detection strategies. Existing approaches primarily focus on raw data analysis or identifying learned artifacts or manual data-driven rules resulting in the mis-classification of deepfakes with distorted facial poses. These architectures also neglect the potential power of combining learned visual features with explicit rules.To address this gap, we introduce RuleBoost, a novel NeuroSymbolic AI based framework that seamlessly fuses extracted visual features with automatically learned rules. Our framework employs a scalable rule-based learning approach to extract learned rules from facial geometry such as distance, area, and angle. The extracted rules integrated with deep visual features show promising results giving state-of-the-art area-under-the-curve of 96.19% and 95.44% on WLDR and FaceForensics++ Datasets respectively, surpassing other deep learning specific methods. To figure out the difference NeuroSymbolic approach makes, we also analyze the samples misclassified by traditional DL-based architectures and correctly classified by Rule- Boosted architecture. Based on empirical evidence, we conclude that DL-based architectures struggle to accurately detect real and fake samples when facial artifacts lead to poses that deviate from standard facial positioning, while RuleBoost exhibits improved performance in the same scenario.  © 2024 IEEE.
KW  - Contrastive Learning
KW  - Areas under the curves
KW  - Classifieds
KW  - Data driven
KW  - Facial geometry
KW  - Learning approach
KW  - Potential power
KW  - Rule-based learning
KW  - State of the art
KW  - User friendly
KW  - Visual feature
KW  - Spatio-temporal data
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Dolas, A.
AU  - Bodile, R.
AU  - Kaushik, A.
AU  - Kaur, A.
AU  - Singh, R.
AU  - Chatzimisios, P.
TI  - Integrated AI and 6G Driven e-Health: Enabling Design, Challenges, and Future Prospects
PY  - 2024
T2  - 2024 IEEE Conference on Standards for Communications and Networking, CSCN 2024
SP  - 371
EP  - 376
DO  - 10.1109/CSCN63874.2024.10849692
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218207272&doi=10.1109%2fCSCN63874.2024.10849692&partnerID=40&md5=299f9a14115e6b34571f2ee9335df2a7
AB  - The next generation of wireless networks is set to leverage artificial intelligence (AI) algorithms for enhanced application support, which is currently intensifying through the fusion of modern learning techniques (e.g., symbolic AI and neural networks). Further, the fusion of these AI tools offers immense potential, addressing critical wireless use cases with a focus on driving advancements in the communication and healthcare industry. Observing these potentials, this paper explores the integration of AI with 6G networks to develop an advanced e-health system. Firstly, we provide an overview of how the fusion of symbolic AI, i.e., an advanced AI tool, enhances decision-making and cognitive modeling in e-healthcare in conjunction with the 6G network. Further, we propose an integrated 6G-neuro-symbolic AI healthcare architecture that leverages several enabling features of AI-assisted computing and 6G transmission support. Moreover, the performance of the proposed architecture has been evaluated, presenting prediction accuracy and latency. Finally, we discuss industrial and standardization challenges, offering recommendations for addressing infrastructure, scalability, and ethical concerns in AI-driven healthcare systems.  © 2024 IEEE.
KW  - 6G for e-Health
KW  - AI for Healthcare
KW  - Internet of Medical-things (IoMT)
KW  - eHealth
KW  - 6g for e-health
KW  - Artificial intelligence algorithms
KW  - Artificial intelligence for healthcare
KW  - Artificial intelligence tools
KW  - Design challenges
KW  - E health
KW  - Ehealth
KW  - Future prospects
KW  - Internet of medical-thing
KW  - Learning techniques
KW  - Electronic health record
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Melo Castillo, A.N.
AU  - Salinas Maldonado, C.
AU  - Sotelo, Á.
TI  - Towards Explainable Pedestrian Behavior Prediction: A Neuro-Symbolic Framework for Autonomous Driving
PY  - 2025
T2  - Applied Sciences (Switzerland)
VL  - 15
IS  - 11
C7  - 6283
DO  - 10.3390/app15116283
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007806809&doi=10.3390%2fapp15116283&partnerID=40&md5=78dcc35c171e439d9bf1e688b4e3488a
AB  - In the context of autonomous driving, predicting pedestrian behavior is a critical component for enhancing road safety. Currently, the focus of such predictions extends beyond accuracy and reliability, placing increasing emphasis on the explainability and interpretability of the models. This research presents a novel neuro-symbolic approach that integrates deep learning with fuzzy logic to develop a pedestrian behavior predictor. The proposed model leverages a set of explainable features and utilizes a fuzzy inference system to determine whether a pedestrian is likely to cross the street. The pipeline was trained and evaluated using both the Pedestrian Intention Estimation (PIE) and Joint Attention for Autonomous Driving (JAAD) datasets. The results provide experimental insights into achieving greater explainability in pedestrian behavior prediction. Additionally, the proposed method was applied to assess the data selection process through a series of experiments, leading to a set of guidelines and recommendations for data selection, feature engineering, and explainability. © 2025 by the authors.
KW  - autonomous driving
KW  - dataset selection
KW  - explainability
KW  - feature selection
KW  - interpretability
KW  - neuro-symbolic
KW  - pedestrian behavior prediction
KW  - Deep neural networks
KW  - Fuzzy neural networks
KW  - Autonomous driving
KW  - Behavior prediction
KW  - Data Selection
KW  - Dataset selections
KW  - Explainability
KW  - Features selection
KW  - Interpretability
KW  - Neuro-symbolic
KW  - Pedestrian behavior
KW  - Pedestrian behavior prediction
KW  - Pedestrian safety
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Ferfoglia, I.
AU  - Saveri, G.
AU  - Nenzi, L.
AU  - Bortolussi, L.
TI  - ECATS: Explainable-by-Design Concept-Based Anomaly Detection for Time Series
PY  - 2024
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14980 LNAI
SP  - 175
EP  - 191
DO  - 10.1007/978-3-031-71170-1_16
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204915977&doi=10.1007%2f978-3-031-71170-1_16&partnerID=40&md5=606aa2423b86aa3125eb65cad19e819b
AB  - Deep learning methods for time series have already reached excellent performances in both prediction and classification tasks, including anomaly detection. However, the complexity inherent in Cyber Physical Systems (CPS) creates a challenge when it comes to explainability methods. To overcome this inherent lack of interpretability, we propose ECATS, a concept-based neuro-symbolic architecture where concepts are represented as Signal Temporal Logic (STL) formulae. Leveraging kernel-based methods for STL, concept embeddings are learnt in an unsupervised manner through a cross-attention mechanism. The network makes class predictions through these concept embeddings, allowing for a meaningful explanation to be naturally extracted for each input. Our preliminary experiments with simple CPS-based datasets show that our model is able to achieve great classification performance while ensuring local interpretability. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - Anomaly detection
KW  - Concept-based learning
KW  - CPS
KW  - STL
KW  - Adversarial machine learning
KW  - Anomaly detection
KW  - Cyber Physical System
KW  - Deep learning
KW  - Embedded systems
KW  - Network embeddings
KW  - Temporal logic
KW  - Anomaly detection
KW  - Concept-based
KW  - Concept-based learning
KW  - Cybe-physical systems
KW  - Cyber-physical systems
KW  - Design concept
KW  - Embeddings
KW  - Interpretability
KW  - Signal temporal logic
KW  - Times series
KW  - Time series
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Shi, T.
AU  - Zhang, H.
AU  - Cui, S.
AU  - Liu, J.
AU  - Gu, Z.
AU  - Wang, Z.
AU  - Yan, X.
AU  - Liu, Q.
TI  - Stochastic neuro-fuzzy system implemented in memristor crossbar arrays
PY  - 2024
T2  - Science Advances
VL  - 10
IS  - 12
C7  - eadl3135
DO  - 10.1126/sciadv.adl3135
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188876633&doi=10.1126%2fsciadv.adl3135&partnerID=40&md5=e2a19634e2dc8349d156fab45e54afed
AB  - Neuro-symbolic artificial intelligence has garnered considerable attention amid increasing industry demands for high-performance neural networks that are interpretable and adaptable to previously unknown problem domains with minimal reconfiguration. However, implementing neuro-symbolic hardware is challenging due to the complexity in symbolic knowledge representation and calculation. We experimentally demonstrated a memristor-based neuro-fuzzy hardware based on TiN/TaOx/HfOx/TiN chips that is superior to its silicon-based counterpart in terms of throughput and energy efficiency by using array topological structure for knowledge representation and physical laws for computing. Intrinsic memristor variability is fully exploited to increase robustness in knowledge representation. A hybrid in situ training strategy is proposed for error minimizing in training. The hardware adapts easier to a previously unknown environment, achieving ~6.6 times faster convergence and ~6 times lower error than deep learning. The hardware energy efficiency is over two orders of magnitude greater than field-programmable gate arrays. This research greatly extends the capability of memristor-based neuromorphic computing systems in artificial intelligence. © 2024 American Association for the Advancement of Science. All rights reserved.
KW  - Deep learning
KW  - Energy efficiency
KW  - Field programmable gate arrays (FPGA)
KW  - Fuzzy inference
KW  - Fuzzy neural networks
KW  - Fuzzy systems
KW  - Memristors
KW  - Stochastic systems
KW  - silicon
KW  - Crossbar arrays
KW  - Knowledge-representation
KW  - Memristor
KW  - Neural-networks
KW  - Neuro-Fuzzy
KW  - Neurofuzzy system
KW  - Performance
KW  - Problem domain
KW  - Stochastics
KW  - Symbolic knowledge
KW  - article
KW  - artificial intelligence
KW  - controlled study
KW  - deep learning
KW  - fuzzy system
KW  - in-law
KW  - memristor
KW  - nerve cell network
KW  - pharmaceutics
KW  - Knowledge representation
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Hashemi, N.
AU  - Williams, S.
AU  - Hoxha, B.
AU  - Prokhorov, D.
AU  - Fainekos, G.
AU  - Deshmukh, J.
TI  - LB4TL: A Smooth Semantics for Temporal Logic to Train Neural Feedback Controllers
PY  - 2024
T2  - IFAC-PapersOnLine
VL  - 58
IS  - 11
SP  - 183
EP  - 188
DO  - 10.1016/j.ifacol.2024.07.445
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203065126&doi=10.1016%2fj.ifacol.2024.07.445&partnerID=40&md5=f78187a01936fabdbf4cf80fec9a6cd9
AB  - This paper presents a framework for training neural network (NN)-based feedback controllers for autonomous agents with deterministic nonlinear dynamics to satisfy task objectives and safety constraints expressed in discrete-time Signal Temporal Logic (DT-STL). Control synthesis that uses the robustness semantics of DT-STL poses challenges due to its non-convexity, non-differentiability, and recursive definition, in particular when it is used to train NN-based controllers. We introduce a smooth neuro-symbolic computation graph to encode DT-STL robustness to represent a smooth approximation of the robustness, enabling the use of powerful stochastic gradient descent and backpropagation-based optimization for training. Our approximation guarantees that it lower bounds the robustness value of a given DT-STL formula, and shows orders of magnitude improvement over existing smooth approximations when applied to control synthesis. We demonstrate our approach on planning to satisfy complex spatio-temporal and sequential tasks, and show scalability with formula complexity.  © 2024 The Authors. This is an open access article under the CC BY-NC-ND license.
KW  - Learning
KW  - Neural Networks
KW  - Nonlinear Control
KW  - Smoothing
KW  - STL
KW  - Adaptive control systems
KW  - Control system synthesis
KW  - Discrete time control systems
KW  - Feedback control
KW  - Graph neural networks
KW  - Nonlinear control systems
KW  - Nonlinear feedback
KW  - Robustness (control systems)
KW  - Stochastic control systems
KW  - Control synthesis
KW  - Discrete-time signals
KW  - Feedback controller
KW  - Learning
KW  - Neural feedback
KW  - Neural-networks
KW  - Non linear control
KW  - Smooth approximation
KW  - Smoothing
KW  - STL
KW  - Temporal logic
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Zheng, H.
AU  - Liu, T.
AU  - Zheng, H.
AU  - Zuo, D.
AU  - Bao, J.
AU  - Wang, S.
TI  - Neural-symbolic system for multimodal visual reasoning towards digital twin
ST  - 数字孪生多模态视觉推理的神经-符号系统
PY  - 2024
T2  - Jisuanji Jicheng Zhizao Xitong/Computer Integrated Manufacturing Systems, CIMS
VL  - 30
IS  - 5
SP  - 1571
EP  - 1586
DO  - 10.13196/j.cims.2024.0098
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196509274&doi=10.13196%2fj.cims.2024.0098&partnerID=40&md5=787d584d48d9a40d217d2bcb308c97af
AB  - Faced with the complexities of fusing heterogeneous multimodal visual data in digital twins, a novel neuro-symbolic approach for combining the analytical capabilities of deep learning with the structured reasoning of symbolic intelligence was proposed. This approach employed deep neural networks to analyze the visual data in real-time and supplemented autonomous management of complex reasoning processes by the knowledge and event-response rules stored in a symbolic system. To enhance the system's adaptability for the physical world changes, an augmented reasoning mechanism integrating multimodal information with external knowledge was proposed. This mechanism effectively consolidated real-time sensor data with information from historical knowledge bases to support more accurate and rational decision-making. The efficacy of the proposed method was demonstrated through a case study on the disassembly of retired lithium batteries, and its capability to achieve high accuracy in identifying and analyzing multimodal data was illustrated. Furthermore, the coherent and logical operational recommendations based on the reasoning capabilities were generated, which significantly improved disassembly efficiency and safety. © 2024 CIMS. All rights reserved.
KW  - digital twin
KW  - lithium battery disassembly
KW  - multi-modal
KW  - neural-symbolic system
KW  - visual reasoning
KW  - Deep neural networks
KW  - Information management
KW  - Lithium batteries
KW  - Autonomous managements
KW  - Event-response
KW  - Lithium battery disassembly
KW  - Multi-modal
KW  - Neural-symbolic systems
KW  - Real- time
KW  - Reasoning process
KW  - Symbolic systems
KW  - Visual data
KW  - Visual reasoning
KW  - Decision making
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Wang, B.
AU  - De Gortari Briseno, J.
AU  - Han, L.
AU  - Phillips, H.
AU  - Craighead, J.
AU  - Purman, B.
AU  - Kaplan, L.
AU  - Srivastava, M.
TI  - Adapting Complex Event Detection to Perceptual Domain Shifts
PY  - 2024
T2  - Proceedings - IEEE Military Communications Conference MILCOM
DO  - 10.1109/MILCOM61039.2024.10773796
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214579531&doi=10.1109%2fMILCOM61039.2024.10773796&partnerID=40&md5=b4ecf8554fe6ea4d23b84281e85fa38e
AB  - Human decision-making, as well as control of autonomous systems, have deployed deep learning models for detecting complex events from unstructured sensory data. However, the strong performance of these models is restricted to events with short intervals of time and space due to the limited context memory of their architectures. Thus, detecting events that transpire over long periods of time with multiple spatially distant sensor sources (known as complex events) remains challenging for these purely neural-based methods, particularly as environmental conditions and object appearances change. In recent years, neurosymbolic approaches have been proposed that use both neural-based perception and symbolic reasoning for capturing complex events. However, these approaches still face issues of adaptation to perceptual domain shift in complex events. We address these problems in the context of a prototype neurosymbolic system called DANCER, which performs Domain Adaptation and Neurosymbolic inference in Complex Event Reasoning. DANCER aims to provide domain adaptation in a post-deployment setting while minimizing runtime user burden for annotation. To enable training and evaluation of DANCER, we also provide a physics-based synthetic sensor data generator to create videos given complex scenario specifications. We evaluate DANCER on a dataset of generated synthetic data. We show that DANCER yields a 48% increase in accuracy of complex event detection using domain adaptation while significantly reducing the annotation time of our synthetic complex events by up to 2.7x, demonstrating DANCER's ability to effectively detect complex events under perceptual domain shift. © 2024 IEEE.
KW  - Contrastive Learning
KW  - Network security
KW  - Spatio-temporal data
KW  - Complex event detection
KW  - Complex events
KW  - Decision control
KW  - Domain adaptation
KW  - Human decision-making
KW  - Learning models
KW  - Perceptual domain
KW  - Performance
KW  - Sensory data
KW  - Short-interval
KW  - Deep learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Liang, C.
AU  - Sun, Y.
AU  - Thomas, C.K.
AU  - Mohjazi, L.
AU  - Saad, W.
TI  - Semantic Communication for the Internet of Sounds: Architecture, Design Principles, and Challenges
PY  - 2025
T2  - IEEE Wireless Communications
DO  - 10.1109/MWC.013.2400344
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003554088&doi=10.1109%2fMWC.013.2400344&partnerID=40&md5=ddb3ab1d245bc5806d816db3eb0027c9
AB  - The Internet of Sounds (IoS) combines sound sensing, processing, and transmission techniques, enabling collaboration among diverse sound devices. To achieve a perceptual quality of sound synchronization in the IoS, it is necessary to precisely synchronize three critical factors: sound quality, timing, and behavior control. However, conventional bit-oriented communication, which focuses on bit reproduction, may not be able to fulfill these synchronization requirements under dynamic channel conditions. One promising approach to address the synchronization challenges of the IoS is relying on semantic communication (SC) that can capture and leverage the logical relationships in its source data. Consequently, in this article, we propose an IoS-centric SC framework with a transceiver design. The designed encoder extracts semantic information from diverse sources by leveraging neuro-symbolic AI and then transmits it to IoS listeners. For low-bandwidth scenarios, the encoder selectively distills important semantic information to reduce transmission latency for timing synchronization. At the receiver's end, the decoder reconstructs sounds and integrates them by leveraging semantic-aware reasoning, which helps achieve sound quality synchronization. Moreover, we present simulation results in a case study to validate the effectiveness of our framework. Finally, we explore several open issues on mathematical models, resource allocation, and cross-layer protocols. © 2002-2012 IEEE.
KW  - Acoustic devices
KW  - Radio transceivers
KW  - Architecture designs
KW  - Design challenges
KW  - Design Principles
KW  - Processing technique
KW  - Semantic communication
KW  - Semantics Information
KW  - Sensing techniques
KW  - Sound architecture
KW  - Sound Quality
KW  - Transmission techniques
KW  - Resource allocation
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Djenouri, Y.
AU  - Belbachir, A.N.
AU  - Belhadi, A.
AU  - Michalak, T.
TI  - Neurosymbolic Visual Transform Based on Logic Tensor Network for Defect Detection
PY  - 2025
T2  - Lecture Notes in Computer Science
VL  - 15626 LNCS
SP  - 18
EP  - 34
DO  - 10.1007/978-3-031-92805-5_2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006891059&doi=10.1007%2f978-3-031-92805-5_2&partnerID=40&md5=30ce9b7f57255c3ffc1d8fb5b4cb2113
AB  -  In this study, we explore the integration of visual transformers and logic tensor networks for defect detection in industrial inspections. Visual transformers excel in capturing visual patterns within high-dimensional image data, while logic tensor networks enable the incorporation of logical reasoning and domain knowledge into the learning process. This neurosymbolic AI approach enhances defect detection by leveraging visual transformer’s robust feature extraction capabilities and logic tensor networks’ ability to encode expert knowledge through logical rules. We evaluate our method on industrial MVTec AD dataset, demonstrating improved accuracy and interpretability compared to traditional deep learning models. Our findings underscore the effectiveness of combining visual transformer and logic tensor network within a neurosymbolic framework for tackling the complexities of defect detection in real-world environments. The code is available at https://github.com/YousIA/NSViT-LTN/. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
KW  - Defect Detection
KW  - Industrial Inspection
KW  - Logic Tensor Network
KW  - Neurosymbolic AI
KW  - Visual Transformers
KW  - Deep neural networks
KW  - Feature Selection
KW  - Defect detection
KW  - Excel
KW  - High-dimensional images
KW  - Image data
KW  - Industrial inspections
KW  - Logic tensor network
KW  - Logical reasoning
KW  - Neurosymbolic AI
KW  - Visual pattern
KW  - Visual transformer
KW  - Leak detection
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Karunaratne, G.
AU  - Hersche, M.
AU  - Cherubini, G.
AU  - Sebastian, A.
AU  - Rahimi, A.
TI  - Few-shot continual learning based on vector symbolic architectures
PY  - 2023
T2  - Compendium of Neurosymbolic Artificial Intelligence
SP  - 522
EP  - 546
DO  - 10.3233/FAIA230156
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172815654&doi=10.3233%2fFAIA230156&partnerID=40&md5=0201eca1e6d289c5773aac8748cf6fb5
AB  - Vector Symbolic Architecture (VSA) is a powerful computing model that is built on a rich algebra in which all representations-from atomic to composite structures-are high-dimensional holographic distributed vectors of the same, fixed dimensionality. VSA is mainly characterized by the following intriguing properties: (i) quasi-orthogonality of a randomly chosen vector to other random vectors with very high probability, aka concentration of measure; (ii) exponential growth of the number of such quasi-orthogonal vectors with the dimensionality, which provides a sufficiently large capacity to accommodate novel concepts over time; (iii) availability of these vectors to be composed, decomposed, probed, and transformed in various ways using a set of well-defined operations. Motivated by these properties, this chapter presents a summary of recently developed methodologies on the integration of VSA with deep neural networks that enabled impactful applications to few-shot [1] and continual [2, 3] learning. Resorting to VSAbased embedding allows deep neural networks to quickly learn from few training samples by storing them in an explicit memory, where many more class categories can be continually expressed in the abstract vector space of VSA with fixed dimensions, without causing interference among the learned classes. Experiments on various image datasets show that the considered neuro-symbolic AI approach outperforms pure deep neural network baselines with remarkable accuracy, scalability, and compute/memory efficiency. © 2023 The authors and IOS Press. All rights reserved.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Trifan, M.
AU  - Ionescu, B.
AU  - Ionescu, D.
TI  - A Real Time Self-Generating Control for AI Platforms
PY  - 2024
T2  - SACI 2024 - 18th IEEE International Symposium on Applied Computational Intelligence and Informatics, Proceedings
SP  - 599
EP  - 604
DO  - 10.1109/SACI60582.2024.10619873
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202343013&doi=10.1109%2fSACI60582.2024.10619873&partnerID=40&md5=05ae3464c7e34fb23602eeb940f08068
AB  - Recent advancements in hardware and software implementations of Artificial Intelligence have sparked a multitude of revolutionary applications in the theory and implementation of AI algorithms and tools. Significant new developments have been driven by the application of the Transformer concept in the fields of Large Language Models (LLMs), Reinforcement Learning, and other areas. This in turn led to capturing long-range dependencies and contextual information based on data. More recently, strong positions in the AI research community, around the proper implementations and usage of certain Machine Learning (ML) applications, have been thoroughly debated. However, it is very much known, that ChatGPT and other like platforms, such as Llama, or large GNNs, suffer from a series of black-box drawbacks out of which the”factual accuracy”,”halucinations”,”overgeneralization” and others open loop LLMs were reported in the literature. This paper presents an Autonomic Computing (AC) closed-loop architecture that manages and gathers data from user prompts via a DOMifire module. The DOMifire acts as the sensor element of the LLM AC system, referred to as the Plant. This data is logically compared by an Expert System (ES), which serves as the core of the Autonomic Manager in the AC loop of the LLM, with the data obtained from the LLM's output-in this case, the responses generated by ChatGPT. After a reduced number of iterations, the results are evaluated using a Mean Absolute Scaled Error (MASE) metric. In the context of a time series, this process results in a stable set of sentences or rules produced by the Knowledge Base module. An example, in which the”Time Series” of AutoGluOn illustrates the AC - AI interactions for a complementary contributions to a more robust AI platform. An example of the interaction AC-AI is given in the Conclusion section of this paper. © 2024 IEEE.
KW  - AutoGluon
KW  - AutoML
KW  - Autonomic Computing
KW  - ChatGPT
KW  - Large Language Models
KW  - Machine Learning
KW  - PlantUML
KW  - Adversarial machine learning
KW  - Chatbots
KW  - Problem oriented languages
KW  - Reinforcement learning
KW  - Autogluon
KW  - Automl
KW  - Autonomic Computing
KW  - ChatGPT
KW  - Language model
KW  - Large language model
KW  - Machine-learning
KW  - Plantuml
KW  - Real- time
KW  - Times series
KW  - Expert systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Yadav, P.
AU  - Salwala, D.
AU  - Sudharsan, B.
AU  - Curry, E.
TI  - GNOSIS-query-driven multimodal event processing for unstructured data streams
PY  - 2021
T2  - Middleware 2021 Demos and Posters - Proceedings of the 2021 International Middleware Conference Demos and Posters
SP  - 16
EP  - 17
DO  - 10.1145/3491086.3492475
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121423280&doi=10.1145%2f3491086.3492475&partnerID=40&md5=c8c63be2af6069c82bafffeefcf221e4
AB  - This paper presents GNOSIS, an event processing engine to detect complex event patterns over multimodal data streams. GNOSIS follows a query-driven approach where users can write complex event queries using Multimodal Event Processing Language (MEPL). The system models incoming multimodal data into an evolving Multimodal Event Knowledge Graph (MEKG) using an ensemble of deep neural network (DNN) and machine learning (ML) models and applies a neuro-symbolic approach for event matching. GNOSIS follows a serverless paradigm where its different components act as independent microservices and can be deployed across different nodes with optimized edge support. The paper demonstrates two multimodal use case queries from Occupational Health and Safety and Accessibility domain.  © 2021 Owner/Author.
KW  - event processing
KW  - event queries
KW  - multimodal
KW  - Complex networks
KW  - Data handling
KW  - Industrial hygiene
KW  - Knowledge graph
KW  - Complex events
KW  - Data stream
KW  - Event pattern
KW  - Event Processing
KW  - Event query
KW  - Event-processing engine
KW  - Multi-modal
KW  - Multimodal data streams
KW  - Query-driven approach
KW  - Unstructured data
KW  - Deep neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
TI  - Proceedings of the 2023 Forum on Specification and Design Languages, FDL 2023
PY  - 2023
T2  - Forum on Specification and Design Languages
VL  - 2023-September
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175236012&partnerID=40&md5=d1a8e5b6a6ff2350878ada7524a180d8
AB  - The proceedings contain 14 papers. The topics discussed include: PLiNIO: a user-friendly library of gradient-based methods for complexity-aware DNN optimization; hybrid PTX analysis for GPU accelerated CNN inferencing aiding computer architecture design; neuro-symbolic empowered denoising diffusion probabilistic models for real-time anomaly detection in industry 4.0; satellite payload design for optimized thermal management using a distributed processor system; virtual prototype driven application specific hardware optimization; secure programming platform for edge-based IoT; formal methods-based optimization of dataflow models with translation to synchronous models; VIR2EM: virtualization and remotization for resilient and efficient manufacturing; and enhancing compiler-driven HDL design with automatic waveform analysis.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Demidovskij, A.V.
AU  - Babkin, E.A.
TI  - Integrated neurosymbolic decision support systems: problems and opportunities
PY  - 2021
T2  - Business Informatics
VL  - 15
IS  - 3
SP  - 7
EP  - 23
DO  - 10.17323/2587-814X.2021.3.7.23
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117521014&doi=10.17323%2f2587-814X.2021.3.7.23&partnerID=40&md5=842b1fb7e333d00d89eb79eb8cfa30b6
AB  - The current problem of developing new kinds of decision support systems for different categories of management personnel is addressed in this study. A critical feature of such systems is their distributed and decentralized nature, which enables the construction of next-generation information systems in the form of Multi-Agent Systems, Internet of Things, or Fog Computing Architectures. Parallel models of the dynamics of artificial neural networks are produced under such realistic circumstances, demonstrating their potential for addressing a variety of issues. The purpose of this study is to conduct a critical analysis of the problem of integrating Artificial Neural Networks with decision support systems using a corpus of relevant scholarly literature. To tackle this question, the Design Science Research methodology was considered. According to this methodology, a literary search strategy was established, scientific literature was collected and analyzed, and key comparisons between different solutions were emphasized. The study resulted in the presentation of the most important findings, outstanding issues, and potential areas of fundamental and applied solutions. A consistent trend toward the development of decision support systems based on integrated neural-network methods has been observed, which is efficient and cost-effective since it enables the creation of distributed and trainable decision support systems. © 2021 The Author(s).
KW  - Artificial intelligence
KW  - Decision support systems
KW  - Linguistic decision-making
KW  - Multi-criteria decision-making
KW  - Neurosymbolic systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Moon, J.
TI  - Plugin framework-based neuro-symbolic grounded task planning for multi-agent system
PY  - 2021
T2  - Sensors
VL  - 21
IS  - 23
C7  - 7896
DO  - 10.3390/s21237896
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119720244&doi=10.3390%2fs21237896&partnerID=40&md5=adc01d4c87fe34ea03d3da2b145dcd8a
AB  - As the roles of robots continue to expand in general, there is an increasing demand for research on automated task planning for a multi-agent system that can independently execute tasks in a wide and dynamic environment. This study introduces a plugin framework in which multiple robots can be involved in task planning in a broad range of areas by combining symbolic and connectionist approaches. The symbolic approach for understanding and learning human knowledge is useful for task planning in a wide and static environment. The network-based connectionist approach has the advantage of being able to respond to an ever-changing dynamic environment. A planning domain definition language-based planning algorithm, which is a symbolic approach, and the cooperative– competitive reinforcement learning algorithm, which is a connectionist approach, were utilized in this study. The proposed architecture is verified through a simulation. It is also verified through an experiment using 10 unmanned surface vehicles that the given tasks were successfully executed in a wide and dynamic environment. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.
KW  - Cooperative–competitive teaming
KW  - Multi agent reinforcement learning
KW  - Neuro-symbolic
KW  - Planning domain definition language
KW  - Task planning
KW  - Algorithms
KW  - Computer Simulation
KW  - Humans
KW  - Language
KW  - Neural Networks, Computer
KW  - Learning algorithms
KW  - Reinforcement learning
KW  - Robot programming
KW  - Unmanned surface vehicles
KW  - Automated tasks
KW  - Connectionist approach
KW  - Cooperative–competitive teaming
KW  - Dynamic environments
KW  - Multi-agent reinforcement learning
KW  - Multiple-robots
KW  - Neuro-symbolic
KW  - Planning domain definition language
KW  - Plug-ins
KW  - Task planning
KW  - algorithm
KW  - computer simulation
KW  - human
KW  - language
KW  - Multi agent systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Alonso, R.S.
TI  - Deep symbolic learning and semantics for an explainable and ethical artificial intelligence
PY  - 2021
T2  - Advances in Intelligent Systems and Computing
VL  - 1239 AISC
SP  - 272
EP  - 278
DO  - 10.1007/978-3-030-58356-9_30
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091480696&doi=10.1007%2f978-3-030-58356-9_30&partnerID=40&md5=672234b1e7c2ef4a70311d0e0ac8dff6
AB  - The main objective of this research is to investigate new hybrid neuro-symbolic algorithms for the construction of an open-source Deep Symbolic Learning framework that allows the training and application of explainable and ethical Deep Learning models. This framework will be supported by an ontology and a layer model in which it is taken into account which user is responsible for interpreting each of the output results according to his or her role, considering, also, the ethical implications of those results. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2021.
KW  - Deep Learning
KW  - Deep Symbolic Learning
KW  - Ethical artificial intelligence
KW  - Explainable artificial intelligence
KW  - Interpretable machine learning
KW  - Application programs
KW  - Deep learning
KW  - Open source software
KW  - Philosophical aspects
KW  - Semantics
KW  - Ethical implications
KW  - Layer model
KW  - Learning models
KW  - Open sources
KW  - Symbolic algorithms
KW  - Symbolic learning
KW  - Ambient intelligence
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Alsaif, K.
AU  - Albeshri, A.
AU  - Khemakhem, M.
AU  - Eassa, F.
TI  - Healthcare 4.0: A Large Language Model-Based Blockchain Framework for Medical Device Fault Detection and Diagnostics
PY  - 2025
T2  - International Journal of Advanced Computer Science and Applications
VL  - 16
IS  - 4
SP  - 980
EP  - 992
DO  - 10.14569/IJACSA.2025.0160495
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004068703&doi=10.14569%2fIJACSA.2025.0160495&partnerID=40&md5=5e44bcbf96c39f48c79f768dc5925162
AB  - This paper introduces a novel framework integrating Large Language Models (LLMs) with blockchain technology for medical device fault detection and diagnostics in Healthcare 4.0 environments. The proposed framework addresses key challenges, including real-time fault detection, data security, and automated diagnostics through a multi-layered architecture incorporating Internet of Things (IoT) integration, blockchain-based security, and LLM-driven diagnostics. Experimental evaluations demonstrate substantial improvements in diagnostic accuracy and response time while maintaining stringent security standards and regulatory compliance. The system provides enhanced fault detection with real-time monitoring capabilities and secure maintenance record management for smart healthcare. Comparative analysis of different LLMs and traditional Machine Learning (ML) methods shows that Deepseek-R1:7b achieved 97.6% classification accuracy, while O3-mini reached 90.4% and 91.2% in diagnosis accuracy and problem identification, respectively. Claude demonstrated the highest technical accuracy (98.4%), while Traditional ML excelled in processing time (11.7) and processing rate (10.68). Deepseek-R1:7b’s offline capabilities ensure stringent security, privacy, and confidentiality with restricted connectivity, making it particularly suitable for sensitive healthcare applications where data protection is paramount. © (2025), (Science and Information Organization). All rights reserved.
KW  - blockchain technology
KW  - fault detection
KW  - Healthcare 4.0
KW  - IoT healthcare security
KW  - Large Language Models
KW  - machine learning
KW  - medical device diagnostics
KW  - smart healthcare
KW  - Anesthetics
KW  - Diagnosis
KW  - Vaccines
KW  - Block-chain
KW  - Blockchain technology
KW  - Device diagnostics
KW  - Faults detection
KW  - Healthcare 4.0
KW  - Internet of thing healthcare security
KW  - Language model
KW  - Large language model
KW  - Machine-learning
KW  - Medical device diagnostic
KW  - Medical Devices
KW  - Smart healthcare
KW  - Records management
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
TI  - 23rd International Conference of the Italian Association for Artificial Intelligence, AIxIA 2024
PY  - 2025
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 
VL  - 15450 LNAI
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215701776&partnerID=40&md5=f50880624ac7fb3d5504443badcc2adb
AB  - The proceedings contain 25 papers. The special focus in this conference is on Italian Association for Artificial Intelligence. The topics include: A Novel Approach for Leveraging Agent-Based Experts on Large Language Models to Enable Data Sharing Among Heterogeneous IoT Devices in Agriculture; an Extensive Empirical Analysis of Macro-actions for Numeric Planning; feature Selection on Contextual Embedding Pushing the Sparseness; neuro-Symbolic Integration for Open Set Recognition in Network Intrusion Detection; MM-IGLU-IT: Multi-modal Interactive Grounded Language Understanding in Italian; IDADA: A Blended Inductive-Deductive Approach for Data Augmentation; HaWANet: Road Scene Understanding with Multi-modal Sensor Data Using Height-Width-Driven Attention Network; hybrid Classification of European Legislation Using Sustainable Development Goals; supporting Decision-Making for City Management Through Automated Planning and Execution; NutriWell: An Explainable Ontology-Based FoodAI Service for Nutrition and Health Management; regular Clocks for Temporal Task Specifications in Reinforcement Learning; a Real-Time Support with Haptic Feedback for Safer Driving Using Monocular Camera; relating Explanations with the Inductive Biases of Deep Graph Networks; integrating Temporal Planning and Knowledge Representation to Generate Personalized Touristic Itineraries; ASR Systems Under Acoustic Challenges: A Multilingual Study; automating Resume Analysis: Knowledge Graphs via Prompt Engineering; combined Text-Visual Attention Models for Robot Task Learning and Execution; ICE: An Evaluation Metric to Assess Symbolic Knowledge Quality; hierarchical Knowledge Extraction from Opaque Machine Learning Predictors; on Different Symbolic Music Representations for Algorithmic Composition Approaches Based on Neural Sequence Models; DR-Minerva: A Multimodal Language Model Based on Minerva for Diagnostic Information Retrieval; REPAIR Platform: Robot-AidEd PersonAlIzed Rehabilitation; Integrating Classical Planners with GPT-Based Planning Policies.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Kumar, A.
AU  - Sangwan, S.R.
AU  - Arora, A.
AU  - Menon, V.G.
TI  - Depress-DCNF: A deep convolutional neuro-fuzzy model for detection of depression episodes using IoMT
PY  - 2022
T2  - Applied Soft Computing
VL  - 122
C7  - 108863
DO  - 10.1016/j.asoc.2022.108863
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129495729&doi=10.1016%2fj.asoc.2022.108863&partnerID=40&md5=ab4757fe2cbc1ae144fabb8666e0d572
AB  - Discernible patterns of a person's daily activities can be utilized to detect behavioral symptomatology of mental illness at early stages. Wearable Internet of Medical Things (IoMT) devices with sensors that collect motion data and provide objective measures of physical activity can help to better monitor and detect potential episodes related to the mental health conditions at earlier, more treatable stages. This research puts forward a neuro-symbolic model which uses learnable parameters with integrated knowledge for detection of depression episodes using IoMT based actigraphic input. A novel deep fuzzy model, Depress-DCNF is a hybrid of convolutional neural network (CNN) and an adaptive neuro fuzzy inference system (ANFIS) where CNN is used to extract high-level features from the motor activity recordings which are eventually combined with the discriminative statistical features to produce an optimized feature map. This optimized feature map is finally used to train the ANFIS model which accurately performs the depression classification task. The model is validated on the Depresjon benchmark dataset and compares favorably to state-of-the-art approach giving a superior performance accuracy of 85.10%. © 2022 Elsevier B.V.
KW  - Convolutional neural network
KW  - Depression
KW  - Fuzzy inference system
KW  - IoMT
KW  - Motor activity
KW  - Benchmarking
KW  - Convolution
KW  - Convolutional neural networks
KW  - Diagnosis
KW  - Diseases
KW  - Fuzzy inference
KW  - Fuzzy neural networks
KW  - Adaptive neuro-fuzzy inference
KW  - Convolutional neural network
KW  - Daily activity
KW  - Depression
KW  - Feature map
KW  - Fuzzy inference systems
KW  - Internet of medical thing
KW  - Motor activity
KW  - Neuro-fuzzy inference systems
KW  - Neuro-fuzzy modeling
KW  - Fuzzy systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 30
ER  -

TY  - JOUR
AU  - Gill, S.S.
AU  - Wu, H.
AU  - Patros, P.
AU  - Ottaviani, C.
AU  - Arora, P.
AU  - Pujol, V.C.
AU  - Haunschild, D.
AU  - Parlikad, A.K.
AU  - Cetinkaya, O.
AU  - Lutfiyya, H.
AU  - Stankovski, V.
AU  - Li, R.
AU  - Ding, Y.
AU  - Qadir, J.
AU  - Abraham, A.
AU  - Ghosh, S.K.
AU  - Song, H.H.
AU  - Sakellariou, R.
AU  - Rana, O.
AU  - Rodrigues, J.J.P.C.
AU  - Kanhere, S.S.
AU  - Dustdar, S.
AU  - Uhlig, S.
AU  - Ramamohanarao, K.
AU  - Buyya, R.
TI  - Modern computing: Vision and challenges
PY  - 2024
T2  - Telematics and Informatics Reports
VL  - 13
C7  - 100116
DO  - 10.1016/j.teler.2024.100116
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185190962&doi=10.1016%2fj.teler.2024.100116&partnerID=40&md5=0ca01b5eb9cef22b9f78c055409f3313
AB  - Over the past six decades, the computing systems field has experienced significant transformations, profoundly impacting society with transformational developments, such as the Internet and the commodification of computing. Underpinned by technological advancements, computer systems, far from being static, have been continuously evolving and adapting to cover multifaceted societal niches. This has led to new paradigms such as cloud, fog, edge computing, and the Internet of Things (IoT), which offer fresh economic and creative opportunities. Nevertheless, this rapid change poses complex research challenges, especially in maximizing potential and enhancing functionality. As such, to maintain an economical level of performance that meets ever-tighter requirements, one must understand the drivers of new model emergence and expansion, and how contemporary challenges differ from past ones. To that end, this article investigates and assesses the factors influencing the evolution of computing systems, covering established systems and architectures as well as newer developments, such as serverless computing, quantum computing, and on-device AI on edge devices. Trends emerge when one traces technological trajectory, which includes the rapid obsolescence of frameworks due to business and technical constraints, a move towards specialized systems and models, and varying approaches to centralized and decentralized control. This comprehensive review of modern computing systems looks ahead to the future of research in the field, highlighting key challenges and emerging trends, and underscoring their importance in cost-effectively driving technological progress. © 2024 The Authors
KW  - Artificial Intelligence
KW  - Cloud computing
KW  - Computing
KW  - Edge AI
KW  - Edge computing
KW  - Machine learning
KW  - Modern computing
KW  - Quantum computing
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 109
ER  -

TY  - CONF
AU  - Wan, Z.
AU  - Liu, C.-K.
AU  - Ibrahim, M.
AU  - Yang, H.
AU  - Spetalnick, S.
AU  - Krishna, T.
AU  - Raychowdhury, A.
TI  - H3DFact: Heterogeneous 3D Integrated CIM for Factorization with Holographic Perceptual Representations
PY  - 2024
T2  - Proceedings -Design, Automation and Test in Europe, DATE
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196553958&partnerID=40&md5=769101826c13e1484b8632d44ee7f402
AB  - Disentangling attributes of various sensory signals is central to human-like perception and reasoning and a critical task for higher-order cognitive and neuro-symbolic AI systems. An elegant approach to represent this intricate factorization is via high-dimensional holographic vectors drawing on brain-inspired vector symbolic architectures. However, holographic factorization involves iterative computation with high-dimensional matrix-vector multiplications and suffers from non-convergence problems. In this paper, we present H3DFact, a heterogeneous 3D integrated in-memory compute engine capable of efficiently factorizing high-dimensional holographic representations. H3DFact exploits the computation-in-superposition capability of holographic vectors and the intrinsic stochasticity associated with memristive-based 3D compute-in-memory. Evaluated on large-scale factorization and perceptual problems, H3DFact demonstrates superior capability in factorization accuracy and operational capacity by up to five orders of magnitude, with 5.5 x compute density, 1.2 x energy efficiency improvements, and 5.9 x less silicon footprint compared to iso-capacity 2D designs. © 2024 EDAA.
KW  - Cognitive systems
KW  - Energy efficiency
KW  - Holography
KW  - Sensory perception
KW  - Vectors
KW  - AI systems
KW  - Brain-inspired
KW  - Critical tasks
KW  - High-dimensional
KW  - High-order
KW  - Higher-dimensional
KW  - Higher-order
KW  - Human like
KW  - Perceptual representations
KW  - Sensory signals
KW  - Factorization
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Sowinski, P.
AU  - Lacalle, I.
AU  - Vano, R.
AU  - Palau, C.E.
TI  - Autonomous Choreography of WebAssembly Workloads in the Federated Cloud-Edge-IoT Continuum
PY  - 2023
T2  - 2023 IEEE 12th International Conference on Cloud Networking, CloudNet 2023
SP  - 454
EP  - 459
DO  - 10.1109/CloudNet59005.2023.10490045
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191249915&doi=10.1109%2fCloudNet59005.2023.10490045&partnerID=40&md5=42323b13068eea33f42f8862fd4c4843
AB  - The concept of the federated Cloud-Edge-IoT continuum promises to alleviate many woes of current systems, improving resource use, energy efficiency, quality of service, and more. However, this continuum is still far from being realized in practice, with no comprehensive solutions for developing, deploying, and managing continuum-native applications. Breakthrough innovations and novel system architectures are needed to cope with the ever-increasing heterogeneity and the multi-stakeholder nature of computing resources. This work proposes a novel architecture for choreographing workloads in the continuum, attempting to address these challenges. The architecture tackles this issue comprehensively, spanning from the workloads themselves, through networking and data exchange, up to the orchestration and choreography mechanisms. The concept emphasizes the use of varied AI techniques, enabling autonomous and intelligent management of resources and workloads. Open standards are also a key part of the proposition, making it possible to fully engage third parties in multi-stakeholder scenarios. Although the presented architecture is promising, much work is required to realize it in practice. To this end, the key directions for future research are outlined. © 2023 IEEE.
KW  - computing continuum
KW  - orchestration
KW  - scheduler
KW  - WebAssembly
KW  - Architecture
KW  - Computer architecture
KW  - Energy efficiency
KW  - Green computing
KW  - Internet of things
KW  - Quality of service
KW  - Breakthrough innovations
KW  - Computing continuum
KW  - Current system
KW  - Federated clouds
KW  - Multi-stakeholder
KW  - Orchestration
KW  - Quality-of-service
KW  - Resource use
KW  - Scheduler
KW  - Webassembly
KW  - Electronic data interchange
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Menon, I.U.
AU  - Babu Kumaravelu, V.
AU  - Kumar, V.C.
AU  - Rammohan, A.
AU  - Chinnadurai, S.
AU  - Venkatesan, R.
AU  - Hai, H.
AU  - Selvaprabhu, P.
TI  - AI-Powered IoT: A Survey on Integrating Artificial Intelligence With IoT for Enhanced Security, Efficiency, and Smart Applications
PY  - 2025
T2  - IEEE Access
VL  - 13
SP  - 50296
EP  - 50339
DO  - 10.1109/ACCESS.2025.3551750
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001851669&doi=10.1109%2fACCESS.2025.3551750&partnerID=40&md5=e780b3e06098a53fd3c8c37b5e5a4d72
AB  - The Internet of Things (IoT) and artificial intelligence (AI) enabled IoT is a significant paradigm that has been proliferating to new heights in recent years. IoT is a smart technology in which the physical objects or the things that are ubiquitously around us are networked and linked to the internet to deliver new services and enhance efficiency. The primary objective of the IoT is to connect all the physical objects or the things of the world under a common infrastructure, allowing humans to control them and get timely, frequent updates on their status. These things or devices connected to IoT generate, gather and process a massive volume of binary data. This massive volume of data generated from these devices is analyzed and learned by AI algorithms and techniques that aid in providing users with better services. Thus, AI-enabled IoT or artificial IoT (AIoT) is a hybrid technology that merges AI with IoT and is capable of simplifying complicated and strenuous tasks with ease and efficiency. The various machine learning (ML) and deep learning (DL) algorithms in IoT are necessary to ensure the IoT network’s improved security and confidentiality. Furthermore, this paper also surveys the various architectures that form the backbone of IoT and AIoT. Moreover, the myriad state-of-the-art ML and DL-based approaches for securing IoT, including detecting anomalies/intrusions, authentication and access control, attack detection and mitigation, preventing distributed denial of service (DDoS) attacks, and analyzing malware in IoT, are also enlightened. In addition, this work also reviews the role of AIoT in optimizing network efficiency, securing IoT infrastructures, and addressing key challenges. Furthermore, it explores cutting-edge technologies like blockchain, 6G-enabled AIoT, federated learning (FL), and hyperdimensional (HD) computing, indicating their potential in advancing IoT and AIoT-driven applications within sectors like healthcare, autonomous systems, and industrial automation. Therefore, based on the plethora of prevailing significant works, the objective of this manuscript is to provide a comprehensive survey that expounds on AIoT in terms of security, architecture, applications, emerging technologies, and challenges. © 2013 IEEE.
KW  - 6G
KW  - AIoT
KW  - artificial intelligence
KW  - blockchain
KW  - Internet of Things
KW  - IoT security
KW  - machine learning
KW  - Access control
KW  - Adversarial machine learning
KW  - Denial-of-service attack
KW  - 6g
KW  - Artificial intelligence blockchain
KW  - Block-chain
KW  - Emerging technologies
KW  - Internet of thing security
KW  - Machine-learning
KW  - Physical objects
KW  - Security application
KW  - Smart applications
KW  - Smart technology
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Saha, S.S.
AU  - Sandha, S.S.
AU  - Srivastava, M.
TI  - Machine Learning for Microcontroller-Class Hardware: A Review
PY  - 2022
T2  - IEEE Sensors Journal
VL  - 22
IS  - 22
SP  - 21362
EP  - 21390
DO  - 10.1109/JSEN.2022.3210773
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138710107&doi=10.1109%2fJSEN.2022.3210773&partnerID=40&md5=570682abe461f01ef515eb00d5023265
AB  - The advancements in machine learning (ML) opened a new opportunity to bring intelligence to the low-end Internet-of-Things (IoT) nodes, such as microcontrollers. Conventional ML deployment has high memory and computes footprint hindering their direct deployment on ultraresource-constrained microcontrollers. This article highlights the unique requirements of enabling onboard ML for microcontroller-class devices. Researchers use a specialized model development workflow for resource-limited applications to ensure that the compute and latency budget is within the device limits while still maintaining the desired performance. We characterize a closed-loop widely applicable workflow of ML model development for microcontroller-class devices and show that several classes of applications adopt a specific instance of it. We present both qualitative and numerical insights into different stages of model development by showcasing several use cases. Finally, we identify the open research challenges and unsolved questions demanding careful considerations moving forward.  © 2001-2012 IEEE.
KW  - Feature projection
KW  - Internet of Things
KW  - machine learning (ML)
KW  - microcontrollers
KW  - model compression
KW  - neural architecture search (NAS)
KW  - neural networks
KW  - optimization
KW  - sensors
KW  - TinyML
KW  - Budget control
KW  - Controllers
KW  - Data structures
KW  - Internet of things
KW  - Learning systems
KW  - Machine learning
KW  - Computational modelling
KW  - Feature projection
KW  - Hardware
KW  - Machine-learning
KW  - Model compression
KW  - Neural architecture search
KW  - Neural architectures
KW  - Neural-networks
KW  - Optimisations
KW  - Random access memory
KW  - Tinyml
KW  - Microcontrollers
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 128
ER  -

TY  - JOUR
AU  - Capitanelli, A.
AU  - Mastrogiovanni, F.
TI  - A framework for neurosymbolic robot action planning using large language models
PY  - 2024
T2  - Frontiers in Neurorobotics
VL  - 18
C7  - 1342786
DO  - 10.3389/fnbot.2024.1342786
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196261608&doi=10.3389%2ffnbot.2024.1342786&partnerID=40&md5=8e086edb7d554143eb243c52e3d27f01
AB  - Symbolic task planning is a widely used approach to enforce robot autonomy due to its ease of understanding and deployment in engineered robot architectures. However, techniques for symbolic task planning are difficult to scale in real-world, highly dynamic, human-robot collaboration scenarios because of the poor performance in planning domains where action effects may not be immediate, or when frequent re-planning is needed due to changed circumstances in the robot workspace. The validity of plans in the long term, plan length, and planning time could hinder the robot's efficiency and negatively affect the overall human-robot interaction's fluency. We present a framework, which we refer to as Teriyaki, specifically aimed at bridging the gap between symbolic task planning and machine learning approaches. The rationale is training Large Language Models (LLMs), namely GPT-3, into a neurosymbolic task planner compatible with the Planning Domain Definition Language (PDDL), and then leveraging its generative capabilities to overcome a number of limitations inherent to symbolic task planners. Potential benefits include (i) a better scalability in so far as the planning domain complexity increases, since LLMs' response time linearly scales with the combined length of the input and the output, instead of super-linearly as in the case of symbolic task planners, and (ii) the ability to synthesize a plan action-by-action instead of end-to-end, and to make each action available for execution as soon as it is generated instead of waiting for the whole plan to be available, which in turn enables concurrent planning and execution. In the past year, significant efforts have been devoted by the research community to evaluate the overall cognitive capabilities of LLMs, with alternate successes. Instead, with Teriyaki we aim to providing an overall planning performance comparable to traditional planners in specific planning domains, while leveraging LLMs capabilities in other metrics, specifically those related to their short- and mid-term generative capabilities, which are used to build a look-ahead predictive planning model. Preliminary results in selected domains show that our method can: (i) solve 95.5% of problems in a test data set of 1,000 samples; (ii) produce plans up to 13.5% shorter than a traditional symbolic planner; (iii) reduce average overall waiting times for a plan availability by up to 61.4%. Copyright © 2024 Capitanelli and Mastrogiovanni.
KW  - AI
KW  - generative
KW  - GPT
KW  - human-robot interaction
KW  - large language model
KW  - neurosymbolic
KW  - PDDL
KW  - task planning
KW  - Computational linguistics
KW  - Man machine systems
KW  - Robot programming
KW  - Statistical tests
KW  - Generative
KW  - GPT
KW  - Humans-robot interactions
KW  - Language model
KW  - Large language model
KW  - Neurosymbolic
KW  - Planning domain definition language
KW  - Planning domains
KW  - Task planner
KW  - Task planning
KW  - Article
KW  - ChatGPT
KW  - computer model
KW  - computer simulation
KW  - human
KW  - language
KW  - learning algorithm
KW  - long short term memory network
KW  - machine learning
KW  - man machine interaction
KW  - neurosymbolic robot action planning
KW  - planning
KW  - training
KW  - transfer of learning
KW  - Human robot interaction
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Saha, S.S.
AU  - Du, Y.
AU  - Sandha, S.S.
AU  - Garcia, L.A.
AU  - Jawed, M.K.
AU  - Srivastava, M.
TI  - Inertial Navigation on Extremely Resource-Constrained Platforms: Methods, Opportunities and Challenges
PY  - 2023
T2  - 2023 IEEE/ION Position, Location and Navigation Symposium, PLANS 2023
SP  - 708
EP  - 723
DO  - 10.1109/PLANS53410.2023.10139997
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162869043&doi=10.1109%2fPLANS53410.2023.10139997&partnerID=40&md5=090e1380122f00dfd0231688f93b2372
AB  - Inertial navigation provides a small footprint, low-power, and low-cost pathway for localization in GPS-denied environments on extremely resource-constrained Internet-of-Things (IoT) platforms. Traditionally, application-specific heuristics and physics-based kinematic models are used to mitigate the curse of drift in inertial odometry. These techniques, albeit lightweight, fail to handle domain shifts and environmental non-linearities. Recently, deep neural-inertial sequence learning has shown superior odometric resolution in capturing non-linear motion dynamics without human knowledge over heuristic-based methods. These AI-based techniques are data-hungry, suffer from excessive resource usage, and cannot guarantee following the underlying system physics. This paper highlights the unique methods, opportunities, and challenges in porting real-time AI-enhanced inertial navigation algorithms onto IoT platforms. First, we discuss how platform-aware neural architecture search coupled with ultra-lightweight model backbones can yield neural-inertial odometry models that are 31-134 x smaller yet achieve or exceed the localization resolution of state-of-the-art AI-enhanced techniques. The framework can generate models suitable for locating humans, animals, underwater sensors, aerial vehicles, and precision robots. Next, we showcase how techniques from neurosymbolic AI can yield physics-informed and interpretable neural-inertial navigation models. Afterward, we present opportunities for fine-tuning pre-trained odometry models in a new domain with as little as 1 minute of labeled data, while discussing inexpensive data collection and labeling techniques. Finally, we identify several open research challenges that demand careful consideration moving forward.  © 2023 IEEE.
KW  - Bayesian
KW  - dead-reckoning
KW  - inertial
KW  - kalman filtering
KW  - neural architecture search
KW  - neural networks
KW  - neurosym-bolic
KW  - odometry
KW  - platform-aware
KW  - sequence learning
KW  - TinyML
KW  - Air navigation
KW  - Antennas
KW  - Bayesian networks
KW  - Inertial navigation systems
KW  - Internet of things
KW  - Kinematics
KW  - Learning systems
KW  - Network architecture
KW  - Robots
KW  - Bayesian
KW  - Dead reckoning
KW  - Inertial
KW  - Kalman-filtering
KW  - Neural architecture search
KW  - Neural architectures
KW  - Neural-networks
KW  - Neurosym-bolic
KW  - Odometry
KW  - Platform-aware
KW  - Sequence learning
KW  - Tinyml
KW  - Heuristic methods
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Chowdhary, M.
AU  - Lilienthal, D.
AU  - Saha, S.S.
AU  - Palle, K.C.
TI  - AutoML for On-Sensor Tiny Machine Learning
PY  - 2023
T2  - IEEE Sensors Letters
VL  - 7
IS  - 11
C7  - 6008504
SP  - 1
EP  - 4
DO  - 10.1109/LSENS.2023.3327914
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177036431&doi=10.1109%2fLSENS.2023.3327914&partnerID=40&md5=f6de2d5b3349e718037fad90d5b55606
AB  - Sensors with embedded machine learning core (MLC) ena-ble ultra-low-power, low latency, and intelligent inferences at the extreme edge. However, deploying performant machine learning (ML) models within the resource bounds of MLC is challenging. This letter presents an automatic ML framework that trains and deploys ML models on the MLC embedded in the iNEMO inertial measurement units. Given a labeled inertial sensor dataset, the framework automatically selects the best set of features, filters, and window size to apply to the dataset from a search space of supported MLC parameters. The framework then trains a decision tree or random forest within the resource bounds of the MLC and generates the register configuration file to deploy the trained ML model on sensor with MLC capability. For human activity recognition, the framework achieves 93% test accuracy under 1 mW of power, which is 41× lower than an ARM Cortex-M4 implementation. The framework also enables on-sensor fall detection with 95% test accuracy under 0.3 mW of power.  © 2017 IEEE.
KW  - feature selection
KW  - filter selection
KW  - inertial measurement unit (IMU)
KW  - machine learning core (MLC)
KW  - Sensor applications
KW  - tinyml
KW  - Feature Selection
KW  - Features selection
KW  - Filter selection
KW  - Inertial measurement unit
KW  - Inertial measurements units
KW  - Machine learning core
KW  - Machine learning models
KW  - Machine-learning
KW  - Resource bounds
KW  - Sensor applications
KW  - Tinyml
KW  - Decision trees
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - JOUR
AU  - Curry, E.
AU  - Salwala, D.
AU  - Dhingra, P.
AU  - Pontes, F.A.
AU  - Yadav, P.
TI  - Multimodal Event Processing: A Neural-Symbolic Paradigm for the Internet of Multimedia Things
PY  - 2022
T2  - IEEE Internet of Things Journal
VL  - 9
IS  - 15
SP  - 13705
EP  - 13724
DO  - 10.1109/JIOT.2022.3143171
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123310192&doi=10.1109%2fJIOT.2022.3143171&partnerID=40&md5=0bf409ab711cb0f9129fd6f218ec4702
AB  - With the Internet of Multimedia Things (IoMT) becoming a reality, new approaches are needed to process real-time multimodal event streams. Existing approaches to event processing have limited consideration for the challenges of multimodal events, including the need for complex content extraction, and increased computational and memory costs. This article explores event processing as a basis for processing real-time IoMT data. This article introduces the multimodal event processing (MEP) paradigm, which provides a formal basis for native approaches to neural multimodal content analysis (i.e., computer vision, linguistics, and audio) with symbolic event processing rules to support real-time queries over multimodal data streams using the multimodal event processing language to express single, primitive multimodal, and complex multimodal event patterns. The content of multimodal streams is represented using multimodal event knowledge graphs to capture the semantic, spatial, and temporal content of the multimodal streams. The approach is implemented and evaluated within a MEP engine using single and multimodal queries achieving near real-time performance with a throughput of 30 frames processed per second (fps) and subsecond latency of 0.075-0.30 s for video streams of 30 fps input rate. Support for high input stream rates (45 fps) is achieved through content-aware load-shedding techniques with a 127X latency improvement resulting in only a minor decrease in accuracy.  © 2014 IEEE.
KW  - Data management and analytics
KW  - event processing
KW  - Internet of Multimedia Things (IoMT)
KW  - service middleware and platform
KW  - Computer hardware description languages
KW  - Data mining
KW  - Distributed computer systems
KW  - Information management
KW  - Interactive computer systems
KW  - Internet of things
KW  - Media streaming
KW  - Middleware
KW  - Real time systems
KW  - Semantics
KW  - Computing infrastructures
KW  - Data stream
KW  - Event Processing
KW  - Internet of multimedium thing.
KW  - Multi-modal
KW  - Real - Time system
KW  - Real- time
KW  - Service middlewares
KW  - Service platforms
KW  - Streaming medium
KW  - Engines
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 20
ER  -

TY  - JOUR
AU  - Bök, P.-B.
AU  - Micucci, D.
TI  - The future of human and animal digital health platforms
PY  - 2024
T2  - Journal of Reliable Intelligent Environments
VL  - 10
IS  - 3
SP  - 245
EP  - 256
DO  - 10.1007/s40860-024-00232-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199500158&doi=10.1007%2fs40860-024-00232-0&partnerID=40&md5=5c33f75d2db70674d3f756bc53225523
AB  - Electronic Health (eHealth) has emerged as a pivotal driver of change in modern healthcare, reshaping the way medical information is collected, processed, and utilized. e-health includes digital solutions aimed at improving healthcare delivery, management, and accessibility. The Internet of Medical Things (IoMT) is specifically focused on establishing connections between medical devices and sensors to gather and transmit health-related data. Its primary objective is to enhance healthcare by facilitating real-time monitoring, employing data analytics, and integrating intelligent medical devices. The IoMT and, more broadly, eHealth are yielding positive outcomes, prompting their expanding application into the animal domain. Recent technological advancements facilitate the integration of health platforms, fostering a connection between human and animal health for improved well-being. This article introduces a conceptual framework that synthesizes the main activities in the medial data acquisition-processing pipeline. The framework has been derived from an analysis of the state of the art in the field of the IoMT in human healthcare. Furthermore, the article explores the application of eHealth concepts in the animal domain. Addressing both human and animal health, the paper summarizes the outstanding issues that need to be addressed for the full integration of these technologies into daily life. © The Author(s) 2024.
KW  - Animal health
KW  - eHealth
KW  - Human health
KW  - IoMT
KW  - Platform
KW  - Veterinary
KW  - Animal health
KW  - E health
KW  - Ehealth
KW  - Electronic health
KW  - Human health
KW  - Internet of medical thing
KW  - Medical Devices
KW  - Medical information
KW  - Platform
KW  - Veterinary
KW  - Electronic health record
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Skinner, L.T.
AU  - Johnson, M.A.
TI  - Bayesian Networks for Interpretable and Extensible Multi-Sensor Fusion
PY  - 2024
T2  - Proceedings of SPIE - The International Society for Optical Engineering
VL  - 13206
C7  - 1320603
DO  - 10.1117/12.3028532
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213526250&doi=10.1117%2f12.3028532&partnerID=40&md5=3eb0b8aa90a1942ed14c8b7f99836802
AB  - In response to the broad range of threats experienced across the battlespace, modern defense systems have trended toward high levels of interconnectedness on the assumption that information from systems spanning numerous domains will be fused at the speed of relevance. One regime emblematic of these types of challenges is that of modern air defense, in which threats are increasing in sophistication and numerosity. To ensure the success of next generation defense systems, we need solutions where legacy and next generation sensors coexist and cohesively integrate information across domains and sources. Neural network-based approaches have demonstrated significant capabilities in dealing with complex data processing and fusion systems, however, in the context of safety critical defense systems there are various limitations that hinder their deployment. In particular, the lack of explainable outputs, the need for large amounts of data, which is typically lacking or severely limited in defense settings, and their high computational costs make NN-based solutions unsuitable. Often overlooked are more traditional and intuitive machine learning techniques such as Bayesian networks. The attributes of Bayesian networks such flexibility, ease of use, lightweight computational needs, and innate explainability and reasoning capabilities has already led to their successful application in air defense for target tracking, identification, and intent classification. These same attributes also make Bayesian networks suitable for use in high level multi-sensor fusion. In this work we showcase the feasibility of using Bayesian networks as an extensible and dynamic multi-sensor fusion system to perform reasoning over any number of disparate black-box approaches, as well as their utility in producing more reliable, trustable, and interpretable results than any individual sensor system operating independently. We also demonstrate the ability of Bayesian networks to produce compelling results without incurring the computational overhead and difficulties associated with interpreting the results of large neural network-based approaches. © 2024 SPIE.
KW  - Bayesian networks
KW  - behavior analysis
KW  - explainable AI
KW  - intent classification
KW  - Multi-source data fusion
KW  - object recognition
KW  - Aircraft detection
KW  - Information fusion
KW  - Military rockets
KW  - Network security
KW  - Sensor data fusion
KW  - Bayesia n networks
KW  - Behavior analysis
KW  - Defence systems
KW  - Explainable AI
KW  - Intent classification
KW  - Multi-sensor fusion
KW  - Multi-source data fusion
KW  - Multi-Sources
KW  - Objects recognition
KW  - Source data
KW  - Fighter aircraft
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Yan, S.
AU  - Binbin, W.
AU  - Xiaohu, Y.
AU  - Tinghui, L.
AU  - Shanshan, Z.
AU  - Daojing, H.
AU  - Guisong, Y.
AU  - Sammy, C.
TI  - Review of Firmware Homology Detection: a System Aspect
PY  - 2021
T2  - Proceedings - 2021 IEEE 6th International Conference on Data Science in Cyberspace, DSC 2021
SP  - 556
EP  - 563
DO  - 10.1109/DSC53577.2021.00088
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128773779&doi=10.1109%2fDSC53577.2021.00088&partnerID=40&md5=5f086d4fbd420ec1d827f6c42080f111
AB  - In recent years, Internet of Things (IoT) devices have received extensive attention and can be seen everywhere in daily life. Attacks against firmware vulnerabilities are becoming more and more frequent. Homology analysis technology is a hot topic in recent years. Firmware vulnerability analysis based on homology analysis can classify the firmware of different versions or even different devices, and detect the vulnerabilities in the firmware by detecting the homology of the open source library. This paper provides a literature review of firmware homology detection. Firstly, the background of firmware vulnerability analysis and the research status of homology detection at home and abroad are briefly introduced. Then, under the source code based homology analysis technology, according to whether it chooses to use the intermediate form to explain the source code and the different intermediate forms, three different homology analysis technologies based on text, token and structure are divided, and the three technologies are compared horizontally. Then, in the non source code based homology analysis technology, the overall process of homology detection based on binary files is introduced, as well as the main technologies such as byte stream comparison and reverse analysis. Finally, various homology analysis methods are analyzed and compared from the aspects of efficiency and accuracy, and the research focus and direction in this field are summarized and prospected.  © 2021 IEEE.
KW  - firmware
KW  - homology
KW  - Internet of Things
KW  - summary and analysis
KW  - Internet of things
KW  - Open source software
KW  - Daily lives
KW  - Homology
KW  - Hot topics
KW  - Literature reviews
KW  - Open-source libraries
KW  - Research status
KW  - Source codes
KW  - Summary and analyse
KW  - System aspects
KW  - Vulnerability analysis
KW  - Firmware
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Kukreja, V.
AU  - Brar, T.P.S.
AU  - Vats, S.
AU  - Bansal, A.
AU  - Sharma, R.
TI  - Advancing Climate Forecasting Accuracy Through Neurosymbolic Integration: Unveiling the Neurosymbolic Climate Inference and Prediction (NS-CIP) Model’s Approach to Predicting Extreme Weather Events
PY  - 2024
T2  - SN Computer Science
VL  - 5
IS  - 7
C7  - 958
DO  - 10.1007/s42979-024-03321-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206470516&doi=10.1007%2fs42979-024-03321-2&partnerID=40&md5=716553615eaa3d20c32df1804b8f84e4
AB  - In an era where climate change and its associated impacts increasingly threaten global stability, the demand for advanced predictive models capable of accurately forecasting extreme weather events and elucidating complex climate phenomena has never been more critical. Although foundational to our current understanding, traditional climate modeling techniques often fall short of capturing the intricate interplay of factors driving climate variability and change. These limitations underscore the urgent need for innovative approaches to bridging the gap between comprehensive data analysis and actionable climate intelligence. The Neurosymbolic Climate Inference and Prediction (NS-CIP) Model is a creative method that combines the predictive capabilities of neural networks with the logical precision of symbolic AI. The NS-CIP Model sets a new standard in climate science, offering enhanced predictive accuracy, improved interpretability, and a robust framework for integrating diverse climatic data. Demonstrating remarkable proficiency across key datasets, the model achieves accuracy rates of 92.86% on the Global Historical Climatology Network (GHCN), 94.62% on the European Monitoring Agency (ERA) 5 reanalysis dataset, and 95.48% on Sentinel satellite data. These unprecedented levels of accuracy not only highlight the NS-CIP Model's capability to navigate the complexities of climate data but also underscore its potential to significantly advance our predictive capabilities and deepen our understanding of climate dynamics, making it an invaluable asset in the ongoing effort to mitigate and adapt to the effects of climate change. © The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd. 2024.
KW  - Climate change analytics
KW  - Climate prediction models
KW  - Climatology
KW  - ERA5 reanalysis
KW  - Global historical climatology network
KW  - Neurosymbolic artificial intelligence
KW  - Symbolic artificial intelligence
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Kursuncu, U.
AU  - Gaur, M.
AU  - Sheth, A.
TI  - Knowledge infused learning (K-IL): Towards deep incorporation of knowledge in deep learning
PY  - 2020
T2  - CEUR Workshop Proceedings
VL  - 2600
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085203414&partnerID=40&md5=b993be177b9eec5748e9a5a53e42ac97
AB  - Learning the underlying patterns in data goes beyond instance-based generalization to external knowledge represented in structured graphs or networks. Deep learning that primarily constitutes neural computing stream in AI has shown significant advances in probabilistically learning latent patterns using a multi-layered network of computational nodes (i.e., neurons/hidden units). Structured knowledge that underlies symbolic computing approaches and often supports reasoning, has also seen significant growth in recent years, in the form of broad-based (e.g., DBPedia, Yago) and domain, industry or application specific knowledge graphs. A common substrate with careful integration of the two will raise opportunities to develop neuro-symbolic learning approaches for AI, where conceptual and probabilistic representations are combined. As the incorporation of external knowledge will aid in supervising the learning of features for the model, deep infusion of representational knowledge from knowledge graphs within hidden layers will further enhance the learning process. Although much work remains, we believe that knowledge graphs will play an increasing role in developing hybrid neuro-symbolic intelligent systems (bottom-up deep learning with top-down symbolic computing) as well as in building explainable AI systems for which knowledge graphs will provide scaffolding for punctuating neural computing. In this position paper, we describe our motivation for such a neuro-symbolic approach and framework that combines knowledge graph and neural networks. Copyright © 2020 held by the author(s).
KW  - Graphic methods
KW  - Intelligent systems
KW  - Knowledge engineering
KW  - Learning systems
KW  - Multilayer neural networks
KW  - Network layers
KW  - Scaffolds
KW  - Springs (components)
KW  - Computational nodes
KW  - External knowledge
KW  - Learning process
KW  - Probabilistic representation
KW  - Structured graphs
KW  - Structured knowledge
KW  - Symbolic computing
KW  - Symbolic learning
KW  - Deep learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Sheth, A.
AU  - Thirunarayan, K.
TI  - The Duality of Data and Knowledge across the Three Waves of AI
PY  - 2021
T2  - IT Professional
VL  - 23
IS  - 3
C7  - 9464111
SP  - 35
EP  - 45
DO  - 10.1109/MITP.2021.3070985
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112397167&doi=10.1109%2fMITP.2021.3070985&partnerID=40&md5=2a24aab9c4fc3f797d10751aaf8f3662
AB  - We discuss how, over the last 30-50 years, artificial intelligence (AI) systems that focused only on data have been handicapped and how knowledge has been critical in developing smarter, intelligent, and more effective systems. In fact, the vast progress in AI can be viewed in terms of the three waves of AI as identified by DARPA. During the first wave, handcrafted knowledge has been at the center, while during the second wave, the datadriven approaches supplanted knowledge. Now we see a strong role and resurgence of knowledge fueling major breakthroughs in the third wave of AI underpinning future intelligent systems as they attempt human-like decision making and seek to become trusted assistants and companions for humans. We find a wider availability of knowledge created from diverse sources, using manual to automated means both by repurposing as well as by extraction. Using knowledge with statistical learning is becoming increasingly indispensable to help make AI systems more transparent and auditable. We will draw a parallel with the role of knowledge and experience in human intelligence based on cognitive science, and discuss emerging neuro-symbolic or hybrid AI systems in which knowledge is the critical enabler for combining capabilities of the data-intensive statistical AI systems with those of symbolic AI systems, resulting in more capable AI systems that support more human-like intelligence.  © 1999-2012 IEEE.
KW  - Behavioral research
KW  - Decision making
KW  - Intelligent systems
KW  - Cognitive science
KW  - Data intensive
KW  - Data-driven approach
KW  - Effective systems
KW  - Human intelligence
KW  - Human-like intelligence
KW  - Knowledge and experience
KW  - Statistical learning
KW  - Cognitive systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Wang, T.
AU  - Kara, D.
AU  - Li, J.
AU  - Liu, S.
AU  - Abdelzaher, T.
AU  - Jalaian, B.
TI  - The Methodological Pitfall of Dataset-Driven Research on Deep Learning: An IoT Example
PY  - 2022
T2  - Proceedings - IEEE Military Communications Conference MILCOM
VL  - 2022-November
SP  - 1082
EP  - 1087
DO  - 10.1109/MILCOM55135.2022.10017612
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147324687&doi=10.1109%2fMILCOM55135.2022.10017612&partnerID=40&md5=502e9a84e7b8ce6e60221a4d188b0da9
AB  - In this paper, we highlight a dangerous pitfall in the state-of-the-art evaluation methodology of deep learning algorithms. It results in deceptively good evaluation outcomes on test datasets, whereas the underlying algorithms remain prone to catastrophic failure in practice. We illustrate the pitfall in the context of an Internet-of-Things (IoT) application example and show that it occurs despite the use of cross-validation that breaks down the data into separate training, validation, and testing sets. The pitfall is illustrated by designing two target detection and classification algorithms. One is based on a recently proposed neural network architecture for embedded AI, and the other is based on a traditional machine learning approach with domain-inspired feature engineering. The neural network approach outperforms the traditional one on test data. Yet, it fails in deployment. The mechanics behind the failure are explained and linked to the way the algorithms are trained. Suggestions are presented to avoid the pitfall. The paper is a 'call to arms' to improve the evaluation methodology of machine learning algorithms for mission-critical systems.  © 2022 IEEE.
KW  - Deep learning
KW  - Learning algorithms
KW  - Learning systems
KW  - Network architecture
KW  - Application examples
KW  - Break down
KW  - Catastrophic failures
KW  - Cross validation
KW  - Evaluation methodologies
KW  - State of the art
KW  - Target detection algorithm
KW  - Testing sets
KW  - Training sets
KW  - Validation sets
KW  - Internet of things
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 9
ER  -

TY  - CONF
AU  - Khan, A.
AU  - Konig, T.
AU  - Liebgott, F.
AU  - Greiner, T.
TI  - External Magnetic Interference Classification in Magnetostrictive Position Sensors using Neuro-Symbolic AI with Log-Likelihood Ratios
PY  - 2023
T2  - IEEE International Conference on Industrial Informatics (INDIN)
VL  - 2023-July
DO  - 10.1109/INDIN51400.2023.10217878
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171164299&doi=10.1109%2fINDIN51400.2023.10217878&partnerID=40&md5=e2b7daf82c08c605c9b2dad10aa08ca1
AB  - Magnetostrictive Position Sensors (MPS) are used for precise distance and velocity measurements. They utilize magnetostriction to generate structure-borne sound waves and work on the basis of Time-of-Flight (ToF) calculations. However, external electromagnetic interference (EMI) can impact the accuracy of these sensors by interacting with the magnetic fields of magnetostriction. To address this issue, a novel hybrid approach utilizing both neural and symbolic AI has been developed to classify the intensity of EMI. This system is based on the combination of Log-Likelihood Ratios (LLRs). This study's findings are particularly significant for industrial environments with numerous sources of external electromagnetic interference, where precise measurement is critical. © 2023 IEEE.
KW  - Electromagnetic pulse
KW  - Electromagnetic wave interference
KW  - Magnetostriction
KW  - Magnetostrictive devices
KW  - Hybrid approach
KW  - Industrial environments
KW  - Log likelihood ratio
KW  - Magnetic interference
KW  - Magnetic-field
KW  - Position sensors
KW  - Precise measurements
KW  - Structure borne sound
KW  - Time-of flight
KW  - Signal interference
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Yuan, Y.
AU  - Tang, B.
AU  - Zhou, T.
AU  - Zhang, Z.
AU  - Qin, J.
TI  - nsDB: Architecting the Next Generation Database by Integrating Neural and Symbolic Systems
PY  - 2024
T2  - Proceedings of the VLDB Endowment
VL  - 17
IS  - 11
SP  - 3283
EP  - 3289
DO  - 10.14778/3681954.3682000
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205361860&doi=10.14778%2f3681954.3682000&partnerID=40&md5=c4d135510447d679ce310815b7ef47e7
AB  - In this paper, we propose nsDB, a novel neuro-symbolic database system that integrates neural and symbolic system architectures natively to address the weaknesses of each, providing a strong database capable of data managing, model learning, and complex analytical query processing over multi-modal data. We employ a real-world NBA data analytical query as an example to illustrate the functionality of each component in nsDB and highlight the research challenges to build it. We then present the key design principles and our preliminary attempts to address them. In a nutshell, we envision that the next generation database system nsDB integrates the complex neural system with the simple symbolic system. Undoubtedly, nsDB will serve as a bridge between databases with AI models, which abstracts away the AI complexities but allows end users to enjoy the strong capabilities of them. We are in the early stages of the journey to build nsDB, there are many opening challenges, e.g., in-database model training, multi-objective query optimization, and database agent development. We hope the researchers from different communities (e.g., system, architecture, database, artificial intelligence) could tackle them together. © 2024, VLDB Endowment. All rights reserved.
KW  - Data handling
KW  - Database systems
KW  - Query processing
KW  - Analytical queries
KW  - Model complexes
KW  - Model learning
KW  - Multi-modal data
KW  - Neural systems
KW  - Real-world
KW  - Research challenges
KW  - Symbolic database
KW  - Symbolic systems
KW  - Systems architecture
KW  - Structured Query Language
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Johnston, P.
AU  - Nogueira, K.
AU  - Swingler, K.
TI  - NS-IL: Neuro-Symbolic Visual Question Answering Using Incrementally Learnt, Independent Probabilistic Models for Small Sample Sizes
PY  - 2023
T2  - IEEE Access
VL  - 11
SP  - 141406
EP  - 141420
DO  - 10.1109/ACCESS.2023.3341007
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179829960&doi=10.1109%2fACCESS.2023.3341007&partnerID=40&md5=7d7b597e8e365544d28bb7a30877447b
AB  - This paper is motivated by the challenge of providing accurate and contextually relevant answers to natural language questions about visual scenes, particularly in support of individuals with visual impairments. We present a system that is capable of incrementally learning both visual concepts and symbolic facts to answer natural language questions about visual scenes via rich concepts. Deep neural networks are used to learn a feature space from which visual classes are learned as independent probability distributions, allowing new classes to be added arbitrarily with small sample sizes and without the risk of catastrophic forgetting associated with traditional neural networks. Visual classes are not limited to object labels, but also include visual attributes. A knowledge graph is used to represent facts about objects, such as their actions, locations and the relationships between different objects. This allows facts to be stored explicitly and added incrementally. A large language model is used to translate between natural language questions and knowledge graph traversal queries, providing a natural visual question answering process.  © 2013 IEEE.
KW  - classification system
KW  - Gaussian mixture model
KW  - incremental learning
KW  - Neuro-symbolic system
KW  - visual question answering
KW  - Deep neural networks
KW  - Knowledge graph
KW  - Natural language processing systems
KW  - Search engines
KW  - Visual languages
KW  - Adaptation models
KW  - Classification system
KW  - Cognition
KW  - Gaussian Mixture Model
KW  - Incremental learning
KW  - Knowledge graphs
KW  - Natural languages
KW  - Neuro-symbolic system
KW  - Question Answering
KW  - Question answering (information retrieval)
KW  - Visual question answering
KW  - Gaussian distribution
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Da Costa Nascimento, J.J.
AU  - Marques, A.G.
AU  - Dos Santos, M.A.
AU  - De Oliveira, L.
AU  - Chaves, J.M.
AU  - De Freitas Souza, L.F.
AU  - Rebouças Filho, P.P.
TI  - New Health of Things Approach to Classification and Detection of Brain Tumors Using Transfer Learning for Segmentation in IMR Images
PY  - 2023
T2  - Proceedings of the International Joint Conference on Neural Networks
VL  - 2023-June
DO  - 10.1109/IJCNN54540.2023.10191399
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169544121&doi=10.1109%2fIJCNN54540.2023.10191399&partnerID=40&md5=b4ec23930497bc6672e6ccaacbe533cc
AB  - A multitude of diseases can afflict the human body, each potentially causing a range of health problems. Among the most devastating are brain diseases that originate from tumors, affecting the well-being of countless people worldwide. Brain tumors are a pathology that results in numerous sequelae, significantly impacting public spending due to the costs of hospital clinical treatments, exams, and medicines for patients. These factors are linked to the problem, resulting in significant financial impacts on the health sector worldwide. The problem of detection and segmentation in medical images provides new solutions through different methods based on computer vision. This study proposes a fully automatic model based on the Internet of Things (IoT), capable of classifying, detecting, and segmenting magnetic resonance images of brain tumors. The proposed model can classify MR images, detect the tumor region, and segment it through deep extractors and classifiers, combined with deep learning using the Detectron2 network for brain tumor detection and fine-tuning for brain tumor segmentation. The model was trained and tested with the dataset (Brain MRI Segmentation - LGG Segmentation Dataset), obtaining excellent classification results using a transfer learning model of DenseNet201 + SVM RBF, achieving 93.10% accuracy. For the Detectron2 network, 99.38% accuracy was achieved, with 99.41% for brain tumor segmentation. The fully automatic IoT-based model (Health of Things) efficiently classified, detected, and segmented brain tumors in MR images, surpassing different reputable works in the literature. © 2023 IEEE.
KW  - brain tumor classification
KW  - deep learning
KW  - detection and segmentation
KW  - medical images
KW  - Brain
KW  - Classification (of information)
KW  - Deep learning
KW  - Image classification
KW  - Image segmentation
KW  - Internet of things
KW  - Magnetic resonance
KW  - Magnetic resonance imaging
KW  - Medical imaging
KW  - Support vector machines
KW  - Brain disease
KW  - Brain tumor classifications
KW  - Brain tumor segmentation
KW  - Brain tumors
KW  - Deep learning
KW  - Detection and segmentation
KW  - Human bodies
KW  - Medical image
KW  - MR-images
KW  - Transfer learning
KW  - Tumors
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - CONF
AU  - Zhou, B.
AU  - Nikolov, N.
AU  - Zheng, Z.
AU  - Luo, X.
AU  - Savkovic, O.
AU  - Roman, D.
AU  - Soylu, A.
AU  - Kharlamov, E.
TI  - Scaling Data Science Solutions with Semantics and Machine Learning: Bosch Case
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14266 LNCS
SP  - 380
EP  - 399
DO  - 10.1007/978-3-031-47243-5_21
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177463135&doi=10.1007%2f978-3-031-47243-5_21&partnerID=40&md5=a2e7ae369cfe5e351d72dc94570ba225
AB  - Industry 4.0 and Internet of Things (IoT) technologies unlock unprecedented amount of data from factory production, posing big data challenges in volume and variety. In that context, distributed computing solutions such as cloud systems are leveraged to parallelise the data processing and reduce computation time. As the cloud systems become increasingly popular, there is increased demand that more users that were originally not cloud experts (such as data scientists, domain experts) deploy their solutions on the cloud systems. However, it is non-trivial to address both the high demand for cloud system users and the excessive time required to train them. To this end, we propose SemCloud, a semantics-enhanced cloud system, that couples cloud system with semantic technologies and machine learning. SemCloud relies on domain ontologies and mappings for data integration, and parallelises the semantic data integration and data analysis on distributed computing nodes. Furthermore, SemCloud adopts adaptive Datalog rules and machine learning for automated resource configuration, allowing non-cloud experts to use the cloud system. The system has been evaluated in industrial use case with millions of data, thousands of repeated runs, and domain users, showing promising results. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.
KW  - cloud computing
KW  - Datalog
KW  - Industry 4.0
KW  - knowledge graph
KW  - machine learning
KW  - ontology engineering
KW  - quality monitoring
KW  - rule-based reasoning
KW  - semantic ETL
KW  - welding
KW  - Data integration
KW  - Distributed computer systems
KW  - Industry 4.0
KW  - Internet of things
KW  - Knowledge graph
KW  - Machine learning
KW  - Ontology
KW  - Semantic Web
KW  - Cloud systems
KW  - Cloud-computing
KW  - Datalog
KW  - Knowledge graphs
KW  - Machine-learning
KW  - Ontology engineering
KW  - Quality monitoring
KW  - Rule-based reasoning
KW  - Scalings
KW  - Semantic ETL
KW  - Semantics
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Shumsky, S.
TI  - Hierarchical AGI from First Principles
PY  - 2024
T2  - Studies in Computational Intelligence
VL  - 1130 LNCS
SP  - 823
EP  - 831
DO  - 10.1007/978-3-031-50381-8_89
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186692853&doi=10.1007%2f978-3-031-50381-8_89&partnerID=40&md5=97d0d9b68b7b7cd167337bcd7b8c8276
AB  - The paper provides evidence based on the free energy principle in favor of the hierarchical design of AGI. A neuro-symbolic hierarchical architecture of AGI is proposed as a development of Friston’s hierarchical model of the brain.  © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - Artificial general intelligence
KW  - Hierarchical reinforcement learning
KW  - Neuro-symbolic architecture
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Abraham, S.S.
AU  - Alirezaie, M.
AU  - De Raedt, L.
TI  - CLEVR-POC: Reasoning-Intensive Visual Question Answering in Partially Observable Environments
PY  - 2024
T2  - 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings
SP  - 3297
EP  - 3313
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195916891&partnerID=40&md5=06e56fb4f9f7a8baab901ae506309370
AB  - The integration of learning and reasoning is high on the research agenda in AI. Nevertheless, there is only a little attention to use existing background knowledge for reasoning about partially observed scenes to answer questions about the scene. Yet, we as humans use such knowledge frequently to infer plausible answers to visual questions (by eliminating all inconsistent ones). Such knowledge often comes in the form of constraints about objects and it tends to be highly domain or environment-specific. We contribute a novel benchmark called CLEVR-POC for reasoning-intensive visual question answering (VQA) in partially observable environments under constraints. In CLEVR-POC, knowledge in the form of logical constraints needs to be leveraged to generate plausible answers to questions about a hidden object in a given partial scene. For instance, if one has the knowledge that all cups are colored either red, green or blue and that there is only one green cup, it becomes possible to deduce the color of an occluded cup as either red or blue, provided that all other cups, including the green one, are observed. Through experiments, we observe that the low performance of pre-trained vision language models like CLIP (≈ 22%) and a large language model (LLM) like GPT-4 (≈ 46%) on CLEVR-POC ascertains the necessity for frameworks that can handle reasoning-intensive tasks where environment-specific background knowledge is available and crucial. Furthermore, our demonstration illustrates that a neuro-symbolic model, which integrates an LLM like GPT-4 with a visual perception network and a formal logical reasoner, exhibits exceptional performance on CLEVR-POC. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.
KW  - LLM and Reasoning
KW  - logical constraints
KW  - partial observability
KW  - visual question answering
KW  - Computational linguistics
KW  - Visual languages
KW  - Background knowledge
KW  - Language model
KW  - Large language model and reasoning
KW  - Logical constraints
KW  - Partial observability
KW  - Partially observable environments
KW  - Performance
KW  - Question Answering
KW  - Research agenda
KW  - Visual question answering
KW  - Knowledge management
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Marra, G.
AU  - Dumančić, S.
AU  - Manhaeve, R.
AU  - De Raedt, L.
TI  - From statistical relational to neurosymbolic artificial intelligence: A survey
PY  - 2024
T2  - Artificial Intelligence
VL  - 328
C7  - 104062
DO  - 10.1016/j.artint.2023.104062
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183330773&doi=10.1016%2fj.artint.2023.104062&partnerID=40&md5=de67bbb42698653f61c2f0372aaa72ba
AB  - This survey explores the integration of learning and reasoning in two different fields of artificial intelligence: neurosymbolic and statistical relational artificial intelligence. Neurosymbolic artificial intelligence (NeSy) studies the integration of symbolic reasoning and neural networks, while statistical relational artificial intelligence (StarAI) focuses on integrating logic with probabilistic graphical models. This survey identifies seven shared dimensions between these two subfields of AI. These dimensions can be used to characterize different NeSy and StarAI systems. They are concerned with (1) the approach to logical inference, whether model or proof-based; (2) the syntax of the used logical theories; (3) the logical semantics of the systems and their extensions to facilitate learning; (4) the scope of learning, encompassing either parameter or structure learning; (5) the presence of symbolic and subsymbolic representations; (6) the degree to which systems capture the original logic, probabilistic, and neural paradigms; and (7) the classes of learning tasks the systems are applied to. By positioning various NeSy and StarAI systems along these dimensions and pointing out similarities and differences between them, this survey contributes fundamental concepts for understanding the integration of learning and reasoning. © 2024 The Authors
KW  - Learning and reasoning
KW  - Neurosymbolic AI
KW  - Probabilistic logics
KW  - Statistical relational AI
KW  - Artificial intelligence
KW  - Computer circuits
KW  - Integration
KW  - Learning systems
KW  - Probabilistic logics
KW  - Statistics
KW  - Artificial intelligence systems
KW  - Learning and reasoning
KW  - Logical inference
KW  - Logical theories
KW  - Neural-networks
KW  - Neurosymbolic AI
KW  - Probabilistic graphical models
KW  - Statistical relational AI
KW  - Subfields
KW  - Symbolic reasoning
KW  - Semantics
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 31
ER  -

TY  - JOUR
AU  - Rezazadeh, F.
AU  - Barrachina-Munoz, S.
AU  - Chergui, H.
AU  - Mangues, J.
AU  - Bennis, M.
AU  - Niyato, D.
AU  - Song, H.
AU  - Liu, L.
TI  - Toward Explainable Reasoning in 6G: A Proof of Concept Study on Radio Resource Allocation
PY  - 2024
T2  - IEEE Open Journal of the Communications Society
VL  - 5
SP  - 6239
EP  - 6260
DO  - 10.1109/OJCOMS.2024.3466225
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205436363&doi=10.1109%2fOJCOMS.2024.3466225&partnerID=40&md5=0a5933c3d2c6c047274883a016621c75
AB  - The move toward artificial intelligence (AI)-native sixth-generation (6G) networks has put more emphasis on the importance of explainability and trustworthiness in network management operations, especially for mission-critical use-cases. Such desired trust transcends traditional post-hoc explainable AI (XAI) methods to using contextual explanations for guiding the learning process in an in-hoc way. This paper proposes a novel graph reinforcement learning (GRL) framework named TANGO which relies on a symbolic subsystem. It consists of a Bayesian-graph neural network (GNN) Explainer, whose outputs, in terms of edge/node importance and uncertainty, are periodically translated to a logical GRL reward function. This adjustment is accomplished through defined symbolic reasoning rules within a Reasoner. Considering a real-world testbed proof-of-concept (PoC), a gNodeB (gNB) radio resource allocation problem is formulated, which aims to minimize under- and over-provisioning of physical resource blocks (PRBs) while penalizing decisions emanating from the uncertain and less important edge-nodes relations. Our findings reveal that the proposed in-hoc explainability solution significantly expedites convergence compared to standard GRL baseline and other benchmarks in the deep reinforcement learning (DRL) domain. The experiment evaluates performance in AI, complexity, energy consumption, robustness, network, scalability, and explainability metrics. Specifically, the results show that TANGO achieves a noteworthy accuracy of 96.39% in terms of optimal PRB allocation in inference phase, outperforming the baseline by 1.22×.  © 2020 IEEE.
KW  - AI/ML
KW  - B5G/6G
KW  - DRL
KW  - GNN
KW  - GRL
KW  - neuro-symbolic
KW  - resource allocation
KW  - XAI
KW  - Benchmarking
KW  - Deep neural networks
KW  - Graph neural networks
KW  - Reinforcement learning
KW  - Resource allocation
KW  - Artificial intelligence/ML
KW  - B5G/6g
KW  - Graph neural networks
KW  - Graph reinforcement learning
KW  - Neuro-symbolic
KW  - Proof of concept
KW  - Reinforcement learnings
KW  - Resources allocation
KW  - XAI
KW  - Deep reinforcement learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - BOOK
AU  - Zhao, J.
AU  - Kumar, V.V.
TI  - Handbook of research on innovations and applications of AI, IoT, and cognitive technologies
PY  - 2021
T2  - Handbook of Research on Innovations and Applications of AI, IoT, and Cognitive Technologies
SP  - 1
EP  - 570
DO  - 10.4018/978-1-7998-6870-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118523969&doi=10.4018%2f978-1-7998-6870-5&partnerID=40&md5=cc6b074ce9d3e683e33201f653044bd8
AB  - Recently, artificial intelligence (AI), the internet of things (IoT), and cognitive technologies have successfully been applied to various research domains, including computer vision, natural language processing, voice recognition, and more. In addition, AI with IoT has made a significant breakthrough and a shift in technical direction to achieve high efficiency and adaptability in a variety of new applications. On the other hand, network design and optimization for AI applications addresses a complementary topic, namely the support of AI-based systems through novel networking techniques, including new architectures, as well as performance models for IoT systems. IoT has paved the way to a plethora of new application domains, at the same time posing several challenges as a multitude of devices, protocols, communication channels, architectures, and middleware exist. Big data generated by these devices calls for advanced learning and data mining techniques to effectively understand, learn, and reason with this volume of information, such as cognitive technologies. Cognitive technologies play a major role in developing successful cognitive systems which mimic "cognitive" functions associated with human intelligence, such as "learning" and "problem solving." Thus, there is a continuing demand for recent research in these two linked fields. The Handbook of Research on Innovations and Applications of AI, IoT, and Cognitive Technologies discusses the latest innovations and applications of AI, IoT, and cognitive-based smart systems. The chapters cover the intersection of these three fields in emerging and developed economies in terms of their respective development situation, public policies, technologies and intellectual capital, innovation systems, competition and strategies, marketing and growth capability, and governance and relegation models. These applications span areas such as healthcare, security and privacy, industrial systems, multidisciplinary sciences, and more. This book is ideal for technologists, IT specialists, policymakers, government officials, academics, students, and practitioners interested in the experiences of innovations and applications of AI, IoT, and cognitive technologies. © 2021 by IGI Global. All rights reserved.
M3  - Book
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Dhont, M.
AU  - Munteanu, A.
AU  - Tsiporkova, E.
TI  - Forecasting Traffic Progression in Terms of Semantically Interpretable States by Exploring Multiple Data Representations
PY  - 2025
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 26
IS  - 6
SP  - 8368
EP  - 8381
DO  - 10.1109/TITS.2025.3553238
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002038288&doi=10.1109%2fTITS.2025.3553238&partnerID=40&md5=ab94bfc5912436d1270f30c3cbdb69f7
AB  - In the rapidly evolving landscape of mobility modelling, the application of deep learning approaches introduces both opportunities and challenges. Such approaches, while powerful, yield opaque models that lack interpretability and adaptability to diverse traffic contexts. Addressing those challenges, a finite set of humanly-interpretable traffic states is exploited here for the purpose of facilitating the annotation of mobility data with meaningful labels such as congestion, free-flow, traffic build-up, etc. Such annotation unlocks a range of opportunities to integrate multiple complementary approaches for modelling state transition behaviour. Concretely, a novel hybrid modelling framework is introduced in this article leveraging multiple data representations (temporal, time-frequency and symbolic) with the aim to forecast traffic progression in terms of humanly-explicable state transitions. Three distinct modelling paradigms are subsequently explored: neural, neural-to-symbolic, and symbolic-to-neural, by demonstrating their potential to capture and forecast traffic dynamics on real-world mobility data. While the fully neural approach is undoubtedly the most accurate one, the two neuro-symbolic approaches offer a better trade-off between accuracy on one side and interpretability, probability calibration, and computational efficiency, on the other. This work illustrates the importance of tailored data representations in understanding and predicting complex mobility behaviour, highlighting the benefits of hybrid approaches in achieving interpretability and efficiency in traffic data analysis. © 2000-2011 IEEE.
KW  - forecasting
KW  - Markov processes
KW  - multi-representation
KW  - neuro-symbolic
KW  - state transitions
KW  - Traffic states
KW  - Markov processes
KW  - Traffic congestion
KW  - Data representations
KW  - Finite set
KW  - Interpretability
KW  - Learning approach
KW  - Mobility modeling
KW  - Multi-representations
KW  - Multiple data
KW  - Neuro-symbolic
KW  - State transitions
KW  - Traffic state
KW  - Spatio-temporal data
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Kovacova, M.
AU  - Horak, J.
AU  - Popescu, G.H.
TI  - Haptic and Biometric Sensor Technologies, Deep Learning-based Image Classification Algorithms, and Movement and Behavior Tracking Tools in the Metaverse Economy
PY  - 2022
T2  - Analysis and Metaphysics
VL  - 21
SP  - 176
EP  - 192
DO  - 10.22381/AM21202211
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146478258&doi=10.22381%2fAM21202211&partnerID=40&md5=921c0474c0e5e9d6e582a3e5a9834545
AB  - Despite the relevance of immersive shopping experiences in the block-chain-based virtual economy, only limited research has been conducted on this topic. In this article, we cumulate previous research findings indicating that machine vision algorithms, immersive technologies, and customer personalization tools enable personalized digital shopping experiences in the virtual commerce. Throughout May 2022, we performed a quantitative literature review of the Web of Science, Scopus, and ProQuest databases, with search terms including “metaverse” + “haptic and biometric sensor technologies,” “deep learning-based image classification algorithms,” and “movement and behavior tracking tools.” As we inspected research published between 2021 and 2022, only 152 articles satisfied the eligibility criteria. By elim-inating controversial findings, outcomes unsubstantiated by replication, too imprecise material, or having similar titles, we decided upon 27, generally empirical, sources. Data visualization tools: Dimensions (bibliometric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AXIS, Dedoose, Distiller SR, and MMAT. © 2022, Addleton Academic Publishers. All rights reserved.
KW  - deep learning
KW  - haptic and biometric sensor technologies
KW  - image classification
KW  - metaverse
KW  - movement and behavior tracking
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 19
ER  -

TY  - JOUR
AU  - Xu, S.
AU  - Kurisummoottil Thomas, C.
AU  - Hashash, O.
AU  - Muralidhar, N.
AU  - Saad, W.
AU  - Ramakrishnan, N.
TI  - Large Multi-Modal Models (LMMs) as Universal Foundation Models for AI-Native Wireless Systems
PY  - 2024
T2  - IEEE Network
VL  - 38
IS  - 5
SP  - 10
EP  - 20
DO  - 10.1109/MNET.2024.3427313
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199115312&doi=10.1109%2fMNET.2024.3427313&partnerID=40&md5=c436c47d0b1614a978735df0f03209fd
AB  - Large language models (LLMs) and foundation models have been recently touted as a game-changer for 6 G systems. However, recent efforts on LLMs for wireless networks are limited to a direct application of existing language models that were designed for natural language processing (NLP) applications. To address this challenge and create wireless-centric foundation models, this paper presents a comprehensive vision on how to design universal foundation models that are tailored towards the unique needs of next-generation wireless systems, thereby paving the way towards the deployment of artificial intelligence (AI)-native networks. Diverging from NLP-based foundation models, the proposed framework promotes the design of large multi-modal models (LMMs) fostered by three key capabilities: 1) processing of multi-modal sensing data, 2) grounding of physical symbol representations in real-world wireless systems using causal reasoning and retrieval-augmented generation (RAG), and 3) enabling instructibility from the wireless environment feedback to facilitate dynamic network adaptation thanks to logical and mathematical reasoning facilitated by neuro-symbolic AI. In essence, these properties enable the proposed LMM framework to build universal capabilities that cater to various cross-layer networking tasks and alignment of intents across different domains. Preliminary results from experimental evaluation demonstrate the efficacy of grounding using RAG in LMMs, and showcase the alignment of LMMs with wireless system designs. Furthermore, the enhanced rationale exhibited in the responses to mathematical questions by LMMs, compared to vanilla LLMs, demonstrates the logical and mathematical reasoning capabilities inherent in LMMs. Building on those results, we present a sequel of open questions and challenges for LMMs. We then conclude with a set of recommendations that ignite the path towards LMM-empowered AI-native systems.  © 1986-2012 IEEE.
KW  - AI-native
KW  - Alignment
KW  - Grounding
KW  - Instructibility
KW  - Large multi-modal models
KW  - Universal foundation model
KW  - Alignment
KW  - Artificial intelligence
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Network layers
KW  - Search engines
KW  - Artificial intelligence-native
KW  - Cognition
KW  - Foundation models
KW  - Instructibility
KW  - Large multi-modal model
KW  - Modal models
KW  - Multi-modal
KW  - Symbol
KW  - Universal foundation model
KW  - Wireless communications
KW  - Wireless sensor networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - JOUR
AU  - Prakash V, J.
AU  - Vijay S, A.A.
TI  - A Comprehensive Multimodal Framework for Optimizing Social Media Hashtag Recommendations
PY  - 2024
T2  - IEEE Transactions on Computational Social Systems
DO  - 10.1109/TCSS.2024.3508733
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212255578&doi=10.1109%2fTCSS.2024.3508733&partnerID=40&md5=3bf22549f41ff32705da61be987d6ba5
AB  - In the dynamic landscape of social media, the strategic use of hashtags has emerged as a crucial tool for enhancing content discoverability and engagement. This research introduces the neurosymbolic contrastive framework (NSCF), an innovative methodology designed to address the multifaceted challenges inherent in automated hashtag recommendation, such as the integration of multimodal data, the context sensitivity of content, and the dynamic nature of social media trends. By combining deep learning's representational strengths with the deductive prowess of symbolic artificial Intelligence (AI), NSCF crafts contextually relevant and logically coherent hashtag suggestions. Its dual-stream architecture meticulously processes and aligns textual and visual content through contrastive learning, ensuring a comprehensive understanding of multimodal social media data. The framework's neurosymbolic integration leverages structured knowledge and logical inference, significantly enhancing the relevance and coherence of its recommendations. Evaluated against a variety of datasets, including MM-INS, NUS-WIDE, and HARRISON, NSCF has demonstrated exceptional performance, outshining existing models and baseline methods across key metrics such as precision (0.721-0.701), recall (0.736-0.716), and F1 score (0.728-0.708). This research represents a major advancement in social media analytics as it not only demonstrates NSCF's novel approach but also sheds light on its potential to transform hashtag recommendation systems.  © 2014 IEEE.
KW  - Artificial Intelligence (AI)
KW  - contrastive learning
KW  - explainable AI
KW  - hashtag recommendation
KW  - multimodal social media analysis
KW  - neurosymbolic AI
KW  - Recommender systems
KW  - Artificial intelligence
KW  - Explainable artificial intelligence
KW  - Hashtag recommendation
KW  - Hashtags
KW  - Multi-modal
KW  - Multimodal frameworks
KW  - Multimodal social medium analyze
KW  - Neurosymbolic artificial intelligence
KW  - Social media
KW  - Social media analysis
KW  - Contrastive Learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CHAP
AU  - Ajibesin, A.A.
AU  - Çela, E.
AU  - Vedishchev, A.
AU  - Vajjhala, N.R.
TI  - Future Horizons in Explainable AI and Blockchain for Supply Chain Management
PY  - 2025
T2  - Explainable AI and Blockchain for Secure and Agile Supply Chains: Enhancing Transparency, Traceability, and Accountability
SP  - 197
EP  - 213
DO  - 10.1201/9781003497363-14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004539896&doi=10.1201%2f9781003497363-14&partnerID=40&md5=77f91115b88be052c4abf3ff8ba682b4
AB  - This chapter explores the transformative potential of explainable artificial intelligence (XAI) and blockchain technology in supply chain management, focusing on their combined ability to enhance transparency, traceability, and accountability. This chapter begins by examining emerging trends, such as federated learning and quantum artificial intelligence (AI), and their implications for supply chains. Advancements in blockchain scalability, interoperability, and integration with the Internet of Things (IoT) and 6G networks are highlighted, showcasing their role in enabling real-time data analysis and improved operational efficiency. This chapter also examines the challenges of implementing these technologies, including scalability concerns, balancing transparency with privacy, ethical and regulatory implications, and resistance to adoption in legacy systems. Practical opportunities, such as enhanced decision-making through predictive analytics and blockchain’s secure, decentralized ecosystems, are discussed alongside real-world use cases, including combating counterfeiting, ensuring ethical sourcing, and achieving compliance. Finally, a strategic roadmap is outlined to guide policy development, foster innovation, and explore future research areas, culminating in a vision for a resilient, efficient, and agile supply chain ecosystem powered by XAI and blockchain. © 2025 selection and editorial matter, Ajay Kumar Sharma, Narasimha Rao Vajjhala, Rakshit Kothari, and Rajasekhara Mouly Potluri; individual chapters, the contributors.
KW  - Ethical technology
KW  - Federated learning
KW  - Risk perception
KW  - Block-chain
KW  - Chain management
KW  - Decentralised
KW  - Decisions makings
KW  - Emerging trends
KW  - Future Horizons
KW  - Operational efficiencies
KW  - Real time data analysis
KW  - Real-world
KW  - Roadmap
KW  - Supply chain management
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Chaccour, C.
AU  - Karapantelakis, A.
AU  - Murphy, T.
AU  - Dohler, M.
TI  - Telecom's Artificial General Intelligence (AGI) Vision: Beyond the GenAI Frontier
PY  - 2024
T2  - IEEE Network
VL  - 38
IS  - 5
SP  - 21
EP  - 28
DO  - 10.1109/MNET.2024.3425594
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199072720&doi=10.1109%2fMNET.2024.3425594&partnerID=40&md5=442aac6562eb87aaccaa4315f753348a
AB  - This paper unveils the groundbreaking impact of Generative AI (GenAI) as the dawn of a transformative era in 5G/6G networks and beyond. Exploring its disruptive potential across the value chain - from network design to agile and robust automation - we showcase GenAI as a catalyst for innovation and unparalleled efficiency. While tracing its historical journey from conception to practical implementation, the paper positions GenAI not as the sole solution but as the inception of a new era shaping network design, deployment strategies, and synchronous optimization dynamics. We also scrutinize the role of causal AI and transparent frameworks, such as explainable AI and neuro-symbolic AI in fostering trust and seamlessly integrating domain knowledge. Looking ahead beyond GenAI, we envision a future AI landscape composed of semantic communications, collaborative GenAI and discriminative agents. We also examine the challenges related to scalability and complexity that must be overcome to achieve sustainable AI deployments. Finally, we highlight the significance of emerging computing technologies and frameworks, such as quantum and neuromorphic computing, that play a pivotal role in the broader trajectory towards artificial general intelligence. © 1986-2012 IEEE.
KW  - artificial general intelligence (AGI)
KW  - artificial intelligence (AI)
KW  - causality
KW  - explainability
KW  - generative AI (GenAI)
KW  - machine learning (ML)
KW  - semantic communications
KW  - 5G mobile communication systems
KW  - Domain Knowledge
KW  - Job analysis
KW  - Semantics
KW  - Artificial general intelligence
KW  - Artificial general intelligences
KW  - Artificial intelligence
KW  - Causality
KW  - Decoding
KW  - Explainability
KW  - Generative artificial intelligence
KW  - Machine learning
KW  - Machine-learning
KW  - Probability: distributions
KW  - Semantic communication
KW  - Task analysis
KW  - Transformer
KW  - Probability distributions
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
TI  - ICCPS 2023 - Proceedings of the 2023 ACM/IEEE 14th International Conference on Cyber-Physical Systems with CPS-IoT Week 2023
PY  - 2023
T2  - ICCPS 2023 - Proceedings of the 2023 ACM/IEEE 14th International Conference on Cyber-Physical Systems with CPS-IoT Week 2023
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167923296&partnerID=40&md5=110e109103962037b29bb2be78564cb3
AB  - The proceedings contain 45 papers. The topics discussed include: autonomous and cost-effective defect detection system for molded pulp products; BubCam: a vision system for automated quality inspection at manufacturing lines; digital-twin-based patient evaluation during stroke rehabilitation; towards non-invasive bladder volume sensing via bio-impedance spectroscopy: feasibility demonstration in ex-vivo bladder models; offline learning of closed-loop deep brain stimulation controllers for Parkinson disease treatment; DOME: drone-assisted monitoring of emergent events for wildland fire resilience; learning spatio-temporal aggregations for large-scale capacity expansion problems; Pishgu: universal path prediction network architecture for real-time cyber-physical edge systems; a neurosymbolic approach to the verification of temporal logic properties of learning-enabled control systems; self-preserving genetic algorithms for safe learning in discrete action spaces; joint differentiable optimization and verification for certified reinforcement learning; and monitoring signal temporal logic in distributed cyber-physical systems.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Endo, M.
AU  - Hsu, J.
AU  - Li, J.
AU  - Wu, J.
TI  - Motion Question Answering via Modular Motion Programs
PY  - 2023
T2  - Proceedings of Machine Learning Research
VL  - 202
SP  - 9312
EP  - 9328
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174421462&partnerID=40&md5=2597f56c6f2b1442f8c1cb5f6d30c158
AB  - In order to build artificial intelligence systems that can perceive and reason with human behavior in the real world, we must first design models that conduct complex spatio-temporal reasoning over motion sequences. Moving towards this goal, we propose the HumanMotionQA task to evaluate complex, multi-step reasoning abilities of models on long-form human motion sequences. We generate a dataset of question-answer pairs that require detecting motor cues in small portions of motion sequences, reasoning temporally about when events occur, and querying specific motion attributes. In addition, we propose NSPose, a neuro-symbolic method for this task that uses symbolic reasoning and a modular design to ground motion through learning motion concepts, attribute neural operators, and temporal relations. We demonstrate the suitability of NSPose for the HumanMotionQA task, outperforming all baseline methods. © 2023 Proceedings of Machine Learning Research. All rights reserved.
KW  - Machine learning
KW  - Artificial intelligence systems
KW  - Design models
KW  - First designs
KW  - Human behaviors
KW  - Modulars
KW  - Motion sequences
KW  - Multisteps
KW  - Question Answering
KW  - Real-world
KW  - Spatio-temporal reasoning
KW  - Behavioral research
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Matthew, A.O.
AU  - Ebiniyi, O.E.
TI  - Advancing Supply Chain with Blockchain-Backed Explainable AI
PY  - 2025
T2  - Explainable AI and Blockchain for Secure and Agile Supply Chains: Enhancing Transparency, Traceability, and Accountability
SP  - 82
EP  - 101
DO  - 10.1201/9781003497363-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004494126&doi=10.1201%2f9781003497363-6&partnerID=40&md5=d23cf46172c9a8ff9c5d7ef94199c96d
AB  - This chapter provides a comprehensive overview of how blockchain and explainable artificial intelligence (XAI) can advance supply chain management (SCM), delivering heightened transparency, security, and efficiency. This chapter examines the convergence of blockchain technology and XAI in the context of SCM. The chapter begins by exploring the fundamental principles of blockchain and XAI, outlining their individual contributions to SCM. This chapter highlights how blockchain’s cryptographic security and distributed ledger system provide an unalterable record of transactions, while XAI addresses the black-box problem of AI by offering explanations that are understandable to non-technical stakeholders. This chapter examines specific applications of these technologies, such as end-to-end product traceability, smart contract automation, and fair vendor selection, demonstrating how they can enhance decision-making, improve operational resilience, and encourage collaboration among supply chain participants. In addition, the chapter addresses key challenges related to scalability, data standardization, and regulatory hurdles, offering strategies for successful implementation. This chapter concludes by discussing future directions, including the potential for new innovations such as predictive maintenance systems and the incorporation of Internet of Things (IoT) and edge computing. © 2025 selection and editorial matter, Ajay Kumar Sharma, Narasimha Rao Vajjhala, Rakshit Kothari, and Rajasekhara Mouly Potluri; individual chapters, the contributors.
KW  - Supply chain management
KW  - Black boxes
KW  - Block-chain
KW  - Chain management
KW  - Cryptographic security
KW  - End to end
KW  - End-products
KW  - Fundamental principles
KW  - Product traceability
KW  - Technical stakeholders
KW  - Vendor Selection
KW  - Risk perception
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Harmon, I.
AU  - Marconi, S.
AU  - Weinstein, B.
AU  - Bai, Y.
AU  - Wang, D.Z.
AU  - White, E.
AU  - Bohlman, S.
TI  - Improving Rare Tree Species Classification Using Domain Knowledge
PY  - 2023
T2  - IEEE Geoscience and Remote Sensing Letters
VL  - 20
C7  - 8500305
DO  - 10.1109/LGRS.2023.3278170
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160254753&doi=10.1109%2fLGRS.2023.3278170&partnerID=40&md5=3e4808515882c578c05b5217e979d7c0
AB  - Forest inventory forms the foundation of forest management. Remote sensing (RS) is an efficient means of measuring forest parameters at scale. Remotely sensed species classification can be used to estimate species abundances, distributions, and to better approximate metrics such as aboveground biomass. State-of-the-art methods of RS species classification rely on deep-learning models such as convolutional neural networks (CNNs). These models have two major drawbacks: they require large samples of each species to classify well and they lack explainability. Therefore, rare species are poorly classified causing poor approximations of their associated parameters. We show that the classification of rare species can be improved by as much as eight F1-points using a neuro-symbolic (NS) approach that combines CNNs with an NS framework. The framework allows for the incorporation of domain knowledge into the model through the use of mathematically represented rules, improving model explainability.  © 2004-2012 IEEE.
KW  - Convolutional neural network (CNN)
KW  - explainable machine learning
KW  - neuro-symbolics (NS)
KW  - remote sensing (RS)
KW  - tree species classification
KW  - Biological systems
KW  - Deep learning
KW  - Domain Knowledge
KW  - Forestry
KW  - Neural networks
KW  - Remote sensing
KW  - Biological system modeling
KW  - Convolutional neural network
KW  - Explainable machine learning
KW  - Machine-learning
KW  - Neuro-symbolic
KW  - Remote-sensing
KW  - Species classification
KW  - Task analysis
KW  - Tree species
KW  - Tree species classification
KW  - artificial neural network
KW  - image classification
KW  - machine learning
KW  - rare species
KW  - remote sensing
KW  - tree
KW  - Convolution
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Rezvani, A.
AU  - Huang, W.
AU  - Chen, H.
AU  - Ni, Y.
AU  - Imani, M.
TI  - Self-trainable and adaptive sensor intelligence for selective data generation
PY  - 2024
T2  - Frontiers in Artificial Intelligence
VL  - 7
C7  - 1403187
DO  - 10.3389/frai.2024.1403187
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216810024&doi=10.3389%2ffrai.2024.1403187&partnerID=40&md5=cd57fa784197350ff9f3d424ccb65798
AB  - With the increasing integration of machine learning into IoT devices, managing energy consumption and data transmission has become a critical challenge. Many IoT applications depend on complex computations performed on server-side infrastructure, necessitating efficient methods to reduce unnecessary data transmission. One promising solution involves deploying compact machine learning models near sensors, enabling intelligent identification and transmission of only relevant data frames. However, existing near-sensor models lack adaptability, as they require extensive pre-training and are often rigidly configured prior to deployment. This paper proposes a novel framework that fuses online learning, active learning, and knowledge distillation to enable adaptive, resource-efficient near-sensor intelligence. Our approach allows near-sensor models to dynamically fine-tune their parameters post-deployment using online learning, eliminating the need for extensive pre-labeling and training. Through a sequential training and execution process, the framework achieves continuous adaptability without prior knowledge of the deployment environment. To enhance performance while preserving model efficiency, we integrate knowledge distillation, enabling the transfer of critical insights from a larger teacher model to a compact student model. Additionally, active learning reduces the required training data while maintaining competitive performance. We validated our framework on both benchmark data from the MS COCO dataset and in a simulated IoT environment. The results demonstrate significant improvements in energy efficiency and data transmission optimization, highlighting the practical applicability of our method in real-world IoT scenarios. Copyright © 2025 Rezvani, Huang, Chen, Ni and Imani.
KW  - active learning
KW  - intelligent sensing
KW  - Internet of Things
KW  - knowledge distillation
KW  - machine learning
KW  - near-sensor computing
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - de Graaff, T.
AU  - Wild, M.
AU  - Werner, T.
AU  - Möhlmann, E.
AU  - Seibt, S.
AU  - Ebrecht, B.
TI  - Increasing Explainability in Time Series Classification by Functional Decomposition
PY  - 2024
T2  - Communications in Computer and Information Science
VL  - 2156 CCIS
SP  - 125
EP  - 144
DO  - 10.1007/978-3-031-63803-9_7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200668509&doi=10.1007%2f978-3-031-63803-9_7&partnerID=40&md5=f15fe0aa1e4300dbed74c6f0619e2808
AB  - In this work, we develop a generic methodology for time series classification in order to increase explainability and trustworthiness of the predictions. We achieve this by dividing the whole time series into sub-sequences with a sliding window approach, transforming and classifying each chunk using paradigms from functional decomposition, and then aggregating the results to a final class. Visual as well as dataset-based explanations will be derived, enabling the investigation of errors. We demonstrate our concepts on a case study in the railway domain, where the train type is to be inferred based on the signal of a commonly used axle counting sensor. While outperforming LSTM- and FCN-based end-to-end models regarding the classification accuracy, our method further reveals interesting insights into causes of misclassifications. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - Explainable AI
KW  - Neuro-symbolic AI
KW  - Time Series Classification
KW  - Long short-term memory
KW  - Case-studies
KW  - Classification accuracy
KW  - End-to-end models
KW  - Explainable AI
KW  - Functional decomposition
KW  - Misclassifications
KW  - Neuro-symbolic AI
KW  - Sliding Window
KW  - Time series classifications
KW  - Times series
KW  - Time series
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Škrlj, B.
AU  - Kralj, J.
AU  - Konc, J.
AU  - Robnik-Šikonja, M.
AU  - Lavrač, N.
TI  - Deep node ranking for neuro-symbolic structural node embedding and classification
PY  - 2022
T2  - International Journal of Intelligent Systems
VL  - 37
IS  - 1
SP  - 914
EP  - 943
DO  - 10.1002/int.22651
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114619014&doi=10.1002%2fint.22651&partnerID=40&md5=b5282e77d54f7963579d5a12caf91572
AB  - Network node embedding is an active research subfield of complex network analysis. This paper contributes a novel approach to learning network node embeddings and direct node classification using a node ranking scheme, coupled with an autoencoder-based neural network architecture. The main advantages of the proposed Deep Node Ranking (DNR) algorithm are competitive or better classification performance, significantly higher learning speed and lower space requirements when compared to state-of-the-art approaches on 15 real-life structural node classification benchmarks. It also enables exploration of the relationship between symbolic and the derived sub-symbolic node representations, offering insights into the learned node space structure. To avoid the space complexity bottleneck in a direct node classification setting, DNR, if needed, computes stationary distributions of personalized random walks from given nodes in mini-batches, scaling seamlessly to larger networks. The scaling laws associated with DNR were also investigated by considering 1,488 synthetic Erdős-Rényi networks, demonstrating its scalability to tens of millions of links. © 2021 Wiley Periodicals LLC.
KW  - complex networks
KW  - deep learning
KW  - network node embedding
KW  - node classification
KW  - Benchmarking
KW  - Complex networks
KW  - Embeddings
KW  - Learning systems
KW  - Network architecture
KW  - Classification performance
KW  - Higher learning
KW  - Learning network
KW  - Space complexity
KW  - Space requirements
KW  - Space structure
KW  - State-of-the-art approach
KW  - Stationary distribution
KW  - Neural networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Al Mahmud, S.
AU  - Kamarulariffin, A.
AU  - Ibrahim, A.M.
AU  - Mohideen, A.J.H.
TI  - Advancements and Challenges in Mobile Robot Navigation: A Comprehensive Review of Algorithms and Potential for Self-Learning Approaches
PY  - 2024
T2  - Journal of Intelligent and Robotic Systems: Theory and Applications
VL  - 110
IS  - 3
C7  - 120
DO  - 10.1007/s10846-024-02149-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201564643&doi=10.1007%2fs10846-024-02149-5&partnerID=40&md5=198562e9beab0ecd792cd02ec5702fe5
AB  - Mobile robot navigation has been a very popular topic of practice among researchers since a while. With the goal of enhancing the autonomy in mobile robot navigation, numerous algorithms (traditional AI-based, swarm intelligence-based, self-learning-based) have been built and implemented independently, and also in blended manners. Nevertheless, the problem of efficient autonomous robot navigation persists in multiple degrees due to the limitation of these algorithms. The lack of knowledge on the implemented techniques and their shortcomings act as a hindrance to further development on this topic. This is why an extensive study on the previously implemented algorithms, their applicability, their weaknesses as well as their potential needs to be conducted in order to assess how to improve mobile robot navigation performance. In this review paper, a comprehensive review of mobile robot navigation algorithms has been conducted. The findings suggest that, even though the self-learning algorithms require huge amounts of training data and have the possibility of learning erroneous behavior, they possess huge potential to overcome challenges rarely addressed by the other traditional algorithms. The findings also insinuate that in the domain of machine learning-based algorithms, integration of knowledge representation with a neuro-symbolic approach has the capacity to improve the accuracy and performance of self-robot navigation training by a significant margin. © The Author(s) 2024.
KW  - Advancement
KW  - Challenges
KW  - Mobile robot
KW  - Navigation
KW  - Self-learning
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Federated learning
KW  - Knowledge representation
KW  - Microrobots
KW  - Mobile robots
KW  - Robot learning
KW  - Self-supervised learning
KW  - Swarm intelligence
KW  - Advancement
KW  - Autonomous robot navigation
KW  - Challenge
KW  - Further development
KW  - Learning approach
KW  - Mobile Robot Navigation
KW  - Navigation performance
KW  - Potential needs
KW  - Review papers
KW  - Self-learning
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Schneider, H.
TI  - A Brain-Inspired Cognitive Architecture (BICA) Approach to the Neurosymbolic Gap
PY  - 2024
T2  - Studies in Computational Intelligence
VL  - 1130 LNCS
SP  - 775
EP  - 786
DO  - 10.1007/978-3-031-50381-8_84
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186662594&doi=10.1007%2f978-3-031-50381-8_84&partnerID=40&md5=73d5de25e48ed02f533451e23b4c9b4b
AB  - In this paper we consider a brain-inspired cognitive architecture approach to the neurosymbolic gap. The difference in the abilities of artificial neural networks (e.g., excellent perception) and symbolic systems (e.g., excellent logic) can be referred to as the neurosymbolic gap. Most attempts to combine properties of neural networks and symbolic systems are hybrid combinations of these different systems. A brain-inspired cognitive architecture (BICA), the Causal Cognitive Architecture 5 (CCA5), has both connectionist and symbolic properties. This architecture uses spatial navigation maps as the common data structure and requires spatial and temporal binding of inputs, predictive coding, innate knowledge procedures, and the ability to feed back and re-operate on intermediate results. We show how this BICA approach closes the neurosymbolic gap without the need to overtly combine separate symbolic systems and neural networks. As well, given that the BICA model presented is inspired by the mammalian and in particular the human brain, it provides insight into the mechanisms at work in cognition. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - Artificial intelligence (AI)
KW  - Cognitive architecture
KW  - Neurosymbolic
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Armary, P.
AU  - El-Vaigh, C.-B.
AU  - Spicher, A.
AU  - Narsis, O.L.
AU  - Nicolle, C.
TI  - Identifying Logical Patterns in Text for Reasoning
PY  - 2024
T2  - Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI
SP  - 837
EP  - 844
DO  - 10.1109/ICTAI62512.2024.00122
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217432359&doi=10.1109%2fICTAI62512.2024.00122&partnerID=40&md5=b1d5679de4ecd7546b8990c118e6612e
AB  - Translating unstructured text into logical format is a key challenge for building ontologies automatically and addressing deductive inference. Most of the approaches have tackled the identification of concepts and relations in text, but few of them have addressed the most complex axioms like class expression subsumption. This work proposes DeLIR, a neuro-symbolic approach to identify complex logical patterns in text by combining a grammatical translation of dependency parsing trees and a fine-tuned Large language Model (LLM). DeLIR combines the strength of the parsing accuracy provided by a grammatical approach and pattern flexibility provided by a finetuned LLM. We evaluated our approach on FOLIO dataset for both translation capacity and inference capability. Our grammatical approach has a perfect parsing accuracy and combining the grammatical approach with LLMs improves the LLMS translation capacity: tinyLlama, T5-small-text2logic, Llama-7B and Mistral-7B. We also evaluate the inference capacity of the different LLMs. Mistral-7B, while being smaller than the state-of-the-art approach using GPT-4, presents similar results to predict the correct inference labels. © 2024 IEEE.
KW  - Natural Language Inference
KW  - Ontology Learning
KW  - Translation to Logic
KW  - Computer aided language translation
KW  - Computer circuits
KW  - Contrastive Learning
KW  - Dependency parsing
KW  - Language inference
KW  - Language model
KW  - Natural language inference
KW  - Natural languages
KW  - Ontology learning
KW  - Ontology's
KW  - State-of-the-art approach
KW  - Translation to logic
KW  - Unstructured texts
KW  - Ontology
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Balayn, A.
AU  - He, G.
AU  - Hu, A.
AU  - Yang, J.
AU  - Gadiraju, U.
TI  - Ready Player One! Eliciting Diverse Knowledge Using A Configurable Game
PY  - 2022
T2  - WWW 2022 - Proceedings of the ACM Web Conference 2022
SP  - 1709
EP  - 1719
DO  - 10.1145/3485447.3512241
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129888905&doi=10.1145%2f3485447.3512241&partnerID=40&md5=b4d0ddc92b40f32f3bae2636bb24fb62
AB  - Access to commonsense knowledge is receiving renewed interest for developing neuro-symbolic AI systems, or debugging deep learning models. Little is currently understood about the types of knowledge that can be gathered using existing knowledge elicitation methods. Moreover, these methods fall short of meeting the evolving requirements of several downstream AI tasks. To this end, collecting broad and tacit knowledge, in addition to negative or discriminative knowledge can be highly useful. Addressing this research gap, we developed a novel game with a purpose, 'FindItOut', to elicit different types of knowledge from human players through easily configurable game mechanics. We recruited 125 players from a crowdsourcing platform, who played 2430 rounds, resulting in the creation of more than 150k tuples of knowledge. Through an extensive evaluation of these tuples, we show that FindItOut can successfully result in the creation of plural knowledge with a good player experience. We evaluate the efficiency of the game (over 10 × higher than a reference baseline) and the usefulness of the resulting knowledge, through the lens of two downstream tasks - commonsense question answering and the identification of discriminative attributes. Finally, we present a rigorous qualitative analysis of the tuples' characteristics, that informs the future use of FindItOut across various researcher and practitioner communities. © 2022 Owner/Author.
KW  - commonsense
KW  - discriminative knowledge
KW  - GWAP
KW  - human computation
KW  - knowledge elicitation
KW  - neuro-symbolic AI
KW  - Deep learning
KW  - Knowledge management
KW  - AI systems
KW  - Commonsense
KW  - Commonsense knowledge
KW  - Discriminative knowledge
KW  - Down-stream
KW  - Elicitation methods
KW  - GWAP
KW  - Human computation
KW  - Learning models
KW  - Neuro-symbolic AI
KW  - Program debugging
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 9
ER  -

TY  - CONF
AU  - Shenoy, M.
AU  - Sahasrabudhe, S.
AU  - Ameri, F.
TI  - Neurosymbolic AI-Driven Zero-Defect Manufacturing in Semiconductor Assembly: A Hybrid Framework
PY  - 2025
T2  - ASMC (Advanced Semiconductor Manufacturing Conference) Proceedings
DO  - 10.1109/ASMC64512.2025.11010401
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007552476&doi=10.1109%2fASMC64512.2025.11010401&partnerID=40&md5=e2cb5686d52c2718b29447185c187b3f
AB  - -This paper presents an innovative framework for defect diagnosis and quality control in semiconductor manufacturing using neurosymbolic AI. By integrating knowledge graphs, ontologies, and deep neural networks, the approach harmonizes human expertise and machine learning to predict, diagnose, and mitigate defects in real time. Focusing on Failure Mode and Effects Analysis (FMEA) and other expert sources, the research transforms this knowledge into structured physics-aware ontologies and knowledge graphs to enable seamless integration with neural networks. Additionally, novel ensemble neural network architectures are explored to leverage the full potential of physics-aware neurosymbolic techniques. The proposed framework enhances defect prediction and root cause analysis and also paves the way for more interpretable and adaptive AI-driven quality control systems in semiconductor manufacturing. © 2025 IEEE.
KW  - Deep Learning
KW  - Defect Detection
KW  - Effects Analysis (FMEA)
KW  - Explainable AI (XAI)
KW  - Failure Mode
KW  - Graph Neural Networks (GNNs)
KW  - Knowledge Graphs
KW  - Neurosymbolic AI
KW  - Ontologies
KW  - Root Cause Analysis (RCA)
KW  - Semiconductor Manufacturing
KW  - Zero Defect Manufacturing (ZDM)
KW  - Adaptive control systems
KW  - Damage detection
KW  - Deep neural networks
KW  - Graph neural networks
KW  - Graphitization
KW  - Knowledge graph
KW  - Network theory (graphs)
KW  - Ontology
KW  - Deep learning
KW  - Defect detection
KW  - Effect analyze (failure mode and effect analyze)
KW  - Effects analysis
KW  - Explainable AI (XAI)
KW  - Failure mode and effects analysis
KW  - Graph neural network
KW  - Graph neural networks
KW  - Knowledge graphs
KW  - Neurosymbolic AI
KW  - Ontology's
KW  - Root cause analysis
KW  - Root cause analyze
KW  - Semiconductor manufacturing
KW  - Zero defect manufacturing
KW  - Zero defects
KW  - Model predictive control
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Blasch, E.
TI  - Digital Twins for Cognitive Situation Awareness
PY  - 2024
T2  - 2024 IEEE Conference on Cognitive and Computational Aspects of Situation Management, CogSIMA 2024
SP  - 63
EP  - 70
DO  - 10.1109/CogSIMA61085.2024.10553721
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196741387&doi=10.1109%2fCogSIMA61085.2024.10553721&partnerID=40&md5=6df23b4b03642f60755e05d25bbffe41
AB  - Situation analysis (SAn) multi-dimensional modeling from machine situation assessment (SAs) rarely presents results that match user cognitive reasoning of situation awareness (SAw). However, new machine opportunities exist that can support situation analytics from high performance modeling to go beyond computer simulations. Two recent advances afford SAn that include (1) artificial intelligence methods such as deep learning (DL) and neurosymbolic architectures, and (2) digital engineering to include open architectures and digital twins. While deep learning and open architectures are common in the last decade, recent advances in neurosymbolic approaches are becoming popular to combine neuro (e.g., DL) with probabilistic symbolic reasoning for cognitive understanding. Likewise open architectures allow many digital models to be connected through digital twins. This article highlights the opportunities for digital twins to enhance cognitive situation analytics to support situation control, situation understanding, as well as situation forecasting of plausible futures. © 2024 IEEE.
KW  - context assessment
KW  - Data Fusion
KW  - Digital engineering
KW  - Digital Twins
KW  - information fusion
KW  - Information Management
KW  - Automata theory
KW  - Data fusion
KW  - Deep learning
KW  - Information fusion
KW  - Artificial intelligence methods
KW  - Cognitive reasoning
KW  - Context assessment
KW  - Digital engineering
KW  - High performance modeling
KW  - Multi-dimensional model
KW  - Open-architectures
KW  - Situation analysis
KW  - Situation assessment
KW  - Situation awareness
KW  - Information management
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Meghraoui, K.
AU  - Racharak, T.
AU  - Ait El Kadi, K.
AU  - Bensiali, S.
AU  - Sebari, I.
TI  - A new integrated neurosymbolic approach for crop-yield prediction using environmental data and satellite imagery at field scale
PY  - 2025
T2  - Artificial Intelligence in Geosciences
VL  - 6
IS  - 1
C7  - 100125
DO  - 10.1016/j.aiig.2025.100125
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006877620&doi=10.1016%2fj.aiig.2025.100125&partnerID=40&md5=79706815159006fafdf866193c696a9b
AB  - Crop-yield is a crucial metric in agriculture, essential for effective sector management and improving the overall production process. This indicator is heavily influenced by numerous environmental factors, particularly those related to soil and climate, which present a challenging task due to the complex interactions involved. In this paper, we introduce a novel integrated neurosymbolic framework that combines knowledge-based approaches with sensor data for crop-yield prediction. This framework merges predictions from vectors generated by modeling environmental factors using a newly developed ontology focused on key elements and evaluates this ontology using quantitative methods, specifically representation learning techniques, along with predictions derived from remote sensing imagery. We tested our proposed methodology on a public dataset centered on corn, aiming to predict crop-yield. Our developed smart model achieved promising results in terms of crop-yield prediction, with a root mean squared error (RMSE) of 1.72, outperforming the baseline models. The ontology-based approach achieved an RMSE of 1.73, while the remote sensing-based method yielded an RMSE of 1.77. This confirms the superior performance of our proposed approach over those using single modalities. This integrated neurosymbolic approach demonstrates that the fusion of statistical and symbolic artificial intelligence (AI) represents a significant advancement in agricultural applications. It is particularly effective for crop-yield prediction at the field scale, thus facilitating more informed decision-making in advanced agricultural practices. Additionally, it is acknowledged that results might be further improved by incorporating more detailed ontological knowledge and testing the model with higher-resolution imagery to enhance prediction accuracy. © 2025 The Authors
KW  - Crop-yield prediction
KW  - Machine learning
KW  - Neuro-symbolic AI
KW  - Ontology
KW  - Ontology embedding
KW  - Satellite imagery
KW  - Combines
KW  - Domain Knowledge
KW  - Inference engines
KW  - Knowledge acquisition
KW  - Knowledge representation
KW  - Crop yield
KW  - Crop-yield prediction
KW  - Embeddings
KW  - Machine-learning
KW  - Neuro-symbolic artificial intelligence
KW  - Ontology embedding
KW  - Ontology's
KW  - Root mean squared errors
KW  - Yield prediction
KW  - agricultural modeling
KW  - crop yield
KW  - cropping practice
KW  - environmental factor
KW  - machine learning
KW  - micropaleontology
KW  - prediction
KW  - remote sensing
KW  - satellite data
KW  - spatial resolution
KW  - Mean square error
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Santos Pinhanez, C.
AU  - Candello, H.
AU  - Cavalin, P.
AU  - Pichiliani, M.C.
AU  - Appel, A.P.
AU  - Ribeiro, V.H.A.
AU  - Nogima, J.
AU  - De Bayser, M.
AU  - Guerra, M.
AU  - Ferreira, H.
AU  - Malfatti, G.
TI  - Integrating machine learning data with symbolic knowledge from collaboration practices of curators to improve conversational systems
PY  - 2021
T2  - Conference on Human Factors in Computing Systems - Proceedings
DO  - 10.1145/3411764.3445368
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002583878&doi=10.1145%2f3411764.3445368&partnerID=40&md5=b6e22f124a7568b1d28ee4eb061304e0
AB  - This paper describes how machine learning training data and symbolic knowledge from curators of conversational systems can be used together to improve the accuracy of those systems and to enable better curatorial tools. This is done in the context of a real-world practice of curators of conversational systems who often embed taxonomically-structured meta-knowledge into their documentation. The paper provides evidence that the practice is quite common among curators, that is used as part of their collaborative practices, and that the embedded knowledge can be mined by algorithms. Further, this meta-knowledge can be integrated, using neuro-symbolic algorithms, to the machine learning-based conversational system, to improve its run-time accuracy and to enable tools to support curatorial tasks. Those results point towards new ways of designing development tools which explore an integrated use of code and documentation by machines. © 2021 ACM.
KW  - Conversational systems
KW  - Curatorial practices
KW  - Documentation
KW  - Neuro-symbolic systems
KW  - Collaboration practices
KW  - Conversational systems
KW  - Curatorial practices
KW  - Documentation
KW  - Integrating machines
KW  - Learning data
KW  - Machine-learning
KW  - Meta-knowledge
KW  - Neuro-symbolic system
KW  - Symbolic knowledge
KW  - Machine learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - CONF
AU  - Borroto, M.
AU  - Ielo, A.
AU  - Mazzotta, G.
AU  - Ricca, F.
TI  - Answer Set Programming and Neurosymbolic AI: Applications and Future Perspectives (Invited Talk)
PY  - 2025
T2  - Communications in Computer and Information Science
VL  - 2492 CCIS
SP  - 1
EP  - 21
DO  - 10.1007/978-3-031-89366-7_1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005483187&doi=10.1007%2f978-3-031-89366-7_1&partnerID=40&md5=01dc7d49a60edc4b07d430d8a9c61a40
AB  - Answer Set Programming (ASP) is a well-known symbolic AI formalism developed in the area of knowledge representation and reasoning. This paper reports on some blendings of ASP with neural approaches, that can be classified as neurosymbolic AI systems. In particular, we describe (i) an industrial application of ASP and neural network that addresses the compliance-checking of electrical control panels, (ii) two possible combinations of ASP with large language models for enabling reasoning from text, and (iii) the usage of machine learning techniques to boost the evaluation of ASP programs by implementing solver selection pipelines. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
KW  - Answer Set Programming
KW  - Applications
KW  - neurosymbolic AI
KW  - Computer aided engineering
KW  - Computer music
KW  - Text processing
KW  - AI applications
KW  - AI systems
KW  - Answer set programming
KW  - Classifieds
KW  - Compliance checking
KW  - Future perspectives
KW  - Invited talk
KW  - Knowledge representation and reasoning
KW  - Neural-networks
KW  - Neurosymbolic AI
KW  - Computer aided instruction
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Ruiz-Torrubiano, R.
AU  - Kormann-Hainzl, G.
AU  - Paudel, S.
TI  - Using Synthetic Data for Improving Robustness and Resilience in ML-Based Smart Services
PY  - 2024
T2  - Progress in IS
VL  - Part F3229
SP  - 3
EP  - 13
DO  - 10.1007/978-3-031-60313-6_1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202027357&doi=10.1007%2f978-3-031-60313-6_1&partnerID=40&md5=dccb29dbaadf621155ed18423f09719f
AB  - We set to answer the question of whether robustness and resilience of machine learning (ML) based smart services in the Internet-of-Things (IoT) context can be improved by using synthetic data. These data can be in the form of training data for ML algorithms or service interactions. While there is plenty of research on the use of synthetic data in general ML models, there is a lack of understanding on the use of synthetic data in the smart service context. This can help make smart services more resilient by solving the cold-start problem and improve their generalization capabilities. We propose an architecture for ML-based smart services that integrates both real and synthetic data and perform an empirical evaluation than combines publicly available sensor data (streamflow data) and state-of-the-art synthetic data generation methods. Using standard performance metrics, our results show that enhancing a dataset with synthetic data can improve performance significantly even with a modest amount of data. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - Machine learning
KW  - Smart services
KW  - Synthetic data
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Umamaheswari, U.
AU  - Suneel, S.
AU  - Ravikumar, K.
AU  - Baburao, D.
AU  - Upadhyay, S.
AU  - Swapna, B.
TI  - Design and Development of a Rescue Robot to Identify Human Presence in Disaster Scenarios by using Artificial Intelligence Assisted Sensor Support
PY  - 2025
T2  - 6th International Conference on Mobile Computing and Sustainable Informatics, ICMCSI 2025 - Proceedings
SP  - 1627
EP  - 1634
DO  - 10.1109/ICMCSI64620.2025.10883140
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000014088&doi=10.1109%2fICMCSI64620.2025.10883140&partnerID=40&md5=5461baf6062278101fefa112bac68e0c
AB  - In disaster scenarios, rapid and accurate identification of human presence is critical for effective rescue operations. This study presents the design and development of an AI-assisted rescue robot equipped with advanced sensor support for detecting human presence in various disaster environments. The proposed system integrates multiple sensors, including thermal imaging, LiDAR, ultrasonic sensors, and cameras, to gather comprehensive environmental data. A YOLO-based AI model processes this data to identify human presence with high accuracy. The model was trained and validated on diverse datasets simulating real-world disaster conditions. Results show that the proposed model outperforms nine existing models, achieving an average accuracy of 97.3% across four different disaster scenarios. This accuracy is significantly higher compared to the closest competing models, highlighting the robustness and reliability of the proposed system. Additionally, the model demonstrated a precision of 96.7%, a recall of 96.5%, and a response time of 49.5 ms, all of which contribute to its superior performance in time-sensitive and complex environments. The findings suggest that this AI-assisted rescue robot is a promising solution for enhancing the efficiency and effectiveness of search and rescue operations in disaster scenarios. © 2025 IEEE.
KW  - AI-Assisted Rescue Robot
KW  - Disaster Scenarios
KW  - Human Detection
KW  - LiDAR
KW  - Thermal Imaging
KW  - YOLO Model
KW  - Disasters
KW  - Radar imaging
KW  - Robots
KW  - Ultrasonic applications
KW  - Ultrasonic cameras
KW  - Ultrasonic sensors
KW  - Advanced sensors
KW  - AI-assisted rescue robot
KW  - Design and Development
KW  - Disaster scenario
KW  - Human detection
KW  - LiDAR
KW  - Rescue operations
KW  - Rescue robot
KW  - Thermal-imaging
KW  - YOLO model
KW  - Thermography (imaging)
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
TI  - International workshops associated with the 36th International Conference on Advanced Information Systems Engineering, CAiSE 2024
PY  - 2024
T2  - Lecture Notes in Business Information Processing
VL  - 521
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196159305&partnerID=40&md5=85f14af837281d59e3399cbc9387e98e
AB  - The proceedings contain 30 papers. The special focus in this conference is on Advanced Information Systems Engineering. The topics include: Blockchain in E-Learning Platform to Enhance Trustworthy and Sharing of Micro-credentials; overstock Problems in a Purchase-to-Pay Process: An Object-Centric Process Mining Case Study; online Next Activity Prediction Under Concept Drifts; a Meta-Design Method for Modeling Customer Value; comparing Process Models Beyond Structural Equivalence; process-Specific Extensions for Enhanced Recommender Systems in Business Process Management; BPMN for Displaying the Progression of Musical Harmony and Chords - Case Study; conceptual Data Normalisation from the Practical View of Using Graph Databases; analyzing Customer Sentiments: A Comparative Evaluation of Large Language Models for Enhanced Business Intelligence; customizing a Generic Digital Transformation Objectives Model onto a Telecommunication Company; an Ontology-Based Meta-modelling Approach for Semantic-Driven Building Management Systems; LLMs for Knowledge-Graphs Enhanced Task-Oriented Dialogue Systems: Challenges and Opportunities; A Survey to Evaluate the Completeness and Correctness of a Morphological Box for AI Solutions; student Performance Prediction Model Based on Course Description and Student Similarity; Enhancing Research Clarity: Ontology-Based Modeling of Argumentation in RPML; a Conceptual Model for Blockchain-Based Trust in Digital Ecosystems (Short Paper); preface; deriving Object Oriented Normalisation from Conceptual Normalisation; empirical Insights into Context-Aware Process Predictions: Model Selection and Context Integration; improving the Service Quality in Fitness Industry by Using a Knowledge Graph Based Modeling Toolkit; An Explanation User Interface for a Knowledge Graph-Based XAI Approach to Process Analysis; Integrating Generative Artificial Intelligence into Supply Chain Management Education Using the SCOR Model; Towards Explainable Public Sector AI: An Exploration of Neuro-Symbolic AI and Enterprise Modeling (Short Paper).
M3  - Conference review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Jiomekong, A.
AU  - Oelen, A.
AU  - Auer, S.
AU  - Anna-Lena, L.
AU  - Lars, V.
TI  - Food information engineering
PY  - 2024
T2  - AI Magazine
VL  - 45
IS  - 3
SP  - 338
EP  - 353
DO  - 10.1002/aaai.12185
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200043017&doi=10.1002%2faaai.12185&partnerID=40&md5=ad4a713cf498b2be1132e9e14ca582e0
AB  - Food information engineering relies on statistical and AI techniques (e.g., symbolic, connectionist, and neurosymbolic AI) for collecting, storing, processing, diffusing, and putting food information in a form exploitable by humans and machines. Food information is collected manually and automatically. Once collected, food information is organized using tabular data representation schema, symbolic, connectionist or neurosymbolic AI techniques. Once collected, processed, and stored, food information is diffused to different stakeholders using appropriate formats. Even if neurosymbolic AI has shown promising results in many domains, we found that this approach is rarely used in the domain of food information engineering. This paper aims to serve as a good reference for food information engineering researchers. Unlike existing reviews on the subject, we cover all the aspects of food information engineering and we linked the paper to online resources built using Open Research Knowledge Graph. These resources are composed of templates, comparison tables of research contributions and smart reviews. All these resources are organized in the “Food Information Engineering” observatory and will be continually updated with new research contributions. © 2024 The Author(s). AI Magazine published by John Wiley & Sons Ltd on behalf of Association for the Advancement of Artificial Intelligence.
KW  - AI techniques
KW  - Data representations
KW  - Information engineerings
KW  - Knowledge graphs
KW  - Online resources
KW  - Representation schema
KW  - Statistical techniques
KW  - Tabular data
KW  - Knowledge graph
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Dhanusha, C.
AU  - Senthil Kumar, A.V.
AU  - Giridhar Akula, V.S.
TI  - Robust Cuckoo Search Enabled Fuzzy Neuro Symbolic Reasoning-Based Alzheimer’s Disease Prediction at Their Earlier Stages
PY  - 2023
T2  - Lecture Notes on Data Engineering and Communications Technologies
VL  - 141
SP  - 871
EP  - 886
DO  - 10.1007/978-981-19-3035-5_65
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140247180&doi=10.1007%2f978-981-19-3035-5_65&partnerID=40&md5=d8bc92b2ed37503d23befe804c2730e9
AB  - The cognitive impairments among elderly peoples make their lifestyle more complex, and it is extremely essential to accurately discover patients with mild cognitive impairment stage as it may or may not progress to Alzheimer’s disease. Many machine learning models have developed to discover the prediction of Alzheimer’s disease, but they are constrained with imbalanced medical dataset with the disease case records. Thus, this paper concentrates on developing the robust model which handles the imbalanced data when there are a smaller number of instances with case label of dementia. In this work, neuro fuzzy symbolic reasoning is developed by adapting case-based reasoning to retrieve similar pattern of matched records with the new instance as input query to determine whether it suffers from dementia or not. The case-based reasoning is empowered by applying cuckoo search model, which involves searching for matching records by applying levy flight strategy to define unknown instances and their corresponding matching instance labels, and this information is given as input to the fuzzy artificial neural network along with training dataset to enhance its prediction accuracy. The FANN with the additional knowledge obtained from cuckoo search-enhanced case-based reasoning during training phase handles uncertainty and produces more accurate results for Alzheimer’s prediction compared to the other traditional models of classification. During testing phase, the new cases are predicted and if the output is correct, then it is added and maintained in the case history for future references. The simulation results proved the prominence of cuckoo search-enabled symbolic reasoning-based Fuzzy Neuro Classifier by applying this strategy on ADNI dataset. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
KW  - ADNI
KW  - Alzheimer’s disease
KW  - Case-based reasoning
KW  - Cuckoo search
KW  - Fuzzy neuro classifier
KW  - Symbolic reasoning
KW  - Case based reasoning
KW  - Classification (of information)
KW  - Fuzzy inference
KW  - Fuzzy neural networks
KW  - Neurodegenerative diseases
KW  - Optimization
KW  - ADNI
KW  - Alzheimer
KW  - Alzheimer’s disease
KW  - Casebased reasonings (CBR)
KW  - Cognitive impairment
KW  - Cuckoo searches
KW  - Fuzzy neuro
KW  - Fuzzy neuro classifier
KW  - Matchings
KW  - Symbolic reasoning
KW  - Forecasting
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Arana-Catania, M.
AU  - Sonee, A.
AU  - Khan, A.-M.
AU  - Fatehi, K.
AU  - Tang, Y.
AU  - Jin, B.
AU  - Soligo, A.
AU  - Boyle, D.
AU  - Calinescu, R.
AU  - Yadav, P.
AU  - Ahmadi, H.
AU  - Tsourdos, A.
AU  - Guo, W.
AU  - Russo, A.
TI  - Explainable Reinforcement and Causal Learning for Improving Trust to 6G Stakeholders
PY  - 2025
T2  - IEEE Open Journal of the Communications Society
VL  - 6
SP  - 4101
EP  - 4125
DO  - 10.1109/OJCOMS.2025.3563415
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003489540&doi=10.1109%2fOJCOMS.2025.3563415&partnerID=40&md5=9049402db17d1bb8a28138d92fe09e9e
AB  - Future telecommunications will increasingly integrate AI capabilities into network infrastructures to deliver seamless and harmonized services closer to end-users. However, this progress also raises significant trust and safety concerns. The machine learning systems orchestrating these advanced services will widely rely on deep reinforcement learning (DRL) to process multi-modal requirements datasets and make semantically modulated decisions, introducing three major challenges: (1) First, we acknowledge that most explainable AI research is stakeholder-agnostic while, in reality, the explanations must cater for diverse telecommunications stakeholders, including network service providers, legal authorities, and end users, each with unique goals and operational practices; (2) Second, DRL lacks prior models or established frameworks to guide the creation of meaningful long-term explanations of the agent's behaviour in a goal-oriented RL task, and we introduce state-of-the-art approaches such as reward machine and sub-goal automata that can be universally represented and easily manipulated by logic programs and verifiably learned by inductive logic programming of answer set programs; (3) Third, most explainability approaches focus on correlation rather than causation, and we emphasise that understanding causal learning can further enhance 6G network optimisation. Together, in our judgement they form crucial enabling technologies for trustworthy services in 6G. This review offers a timely resource for academic researchers and industry practitioners by highlighting the methodological advancements needed for explainable DRL (X-DRL) in 6G. It identifies key stakeholder groups, maps their needs to X-DRL solutions, and presents case studies showcasing practical applications. By identifying and analysing these challenges in the context of 6G case studies, this work aims to inform future research, transform industry practices, and highlight unresolved gaps in this rapidly evolving field.  © 2020 IEEE.
KW  - 6G
KW  - causal learning
KW  - explainable AI
KW  - reinforcement learning
KW  - stakeholders
KW  - trust
KW  - Inductive logic programming (ILP)
KW  - Reinforcement learning
KW  - Self-supervised learning
KW  - 6g
KW  - Case-studies
KW  - Causal learning
KW  - End-users
KW  - Explainable AI
KW  - Network infrastructure
KW  - Reinforcement learnings
KW  - Safety concerns
KW  - Stakeholder
KW  - Trust
KW  - Deep reinforcement learning
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Jayasingha, P.
AU  - Iancu, B.
AU  - Lilius, J.
TI  - Neurosymbolic Approaches in AI Design - An overview
PY  - 2025
T2  - 2025 IEEE Symposium on Trustworthy, Explainable and Responsible Computational Intelligence, CITREx Companion 2025
DO  - 10.1109/CITRExCompanion65208.2025.10981497
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005025270&doi=10.1109%2fCITRExCompanion65208.2025.10981497&partnerID=40&md5=50046fb96c6bf402f95f4a579321a407
AB  - Artificial Intelligence (AI) has seen exponential growth over the last few decades, due to significant advancements in neural networks and other intricate machine learning models. One significant challenge ahead is reconciling the interpretability of symbolic AI with neural networks. The key goal is to integrate neural networks with symbolic frameworks to enable reasoning, explainability, and logical pathways within innovative, complementary architectures that mitigate the shortcomings of both neural networks and symbolic AI. This research investigates NS-AI approaches in the past decade through a systematic review, adhering to a set of criteria created to answer the most fundamental of questions on designing an NS-AI approach. The objective of this study is to unveil a generic standardized design, documenting the integration of NS-AI approaches within a model based on neural networks and symbolic AI. The output of this research shows three clear differentiations in the structure of NS-AI approaches, which are named as follows: Sequential, Multi-Integration and Hybrid. The differentiation on the design phase of the approach brings a more coherent perspective overall and promotes a better understanding of an approach, ascertaining to which of the NS-AI structures it falls into based on its fundamental design.  © 2025 IEEE.
KW  - Neurosymbolic AI
KW  - NS-AI
KW  - sub-symbolic systems
KW  - Engineering education
KW  - Design phase
KW  - Exponential growth
KW  - Interpretability
KW  - Machine learning models
KW  - Model-based OPC
KW  - Neural-networks
KW  - Neurosymbolic artificial intelligence
KW  - NS-artificial intelligence
KW  - Sub-symbolic systems
KW  - Systematic Review
KW  - Design
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Goina, D.
AU  - Hogea, E.
AU  - Maties, G.
TI  - Enhanced Anomaly Detection in Automotive Systems Using SAAD: Statistical Aggregated Anomaly Detection
PY  - 2024
T2  - Proceedings - 2024 26th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing, SYNASC 2024
SP  - 233
EP  - 241
DO  - 10.1109/SYNASC65383.2024.00046
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000190244&doi=10.1109%2fSYNASC65383.2024.00046&partnerID=40&md5=eab4a735c668db012599b3daf024c1f2
AB  - This paper presents a novel anomaly detection methodology termed Statistical Aggregated Anomaly Detection (SAAD). The SAAD approach integrates advanced statistical techniques with machine learning, and its efficacy is demonstrated through validation on real sensor data from a Hardware-in-the-Loop (HIL) environment within the automotive domain, where physical components of the vehicle are interfaced with simulation models. The HIL setup provides a controlled, real-time testing framework that replicates actual driving conditions, allowing for the validation of the vehicle's control systems under various operational scenarios without the need for a physical vehicle prototype. The key innovation of SAAD lies in its ability to significantly enhance the accuracy and robustness of anomaly detection when combined with Fully Connected Networks (FCNs) augmented by dropout layers. Comprehensive experimental evaluations indicate that the standalone statistical method achieves an accuracy of 72.1%, whereas the deep learning model alone attains an accuracy of 71.5%. In contrast, the aggregated method achieves a superior accuracy of 88.3% and an F1 score of 0.921, thereby outperforming the individual models. These results underscore the effectiveness of SAAD, demonstrating its potential for broad application in various domains, including automotive systems.  © 2024 IEEE.
KW  - anomaly detection
KW  - automotive systems
KW  - Hardware-in-the-Loop
KW  - machine learning
KW  - statistical methods
KW  - Ability testing
KW  - Automobile testing
KW  - Digital storage
KW  - Robustness (control systems)
KW  - Anomaly detection
KW  - Automotive domains
KW  - Automotive Systems
KW  - Detection approach
KW  - Hardware in the loops
KW  - Machine-learning
KW  - Physical components
KW  - Real sensor data
KW  - Simulation model
KW  - Statistical techniques
KW  - Hardware-in-the-loop simulation
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
TI  - SACMAT 2024 - Proceedings of the 29th ACM Symposium on Access Control Models and Technologies
PY  - 2024
T2  - Proceedings of ACM Symposium on Access Control Models and Technologies, SACMAT
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197767857&partnerID=40&md5=3a0c029b5a3876032fabb14a615d6e18
AB  - The proceedings contain 20 papers. The topics discussed include: ToneCheck: unveiling the impact of dialects in privacy policy; make split, not hijack: preventing feature-space hijacking attacks in split learning; making privacy-preserving federated graph analytics practical (for certain queries); SecureCheck: user-centric and geolocation-aware access mediation contracts for sharing private data; static and dynamic analysis of a usage control system; SPRT: automatically adjusting SELinux policy for vulnerability mitigation; utilizing threat partitioning for more practical network anomaly detection; prompting LLM to enforce and validate CIS critical security control; pairing human and artificial intelligence: enforcing access control policies with LLMs and formal specifications; and BlueSky: how to raise a robot — a case for neuro-symbolic ai in constrained task planning for humanoid assistive robots.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Mandala, V.
AU  - Reetha Jeyarani, M.A.
AU  - Kousalya, A.
AU  - Pavithra, M.
AU  - Arumugam, M.
TI  - An Innovative Development with Multidisciplinary Perspective in Metaverse Integrating with Blockchain Technology with Cloud Computing Techniques
PY  - 2023
T2  - 6th International Conference on Inventive Computation Technologies, ICICT 2023 - Proceedings
SP  - 1182
EP  - 1187
DO  - 10.1109/ICICT57646.2023.10134108
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163465048&doi=10.1109%2fICICT57646.2023.10134108&partnerID=40&md5=f1705901b92cc13940a5d6b63b2fe358
AB  - The metaverse is a concept of creating an innovative virtual 3D environment immersed with social interconnections. This is the process of establishing the real world into a virtual environment through virtual and augmented reality. The metaverse is considered as the advanced recapitulation of the online platform. The virtual platform adopted through the digital environment helps in improvement with dilute in everyday lives. Thus the future revolution is done through the various advances and challenges in the virtual world. Hence the metaverse is the amalgamation of numerous technologies. The interconnections with the physical environment with the virtual world helps in the sharing of information in diverse field. The development of the digital environment through the exact replica of the real world helps in the overall development in social, economic and political fields. The important requirements of metaverse includes sensors, smart glasses with headsets. The necessary parameter needed to adopt is the privacy of the users in the metaverse environment. This is done through the blockchain technology with cloud computing techniques. © 2023 IEEE.
KW  - augmented reality
KW  - blockchain technology
KW  - cloud computing
KW  - internet of things
KW  - Metaverse
KW  - security and privacy
KW  - virtual reality
KW  - Blockchain
KW  - Cloud computing
KW  - Internet of things
KW  - Virtual reality
KW  - Block-chain
KW  - Blockchain technology
KW  - Cloud-computing
KW  - Computing techniques
KW  - Digital environment
KW  - Metaverses
KW  - Multidisciplinary perspectives
KW  - Real-world
KW  - Security and privacy
KW  - Virtual worlds
KW  - Augmented reality
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - JOUR
AU  - DeLong, L.N.
AU  - Mir, R.F.
AU  - Fleuriot, J.D.
TI  - Neurosymbolic AI for Reasoning Over Knowledge Graphs: A Survey
PY  - 2025
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 36
IS  - 5
SP  - 7822
EP  - 7842
DO  - 10.1109/TNNLS.2024.3420218
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004261580&doi=10.1109%2fTNNLS.2024.3420218&partnerID=40&md5=7758c6885f9365de37244175451937e8
AB  - Neurosymbolic artificial intelligence (AI) is an increasingly active area of research that combines symbolic reasoning methods with deep learning to leverage their complementary benefits. As knowledge graphs (KGs) are becoming a popular way to represent heterogeneous and multirelational data, methods for reasoning on graph structures have attempted to follow this neurosymbolic paradigm. Traditionally, such approaches have utilized either rule-based inference or generated representative numerical embeddings from which patterns could be extracted. However, several recent studies have attempted to bridge this dichotomy to generate models that facilitate interpretability, maintain competitive performance, and integrate expert knowledge. Therefore, we survey methods that perform neurosymbolic reasoning tasks on KGs and propose a novel taxonomy by which we can classify them. Specifically, we propose three major categories: 1) logically informed embedding approaches; 2) embedding approaches with logical constraints; and 3) rule-learning approaches. Alongside the taxonomy, we provide a tabular overview of the approaches and links to their source code, if available, for more direct comparison. Finally, we discuss the unique characteristics and limitations of these methods and then propose several prospective directions toward which this field of research could evolve. © 2012 IEEE.
KW  - Graph neural networks (GNNs)
KW  - hybrid artificial intelligence (AI)
KW  - knowledge graphs (KGs)
KW  - neurosymbolic AI
KW  - representation learning
KW  - Active learning
KW  - Deep neural networks
KW  - Expert systems
KW  - Graph embeddings
KW  - Knowledge graph
KW  - Network embeddings
KW  - Network theory (graphs)
KW  - Active area
KW  - Embeddings
KW  - Graph neural network
KW  - Graph neural networks
KW  - Hybrid artificial intelligence
KW  - Hybrid artificial intelligences
KW  - Knowledge graph
KW  - Knowledge graphs
KW  - Neurosymbolic artificial intelligence
KW  - Representation learning
KW  - article
KW  - artificial intelligence
KW  - deep learning
KW  - human
KW  - reasoning
KW  - taxonomy
KW  - Graph neural networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Hidayat, R.
AU  - Ourairat, A.
AU  - Wicaksono, H.
TI  - Explainable Artificial Intelligence in Agrifood Supply Chain: State of the Art Review
PY  - 2024
T2  - Lecture Notes in Mechanical Engineering
SP  - 291
EP  - 299
DO  - 10.1007/978-3-031-74485-3_33
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213315019&doi=10.1007%2f978-3-031-74485-3_33&partnerID=40&md5=0e5691a14e6226d8d0401274826ff8e7
AB  - The increasing pressure to feed a growing population of humans for food security, with constantly changing food consumption behavior, as well as in recent light of livestock treatment and awareness for food sustainability both economically and ecologically, also due to the challenges of climate change, lead to challenges for the industries operating in the Agrifood Supply Chain (ASC). Recent technological strides in Data Analysis, Internet of Things (IoT), Machine Learning (ML), and Artificial Intelligence (AI) have ushered in a digitized and intelligent era within the ASC, reshaping production quality, sustainability, and food longevity. However, the nascent stage of AI and ML methods within the ASC raises questions about their reliability, value, transparency, and understandability. The prevalent use of black box methods underscores the need for more explainable methodologies, as the opacity of current approaches restricts widespread applicability. This paper presents a State-of-the-Art Review of Explainable AI (XAI) and ML methods in the ASC, delving into operations spanning “Farm-to-Fork,” encompassing agriculture production, processes, quality assurance, tracking, warehousing, distribution, packaging, retailing, safety, and sustainability. The research identifies challenges and proposes research directions, offering researchers an overview of opportunities to implement XAI methods in the ASC. The exploration of coexisting problems and their solutions enhances our understanding of intelligent systems in the ASC, providing valuable insights for stakeholders’ decision-making processes. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - Agrifood Supply Chain
KW  - Explainable Artificial Intelligence
KW  - State-of-the-art Review
KW  - Agri-food supply chains
KW  - Artificial intelligence learning
KW  - Explainable artificial intelligence
KW  - Food consumption
KW  - Food security
KW  - Machine learning methods
KW  - Machine-learning
KW  - Production quality
KW  - Reliability values
KW  - State-of-the art reviews
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Vu, T.-H.
AU  - Kumar Jagatheesaperumal, S.
AU  - Nguyen, M.-D.
AU  - Van Huynh, N.
AU  - Kim, S.
AU  - Pham, Q.-V.
TI  - Applications of Generative AI (GAI) for Mobile and Wireless Networking: A Survey
PY  - 2025
T2  - IEEE Internet of Things Journal
VL  - 12
IS  - 2
SP  - 1266
EP  - 1290
DO  - 10.1109/JIOT.2024.3487627
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208276384&doi=10.1109%2fJIOT.2024.3487627&partnerID=40&md5=98730c4d517faeb003aa8b77e8a2b92d
AB  - The success of artificial intelligence (AI) in multiple disciplines and vertical domains in recent years has promoted the evolution of mobile networking and the future Internet toward an AI-integrated Internet of Things (IoT) era. Nevertheless, most AI techniques rely on data generated by physical devices (e.g., mobile devices and network nodes) or specific applications (e.g., fitness trackers and mobile gaming). Therefore, generative AI (GAI), a.k.a. AI-generated content (AIGC), has emerged as a powerful AI paradigm; thanks to its ability to efficiently learn complex data distributions and generate synthetic data to represent the original data in various forms. This impressive feature is projected to transform the management of mobile networking and diversify the current services and applications provided. On this basis, this work presents a concise tutorial on the role of GAIs in mobile and wireless networking. In particular, this survey first provides the fundamentals of GAI and representative GAI models, serving as an essential preliminary to the understanding of GAI's applications in mobile and wireless networking. Then, this work provides a comprehensive review of state-of-the-art studies and GAI applications in network management, wireless security, semantic communication, and lessons learned from the open literature. Finally, this work summarizes the current research on GAI for mobile and wireless networking by outlining important challenges that need to be resolved to facilitate the development and applicability of GAI in this edge-cutting area. © 2014 IEEE.
KW  - Artificial intelligence (AI)
KW  - generative AI (GAI)
KW  - Internet of Things (IoT)
KW  - machine learning (ML)
KW  - mobile networking
KW  - wireless networks
KW  - 'current
KW  - Artificial intelligence techniques
KW  - Future internet
KW  - Generative artificial intelligence
KW  - Internet of thing
KW  - Machine-learning
KW  - Mobile networking
KW  - Multiple disciplines
KW  - Physical devices
KW  - Wireless networking
KW  - Generative adversarial networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 9
ER  -

TY  - CONF
AU  - Sander, J.
AU  - Yu, C.-E.J.
AU  - Jalaian, B.
AU  - Bastian, N.D.
TI  - Uncertainty-Quantified Neurosymbolic AI for Open Set Recognition in Network Intrusion Detection
PY  - 2024
T2  - Proceedings - IEEE Military Communications Conference MILCOM
SP  - 13
EP  - 18
DO  - 10.1109/MILCOM61039.2024.10773953
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214578593&doi=10.1109%2fMILCOM61039.2024.10773953&partnerID=40&md5=e8f9ab0d47a997ee31312fae9df0a63d
AB  - Network Intrusion Detection Systems (NIDS) are crucial for safeguarding networks by detecting and classifying malicious traffic in real-time. This paper presents a novel neurosymbolic artificial intelligence (NSAI) approach for enhancing NIDS which we call ODXU, which combines neural networks with symbolic reasoning to improve classification accuracy, particularly for challenging classes. Additionally, we introduce uncertainty quantification techniques - Confidence Scoring, Shannon Entropy, and post-hoc Uncertainty Metamodeling - to enhance the reliability of the NIDS. Our experimental results demonstrate that our NSAI model, coupled with post-hoc Uncertainty Meta-modeling, outperforms traditional methods, providing superior detection accuracy and robust uncertainty estimates. © 2024 IEEE.
KW  - Network Intrusion Detection Systems
KW  - Neurosymbolic AI
KW  - Open Set Recognition
KW  - Uncertainty Quantification
KW  - Intrusion detection
KW  - In networks
KW  - Malicious traffic
KW  - Metamodeling
KW  - Network intrusion detection
KW  - Network intrusion detection systems
KW  - Neurosymbolic AI
KW  - Open set recognition
KW  - Real- time
KW  - Uncertainty
KW  - Uncertainty quantifications
KW  - Network intrusion
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Hassan, M.
AU  - Fateh, A.A.
AU  - Lin, J.
AU  - Zhuang, Y.
AU  - Lin, G.
AU  - Xiong, H.
AU  - You, Z.
AU  - Qin, P.
AU  - Zeng, H.
TI  - Unfolding Explainable AI for Brain Tumor Segmentation
PY  - 2024
T2  - Neurocomputing
VL  - 599
C7  - 128058
DO  - 10.1016/j.neucom.2024.128058
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196838099&doi=10.1016%2fj.neucom.2024.128058&partnerID=40&md5=31346a0c4b407603f4e89f9c1b3b9108
AB  - Brain tumor segmentation (BTS) has been studied from handcrafted engineered features to conventional machine learning (ML) methods, followed by the cutting-edge deep learning approaches. Each recent approach has attempted to overcome the challenges of previous methods and brought conveniences in efficacy, throughput, computation, explainability, investigation, and interpretability. Recently, deep learning (DL) algorithms show excellent performance regarding diverse fields, including image process, computer vision, health analytics, autonomous vehicles, and natural language processes; however, ultimately impediment in making the artificial intelligence explainable and interpretable to clinicians while dealing with critical health informatics and radiomics. Besides the sophisticated deep learning models for brain tumor segmentation, notorious notions like explainability, investigation, trust, and interpretability of DL raised significant concerns for clinicians in their domains. Among many DL methods, the neuro-symbolic learning (NSL) concept has gained more attention as it can contribute to explainable and interpretable AI. In the current study, we survey the prominent approaches, from handcrafted engineering conventional ML to deep learning algorithms, highlight the challenges in DL algorithms, and propose NSL architectures for BTS. Compared to existing surveys, our study not only outlines handcrafted to DL methods for BTS but also proposed explainable and interpretable pipelines appropriate for clinical practices. Our study can better facilitate novice learners in explainable AI and propose efficient, robust, interpretable DL models to facilitate the diagnosis, prognosis, and treatment of BTS. © 2024 The Author(s)
KW  - Brain Tumor
KW  - Deep Learning
KW  - Explainable AI
KW  - Machine Learning
KW  - Neuro-Symbolic Learning
KW  - Segmentation
KW  - Brain
KW  - Deep learning
KW  - Diagnosis
KW  - Image processing
KW  - Learning systems
KW  - Medical informatics
KW  - Natural language processing systems
KW  - Tumors
KW  - Brain tumor segmentation
KW  - Brain tumors
KW  - Conventional machines
KW  - Deep learning
KW  - Explainable AI
KW  - Interpretability
KW  - Machine-learning
KW  - Neuro-symbolic learning
KW  - Segmentation
KW  - Symbolic learning
KW  - algorithm
KW  - artificial intelligence
KW  - autonomous vehicle
KW  - brain tumor
KW  - clinical practice
KW  - computer vision
KW  - deep learning
KW  - diagnosis
KW  - explainable artificial intelligence
KW  - human
KW  - learning
KW  - learning algorithm
KW  - machine learning
KW  - medical informatics
KW  - radiomics
KW  - short survey
KW  - therapy
KW  - Learning algorithms
M3  - Short survey
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Nezhadettehad, A.
AU  - Zaslavsky, A.
AU  - Rakib, A.
AU  - Loke, S.W.
TI  - Uncertainty-Aware Parking Prediction Using Bayesian Neural Networks
PY  - 2025
T2  - Sensors
VL  - 25
IS  - 11
C7  - 3463
DO  - 10.3390/s25113463
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007701283&doi=10.3390%2fs25113463&partnerID=40&md5=49fe75808c7c13687246566615bc4475
AB  - Parking availability prediction is a critical component of intelligent transportation systems, aiming to reduce congestion and improve urban mobility. While traditional deep learning models such as Long Short-Term Memory (LSTM) networks have been widely applied, they lack mechanisms to quantify uncertainty, limiting their robustness in real-world deployments. This paper proposes a Bayesian Neural Network (BNN)-based framework for parking occupancy prediction that explicitly models both epistemic and aleatoric uncertainty. Although BNNs have shown promise in other domains, they remain underutilised in parking prediction—likely due to the computational complexity and the absence of real-time context integration in earlier approaches. Our approach leverages contextual features, including temporal and environmental factors, to enhance uncertainty-aware predictions. The framework is evaluated under varying data conditions, including data scarcity (90%, 50%, and 10% of training data) and synthetic noise injection to simulate aleatoric uncertainty. Results demonstrate that BNNs outperform other methods, achieving an average accuracy improvement of 27.4% in baseline conditions, with consistent gains under limited and noisy data. Applying uncertainty thresholds at 20% and 30% further improves reliability by enabling selective, confidence-based decision making. This research shows that modelling both types of uncertainty leads to significantly improved predictive performance in intelligent transportation systems and highlights the potential of uncertainty-aware approaches as a foundation for future work on integrating BNNs with hybrid neuro-symbolic reasoning to enhance decision making under uncertainty. © 2025 by the authors.
KW  - aleatoric uncertainty
KW  - Bayesian neural networks
KW  - context-aware prediction
KW  - epistemic uncertainty
KW  - intelligent transportation systems
KW  - parking availability prediction
KW  - uncertainty quantification
KW  - urban mobility
KW  - Deep neural networks
KW  - Aleatoric uncertainty
KW  - Availability predictions
KW  - Bayesian neural networks
KW  - Context-Aware
KW  - Context-aware prediction
KW  - Epistemic uncertainties
KW  - Intelligent transportation systems
KW  - Parking availability prediction
KW  - Uncertainty
KW  - Uncertainty quantifications
KW  - Urban mobility
KW  - Urban transportation
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Khan, M.U.
AU  - Ullah, M.F.
AU  - Khan, S.U.
AU  - Kong, W.
TI  - Ethical Principles of Integrating ChatGPT Into IoT–Based Software Wearables: A Fuzzy-TOPSIS Ranking and Analysis Approach
PY  - 2025
T2  - International Journal of Intelligent Systems
VL  - 2025
IS  - 1
C7  - 6660868
DO  - 10.1155/int/6660868
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003707997&doi=10.1155%2fint%2f6660868&partnerID=40&md5=7f576d69fb34b188aa34183a33b50b52
AB  - The rapid development of the internet of things (IoT) prompts organizations and developers to seek innovative approaches for future IoT device development and research. Leveraging advanced artificial intelligence (AI) models such as ChatGPT holds promise in reshaping the conceptualization, development, and commercialization of IoT devices. Through real-world data utilization, AI enhances the effectiveness, adaptability, and intelligence of IoT devices and wearables, expediting their production process from ideation to deployment and customer assistance. However, integrating ChatGPT into IoT–based devices and wearables poses ethical concerns including data ownership, security, privacy, accessibility, bias, accountability, cost, design, quality, storage, model training, explainability, consistency, fairness, safety, transparency, trust, and generalizability. Addressing these ethical principles necessitates a comprehensive review of the literature to identify and classify relevant principles. The author identified 14 ethical principles from the literature using a systematic literature review (SLR) with a criteria of frequency ≥ 50% based on similarities. Four categories emerge based on the identified ethical principles, culminating in the application of Fuzzy-TOPSIS for analyzing, categorizing, ranking, and prioritizing these ethical principles. From the Fuzzy-TOPSIS technique results, the principle of data security and privacy is the highly ranked ethical principle for IoT–based software wearable devices with the ranking value of “0.925” as a consistency coefficient index. This method, well-established in computer science, effectively navigates fuzzy and uncertain decision-making scenarios. The pioneer outcomes of this study provide a taxonomy-based valuable insight for software manufacturers, facilitating the analysis, ranking, categorization, and prioritization of ethical principles amid the integration of ChatGPT in IoT–based devices and wearables’ research and development. Copyright © 2025 Maseeh Ullah Khan et al. International Journal of Intelligent Systems published by John Wiley & Sons Ltd.
KW  - ChatGPT
KW  - Fuzzy-TOPSIS
KW  - IoT wearable devices
KW  - LLM
KW  - NLP
KW  - opportunities
KW  - principles
KW  - Computer software selection and evaluation
KW  - Sensitive data
KW  - Analysis approach
KW  - ChatGPT
KW  - Ethical principles
KW  - fuzzy-TOPSIS
KW  - Internet of thing wearable device
KW  - LLM
KW  - Opportunity
KW  - Principle
KW  - Ranking approach
KW  - Wearable devices
KW  - Decision making
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Edwards, D.J.
TI  - A functional contextual, observer-centric, quantum mechanical, and neuro-symbolic approach to solving the alignment problem of artificial general intelligence: safe AI through intersecting computational psychological neuroscience and LLM architecture for emergent theory of mind
PY  - 2024
T2  - Frontiers in Computational Neuroscience
VL  - 18
C7  - 1395901
DO  - 10.3389/fncom.2024.1395901
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201734067&doi=10.3389%2ffncom.2024.1395901&partnerID=40&md5=181dceba06296dc4f294741eb41bd65f
AB  - There have been impressive advancements in the field of natural language processing (NLP) in recent years, largely driven by innovations in the development of transformer-based large language models (LLM) that utilize “attention.” This approach employs masked self-attention to establish (via similarly) different positions of tokens (words) within an inputted sequence of tokens to compute the most appropriate response based on its training corpus. However, there is speculation as to whether this approach alone can be scaled up to develop emergent artificial general intelligence (AGI), and whether it can address the alignment of AGI values with human values (called the alignment problem). Some researchers exploring the alignment problem highlight three aspects that AGI (or AI) requires to help resolve this problem: (1) an interpretable values specification; (2) a utility function; and (3) a dynamic contextual account of behavior. Here, a neurosymbolic model is proposed to help resolve these issues of human value alignment in AI, which expands on the transformer-based model for NLP to incorporate symbolic reasoning that may allow AGI to incorporate perspective-taking reasoning (i.e., resolving the need for a dynamic contextual account of behavior through deictics) as defined by a multilevel evolutionary and neurobiological framework into a functional contextual post-Skinnerian model of human language called “Neurobiological and Natural Selection Relational Frame Theory” (N-Frame). It is argued that this approach may also help establish a comprehensible value scheme, a utility function by expanding the expected utility equation of behavioral economics to consider functional contextualism, and even an observer (or witness) centric model for consciousness. Evolution theory, subjective quantum mechanics, and neuroscience are further aimed to help explain consciousness, and possible implementation within an LLM through correspondence to an interface as suggested by N-Frame. This argument is supported by the computational level of hypergraphs, relational density clusters, a conscious quantum level defined by QBism, and real-world applied level (human user feedback). It is argued that this approach could enable AI to achieve consciousness and develop deictic perspective-taking abilities, thereby attaining human-level self-awareness, empathy, and compassion toward others. Importantly, this consciousness hypothesis can be directly tested with a significance of approximately 5-sigma significance (with a 1 in 3.5 million probability that any identified AI-conscious observations in the form of a collapsed wave form are due to chance factors) through double-slit intent-type experimentation and visualization procedures for derived perspective-taking relational frames. Ultimately, this could provide a solution to the alignment problem and contribute to the emergence of a theory of mind (ToM) within AI. Copyright © 2024 Edwards.
KW  - consciousness
KW  - double slit experiment
KW  - functional contextualism
KW  - hypergraph
KW  - large language model
KW  - predictive coding
KW  - QBism
KW  - Health risks
KW  - Risk analysis
KW  - Risk assessment
KW  - Sensory perception
KW  - Signal to noise ratio
KW  - Stochastic systems
KW  - Syntactics
KW  - Consciousness
KW  - Contextualism
KW  - Double-slit experiment
KW  - Functional contextualism
KW  - Functionals
KW  - Hyper graph
KW  - Language model
KW  - Large language model
KW  - Predictive coding
KW  - Qbism
KW  - article
KW  - artificial general intelligence
KW  - consciousness
KW  - controlled study
KW  - drug development
KW  - empathy
KW  - human
KW  - large language model
KW  - natural language processing
KW  - natural selection
KW  - neuroscience
KW  - probability
KW  - quantum mechanics
KW  - reasoning
KW  - self concept
KW  - theory of mind
KW  - utility value
KW  - waveform
KW  - Problem oriented languages
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Yun, K.
AU  - Lu, T.
AU  - Huyen, A.
AU  - Hammer, P.
AU  - Wang, P.
TI  - Neurosymbolic hybrid approach to driver collision warning
PY  - 2022
T2  - Proceedings of SPIE - The International Society for Optical Engineering
VL  - 12101
C7  - 121010G
DO  - 10.1117/12.2620209
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136092419&doi=10.1117%2f12.2620209&partnerID=40&md5=f87ebdb5332312b594e97b77e1940cb9
AB  - There are two main algorithmic approaches to autonomous driving systems: (1) An end-to-end system in which a single deep neural network learns to map sensory input directly into appropriate warning and driving responses. (2) A mediated hybrid recognition system in which a system is created by combining independent modules that detect each semantic feature. While some researchers believe that deep learning can solve any problem, others believe that a more engineered and symbolic approach is needed to cope with complex environments with less data. Deep learning alone has achieved state-of-the-art results in many areas, from complex gameplay to predicting protein structures. In particular, in image classification and recognition, deep learning models have achieved accuracies as high as humans. But sometimes it can be very difficult to debug if the deep learning model doesn't work. Deep learning models can be vulnerable and are very sensitive to changes in data distribution. Generalization can be problematic. It's usually hard to prove why it works or doesn't. Deep learning models can also be vulnerable to adversarial attacks. Here, we combine deep learning-based object recognition and tracking with an adaptive neurosymbolic network agent, called the Non-Axiomatic Reasoning System (NARS), that can adapt to its environment by building concepts based on perceptual sequences. We achieved an improved intersection-over-union (IOU) object recognition performance of 0.65 in the adaptive retraining model compared to IOU 0.31 in the COCO data pre-trained model. We improved the object detection limits using RADAR sensors in a simulated environment, and demonstrated the weaving car detection capability by combining deep learning-based object detection and tracking with a neurosymbolic model.  © 2022 SPIE.
KW  - deep learning
KW  - driver collision warning
KW  - hybrid deep learning model
KW  - neurosymbolic model
KW  - non-axiomatic reasoning
KW  - Complex networks
KW  - Deep neural networks
KW  - Learning systems
KW  - Object detection
KW  - Semantics
KW  - Tracking radar
KW  - Axiomatics
KW  - Collision warning
KW  - Deep learning
KW  - Driver collision warning
KW  - Hybrid approach
KW  - Hybrid deep learning model
KW  - Learning models
KW  - Neurosymbolic model
KW  - Non-axiomatic reasoning
KW  - Objects recognition
KW  - Object recognition
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Hogea, E.
AU  - Onchiş, D.M.
AU  - Yan, R.
AU  - Zhou, Z.
TI  - LogicLSTM: Logically-driven long short-term memory model for fault diagnosis in gearboxes
PY  - 2024
T2  - Journal of Manufacturing Systems
VL  - 77
SP  - 892
EP  - 902
DO  - 10.1016/j.jmsy.2024.10.003
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208119278&doi=10.1016%2fj.jmsy.2024.10.003&partnerID=40&md5=9bb07557b5d8965e1db9c3ee69e8f367
AB  - This article introduces LogicLSTM, a hybrid neuro-symbolic model obtained by logically guiding a pretrained Long Short-Term Memory (LSTM) network with the support of a customized Logic Tensor Network (LTN). The model is further optimized by explainable AI techniques, for a refined fault classification of time-series data coming from industrial gearboxes. The framework leverages the intrinsic strengths of LSTMs deep recurrent networks for temporal data processing with logical reasoning capabilities, to improve prediction accuracy and interpretability of the classification. Our approach addresses the challenges of extracting relevant data features and integrating connectionist and symbolic methodologies to form a cohesive predictive model. Results from extensive testing show that our model significantly outperforms traditional LSTM models, particularly in complex fault scenarios where conventional methods may fail. Specifically, the hybrid model demonstrates a 16.03% average improvement in accuracy over standard LSTM models under conditions of sufficient data availability, and a 8.56% improvement in scenarios where data is scarce. This research not only demonstrates the potential of hybrid models in industrial applications but also highlights the importance of explainability in AI systems for critical decision-making processes. The proposed model's ability to interpret and explain its predictions makes it a valuable tool for advancing predictive maintenance strategies within the Industry 4.0 framework. © 2024
KW  - Explainable artificial intelligence
KW  - Fault classification
KW  - Long short-term memory networks
KW  - Neuro-symbolic AI
KW  - Time-series analysis
KW  - Ability testing
KW  - Deep neural networks
KW  - Long short-term memory
KW  - Tensors
KW  - Explainable artificial intelligence
KW  - Fault classification
KW  - Faults diagnosis
KW  - Hybrid model
KW  - Long short-term memory network
KW  - Memory modeling
KW  - Memory network
KW  - Neuro-symbolic AI
KW  - Short term memory
KW  - Time-series analysis
KW  - Predictive maintenance
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Lotfi, I.
AU  - Niyato, D.
AU  - Sun, S.
AU  - Kim, D.I.
AU  - Shen, X.
TI  - Semantic Information Marketing in the Metaverse: A Learning-Based Contract Theory Framework
PY  - 2024
T2  - IEEE Journal on Selected Areas in Communications
VL  - 42
IS  - 3
C7  - 10368063
SP  - 710
EP  - 723
DO  - 10.1109/JSAC.2023.3345402
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182379804&doi=10.1109%2fJSAC.2023.3345402&partnerID=40&md5=929e3da7b604ca2dced9492f505ffd3b
AB  - In this paper, we address the problem of designing incentive mechanisms by a virtual service provider (VSP) to hire sensing IoT devices to sell their sensing data to help creating and rendering the digital copy of the physical world in the Metaverse. Due to the limited bandwidth, we propose to use semantic extraction algorithms to reduce the delivered data by the sensing IoT devices. Nevertheless, mechanisms to hire sensing IoT devices to share their data with the VSP and then deliver the constructed digital twin to the Metaverse users are vulnerable to adverse selection problem. The adverse selection problem, which is caused by information asymmetry between the system entities, becomes harder to solve when the private information of the different entities are multi-dimensional. We propose a novel iterative contract design and use a new variant of multi-agent reinforcement learning (MARL) to solve the modelled multi-dimensional contract problem. To demonstrate the effectiveness of our algorithm, we conduct extensive simulations and measure several key performance metrics of the contract for the Metaverse. Our results show that our designed iterative contract is able to incentivize the participants to interact truthfully, which maximizes the profit of the VSP with minimal individual rationality (IR) and incentive compatibility (IC) violation rates. Furthermore, the proposed learning-based iterative contract framework has limited access to the private information of the participants, which is to the best of our knowledge, the first of its kind in addressing the problem of adverse selection in incentive mechanisms.  © 2023 IEEE.
KW  - age of information
KW  - contract theory
KW  - deep reinforcement learning
KW  - Digital twin
KW  - semantic communication
KW  - Deep learning
KW  - Digital devices
KW  - E-learning
KW  - Fertilizers
KW  - Internet of things
KW  - Iterative methods
KW  - Multi agent systems
KW  - Risk management
KW  - Semantics
KW  - Virtual addresses
KW  - Adverse selection
KW  - Age of information
KW  - Contract Theory
KW  - Deep reinforcement learning
KW  - Incentive mechanism
KW  - Metaverses
KW  - Reinforcement learnings
KW  - Semantic communication
KW  - Service provider
KW  - Virtual service
KW  - Reinforcement learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - CONF
AU  - Kozik, R.
AU  - Bus, S.
AU  - Gawdzik, G.
AU  - Pawlicki, M.
AU  - Pawlicka, A.
AU  - Choras, M.
TI  - Real-world Application Facilitating Trustworthy Human-Robot Collaboration with Innovative Explainable Neuro-symbolic Reasoning
PY  - 2024
T2  - IEEE International Conference on Data Mining Workshops, ICDMW
SP  - 364
EP  - 371
DO  - 10.1109/ICDMW65004.2024.00053
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001253961&doi=10.1109%2fICDMW65004.2024.00053&partnerID=40&md5=8caaaa65eff156539434665760337a38
AB  - With advancements in computer vision, robotics, and machine learning, human-robot collaboration is becoming increasingly prevalent in industrial and everyday contexts. The progressing and omnipresent need for automation of various aspects of our lives opens new challenges regarding safety and building trust between humans and autonomous robots. Although human-robot collaboration applications allow for increased productivity, safety is still a significant challenge when designing and deploying HRC systems.The hybrid AI approach developed and presented integrates deep learning algorithms and symbolic AI to efficiently detect potentially dangerous events. The goal is to increase the safety of the human operator and eventually to improve the trust in the robotic system. Moreover, we believe that such an innovative AI-based data analysis approach can lead to more fluent human-robot collaboration and improved productivity without sacrificing the safety of the human operators. Initial results demonstrate a high anomaly detection accuracy with a Balanced Accuracy of 99.9% and an F1-score of 99.8%, indicating our model's effectiveness in enhancing safe and efficient human-robot collaboration. © 2024 IEEE.
KW  - autonomous robots
KW  - deep learning
KW  - human-robot collaboration
KW  - hybrid AI
KW  - neuro-symbolic
KW  - Contrastive Learning
KW  - Deep learning
KW  - Federated learning
KW  - Human robot interaction
KW  - Industrial robots
KW  - Microrobots
KW  - Nanorobots
KW  - Robot applications
KW  - Robot learning
KW  - Deep learning
KW  - Human operator
KW  - Human-robot collaboration
KW  - Hybrid AI
KW  - Neuro-symbolic
KW  - Real-world
KW  - Symbolic reasoning
KW  - Vision learning
KW  - Vision machine
KW  - Vision robotics
KW  - Adversarial machine learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Hornos, M.J.
AU  - Quinde, M.
TI  - Development methodologies for IoT-based systems: challenges and research directions
PY  - 2024
T2  - Journal of Reliable Intelligent Environments
VL  - 10
IS  - 3
SP  - 215
EP  - 244
DO  - 10.1007/s40860-024-00229-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201010774&doi=10.1007%2fs40860-024-00229-9&partnerID=40&md5=963f5a57cd981db3e3d695636922acb0
AB  - The spread of IoT-based systems presents several potential benefits to society but still has crucial challenges in different research areas. From the software development point of view, an established methodology for IoT-based systems development is still yet to be found despite the considerable research efforts that are being made in the area. This article presents a literature review of the existing methodologies for IoT-based systems development, highlighting their benefits and limitations. The article also describes and analyses the existing critical challenges in finding a methodology addressing the complex nature of IoT-based systems. This analysis leads to present the open research directions in developing IoT-based systems, which are pathways to drive the research efforts towards addressing the key issues in the area with the aim of finding a methodology that is simple for developers but that ensures high-quality IoT-based systems. © The Author(s), under exclusive licence to Springer Nature Switzerland AG 2024.
KW  - Development methodologies
KW  - Internet of Things (IoT)
KW  - Methodological approaches
KW  - Software engineering process
KW  - Support tools
KW  - System life cycle stages
KW  - Life cycle
KW  - Software design
KW  - Development methodology
KW  - Internet of thing
KW  - Life cycle stages
KW  - Methodological approach
KW  - Research efforts
KW  - Software engineering process
KW  - Support tool
KW  - System development
KW  - System life cycle
KW  - System life cycle stage
KW  - Internet of things
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - CONF
AU  - Gomaa, A.
AU  - Feld, M.
TI  - Adaptive User-centered Neuro-symbolic Learning for Multimodal Interaction with Autonomous Systems
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3524
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177073959&partnerID=40&md5=c04949ba4bb220f95eab12c6a6a3c35d
AB  - Recent advances in deep learning and data-driven approaches have facilitated the perception and comprehension of objects and their environments in a perceptual subsymbolic manner. Consequently, these autonomous systems can now perform tasks such as object detection, sensor data fusion, and language understanding. However, there is an increasing demand to further enhance these systems to attain a more conceptual and symbolic understanding of objects and their environments and acquire the underlying reasoning behind the learned tasks. Achieving this level of powerful artificial intelligence necessitates considering both explicit teachings provided by humans (e.g., describing a situation or explaining how to act) and implicit teaching obtained through observing human behavior (e.g., through the system's sensors). Hence, it is imperative to incorporate symbolic and subsymbolic learning approaches to support implicit and explicit interaction models. This integration enables the system to achieve multimodal input and output capabilities. In this extended abstract, we argue for considering these input types, along with human-in-the-loop and incremental learning techniques, to advance the field of artificial intelligence and enable autonomous systems to emulate human learning. We propose several hypotheses and design guidelines aimed at achieving this objective. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
KW  - Adaptive Models
KW  - Human-Centered Artificial Intelligence
KW  - Multimodal Interaction
KW  - Personalization
KW  - Behavioral research
KW  - Deep learning
KW  - Interactive computer systems
KW  - Learning systems
KW  - Object recognition
KW  - Real time systems
KW  - Sensor data fusion
KW  - Adaptive models
KW  - Data-driven approach
KW  - Detection sensors
KW  - Human-centered artificial intelligence
KW  - Multimodal Interaction
KW  - Objects detection
KW  - Personalizations
KW  - Sub-symbolic
KW  - Symbolic learning
KW  - User-centred
KW  - Object detection
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Belle, V.
TI  - Excursions in First-Order Logic and Probability: Infinitely Many Random Variables, Continuous Distributions, Recursive Programs and Beyond
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14281 LNAI
SP  - 35
EP  - 46
DO  - 10.1007/978-3-031-43619-2_3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174532495&doi=10.1007%2f978-3-031-43619-2_3&partnerID=40&md5=cdbe157b0729f6aaedfd39686ea0b486
AB  - The unification of the first-order logic and probability has been seen as a long-standing concern in philosophy, AI and mathematics. In this talk, I will briefly review our recent results on revisiting that unification. Although there are plenty of approaches in communities such as statistical relational learning, automated planning, and neuro-symbolic AI that leverage and develop languages with logical and probabilistic aspects, they almost always restrict the representation as well as the semantic framework in various ways which do not fully explain how to combine first-order logic and probability theory in a general way. In many cases, this restriction is justified because it may be necessary to focus on practicality and efficiency. However, the search for a restriction-free mathematical theory remains ongoing. In this article, we discuss our recent results regarding the development of languages that support arbitrary quantification, possibly infinitely many random variables, both discrete and continuous distributions, as well as programming languages built on top of such features to include recursion and branching control. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.
KW  - First-order logic
KW  - Probabilistic logic
KW  - Programs
KW  - Artificial intelligence
KW  - Computer circuits
KW  - Logic programming
KW  - Probabilistic logics
KW  - Probability distributions
KW  - Semantics
KW  - Automated planning
KW  - Continuous distribution
KW  - First order logic
KW  - Logic and probability
KW  - Logic theory
KW  - Probabilistic aspects
KW  - Program
KW  - Recursive programs
KW  - Semantics framework
KW  - Statistical relational learning
KW  - Random variables
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Padalkar, P.
AU  - Ślusarz, N.
AU  - Komendantskaya, E.
AU  - Gupta, G.
TI  - A Neurosymbolic Framework for Bias Correction in Convolutional Neural Networks
PY  - 2024
T2  - CEUR Workshop Proceedings
VL  - 3799
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208595887&partnerID=40&md5=b6a80be4ce2fc4172c29167f3f1b9c22
AB  - Recent efforts in interpreting Convolutional Neural Networks (CNNs) focus on translating the activation of CNN filters into a stratified Answer Set Program (ASP) rule-sets. The CNN filters are known to capture high-level image concepts, thus the predicates in the rule-set are mapped to the concept that their corresponding filter represents. Hence, the rule-set exemplifies the decision-making process of the CNN w.r.t the concepts that it learns for any image classification task. These rule-sets help understand the biases in CNNs, although correcting the biases remains a challenge. We introduce a neurosymbolic framework called NeSyBiCor for bias correction in a trained CNN. Given symbolic concepts, as ASP constraints, that the CNN is biased towards, we convert the concepts to their corresponding vector representations. Then, the CNN is retrained using our novel semantic similarity loss that pushes the filters away from (or towards) learning the desired/undesired concepts. The final ASP rule-set obtained after retraining, satisfies the constraints to a high degree, thus showing the revision in the knowledge of the CNN. We demonstrate that our NeSyBiCor framework successfully corrects the biases of CNNs trained with subsets of classes from the Places dataset while sacrificing minimal accuracy and improving interpretability. © 2024 Copyright for this paper by its authors.
KW  - Answer Set Programming
KW  - CNN
KW  - Neurosymbolic AI
KW  - Representation Learning
KW  - Semantic Loss
KW  - XAI
KW  - Convolutional neural networks
KW  - Image enhancement
KW  - Answer set
KW  - Answer set programming
KW  - Bias correction
KW  - Convolutional neural network
KW  - Neural network filters
KW  - Neurosymbolic AI
KW  - Representation learning
KW  - Rule set
KW  - Semantic loss
KW  - XAI
KW  - Convolution
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Gomaa, A.
AU  - Feld, M.
TI  - Towards Adaptive User-centered Neuro-symbolic Learning for Multimodal Interaction with Autonomous Systems
PY  - 2023
T2  - ACM International Conference Proceeding Series
SP  - 689
EP  - 694
DO  - 10.1145/3577190.3616121
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175790272&doi=10.1145%2f3577190.3616121&partnerID=40&md5=3bced80033b418d9193e5b1d5171bdfa
AB  - Recent advances in deep learning and data-driven approaches have facilitated the perception of objects and their environments in a perceptual subsymbolic manner. Thus, these autonomous systems can now perform object detection, sensor data fusion, and language understanding tasks. However, there is an increasing demand to further enhance these systems to attain a more conceptual and symbolic understanding of objects to acquire the underlying reasoning behind the learned tasks. Achieving this level of powerful artificial intelligence necessitates considering both explicit teachings provided by humans (e.g., explaining how to act) and implicit teaching obtained through observing human behavior (e.g., through system sensors). Hence, it is imperative to incorporate symbolic and subsymbolic learning approaches to support implicit and explicit interaction models. This integration enables the system to achieve multimodal input and output capabilities. In this Blue Sky paper, we argue for considering these input types, along with human-in-the-loop and incremental learning techniques, to advance the field of artificial intelligence and enable autonomous systems to emulate human learning. We propose several hypotheses and design guidelines aimed at achieving this objective.  © 2023 ACM.
KW  - Adaptive Models
KW  - Data Fusion
KW  - Human-Centered Artificial Intelligence
KW  - Multimodal Interaction
KW  - Personalization
KW  - Behavioral research
KW  - Interactive computer systems
KW  - Learning systems
KW  - Object detection
KW  - Object recognition
KW  - Sensor data fusion
KW  - Adaptive models
KW  - Data-driven approach
KW  - Detection sensors
KW  - Human-centered artificial intelligence
KW  - Multimodal Interaction
KW  - Objects detection
KW  - Personalizations
KW  - Sub-symbolic
KW  - Symbolic learning
KW  - User-centred
KW  - Deep learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Namasivayam, K.
AU  - Singh, H.
AU  - Bindal, V.
AU  - Tuli, A.
AU  - Agrawal, V.
AU  - Jain, R.
AU  - Singla, P.
AU  - Paul, R.
TI  - Learning Neuro-symbolic Programs for Language Guided Robot Manipulation
PY  - 2023
T2  - Proceedings - IEEE International Conference on Robotics and Automation
VL  - 2023-May
SP  - 7973
EP  - 7980
DO  - 10.1109/ICRA48891.2023.10160545
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168652224&doi=10.1109%2fICRA48891.2023.10160545&partnerID=40&md5=1716600930184ea88003ac18a492b964
AB  - Given a natural language instruction and an input scene, our goal is to train a model to output a manipulation program that can be executed by the robot. Prior approaches for this task possess one of the following limitations: (i) rely on hand-coded symbols for concepts limiting generalization beyond those seen during training [1] (ii) infer action sequences from instructions but require dense sub-goal supervision [2] or (iii) lack semantics required for deeper object-centric reasoning inherent in interpreting complex instructions [3]. In contrast, our approach can handle linguistic as well as perceptual variations, end-to-end trainable and requires no intermediate supervision. The proposed model uses symbolic reasoning constructs that operate on a latent neural object-centric representation, allowing for deeper reasoning over the input scene. Central to our approach is a modular structure consisting of a hierarchical instruction parser and an action simulator to learn disentangled action representations. Our experiments on a simulated environment with a 7-DOF manipulator, consisting of instructions with varying number of steps and scenes with different number of objects, demonstrate that our model is robust to such variations and significantly outperforms baselines, particularly in the generalization settings. The code, dataset and experiment videos are available at https://nsrmp.github.io © 2023 IEEE.
KW  - Robotics
KW  - Action sequences
KW  - Coded symbols
KW  - End to end
KW  - Generalisation
KW  - Model use
KW  - Modular structures
KW  - Natural languages
KW  - Robot manipulation
KW  - Subgoals
KW  - Symbolic reasoning
KW  - Semantics
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 8
ER  -

TY  - CHAP
AU  - Soldatos, J.
AU  - Ipektsidis, B.
AU  - Kefalakis, N.
AU  - Despotopoulou, A.-M.
TI  - Reference architecture for AI-based industry 5.0 applications
PY  - 2024
T2  - Artificial Intelligence in Manufacturing: Enabling Intelligent, Flexible and Cost-Effective Production Through AI
SP  - 3
EP  - 26
DO  - 10.1007/978-3-031-46452-2_1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200788588&doi=10.1007%2f978-3-031-46452-2_1&partnerID=40&md5=b1769668ab369fc338bc4ff23116f2a6
AB  - Industry 5.0 (I5.0) is a novel paradigm for the development and deployment of industrial applications based on Cyber-Physical Systems (CPS). It evolves Industry 4.0 in directions that exploit trustworthy human-AI interactions in human-in-the-loop scenarios. Despite the rising popularity of I5.0, there is still a lack of reference architectures (RAs) that outline the building blocks of I5.0 applications, along with the structuring principles for effectively integrating them in industrial systems. This chapter introduces a reference model for industrial applications that addresses critical elements and requirements of the I5.0, including human-robot collaboration, cybersecurity, safety, and trust. The model enhances state-of-the-art I4.0 Industrial Internet of Things (IIoT) architectures with human-centered I5.0 features and functionalities. Based on this model, the present chapter introduces a set of blueprints that could ease the development, deployment, and operation of I5.0 applications. These blueprints address technical integration, trustworthy operations, as well as the ever-important compliance to applicable regulations such as General Data Protection Regulation (GDPR) and the emerging AI Act. © The Author(s) 2024. All rights reserved.
KW  - AI act
KW  - Artificial intelligence
KW  - Industrial data reliability
KW  - Industry 4.0
KW  - Industry 5.0
KW  - Reference architecture
KW  - Security
KW  - Trustworthy AI
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
TI  - 4th International Conference on Robotics, Computer Vision and Intelligent Systems, ROBOVIS 2024
PY  - 2024
T2  - Communications in Computer and Information Science
VL  - 2077 CCIS
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194094116&partnerID=40&md5=c09165429bc8244e45260c2f23bd9b50
AB  - The proceedings contain 29 papers. The special focus in this conference is on Robotics, Computer Vision and Intelligent Systems. The topics include: Park Marking Detection and Tracking Based on a Vehicle On-Board System of Fisheye Cameras; analysis of Age Invariant Face Recognition Efficiency Using Face Feature Vectors; uncertainty Driven Active Learning for Image Segmentation in Underwater Inspection; Enhancing Connected Cooperative ADAS: Deep Learning Perception in an Embedded System Utilizing Fisheye Cameras; Weapon Detection Using PTZ Cameras; improving Semantic Mapping with Prior Object Dimensions Extracted from 3D Models; Offline Deep Model Predictive Control (MPC) for Visual Navigation; BiGSiD: Bionic Grasping with Edge-AI Slip Detection; GAT-POSE: Graph Autoencoder-Transformer Fusion for Future Pose Prediction; UCorr: Wire Detection and Depth Estimation for Autonomous Drones; a Quality-Based Criteria for Efficient View Selection; Multi-UAV Weed Spraying; human Comfort Factors in People Navigation: Literature Review, Taxonomy and Framework; region Prediction for Efficient Robot Localization on Large Maps; utilizing Dataset Affinity Prediction in Object Detection to Assess Training Data; Optimizing Mobile Robot Navigation Through Neuro-Symbolic Fusion of Deep Deterministic Policy Gradient (DDPG) and Fuzzy Logic; DAFDeTr: Deformable Attention Fusion Based 3D Detection Transformer; MDC-Net: Multimodal Detection and Captioning Network for Steel Surface Defects; operational Modeling of Temporal Intervals for Intelligent Systems; A Meta-MDP Approach for Information Gathering Heterogeneous Multi-agent Systems; interacting with a Visuotactile Countertop; a Color Event-Based Camera Emulator for Robot Vision; fast Point Cloud to Mesh Reconstruction for Deformable Object Tracking; estimation of Optimal Gripper Configuration Through an Embedded Array of Proximity Sensors; The Twinning Technique of the SyncLMKD Method; intuitive Multi-modal Human-Robot Interaction via Posture and Voice; virtual Model of a Robotic Arm Digital Twin with MuJoCo.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Karabulut, E.
AU  - Groth, P.
AU  - Degeler, V.
TI  - 3K: Knowledge-Enriched Digital Twin Framework
PY  - 2025
T2  - IoT 2024 - Proceedings of the 14th International Conference on the Internet of Things
SP  - 188
EP  - 193
DO  - 10.1145/3703790.3703834
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002829202&doi=10.1145%2f3703790.3703834&partnerID=40&md5=0a5b7a65dca288338c86d234e4edd87f
AB  - Digital Twins (DTs) are the digital equivalent of physical entities that facilitate, among others, monitoring and decision-making, thus helping extend the longevity of the twinned entity. DTs with automated decision-making capabilities require explainable inference mechanisms, especially for critical infrastructures such as water networks. Here we introduce 3K, a DT framework that aims for knowledge-enriched inference that is explainable and fast, by synthesizing knowledge representation (semantics) and knowledge discovery methods. 3K constructs a knowledge graph, which is becoming a mainstream way of metadata storage in DTs, and proposes a new method that can run on both sensor data and knowledge graphs to learn semantic association rules. The rules represent the expected working conditions of the DT and we argue that when combined with domain knowledge in the form of ontological axioms, semantic association rules can help perform downstream tasks in DTs, including extending the longevity of the twinned entities such as an Internet of Things (IoT) system. Furthermore, we demonstrate the 3K framework in a water distribution network use case and show how it can be used for downstream tasks. © 2024 Copyright held by the owner/author(s).
KW  - Digital Twin
KW  - Knowledge discovery
KW  - Neural Networks
KW  - Neurosymbolic
KW  - Rule Learning
KW  - Semantic Web
KW  - Critical infrastructures
KW  - Automated decision making
KW  - Decisions makings
KW  - Digital equivalents
KW  - Down-stream
KW  - Knowledge graphs
KW  - Neural-networks
KW  - Neurosymbolic
KW  - Rule learning
KW  - Semantic associations
KW  - Semantic-Web
KW  - Knowledge graph
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Wickramarachchi, R.
AU  - Henson, C.
AU  - Sheth, A.
TI  - An evaluation of knowledge graph embeddings for autonomous driving data: Experience and practice
PY  - 2020
T2  - CEUR Workshop Proceedings
VL  - 2600
SP  - 24UMMY
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085186421&partnerID=40&md5=c63388cb8c53860e06aa070e6fab294d
AB  - The autonomous driving (AD) industry is exploring the use of knowledge graphs (KGs) to manage the vast amount of heterogeneous data generated from vehicular sensors. The various types of equipped sensors include video, LIDAR and RADAR. Scene understanding is an important topic in AD which requires consideration of various aspects of a scene, such as detected objects, events, time and location. Recent work on knowledge graph embeddings (KGEs) - an approach that facilitates neuro-symbolic fusion - has shown to improve the predictive performance of machine learning models. With the expectation that neuro-symbolic fusion through KGEs will improve scene understanding, this research explores the generation and evaluation of KGEs for autonomous driving data. We also present an investigation of the relationship between the level of informational detail in a KG and the quality of its derivative embeddings. By systematically evaluating KGEs along four dimensions – i.e. quality metrics, KG informational detail, algorithms, and datasets – we show that (1) higher levels of informational detail in KGs lead to higher quality embeddings, (2) type and relation semantics are better captured by the semantic transitional distance-based TransE algorithm, and (3) some metrics, such as coherence measure, may not be suitable for intrinsically evaluating KGEs in this domain. Additionally, we also present an (early) investigation of the usefulness of KGEs for two use-cases in the AD domain. Copyright © 2020 held by the author(s).
KW  - Autonomous vehicles
KW  - Knowledge engineering
KW  - Machine learning
KW  - Object detection
KW  - Optical radar
KW  - Semantics
KW  - Springs (components)
KW  - Autonomous driving
KW  - Evaluation of knowledge
KW  - Heterogeneous data
KW  - Knowledge graphs
KW  - Machine learning models
KW  - Predictive performance
KW  - Relation semantics
KW  - Scene understanding
KW  - Embeddings
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - He, D.
AU  - Yu, X.
AU  - Li, T.
AU  - Chan, S.
AU  - Guizani, M.
TI  - Firmware Vulnerabilities Homology Detection Based on Clonal Selection Algorithm for IoT Devices
PY  - 2022
T2  - IEEE Internet of Things Journal
VL  - 9
IS  - 17
SP  - 16438
EP  - 16445
DO  - 10.1109/JIOT.2022.3152364
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125353334&doi=10.1109%2fJIOT.2022.3152364&partnerID=40&md5=bb2f60e4e0eaacf54571ba657615be8e
AB  - With the wide application of Internet of Things (IoT) devices, security attacks against their firmware often occur, which has attracted more attention from the research community. Firmware is an important part of IoT devices, and attacks against them is one of the main means to destroy them. Therefore, firmware security is considered a core of the overall devices' security. At present, most of the firmware vulnerabilities have a small number of related samples, so it is difficult to use machine learning methods to generate detectors for some of them. Therefore, based on the collected data of related firmware vulnerabilities, this article proposes a firmware vulnerability homology detection method based on the clonal selection algorithm. We design the numerical and structural characteristics of vulnerability functions, train a detector for each function separately, and improve the recall rate of vulnerability detection. Compared with existing machine learning methods, this method only depends on the affinity between the objective function and the detector, which avoids the requirement of a large number of sample data sets. Finally, relevant experiments are carried out to verify the effectiveness of the method.  © 2014 IEEE.
KW  - Clonal selection
KW  - firmware
KW  - homology
KW  - Internet of Things (IoT)
KW  - Artificial intelligence
KW  - Feature extraction
KW  - Firmware
KW  - Internet of things
KW  - Learning systems
KW  - Semantics
KW  - Clonal selection
KW  - Clonal selection algorithms
KW  - Clonal selection.
KW  - Detection methods
KW  - Features extraction
KW  - Homology
KW  - Machine learning methods
KW  - Research communities
KW  - Security
KW  - Security attacks
KW  - Simulated annealing
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 10
ER  -

TY  - JOUR
AU  - Kosasih, E.E.
AU  - Papadakis, E.
AU  - Baryannis, G.
AU  - Brintrup, A.
TI  - A review of explainable artificial intelligence in supply chain management using neurosymbolic approaches
PY  - 2024
T2  - International Journal of Production Research
VL  - 62
IS  - 4
SP  - 1510
EP  - 1540
DO  - 10.1080/00207543.2023.2281663
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177643935&doi=10.1080%2f00207543.2023.2281663&partnerID=40&md5=73d8d50d41b48d9e9b68eb4ff7b68865
AB  - Artificial Intelligence (AI) has emerged as a complementary technology in supply chain research. However, the majority of AI approaches explored in this context afford little to no explainability, which is a significant barrier to a broader adoption of AI in supply chains. In recent years, the need for explainability has been a strong impetus for research in hybrid AI methodologies that combine neural architectures with logic-based reasoning, which are collectively referred to as Neurosymbolic AI. The aim of this paper is to provide a comprehensive overview of supply chain management literature that employs approaches within the neurosymbolic AI spectrum. To that end, a systematic review is conducted, followed by bibliometric, descriptive and thematic analyses on the identified studies. Our findings indicate that researchers have primarily focused on the limited subset of neurofuzzy approaches, while some supply chain applications, such as performance evaluation and sustainability, and sectors such as pharmaceutical and construction have received less attention. To help address these gaps, we propose five pillars of neurosymbolic AI research for supply chains and provide four use cases of applying unexplored neurosymbolic AI approaches to address typical problems in supply chain management, including a discussion of prerequisites for adopting such technologies. We envision that the findings and contributions of this survey will help encourage further research in neurosymbolic AI for supply chains and increase adoption of such technologies within supply chain practice. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.
KW  - artificial intelligence
KW  - explainability
KW  - hybrid AI
KW  - neural networks
KW  - neurosymbolic AI
KW  - Supply chain
KW  - Artificial intelligence
KW  - Based reasonings
KW  - Bibliometrics analysis
KW  - Descriptive analysis
KW  - Explainability
KW  - Hybrid artificial intelligences
KW  - Neural architectures
KW  - Neural-networks
KW  - Neurosymbolic artificial intelligence
KW  - Spectra's
KW  - Systematic Review
KW  - Supply chain management
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 22
ER  -

TY  - CONF
AU  - Xi, M.
AU  - Perera, M.
AU  - Matthews, B.
AU  - Wang, R.
AU  - Weiley, V.
AU  - Somarathna, R.
AU  - Maqbool, H.
AU  - Chen, J.
AU  - Engelke, U.
AU  - Anderson, S.
AU  - Adcock, M.
AU  - Thomas, B.H.
TI  - Towards Immersive AI
PY  - 2024
T2  - Proceedings - 2024 IEEE International Symposium on Mixed and Augmented Reality Adjunct, ISMAR-Adjunct 2024
SP  - 260
EP  - 264
DO  - 10.1109/ISMAR-Adjunct64951.2024.00062
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214375967&doi=10.1109%2fISMAR-Adjunct64951.2024.00062&partnerID=40&md5=fd07c97119d71418bb4365582b1d188c
AB  - With every shift in scientific paradigms comes not only a new way of seeing the world, but as Kunh argues, new tools for seeing [13]. Today, generative AI and neuro-symbolic systems show signs of changing how science functions, making it possible to synthesise complex heterogenous data in real time, interleaved with complex and situated workflows. But the new tools are not yet fully formed. To realise the opportunities and meet the challenges posed by the growth of generative AI for science and other knowledge work requires us to look beyond improvements in algorithms. The decision-making landscape for information workers has drastically changed, and the pressing need for analysts and experts to collaborate with AI in complex, high-tempo data environments has never been more evident.To bring strategic focus to these challenges in ways that will enable social, environmental and economic benefits for all, CSIRO's Data61 (the data and digital specialist arm of the Commonwealth Scientific and Industrial Research Organisation - Australia's national science agency) has established the Immersive AI Research Cluster. The cluster allows more than 30 research scientists and engineers to focus on defining a broad range of scientific disciplines for people to work with and understand the information provided by AI, such as data visualisation, visual analytics, connecting remote people, through immersive technologies like virtual and augmented reality. This workshop paper presents the trending research directions and challenges that emerged from this research cluster, which are closely linked to the scientific domains and illustrated through use cases.  © 2024 IEEE.
KW  - artificial intelligence
KW  - augmented reality
KW  - Immersive analytics
KW  - mixed reality
KW  - situated imaging.
KW  - Data visualization
KW  - Decision making
KW  - Visual analytics
KW  - Heterogenous data
KW  - Immersive
KW  - Immersive analytic
KW  - Mixed reality
KW  - Neuro-symbolic system
KW  - Real- time
KW  - Scientific paradigm
KW  - Situated imaging.
KW  - Time-interleaved
KW  - Work-flows
KW  - Industrial research
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Bovenzi, G.
AU  - Cerasuolo, F.
AU  - Ciuonzo, D.
AU  - Di Monda, D.
AU  - Guarino, I.
AU  - Montieri, A.
AU  - Persico, V.
AU  - Pescape, A.
TI  - Mapping the Landscape of Generative AI in Network Monitoring and Management
PY  - 2025
T2  - IEEE Transactions on Network and Service Management
VL  - 22
IS  - 3
SP  - 2441
EP  - 2472
DO  - 10.1109/TNSM.2025.3543022
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218779879&doi=10.1109%2fTNSM.2025.3543022&partnerID=40&md5=6403a14d0da0651be6edcdb55aaa05c9
AB  - Generative Artificial Intelligence (GenAI) models such as LLMs, GPTs, and Diffusion Models have recently gained widespread attention from both the research and the industrial communities. This survey explores their application in network monitoring and management, focusing on prominent use cases, as well as challenges and opportunities. We discuss how network traffic generation and classification, network intrusion detection, networked system log analysis, and network digital assistance can benefit from the use of GenAI models. Additionally, we provide an overview of the available GenAI models, datasets for large-scale training phases, and platforms for the development of such models. Finally, we discuss research directions that potentially mitigate the roadblocks to the adoption of GenAI for network monitoring and management. Our investigation aims to map the current landscape and pave the way for future research in leveraging GenAI for network monitoring and management. © 2004-2012 IEEE.
KW  - diffusion models
KW  - Generative AI
KW  - GPT
KW  - intrusion detection
KW  - LLM
KW  - networking
KW  - traffic classification
KW  - Diffusion model
KW  - Generative AI
KW  - GPT
KW  - Intrusion-Detection
KW  - LLM
KW  - Monitoring and management
KW  - Network Monitoring
KW  - Networking
KW  - Networks management
KW  - Traffic classification
KW  - Generative adversarial networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Duncan, G.
TI  - Motion Planning and Remote Sensing Algorithms, Predictive Geospatial Modeling and Deep Learning Artificial Intelligence Tools, and Machine Perception and Image Recognition Technologies in the Blockchain-based Virtual Economy
PY  - 2022
T2  - Analysis and Metaphysics
VL  - 21
SP  - 193
EP  - 209
DO  - 10.22381/AM21202212
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146453668&doi=10.22381%2fAM21202212&partnerID=40&md5=546b14feffc74a8d3e438ed24af16e47
AB  - In this article, I cumulate previous research findings indicating that Predictive algorithms, behavioral and demographic analytics, and augmented reality shopping tools assist product customization services across real-time immersive 3D worlds and in the virtual economy. I contribute to the literature on metaverse tech-nologies, simulation modeling tools, and object recognition algorithms by showing that digital twin technology, behavioral and demographic analytics, and predictive modeling algorithms further immersive virtual shopping in the metaverse economy. Throughout July 2022, I performed a quantitative literature review of the Web of Science, Scopus, and ProQuest databases, with search terms including “blockchain-based virtual economy” + “motion planning and remote sensing algorithms,” “predictive geospatial modeling and deep learning artificial intelligence tools,” and “machine perception and image recognition technologies.” As I inspected research published between 2021 and 2022, only 154 articles satisfied the eligibility criteria. By eliminating controversial findings, outcomes unsubstantiated by replication, too imprecise material, or having similar titles, I decided upon 34, generally empirical, sources. Data visualization tools: Dimensions (bibliometric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AXIS, Dedoose, ROBIS, and SRDR. © 2022, Addleton Academic Publishers. All rights reserved.
KW  - blockchain
KW  - deep learning
KW  - machine perception
KW  - motion planning
KW  - predictive geospatial modeling
KW  - remote sensing
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - CONF
AU  - Liatsas, L.
AU  - Kibalya, G.M.
AU  - Antonopoulos, A.
TI  - XAI-driven Model Design for Resource Utilization Forecasting in Cloud-native 6G Networks
PY  - 2024
T2  - 2024 IEEE International Mediterranean Conference on Communications and Networking, MeditCom 2024
SP  - 566
EP  - 571
DO  - 10.1109/MeditCom61057.2024.10621360
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202345329&doi=10.1109%2fMeditCom61057.2024.10621360&partnerID=40&md5=f30236607ba3e5295abe9ac8fe14cd7c
AB  - As cloud-native 6th Generation (6G) networks emerge, the resource utilization forecasting becomes crucial for effective service and network orchestration. While Artificial Intelligence (AI) holds promise in this domain, the diverse nature of the 6G underlying infrastructure and services poses significant challenges on the customization and the efficient design of the AI models. In this paper, we introduce the adoption of eXplainable AI (XAI) to generate spatio-temporal insights on the predictions of advanced AI models. Additionally, we present DuCAT, a Dual Cumulative Attribution Thresholding (DuCAT) heuristic algorithm, for feature and time window size selection towards AI model reduction. Experimental results on a publicly available dataset of cloud resource traces demonstrate that our proposed approach can efficiently reduce the AI model’s complexity (up to 60% decrease in inference time) without compromising prediction accuracy, addressing critical requirements for agile and resource-efficient 6G networks. © 2024 IEEE.
KW  - 6G networks
KW  - cloud-native
KW  - explainable artificial intelligence
KW  - time series forecasting
KW  - workload prediction
KW  - Cloud platforms
KW  - Queueing networks
KW  - 6th generation network
KW  - Cloud-native
KW  - Customisation
KW  - Explainable artificial intelligence
KW  - Intelligence models
KW  - Modeling designs
KW  - Resources utilizations
KW  - Thresholding
KW  - Time series forecasting
KW  - Workload predictions
KW  - Prediction models
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - BOOK
AU  - Chhetri, T.R.
TI  - Improving decision making using semantic web technologies
PY  - 2025
T2  - Improving Decision Making Using Semantic Web Technologies
SP  - 1
EP  - 300
DO  - 10.1007/978-3-658-45877-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005031077&doi=10.1007%2f978-3-658-45877-5&partnerID=40&md5=1eaa39d133e102e6fe123b32c38d3a82
AB  - As technology becomes integral to our lives, its influence on decision making in smart cities, healthcare, and manufacturing is undeniable. However, challenges such as limited contextual awareness, domain knowledge, explainability of machine learning (ML), and issues of interoperability, data quality, and GDPR (General Data Protection Regulation) compliance in data sharing hinder effective decision making. This book addresses these critical challenges by exploring how the synergy of semantic technologies (SW), like ontologies and knowledge graphs, with or without ML, can overcome these challenges to improve decision making. Through real-world case studies in data sharing, manufacturing, and agriculture, it offers theoretical and practical insights and guidelines of how SW can enhance prediction accuracy, integrate domain knowledge, support ML explainability, and tackle interoperability, data quality, and GDPR challenges. © Springer Fachmedien Wiesbaden GmbH, part of Springer Nature 2025. All rights reserved.
KW  - Artificial intelligence (AI)
KW  - Data privacy
KW  - Data sharing
KW  - Decision making
KW  - Edge intelligence
KW  - Explainable AI (XAI)
KW  - General data protection regulation (GDPR) compliance
KW  - Internet of things (IoT)
KW  - Knowledge graphs
KW  - Domain Knowledge
KW  - Knowledge graph
KW  - Artificial intelligence
KW  - Data Sharing
KW  - Decisions makings
KW  - Edge intelligence
KW  - Explainable artificial intelligence (XAI)
KW  - General data protection regulation  compliance
KW  - General data protection regulations
KW  - Internet of thing
KW  - Knowledge graphs
KW  - Regulation compliance
KW  - Decision making
M3  - Book
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Sittón-Candanedo, I.
AU  - Alonso, R.S.
AU  - García, Ó.
AU  - Gil, A.B.
AU  - Rodríguez-González, S.
TI  - A review on edge computing in smart energy by means of a systematic mapping study
PY  - 2020
T2  - Electronics (Switzerland)
VL  - 9
IS  - 1
C7  - 48
DO  - 10.3390/electronics9010048
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077530737&doi=10.3390%2felectronics9010048&partnerID=40&md5=78ad0c9ef53e7f8204a22c07e0f73b95
AB  - Context: Smart Energy is a disruptive concept that has led to the emergence of new energy policies, technology projects, and business models. The development of those models is driven by world capitals, companies, and universities. Their purpose is to make the electric power system more efficient through distributed energy generation/storage, smart meter installation, or reduction of consumption/implementation costs. This work approaches Smart Energy as a paradigm that is concerned with systemic strategies involving the implementation of innovative technological developments in energy systems. However, many of the challenges encountered under this paradigm are yet to be overcome, such as the effective integration of solutions within Smart Energy systems. Edge Computing is included in this new technology group. Objective: To investigate developments that involve the use of Edge Computing and that provide solutions to Smart Energy problems. The research work will be developed using the methodology of systematic mapping of literature, following the guidelines established by Kitchenham and Petersen that facilitate the identification of studies published on the subject. Results: Inclusion and exclusion criteria have been applied to identify the relevant articles. We selected 80 papers that were classified according to the type of publication (journal, conferences, or book chapter), type of research (conceptual, experience, or validation), type of activity (implement, validate, analyze) and asset (architecture, framework, method, or models). Conclusion: A complete review has been conducted of the 80 articles that were closely related to the questions posed in this research. To reach the goal of building Edge Computing architectures for Smart Energy environments, several lines of research have been defined. In the future, such architectures will overcome current problems, becoming highly energy-efficient, cost-effective, and capacitated to process and respond in real-time. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.
KW  - Blockchain
KW  - Edge computing
KW  - IoT
KW  - Security
KW  - Smart energy
KW  - Systematic mapping study
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 44
ER  -

TY  - CONF
AU  - Tsitsipas, A.
TI  - Towards an Ensemble Approach for Sensor Data Sensemaking
PY  - 2022
T2  - International Conference on Pattern Recognition Applications and Methods
VL  - 1
SP  - 323
EP  - 329
DO  - 10.5220/0010898800003122
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174615306&doi=10.5220%2f0010898800003122&partnerID=40&md5=289fd3086ffbc67d677a88e9476c28a8
AB  - In a world of uncertainty and incompleteness, one must “make sense” of found observations. Cyber physical systems output large quantities of data, opening massive opportunities and challenges for scalable techniques to gain exciting insights. One intriguing challenge is the process of Sensor Data Sensemaking. The research presents an approach to handle this process by bringing together the strands of data and knowledge in a single architecture in an interpretable and expressive way. Differently from other works, the use of interpretable patterns from streaming data is in the spotlight. In addition, background knowledge over these patterns gasps the intention to give meaning to these patterns with several possible explanations. A hybrid implementation realises the approach following big data processing models © 2022 by SCITEPRESS – Science and Technology Publications, Lda.
KW  - Abduction
KW  - Hybrid
KW  - Sensor Data Sensemaking
KW  - Shapeoids
KW  - Stream Reasoning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Yang, Z.
AU  - Yuan, S.
AU  - Shao, Z.
AU  - Li, W.
AU  - Liu, R.
TI  - A review on synergizing knowledge graphs and large language models
PY  - 2025
T2  - Computing
VL  - 107
IS  - 6
C7  - 143
DO  - 10.1007/s00607-025-01499-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007788007&doi=10.1007%2fs00607-025-01499-8&partnerID=40&md5=2c8a1ed47e0704565e0a87c1d7dd6df4
AB  - This paper examines the integration of large language models (LLMs) with knowledge graphs (KGs) through a systematic four-layer framework that includes data, model, technology, and application dimensions. We analyze the capabilities and limitations of LLMs in natural language processing along with the strengths and challenges of KGs in knowledge representation. We address fundamental weaknesses in each approach and identify complementary integration methods. Our analysis reveals that LLMs excel at contextual understanding and generation but struggle with factual consistency and reasoning transparency. In contrast, KGs provide structured and verifiable knowledge but lack adaptability to unstructured inputs. We review integration strategies, including knowledge injection techniques, retrieval-augmented generation, and neuro-symbolic approaches. The combined methods demonstrate significant performance improvements. Through the case study of the GLM architecture, we demonstrate how the integration of KGs and LLMs improves accuracy, interpretability, and factual grounding in specialized domains and also shows substantial performance improvements in knowledge-intensive tasks (15–20% on MedQA and 14–17% on the medical MMLU benchmarks). The resulting hybrid systems offer concrete advantages in critical applications requiring precision and adaptability, including healthcare diagnostics, financial compliance, and educational technology. Lightweight knowledge representation, adaptive update mechanisms, and unified cross-modal frameworks are promising research directions to advance KG–LLM integration. © The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature 2025.
KW  - GLM
KW  - Knowledge generation
KW  - Knowledge graphs (KGs)
KW  - Large language models (LLMs)
KW  - Image representation
KW  - Natural language processing systems
KW  - Data application
KW  - Data technologies
KW  - GLM
KW  - Knowledge generations
KW  - Knowledge graph
KW  - Knowledge graphs
KW  - Knowledge-representation
KW  - Language model
KW  - Large language model
KW  - Performance
KW  - Knowledge graph
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - An, J.
AU  - Zhao, J.
AU  - Liu, Q.
AU  - Qian, X.
AU  - Chen, J.
TI  - Self-Constructed Deep Fuzzy Neural Network for Traffic Flow Prediction
PY  - 2023
T2  - Electronics (Switzerland)
VL  - 12
IS  - 8
C7  - 1885
DO  - 10.3390/electronics12081885
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156195672&doi=10.3390%2felectronics12081885&partnerID=40&md5=4ceb92cf68700a0203af309991408976
AB  - Traffic flow prediction is a critical component of intelligent transportation systems, especially in the prevention of traffic congestion in urban areas. While significant efforts have been devoted to enhancing the accuracy of traffic prediction, the interpretability of traffic prediction also needs to be considered to enhance persuasiveness, particularly in the era of deep-learning-based traffic cognition. Although some studies have explored interpretable neural networks from the feature and result levels, model-level explanation, which explains the reasoning process of traffic prediction through transparent models, remains underexplored and requires more attention. In this paper, we propose a novel self-constructed deep fuzzy neural network, SCDFNN, for traffic flow prediction with model interpretability. By leveraging recent advances in neuro-symbolic computation for automatic rule learning, SCDFNN learns interpretable human traffic cognitive rules based on deep learning, incorporating two innovations: (1) a new fuzzy neural network hierarchical architecture constructed for spatial-temporal dependences in the traffic feature domain; (2) a modified Wang–Mendel method used to fuse regional differences in traffic data, resulting in adaptive fuzzy-rule weights without sacrificing interpretability. Comprehensive experiments on well-known traffic datasets demonstrate that the proposed approach is comparable to state-of-the-art deep models, and the SCDFNN’s unique hierarchical architecture allows for transparency. © 2023 by the authors.
KW  - fuzzy neural network
KW  - hierarchical fuzzy inference systems
KW  - intelligent transportation system (ITS)
KW  - modified Wang–Mendel (MWM) method
KW  - traffic flow prediction
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Fang, W.
AU  - Zhou, Z.
AU  - He, J.
AU  - Wang, W.
TI  - StackSight: Unveiling WebAssembly through Large Language Models and Neurosymbolic Chain-of-Thought Decompilation
PY  - 2024
T2  - Proceedings of Machine Learning Research
VL  - 235
SP  - 13010
EP  - 13028
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203822686&partnerID=40&md5=5c1c4dea911cb2f55551aab4c5f726c2
AB  - WebAssembly enables near-native execution in web applications and is increasingly adopted for tasks that demand high performance and robust security. However, its assembly-like syntax, implicit stack machine, and low-level data types make it extremely difficult for human developers to understand, spurring the need for effective WebAssembly reverse engineering techniques. In this paper, we propose StackSight, a novel neurosymbolic approach that combines Large Language Models (LLMs) with advanced program analysis to decompile complex WebAssembly code into readable C++ snippets. StackSight visualizes and tracks virtual stack alterations via a static analysis algorithm and then applies chain-of-thought prompting to harness LLM's complex reasoning capabilities. Evaluation results show that StackSight significantly improves WebAssembly decompilation. Our user study also demonstrates that code snippets generated by StackSight have significantly higher win rates and enable a better grasp of code semantics. Copyright 2024 by the author(s)
KW  - C++ (programming language)
KW  - Reverse engineering
KW  - Static analysis
KW  - Syntactics
KW  - Datatypes
KW  - Decompilation
KW  - High performance security
KW  - Language model
KW  - Program analysis
KW  - Reverse engineering techniques
KW  - Robust security
KW  - Stack machines
KW  - WEB application
KW  - Web applications
KW  - Semantics
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Smirnov, A.
AU  - Ponomarev, A.
AU  - Levashova, T.
AU  - Teslya, N.
AU  - Shilov, N.
TI  - Platform Architecture for Human-AI Collaborative Decision Support
PY  - 2024
T2  - Lecture Notes in Networks and Systems
VL  - 1209 LNNS
SP  - 334
EP  - 345
DO  - 10.1007/978-3-031-77688-5_32
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214233879&doi=10.1007%2f978-3-031-77688-5_32&partnerID=40&md5=0d9809b7b2be44dc04c5262841cc3d99
AB  - Modern decision-maker typically uses several AI-based tools to obtain more information about the problem at hand and to evaluate possible solutions, besides, decision support in complex dynamic environment typically requires knowledge of several experts, therefore, collaboration between them. These trends naturally merge in human-AI collaborative systems, providing the means of collaboration of heterogeneous participants. However, collaborative human-AI decision support is connected with many challenges, both theoretical and technological. This paper addresses the technological side of the problem by presenting a platform for human-AI collaborative decision support systems. The platform provides a set of mechanisms and interfaces, simplifying the development of such systems: team formation and collaboration features, interfaces to define, deploy and manage AI agents, and a set of structured representations facilitating interaction between human experts and AI agents. Possible application of the platform is discussed on a use case in road safety analysis. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - Collaborative Decision Support Systems
KW  - Explainable AI
KW  - Human-AI Interaction
KW  - Neuro-Symbolic AI
KW  - Ontology
KW  - Service Ecosystem
KW  - Decision making
KW  - Collaborative decision support system
KW  - Collaborative decisions
KW  - Decision supports
KW  - Explainable AI
KW  - Human-AI interaction
KW  - Neuro-symbolic AI
KW  - Ontology's
KW  - Platform architecture
KW  - Service ecosystems
KW  - Support systems
KW  - Ontology
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Jagatheesaperumal, S.K.
AU  - Ahmad, K.
AU  - Al-Fuqaha, A.
AU  - Qadir, J.
TI  - Advancing Education Through Extended Reality and Internet of Everything Enabled Metaverses: Applications, Challenges, and Open Issues
PY  - 2024
T2  - IEEE Transactions on Learning Technologies
VL  - 17
SP  - 1120
EP  - 1139
DO  - 10.1109/TLT.2024.3358859
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184002410&doi=10.1109%2fTLT.2024.3358859&partnerID=40&md5=88a547e879f18b52b43f368745442e9d
AB  - Metaverse has evolved as one of the popular research agenda that let users learn, socialize, and collaborate in a networked 3-D immersive virtual world. Due to the rich multimedia streaming capability and immersive user experience with high-speed communication, the metaverse is an ideal model for education, training, and skill development tasks. To facilitate research in this area, we provide a comprehensive review of the various educational use cases and explore how enabling technologies, such as extended reality and the Internet of Everything will play a major role in educational services in future metaverses. Then, we provide an overview of metaverse-based educational applications focusing on education, training, and skill development and analyze the technologies they are built upon. We identify common research problems and future research directions in the domain. This article also identifies core ethical considerations of metaverse for education and potential pitfalls. We believe this survey can fully demonstrate the versatility of metaverse-driven education, which could serve as a potential guideline for the researchers. © 2008-2011 IEEE.
KW  - Artificial intelligence (AI)
KW  - education
KW  - extended reality (XR)
KW  - metaverse
KW  - Interactive computer systems
KW  - Internet of Everything
KW  - Internet of things
KW  - Virtual reality
KW  - Artificial intelligence
KW  - Artificial intelligence-XR
KW  - Education training
KW  - Extended reality
KW  - Extended reality (XR)
KW  - Immersive
KW  - Metaverses
KW  - Real - Time system
KW  - X reality
KW  - Real time systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 61
ER  -

TY  - CONF
AU  - Duppe, B.
TI  - Logic Supervised Learning for Time Series - Continual Learning for Appliance Detection
PY  - 2024
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14980 LNAI
SP  - 32
EP  - 40
DO  - 10.1007/978-3-031-71170-1_4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204918738&doi=10.1007%2f978-3-031-71170-1_4&partnerID=40&md5=e748d7cae9281272eb7e169914d183de
AB  - Classifying parts of time series is an important task when it comes to the usage of Artificial Neural Networks (ANN), e.g. for analyzing the power consumption of households. To make it possible to adapt such ANN for Non Intrusive Load Monitoring (NILM) for the household in which they are deployed is crucial but not easy to manage. The Neurosymbolic Artificial Intelligence (AI) approach in this paper makes it possible to do that by combining ANN modules with Probabilistic Logic which is used as a supervise process to check the outputs of the ANN in case of plausibility. This on the one hand filters implausible results out which is helpful for productive usage, on the other hand these post processed results can be used to retrain the network and adapt it for a specific household in a continual learning process. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - Artificial Neural Networks
KW  - Continual Learning
KW  - Energy Domain
KW  - Neurosymbolic AI
KW  - Probabilistic Logic
KW  - Time Series
KW  - Adversarial machine learning
KW  - Federated learning
KW  - Probabilistic logics
KW  - Supervised learning
KW  - Time series
KW  - Continual learning
KW  - Energy domain
KW  - Learning process
KW  - Neural-networks
KW  - Neurosymbolic artificial intelligence
KW  - Nonintrusive load monitoring
KW  - Power
KW  - Probabilistics
KW  - Times series
KW  - Self-supervised learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Wu, J.
AU  - Bian, J.
TI  - Analysis of Shielding Characteristics of MIT7530 Array Sensing Instrument Based on Digital Twin
PY  - 2023
T2  - 2023 5th International Conference on Intelligent Control, Measurement and Signal Processing, ICMSP 2023
SP  - 222
EP  - 225
DO  - 10.1109/ICMSP58539.2023.10170861
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166199077&doi=10.1109%2fICMSP58539.2023.10170861&partnerID=40&md5=0d4f46e8b0b88b28ddad6647af454073
AB  - Induction logging instrument is a kind of electrical instrument that is now used more frequently, and analyzing the influence of shielded coil on the receiving voltage is the premise to ensure that the voltage value is correct. This paper is based on the array induction instrument MIT7530 and starts from the basic principle of induction instrument logging. Visual Studio software is used to design a shielding characteristic analysis program, and the output data is read and written in the format of JSON files. The characteristics of the imaginary and real parts of the voltage values of the seven arrays at three frequencies were analyzed, and their characteristics changed with the number of turns and source distance of the shielded coil. © 2023 IEEE.
KW  - array sensing instrument
KW  - JSON file
KW  - Masking source distance
KW  - Induction logging
KW  - Array sensing
KW  - Array sensing instrument
KW  - Basic principles
KW  - JSON file
KW  - Logging instruments
KW  - Masking source distance
KW  - Sensing instruments
KW  - Shielded coils
KW  - Shielding characteristic
KW  - Visual studios
KW  - Shielding
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Hashemi, N.
AU  - Prokhorov, D.
AU  - Hoxha, B.
AU  - Fainekos, G.
AU  - Yamaguchi, T.
AU  - Deshmukh, J.V.
TI  - A Neurosymbolic Approach to the Verification of Temporal Logic Properties of Learning enabled Control Systems
PY  - 2023
T2  - ICCPS 2023 - Proceedings of the 2023 ACM/IEEE 14th International Conference on Cyber-Physical Systems with CPS-IoT Week 2023
SP  - 98
EP  - 109
DO  - 10.1145/3576841.3585928
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167864967&doi=10.1145%2f3576841.3585928&partnerID=40&md5=14fdc2f2aa772ca3247fbca073e6992f
AB  - Signal Temporal Logic (STL) has become a popular tool for expressing formal requirements of Cyber-Physical Systems (CPS). The problem of verifying STL properties of neural network-controlled CPS remains a largely unexplored problem. In this paper, we present a model for the verification of Neural Network (NN) controllers for general STL specifications using a custom neural architecture where we map an STL formula into a feed-forward neural network with ReLU activation. In the case where both our plant model and the controller are ReLU-activated neural networks, we reduce the STL verification problem to reachability in ReLU neural networks. We also propose a new approach for neural network controllers with general activation functions; this approach is a sound and complete verification approach based on computing the Lipschitz constant of the closed-loop control system. We demonstrate the practical efficacy of our techniques on a number of examples of learning-enabled control systems. © ICCPS 2023. All rights reserved.
KW  - Controller
KW  - Deep Neural Network
KW  - Lipstchitz constant
KW  - Model
KW  - Reachability
KW  - ReLU
KW  - Signal Temporal Logic
KW  - Verification
KW  - Chemical activation
KW  - Closed loop control systems
KW  - Computer circuits
KW  - Controllers
KW  - Embedded systems
KW  - Feedforward neural networks
KW  - Temporal logic
KW  - Cybe-physical systems
KW  - Cyber-physical systems
KW  - Lipstchitz constant
KW  - Network-controlled
KW  - Neural network controllers
KW  - Neural-networks
KW  - Reachability
KW  - ReLU
KW  - Signal temporal logic
KW  - Temporal logic properties
KW  - Deep neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Reynaud, S.
AU  - Roxin, A.
TI  - Review of eXplainable artificial intelligence for cybersecurity systems
PY  - 2025
T2  - Discover Artificial Intelligence
VL  - 5
IS  - 1
C7  - 78
DO  - 10.1007/s44163-025-00318-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006797274&doi=10.1007%2fs44163-025-00318-5&partnerID=40&md5=cb72698c8204a45be428273ae655f8a0
AB  - This article reviews approaches based on artificial intelligence (AI), which contributes to the security of cyber environments. We examine existing techniques using several indicators: explainability, performance and robustness. These indicators have been chosen based on their importance for user acceptance and interpretability of the approach. Indeed, the AI field is vast and is divided into several sub-domains. The two most well-known sub-domains are symbolic AI (representation of knowledge, rules and operations based on symbols) and numeric AI (calculations and algorithms using numeric information, focusing on the result, not the representation of knowledge). While most approaches investigated come from numeric AI, we conclude on the need for hybrid AI systems, combining the advantages of both AI sub-fields while maximising the protection provided against cyberattacks. © The Author(s) 2025.
KW  - Accuracy
KW  - Artificial intelligence (AI)
KW  - Cybersecurity
KW  - Explainability
KW  - eXplainable AI (XAI)
KW  - Interpretability
KW  - Justifiability
KW  - Precision
KW  - Suitability
KW  - Transparency
KW  - Artificial life
KW  - Cyber Physical System
KW  - Distributed computer systems
KW  - Domain Knowledge
KW  - Embedded systems
KW  - Intelligent computing
KW  - Accuracy
KW  - Artificial intelligence
KW  - Cyber security
KW  - Explainability
KW  - Explainable artificial intelligence (XAI)
KW  - Interpretability
KW  - Justifiability
KW  - Precision
KW  - Subdomain
KW  - Suitability
KW  - Intelligent systems
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Jia, H.
AU  - Lang, B.
AU  - Li, X.
AU  - Yan, Y.
TI  - IDEAL: A malicious traffic detection framework with explanation-guided learning
PY  - 2025
T2  - Knowledge-Based Systems
VL  - 317
C7  - 113419
DO  - 10.1016/j.knosys.2025.113419
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002281244&doi=10.1016%2fj.knosys.2025.113419&partnerID=40&md5=6a4375b1c1ba4eeb93e3f0c464599bc7
AB  - The credibility of deep learning models is crucial for network security tasks. Ensuring that these models make reasonable decisions based on truly relevant features is key to enhancing their credibility. Explanation supervision, which guides models to reason rationally by adding supervision to model explanations, has shown promising results in terms of improving overall model performance. However, the complexity of cyberattack characteristics and packet structures increases the difficulty of integrating explanation supervision and makes it challenging to obtain human annotations that encode domain knowledge concerning cyberattacks. In this paper, we propose a general framework called malIcious traffic Detection with ExplAnation-guided Learning (IDEAL). This framework integrates explanation supervision techniques into malicious traffic detection for the first time, enables researchers to supervise model explanations based on domain knowledge, and jointly optimizes the task and explanation losses. As a result, both the detection performance and explainability of the model improve. In addition, to address the problem of obtaining human annotations, we propose an automatic explanation annotation generation method based on the expert-defined detection rules of the famous Snort firewall. We conduct extensive experiments on the CIC-IDS-2017 and TON_IoT datasets. The experimental results show that, with only approximately 1% of the training data used for explanation supervision, our proposed IDEAL method significantly improves upon the detection performance and explainability of the state-of-the-art models. In addition, IDEAL is applicable across different neural network architectures and exhibits considerable robustness to incomplete low-quality manual annotations. © 2025 Elsevier B.V.
KW  - Deep learning
KW  - Explainability
KW  - Explanation-guided learning
KW  - Malicious traffic detection
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Federated learning
KW  - Cyber-attacks
KW  - Deep learning
KW  - Detection performance
KW  - Domain knowledge
KW  - Explainability
KW  - Explanation-guided learning
KW  - Human annotations
KW  - Malicious traffic
KW  - Malicious traffic detection
KW  - Traffic detection
KW  - Self-supervised learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Ukil, A.
AU  - Jara, A.J.
AU  - Gama, J.
AU  - Marin, L.
TI  - Knowledge-driven Analytics and Systems Impacting Human Quality of Life - Neurosymbolic AI, Explainable AI and Beyond
PY  - 2023
T2  - International Conference on Information and Knowledge Management, Proceedings
SP  - 5296
EP  - 5299
DO  - 10.1145/3583780.3615300
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178143910&doi=10.1145%2f3583780.3615300&partnerID=40&md5=00990a0bec0c1d30c55e3602199c645c
AB  - The management of knowledge-driven artificial intelligence technologies is essential in order to evaluate their impact on human life and society. Social networks and tech use can have a negative impact on us physically, emotionally, socially and mentally. On the other hand, intelligent systems can have a positive effect on people's lives. Currently, we are witnessing the power of large language models (LLMs) like chatGPT and its influence towards the society. The objective of the workshop is to contribute to the advancement of intelligent technologies designed to address the human condition. This could include precise and personalized medicine, better care for elderly people, reducing private data leaks, using AI to manage resources better, using AI to predict risks, augmenting human capabilities, and more. The workshop's objective is to present research findings and perspectives that demonstrate how knowledge-enabled technologies and applications improve human well-being. This workshop indeed focuses on the impacts at different granularity levels made by Artificial Intelligence (AI) research on the micro granular level, where the daily or regular functioning of human life is affected, and also the macro granulate level, where the long-term or far-future effects of artificial intelligence on people's lives and the human society could be pretty high. In conclusion, this workshop explores how AI research can potentially address the most pressing challenges facing modern societies, and how knowledge management can potentially contribute to these solutions. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.
KW  - data privacy
KW  - deep learning
KW  - explainable AI
KW  - human-centric applications
KW  - Knowledge management
KW  - neurosymbolic AI
KW  - Data privacy
KW  - Deep learning
KW  - Intelligent systems
KW  - Artificial intelligence research
KW  - Artificial intelligence technologies
KW  - Deep learning
KW  - Explainable artificial intelligence
KW  - Human lives
KW  - Human society
KW  - Human-centric
KW  - Human-centric application
KW  - Neurosymbolic artificial intelligence
KW  - Quality of life
KW  - Knowledge management
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Lee, D.
AU  - Noh, S.
AU  - Jang, I.
AU  - Kim, S.
AU  - Song, S.
AU  - Bae, H.
TI  - Object-Centric Scene Representation Learning via SAM
PY  - 2024
T2  - International Conference on ICT Convergence
SP  - 215
EP  - 217
DO  - 10.1109/ICTC62082.2024.10827718
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217662551&doi=10.1109%2fICTC62082.2024.10827718&partnerID=40&md5=9a8a5eb2ed34ee4b3d8b6162be9bdabf
AB  - Recent advancements in the segmentation foundation model SAM have demonstrated exceptional performance in image segmentation. This study introduces object-centric representation learning, capitalizing on the segmentation outcomes derived from the foundational segmentation model SAM to elevate generalization performance and accelerate training within scene representation learning. Our approach involves a simple yet effective method to fine-tune unsupervised feature extraction in object-centric learning for scene representation. We conduct an effort to enhance the performance of unsupervised representation learning in out-of-distribution situations, resulting in improved performance in single-object out-of-distribution (OOD) scenarios. © 2024 IEEE.
KW  - Foundation Model
KW  - Generalization
KW  - Object-centric
KW  - Representation Learning
KW  - SAM
KW  - Adversarial machine learning
KW  - Digital elevation model
KW  - Feature extraction
KW  - Federated learning
KW  - Image segmentation
KW  - Unsupervised learning
KW  - Foundation models
KW  - Generalisation
KW  - Generalization performance
KW  - Images segmentations
KW  - Object-centric
KW  - Performance
KW  - Representation learning
KW  - Sams
KW  - Scene representation
KW  - Segmentation models
KW  - Contrastive Learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Zhao, L.
AU  - Lee, S.-W.
TI  - Intelligent Spatial Anomaly Activity Recognition Method Based on Ontology Matching
PY  - 2025
T2  - Computers, Materials and Continua
VL  - 83
IS  - 3
SP  - 4447
EP  - 4476
DO  - 10.32604/cmc.2025.063691
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006673950&doi=10.32604%2fcmc.2025.063691&partnerID=40&md5=23c05069ce3c9c6060a507c61bac8b09
AB  - This research addresses the performance challenges of ontology-based context-aware and activity recognition techniques in complex environments and abnormal activities, and proposes an optimized ontology framework to improve recognition accuracy and computational efficiency. The method in this paper adopts the event sequence segmentation technique, combines location awareness with time interval reasoning, and improves human activity recognition through ontology reasoning. Compared with the existing methods, the framework performs better when dealing with uncertain data and complex scenes, and the experimental results show that its recognition accuracy is improved by 15.6% and processing time is reduced by 22.4%. In addition, it is found that with the increase of context complexity, the traditional ontology inference model has limitations in abnormal behavior recognition, especially in the case of high data redundancy, which tends to lead to a decrease in recognition accuracy. This study effectively mitigates this problem by optimizing the ontology matching algorithm and combining parallel computing and deep learning techniques to enhance the activity recognition capability in complex environments. Copyright © 2025 The Authors.
KW  - activity recognition
KW  - anomaly detection
KW  - complex context
KW  - Context awareness
KW  - ontological reasoning
KW  - Anomaly detection
KW  - Ontology
KW  - Optical character recognition
KW  - Pattern matching
KW  - Activity recognition
KW  - Anomaly detection
KW  - Complex context
KW  - Complex environments
KW  - Context- awareness
KW  - Ontological reasoning
KW  - Ontology matching
KW  - Ontology's
KW  - Recognition accuracy
KW  - Spatial anomalies
KW  - Deep learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Chen, X.
AU  - Ma, R.
TI  - Cognitive UAV-IRS planning for semantic-aware mobile edge computing networks
PY  - 2025
T2  - Physical Communication
VL  - 68
C7  - 102589
DO  - 10.1016/j.phycom.2024.102589
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213034913&doi=10.1016%2fj.phycom.2024.102589&partnerID=40&md5=7b561f2a50b1e6bc8cd9e9c6fcfc2864
AB  - Unmanned aerial vehicle (UAV)-assisted mobile edge computing (MEC) networks offer a powerful solution for enhancing communication efficiency in resource-constrained environments and managing compute-intensive tasks. However, the inherent limitations of UAVs, such as restricted data storage, computation capability and battery capacity, hinder the maximum communication efficiency. For the first time, this paper investigates a semantic-aware mobile edge computing (SMEC) network, where task data is semantically compressed at the users and processed at edge computing servers. This approach aims to significantly reduce the transmission and storage overhead in UAV, and improve task performance in low signal-to-noise ratio (SNR). To further enhance transmission robustness and task performance, we incorporate a UAV-carried mobile intelligent reflecting surface (IRS). The objective is to minimize system costs while maintaining task performance, which requires the joint optimization of UAV trajectories, server pairings, user assignments, and IRS reflecting elements. This problem is NP-hard, posing significant computational challenges. To address the complexity of the formulated problem, we propose a novel cognitive UAV-IRS planning strategy based on deep reinforcement learning (DRL), where the UAV can infer the task intentions of the users. Simulation results demonstrate the effectiveness of our intelligent scheme, showing rapid convergence in solving the complex optimization problem. Comparative analysis with benchmark schemes reveals a substantial reduction in system costs and more robust task performance achieved by our proposed approach. © 2024
KW  - Cognitive semantic communication
KW  - Deep reinforcement learning
KW  - Mobile edge computing
KW  - Unmanned aerial vehicle
KW  - Aircraft communication
KW  - Benchmarking
KW  - Constrained optimization
KW  - Deep learning
KW  - Deep reinforcement learning
KW  - Mobile telecommunication systems
KW  - NP-hard
KW  - Reinforcement learning
KW  - Steganography
KW  - Unmanned aerial vehicles (UAV)
KW  - Aerial vehicle
KW  - Cognitive semantic communication
KW  - Cognitive semantics
KW  - Edge computing
KW  - Reflecting surface
KW  - Reinforcement learnings
KW  - Semantic communication
KW  - Semantic-aware
KW  - Task performance
KW  - Unmanned aerial vehicle
KW  - Mobile edge computing
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Nilsson, M.
AU  - Schelén, O.
AU  - Lindgren, A.
AU  - Bodin, U.
AU  - Paniagua, C.
AU  - Delsing, J.
AU  - Sandin, F.
TI  - Integration of neuromorphic AI in event-driven distributed digitized systems: Concepts and research directions
PY  - 2023
T2  - Frontiers in Neuroscience
VL  - 17
C7  - 1074439
DO  - 10.3389/fnins.2023.1074439
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149655858&doi=10.3389%2ffnins.2023.1074439&partnerID=40&md5=00f29552e041e79556c91e0e8a8a0e05
AB  - Increasing complexity and data-generation rates in cyber-physical systems and the industrial Internet of things are calling for a corresponding increase in AI capabilities at the resource-constrained edges of the Internet. Meanwhile, the resource requirements of digital computing and deep learning are growing exponentially, in an unsustainable manner. One possible way to bridge this gap is the adoption of resource-efficient brain-inspired “neuromorphic” processing and sensing devices, which use event-driven, asynchronous, dynamic neurosynaptic elements with colocated memory for distributed processing and machine learning. However, since neuromorphic systems are fundamentally different from conventional von Neumann computers and clock-driven sensor systems, several challenges are posed to large-scale adoption and integration of neuromorphic devices into the existing distributed digital–computational infrastructure. Here, we describe the current landscape of neuromorphic computing, focusing on characteristics that pose integration challenges. Based on this analysis, we propose a microservice-based conceptual framework for neuromorphic systems integration, consisting of a neuromorphic-system proxy, which would provide virtualization and communication capabilities required in distributed systems of systems, in combination with a declarative programming approach offering engineering-process abstraction. We also present concepts that could serve as a basis for the realization of this framework, and identify directions for further research required to enable large-scale system integration of neuromorphic devices. Copyright © 2023 Nilsson, Schelén, Lindgren, Bodin, Paniagua, Delsing and Sandin.
KW  - edge intelligence
KW  - event-driven systems
KW  - extreme heterogeneity
KW  - interoperability
KW  - microservices
KW  - neuromorphic computing
KW  - non-von Neumann
KW  - system integration
KW  - Article
KW  - artificial intelligence
KW  - bioengineering
KW  - conceptual framework
KW  - declarative programming
KW  - digital computing
KW  - event notification
KW  - information processing
KW  - information querying
KW  - Internet
KW  - learning algorithm
KW  - nerve cell
KW  - nerve cell plasticity
KW  - neuromorphic computing
KW  - process calculus
KW  - process optimization
KW  - semantics
KW  - soft state model
KW  - software
KW  - spiking neural network
KW  - task performance
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 12
ER  -

TY  - CONF
AU  - Shan, R.
AU  - Shan, T.
TI  - ActionFusion: Framework of Large Action Model Enablement
PY  - 2024
T2  - Proceedings - 2024 IEEE International Conference on Big Data, BigData 2024
SP  - 5432
EP  - 5441
DO  - 10.1109/BigData62323.2024.10825136
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218058731&doi=10.1109%2fBigData62323.2024.10825136&partnerID=40&md5=5feca7855e43f05cff3d555e95116f44
AB  - This paper presents an innovative framework for Large Action Model (LAM) enablement, called ActionFusion, to enhance the capability of AI systems to perform autonomous complex actions in real-world dynamic environments. Several key innovations are introduced in this framework, which include multi-modal data fusion, hierarchical action representation, hybrid learning mechanisms that unify reinforcement learning and self-supervised learning, and optimized real-time decision-making algorithms. These features, targeted to collectively address the scalability, adaptability, and latency challenges presented by current AI action modeling, are analyzed in key enabling technologies for each layer of the framework. The architecture of this approach is modular and open, ensuring interoperability across different AI subsystems and various domains, such as autonomous robotics, vehicles, healthcare, smart environments, and industrial automation. Potential applications demonstrate how ActionFusion transforms the field by improving the autonomy, safety, and capabilities of AI-powered systems. This study also points out key design considerations and future research directions like data integration techniques, adaptability, human-AI collaboration, ethics, and emerging technologies. © 2024 IEEE.
KW  - ActionFusion
KW  - Autonomous Systems
KW  - Enablement
KW  - Ethical AI
KW  - Hierarchical Action Representation
KW  - Large Action Model
KW  - Multi-Modal Data Fusion
KW  - Real-Time Decision-Making
KW  - Reinforcement Learning
KW  - Self-Supervised Learning
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Data fusion
KW  - Decision making
KW  - Ethical technology
KW  - Federated learning
KW  - Reinforcement learning
KW  - Semi-supervised learning
KW  - Action modeling
KW  - Action representations
KW  - Actionfusion
KW  - Autonomous system
KW  - Enablement
KW  - Ethical AI
KW  - Hierarchical action representation
KW  - Large action model
KW  - Multi-modal data
KW  - Multi-modal data fusion
KW  - Real time decision-making
KW  - Real-time decision making
KW  - Reinforcement learnings
KW  - Self-supervised learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Wawrzik, F.P.
AU  - Lober, A.
TI  - A Reasoner-Challenging Ontology from the Microelectronics Domain
PY  - 2022
T2  - CEUR Workshop Proceedings
VL  - 3123
SP  - 1
EP  - 12
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128738635&partnerID=40&md5=8160687a5bc12b8e60ae0b050ba4c965
AB  - This paper introduces a hardware software ontology from the microelectronics domain that suffers from the reasoning runtime bottleneck. We present it in detail, with a focus on the axioms related to reasoning. Further we explain the application in the GENIAL! project and make a runtime analysis of current reasoners on the ontology. We report a high runtime on a relatively small ontology, identify the reason and sketch (potential) solutions. © 2021 Copyright for this paper by its authors
KW  - Arrowhead Tools
KW  - GBO
KW  - GENIAL!
KW  - ISO26262
KW  - ontologies
KW  - OWL
KW  - reasoner performance
KW  - reasoning
KW  - Microelectronics
KW  - Arrowhead tool
KW  - GBO
KW  - GENIAL!
KW  - Hardware/software
KW  - Ontology's
KW  - Performance
KW  - Reasoner performance
KW  - Reasoners
KW  - Reasoning
KW  - Runtimes
KW  - Ontology
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Thomas, C.K.
AU  - Saad, W.
TI  - Hypergame Theory for Decentralized Resource Allocation in Multi-user Semantic Communications
PY  - 2024
T2  - Proceedings of the IEEE Conference on Decision and Control
SP  - 6036
EP  - 6043
DO  - 10.1109/CDC56724.2024.10886627
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000638398&doi=10.1109%2fCDC56724.2024.10886627&partnerID=40&md5=9e0bc061268e30ab5c525778e4eb7e74
AB  - Semantic communications (SC) is an emerging communication paradigm in which wireless devices can send only relevant information from a source of data while relying on computing resources to regenerate missing data points. However, the design of a multi-user SC system becomes more challenging because of the computing and communication overhead required for coordination. Existing solutions for learning the semantic language and performing resource allocation often fail to capture the computing and communication tradeoffs involved in multiuser SC. To address this gap, a novel framework for decentralized computing and communication resource allocation in multi-user SC systems is proposed. The challenge of efficiently allocating communication and computing resources (for reasoning) in a decentralized manner to maximize the quality of task experience for the end users is addressed through the application of Stackelberg hypergame theory. Leveraging the concept of second-level hypergames, novel analytical formulations are developed to model misperceptions of the users about each other's communication and control strategies. Further, equilibrium analysis of the learned resource allocation protocols examines the convergence of the computing and communication strategies to a local Stackelberg equilibria, considering misperceptions. Simulation results show that the proposed Stackelberg hypergame results in efficient usage of communication and computing resources while maintaining a high quality of experience for the users compared to state-of-the-art that does not account for the misperceptions. © 2024 IEEE.
KW  - Communication resources
KW  - Communication strategy
KW  - Communications systems
KW  - Computing resource
KW  - Decentralised
KW  - Decentralized resource allocation
KW  - Hypergame
KW  - Multiusers
KW  - Semantic communication
KW  - Stackelberg
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Lu, H.
AU  - Wang, L.
AU  - Ma, X.
AU  - Cheng, J.
AU  - Zhou, M.
TI  - A survey of graph neural networks and their industrial applications
PY  - 2025
T2  - Neurocomputing
VL  - 614
C7  - 128761
DO  - 10.1016/j.neucom.2024.128761
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208097482&doi=10.1016%2fj.neucom.2024.128761&partnerID=40&md5=af4b404f550e2df13ec0a8d49b3c1475
AB  - Graph Neural Networks (GNNs) have emerged as a powerful tool for analyzing and modeling graph-structured data. In recent years, GNNs have gained significant attention in various domains. This review paper aims to provide an overview of the state-of-the-art graph neural network techniques and their industrial applications. First, we introduce the fundamental concepts and architectures of GNNs, highlighting their ability to capture complex relationships and dependencies in graph data. We then delve into the variants and evolution of graphs, including directed graphs, heterogeneous graphs, dynamic graphs, and hypergraphs. Next, we discuss the interpretability of GNN, and GNN theory including graph augmentation, expressivity, and over-smoothing. Finally, we introduce the specific use cases of GNNs in industrial settings, including finance, biology, knowledge graphs, recommendation systems, Internet of Things (IoT), and knowledge distillation. This review paper highlights the immense potential of GNNs in solving real-world problems, while also addressing the challenges and opportunities for further advancement in this field. © 2024
KW  - Autoencoder
KW  - Deep learning
KW  - Graph Neural Networks (GNNs)
KW  - Industrial applications
KW  - Graph algorithms
KW  - Graph neural networks
KW  - Neural network models
KW  - Auto encoders
KW  - Complex relationships
KW  - Deep learning
KW  - Fundamental concepts
KW  - Graph neural network
KW  - Graph neural networks
KW  - Graph structured data
KW  - Neural network techniques
KW  - Review papers
KW  - State of the art
KW  - autoencoder
KW  - deep learning
KW  - distillation
KW  - human
KW  - internet of things
KW  - nerve cell network
KW  - short survey
KW  - Knowledge graph
M3  - Short survey
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Luo, C.
AU  - Huang, Q.
AU  - Wu, A.B.
AU  - Khan, S.
AU  - Li, H.
AU  - Qiu, Q.
TI  - Multi-Agent Cooperative Games Using Belief Map Assisted Training
PY  - 2023
T2  - Frontiers in Artificial Intelligence and Applications
VL  - 372
SP  - 1617
EP  - 1624
DO  - 10.3233/FAIA230444
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175820031&doi=10.3233%2fFAIA230444&partnerID=40&md5=dd76c1b1f460a4bc3ff664ab62c4c1aa
AB  - In a multi-agent system, agents share their local observations to gain global situational awareness for decision making and collaboration using a message passing system. When to send a message, how to encode a message, and how to leverage the received messages directly affect the effectiveness of the collaboration among agents. When training a multi-agent cooperative game using reinforcement learning (RL), the message passing system needs to be optimized together with the agent policies. This consequently increases the model's complexity and poses significant challenges to the convergence and performance of learning. To address this issue, we propose the Belief-map Assisted Multi-agent System (BAMS), which leverages a neuro-symbolic belief map to enhance training. The belief map decodes the agent's hidden state to provide a symbolic representation of the agent's understanding of the environment and other agents' status. The simplicity of symbolic representation allows the gathering and comparison of the ground truth information with the belief, which provides an additional channel of feedback for the learning. Compared to the sporadic and delayed feedback coming from the reward in RL, the feedback from the belief map is more consistent and reliable. Agents using BAMS can learn a more effective message passing network to better understand each other, resulting in better performance in the game. We evaluate BAMS's performance in a cooperative predator and prey game with varying levels of map complexity and compare it to previous multi-agent message passing models. The simulation results showed that BAMS reduced training epochs by 66%, and agents who apply the BAMS model completed the game with 34.62% fewer steps on average. © 2023 The Authors.
KW  - Complex networks
KW  - Decision making
KW  - Game theory
KW  - Learning systems
KW  - Message passing
KW  - Reinforcement learning
KW  - Cooperative game
KW  - Decisions makings
KW  - Local observations
KW  - Message passing systems
KW  - Modeling complexity
KW  - Multi agent
KW  - Performance
KW  - Reinforcement learnings
KW  - Situational awareness
KW  - Symbolic representation
KW  - Multi agent systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Yan, R.
AU  - Julius, A.
AU  - Chang, M.
AU  - Fokoue, A.
AU  - Ma, T.
AU  - Uceda-Sosa, R.
TI  - STONE: Signal Temporal Logic Neural Network for Time Series Classification
PY  - 2021
T2  - IEEE International Conference on Data Mining Workshops, ICDMW
VL  - 2021-December
SP  - 778
EP  - 787
DO  - 10.1109/ICDMW53433.2021.00101
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125363629&doi=10.1109%2fICDMW53433.2021.00101&partnerID=40&md5=a3d51974f7a3ee7a18a9e92802c831eb
AB  - In this paper, we propose a neuro-symbolic frame-work called signal temporal logic neural network (STONE) that combines the characteristics of neural networks and temporal logics. Weighted Signal Temporal Logic (wSTL) formulas are recursively composed of subformulas connected using logical and temporal operators. The quantitative semantics of wSTL is defined such that the quantitative satisfaction of subformulas with higher weights have a more significant influence on the quantitative satisfaction of a wSTL formula. In the STONE, each neuron represents a component of a wSTL formula, and the output of STONE corresponds to the quantitative satisfaction of a wSTL formula. We use STONE to represent wSTL formulas and classify time-series data. WSTL formulas are more interpretable and human-readable than classical time series classification models. The STONE is end-to-end differentiable, which allows learning of wSTL formulas to be done using back-propagation. Experiments on benchmark time-series datasets show that STONE is comparable to the state-of-the-art time series classification models and the wSTL learning algorithm is faster than the traditional STL learning algorithm. © 2021 IEEE.
KW  - Backpropagation
KW  - Classification (of information)
KW  - Computer circuits
KW  - Neural networks
KW  - Semantics
KW  - Time series
KW  - Classification models
KW  - Frame-work
KW  - Higher weight
KW  - Logical operators
KW  - Neural-networks
KW  - Subformulas
KW  - Temporal logic formula
KW  - Temporal operators
KW  - Time series classifications
KW  - Time-series data
KW  - Temporal logic
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 8
ER  -

TY  - CONF
AU  - Latapie, H.
AU  - Gabriel, M.
AU  - Kompella, R.
TI  - Hybrid ai for iot actionable insights and real-Time data-driven networks
PY  - 2022
T2  - Proceedings of Machine Learning Research
VL  - 192
SP  - 127
EP  - 131
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163360379&partnerID=40&md5=0b0d427f026ec9e235a039565270e30a
AB  - Significant increases in industry requirements for network bandwidth are seen year upon year. The exponential growth in streaming data is matched by an increase in the use of machine learning and deep learning to glean actionable-ideally real-Time-insights from these data. However, approaches based on artificial neural networks (ANNs) are often insufficient in terms of functionality, flexibility, accuracy, explainability, and robustness. The demand for new model development and continual updating and retraining is outstripping the model generation capacity of data scientists and others in the field. This gap between supply and demand for real-Time data driven insights continues to grow. In this paper we introduce a hybrid AI solution which adds several elements into the ML/DL mix, specifically a new self-supervised learning mechanism, a knowledge model engineered to include support for machine generated ontologies as well as traditional human-generated ontologies, and interfaces to symbolic AI systems such as OpenNARS, AERA, ONA, and OpenCog, among other elements. Our hybrid AI system enables self-supervised learning of machinegenerated ontologies from millions of time series, to provide real-Time data-driven insights for large-scale deployments including data centers and enterprise networks. We also apply the same hybrid AI to video analytics use cases. Our preliminary results across all the use cases we have attempted to-date are promising although more work is needed to fully characterize both the benefits and limitations of our approach. © 2022 IWSSL. All Rights Reserved.
KW  - Artificial General Intelligence
KW  - Artificial Intelligence
KW  - Data-Driven Networks
KW  - General Machine Intelligence
KW  - Hybrid AI
KW  - Ontologies
KW  - Real-Time
KW  - Self-Supervised Learning
KW  - Deep learning
KW  - Economics
KW  - Internet of things
KW  - Learning systems
KW  - Neural networks
KW  - Supervised learning
KW  - Artificial general intelligences
KW  - Data driven
KW  - Data-driven network
KW  - General machine intelligence
KW  - Hybrid AI
KW  - Machine intelligence
KW  - Ontology's
KW  - Real- time
KW  - Real-time data
KW  - Self-supervised learning
KW  - Ontology
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Guarda, T.
AU  - Lopes, I.
AU  - Fernandes, P.O.
TI  - Cognitive Computing in the Travel and Tourism Industry
PY  - 2024
T2  - Lecture Notes in Networks and Systems
VL  - 800
SP  - 131
EP  - 138
DO  - 10.1007/978-3-031-45645-9_12
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186767797&doi=10.1007%2f978-3-031-45645-9_12&partnerID=40&md5=ba9aab2ef9174c318b9ac47dd1d645ea
AB  - Cognitive computing emerged from a mixture of cognitive science and computer science. Although cognitive computing is seen as a challenge for companies, it is an opportunity that raises the bar for the services provided, allowing companies that are committed to investing in innovation, and in this particular case in the travel and tourism sector, being able to stand out from the competition by adopting new technologies that make it possible to offer revolutionary and value-added experiences. Whether optimizing processes or developing new services, this technology is the key to innovation and competitiveness in the travel and tourism sector. With the user’s history and previous search data, cognitive systems, even before the user realizes it, present specific options according to their profile\preferences. In this sense, the system has the ability to automatically restrict the entire travel package. The main objective of this work is to explore the area of Cognitive computing in the context of Travel and Tourism Industry. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - Artificial Intelligence
KW  - Cognitive computing
KW  - Natural Language Processing
KW  - Travel and Tourism Industry
KW  - Cognitive systems
KW  - Search engines
KW  - Tourism
KW  - Cognitive computers
KW  - Cognitive Computing
KW  - Cognitive science
KW  - Language processing
KW  - Natural language processing
KW  - Natural languages
KW  - Tourism industry
KW  - Tourism sectors
KW  - Travel and tourism
KW  - Travel industry
KW  - Natural language processing systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Smirani, L.K.
AU  - Jamel, L.
AU  - Almuqren, L.
TI  - Improving Channel Estimation in a NOMA Modulation Environment Based on Ensemble Learning
PY  - 2024
T2  - CMES - Computer Modeling in Engineering and Sciences
VL  - 140
IS  - 2
SP  - 1315
EP  - 1337
DO  - 10.32604/cmes.2024.047551
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193732211&doi=10.32604%2fcmes.2024.047551&partnerID=40&md5=0c938b14821df8802e60aa6f01f66361
AB  - This study presents a layered generalization ensemble model for next generation radio mobiles, focusing on supervised channel estimation approaches. Channel estimation typically involves the insertion of pilot symbols with a well-balanced rhythm and suitable layout. The model, called Stacked Generalization for Channel Estimation (SGCE), aims to enhance channel estimation performance by eliminating pilot insertion and improving throughput. The SGCE model incorporates six machine learning methods: random forest (RF), gradient boosting machine (GB), light gradient boosting machine (LGBM), support vector regression (SVR), extremely randomized tree (ERT), and extreme gradient boosting (XGB). By generating meta-data from five models (RF, GB, LGBM, SVR, and ERT), we ensure accurate channel coefficient predictions using the XGB model. To validate the modeling performance, we employ the leave-one-out cross-validation (LOOCV) approach, where each observation serves as the validation set while the remaining observations act as the training set. SGCE performances’ results demonstrate higher mean and median accuracy compared to the separated model. SGCE achieves an average accuracy of 98.4%, precision of 98.1%, and the highest F1-score of 98.5%, accurately predicting channel coefficients. Furthermore, our proposed method outperforms prior traditional and intelligent techniques in terms of throughput and bit error rate. SGCE’s superior performance highlights its efficacy in optimizing channel estimation. It can effectively predict channel coefficients and contribute to enhancing the overall efficiency of radio mobile systems. Through extensive experimentation and evaluation, we demonstrate that SGCE improved performance in channel estimation, surpassing previous techniques. Accordingly, SGCE’s capabilities have significant implications for optimizing channel estimation in modern communication systems. © 2024 Tech Science Press. All rights reserved.
KW  - 5G
KW  - channel estimation
KW  - ensemble learning
KW  - Non-Orthogonal Multiple Access (NOMA)
KW  - Stacked generalization
KW  - 5G mobile communication systems
KW  - Adaptive boosting
KW  - Bit error rate
KW  - Channel estimation
KW  - Forecasting
KW  - 5g
KW  - Channel coefficient
KW  - Ensemble learning
KW  - Estimation performance
KW  - Gradient boosting
KW  - Multiple access
KW  - Non-orthogonal
KW  - Non-orthogonal multiple access
KW  - Random forests
KW  - Stacked generalization
KW  - Learning systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Singh, J.
AU  - Dhurandher, S.
AU  - Kumar, V.
AU  - Woungang, I.
AU  - Barolli, L.
TI  - Survey on securing wireless networks through a blockchain-based framework
PY  - 2024
T2  - Journal of High Speed Networks
VL  - 30
IS  - 4
SP  - 657
EP  - 677
DO  - 10.3233/JHS-240075
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002022143&doi=10.3233%2fJHS-240075&partnerID=40&md5=ad3e74331adaa609b98e258ba909e98c
AB  - In the contemporary era, blockchain technology has brought about a significant transformation in the realm of digital currency through innovations like Bitcoin. A blockchain serves as a decentralized ledger, ensuring an immutable record of transactions across a network. Recent observations indicate the pivotal role of blockchain technology not only in the financial sector but also in networking. This study considers blockchain as the essential link in establishing a genuinely decentralized, trustless, and secure environment for network nodes. The objective is to provide a systematic and comprehensive overview of futuristic endeavours in this domain. The exploration begins with an examination of the fundamental operational concepts of blockchains and how these systems achieve decentralization, security, and suitability. The focus then shifts towards addressing open research challenges within blockchain technologies, particularly in securing diverse communication networks such as Distributed Computing, Vehicular Ad-hoc Networks, Opportunistic Networks, and Delay Tolerant Networks. Simulation results underscore the superior security performance of blockchain, especially under conditions of attack. © © 2024 – IOS Press. All rights reserved.
KW  - attacks
KW  - authentication
KW  - blockchain technology
KW  - blockchain-based framework
KW  - confidentiality
KW  - consensus mechanisms
KW  - cryptography
KW  - distributed ledger
KW  - integrity
KW  - scalability
KW  - security
KW  - Wireless networks
KW  - Attack
KW  - Block-chain
KW  - Blockchain technology
KW  - Blockchain-based framework
KW  - Confidentiality
KW  - Consensus mechanism
KW  - Decentralised
KW  - Integrity
KW  - Security
KW  - Distributed ledger
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Zhang, T.
AU  - Jiang, X.
TI  - Research on the Construction of Ecological Architecture and Technical System of Aviation Metaverse
PY  - 2024
T2  - Lecture Notes in Operations Research
VL  - Part F3800
SP  - 746
EP  - 752
DO  - 10.1007/978-981-97-4045-1_58
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212487462&doi=10.1007%2f978-981-97-4045-1_58&partnerID=40&md5=d06838308e22728c1a6e14a5c08211d5
AB  - With the development of information technology, the concept of Metaverse has gradually entered our vision. The Metaverse is a virtual world that can interact and integrate with the real world. The aviation Metaverse integrates a number of emerging technologies to create an immersive aviation virtual interaction platform, and uses media, digital and virtual elements to bring people immersive and scene based experiences, thus realizing the deep integration of the aviation industry and tourism industry. This paper designs the ecological architecture of the aviation Metaverse from three perspectives of application, technology and market, and designs the technical architecture of the aviation Metaverse from four perspectives of access, basic technology, data and application. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.
KW  - architecture
KW  - aviation
KW  - Metaverse
KW  - technology
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Zvarikova, K.
AU  - Machova, V.
AU  - Nica, E.
TI  - Cognitive Artificial Intelligence Algorithms, Movement and Behavior Tracking Tools, and Customer Identification Technology in the Metaverse Commerce
PY  - 2022
T2  - Review of Contemporary Philosophy
VL  - 21
SP  - 171
EP  - 187
DO  - 10.22381/RCP21202211
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142253457&doi=10.22381%2fRCP21202211&partnerID=40&md5=733ddda7af652798844aed4211348db2
AB  - The aim of this systematic review is to synthesize and analyze biometric authentication features, metaverse capabilities, and real-time predictive analytics. With increasing evidence of digital assets in the metaverse commerce, there is an essential demand for comprehending whether augmented reality shopping tools and deep learning algorithms shape consumer sentiment and behavior and personalized purchase experiences in user-generated digital virtual environments. In this research, prior findings were cumulated indicating that transaction geolocation data, machine learning-based image recognition tools, and artificial vision systems configure consumer behavior and expectations, optimizing purchase journeys in virtual market-places. We carried out a quantitative literature review of ProQuest, Scopus, and the Web of Science throughout April 2022, with search terms including “the meta-verse commerce” + “cognitive artificial intelligence algorithms,” “movement and behavior tracking tools,” and “customer identification technology.” As we analyzed research published between 2021 and 2022, only 148 papers met the eligibility criteria. By removing controversial or unclear findings (scanty/unimportant data), results unsupported by replication, undetailed content, or papers having quite similar titles, we decided on 29, chiefly empirical, sources. Data visualization tools: Dimensions (bibliometric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AXIS, Distiller SR, ROBIS, and SRDR. © 2022, Addleton Academic Publishers. All rights reserved.
KW  - ambient sound recognition software
KW  - immersive visualization systems
KW  - machine learning-based product recognition tools
KW  - metaverse interactive environment
KW  - shopper engagement technologies
KW  - spatial computing technology
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 38
ER  -

TY  - JOUR
AU  - Li, X.
AU  - Xiao, S.
AU  - Li, Q.
AU  - Zhu, L.
AU  - Wang, T.
AU  - Chu, F.
TI  - The bearing multi-sensor fault diagnosis method based on a multi-branch parallel perception network and feature fusion strategy
PY  - 2025
T2  - Reliability Engineering and System Safety
VL  - 261
C7  - 111122
DO  - 10.1016/j.ress.2025.111122
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002223930&doi=10.1016%2fj.ress.2025.111122&partnerID=40&md5=d42d42dfbbcaa7a02436ab43ad34bc58
AB  - Limited information from a single sensor constrains the precision of bearing fault diagnosis. Despite the abundance of multi-sensor data, the high dimensionality and complexity of data fusion make it difficult for existing methods to effectively extract and integrate multi-sensor features. To address these challenges, this paper proposes a novel multi-branch feature cross-fusion bearing fault diagnosis model (MCFormer), leveraging the powerful capabilities of Transformers in feature extraction and global modeling. First, to tackle the heterogeneity of multi-sensor data, a multi-branch structure is introduced to extract local features from each sensor separately, reducing information loss and redundancy. Then, based on the multi-branch feature extraction structure, a feature cross-fusion strategy and a dynamic classifier module are designed to achieve a unified representation of global features, enhancing feature discrimination and classification capabilities. Extensive experimental studies were conducted on two bearing cases, demonstrating that MCFormer achieves excellent diagnostic results on both the Northeast Forestry University (NEFU) bearing dataset and the Huazhong University of Science and Technology (HUST) bearing dataset, achieving diagnostic accuracies of 99.50 % and 98.33 %, respectively, surpassing the best performances of five other methods by 1.17 % and 2.36 %. Finally, ablation experiments confirm the efficacy of both component modules. © 2025 Elsevier Ltd
KW  - Bearing fault diagnosis
KW  - Feature fusion
KW  - Multi-branch structure
KW  - Multi-sensor data
KW  - Bearing fault diagnosis
KW  - Fault diagnosis method
KW  - Features extraction
KW  - Features fusions
KW  - Fusion strategies
KW  - Multi sensor
KW  - Multi-sensor data
KW  - Multibranches structures
KW  - Network fusion
KW  - Sensor fault diagnosis
KW  - Sensor data fusion
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Chow, E.
AU  - Lu, T.
AU  - Payumo, K.
AU  - De Fourou, G.B.
AU  - Sadler, E.
AU  - Janvisloo, N.E.
AU  - Carrillo, J.
AU  - Li, B.
AU  - Hubler, B.
AU  - Littlejohn, O.
AU  - Hernandez-Cruz, V.
AU  - Torrellas, S.
TI  - Collaborative Moonwalkers
PY  - 2024
T2  - IEEE Aerospace Conference Proceedings
DO  - 10.1109/AERO58975.2024.10521103
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193836740&doi=10.1109%2fAERO58975.2024.10521103&partnerID=40&md5=6c1e3e29ccc74fbe27c6c5e3c7af77ff
AB  - We present the results of an advanced concept research for a collective of robotic rovers named Moonwalkers that implement bio-inspired motivations, distributed intelligence, and integrated deep learning techniques to demonstrate autonomous cooperative goal-directed lunar exploration with minimum human interventions. By borrowing concepts from biology, the Moonwalker rovers are driven by a set of balanced motivations (ex. Energy, safety, operating temperature, achievements, respect) to accomplish mission goals while maintaining safety from potential dangers. Drawing from contemporary neuroscience and computer science research, the Moonwalker rovers are equipped with system 1 (low-level) and system 2 (high-level) cognitive functions based on a two-level memory architecture utilizing a pre-trained multi-modal model in conjunction with a graph knowledgebase, which leverages knowledge graph embeddings. This neuro-symbolic approach enables the rovers to learn from and be guided by human knowledge, facilitating zero-shot learning, collaborative planning, and reasoning like human explorers under uncertain conditions. We also describe the construction of a virtual simulation environment with high-fidelity visualizations and prototype rover agents. By addressing selected problems, we demonstrate that physics informed machine learning can enhance the effectiveness of the virtual lunar test environment. © 2024 IEEE.
KW  - Biomimetics
KW  - Computer aided instruction
KW  - Deep learning
KW  - Intelligent robots
KW  - Learning systems
KW  - Lunar missions
KW  - Memory architecture
KW  - Motivation
KW  - Zero-shot learning
KW  - Cognitive functions
KW  - Computer science research
KW  - Distributed intelligence
KW  - Energy safety
KW  - Goal-directed
KW  - Human intervention
KW  - Learning techniques
KW  - Multi-modal
KW  - Operating temperature
KW  - Robotic rovers
KW  - Rovers
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Nedungadi, P.
AU  - Surendran, S.
AU  - Tang, K.-Y.
AU  - Raman, R.
TI  - Big Data and AI Algorithms for Sustainable Development Goals: A Topic Modeling Analysis
PY  - 2024
T2  - IEEE Access
VL  - 12
SP  - 188519
EP  - 188541
DO  - 10.1109/ACCESS.2024.3516500
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212337755&doi=10.1109%2fACCESS.2024.3516500&partnerID=40&md5=80a8b9474c871d4db5445006c59a76f1
AB  - This study makes significant contributions to the field by examining the transformative role of big data and artificial intelligence (AI) in advancing Sustainable Development Goals (SDGs), particularly healthcare (SDG3), sustainable energy (SDG7), and industry and infrastructure (SDG9). Using BERTopic modeling, a machine learning technique, this research systematically analyzes literature from 2013 to 2024, providing an overview of AI and big data applications mapped to SDGs which is a first. This structured approach identifies key SDGs impacted by these technologies and highlights interdisciplinary methods that further enhance SDG outcomes. AI applications notably improve healthcare by advancing disease tracking, tailored treatments, and precision medicine, fostering universal healthcare and reducing noncommunicable disease mortality. In energy, AI-driven solutions optimize forecasting, grid management, and renewable integration, while in industry, they bolster infrastructure resilience through innovations like predictive maintenance and automated quality control within Industry 4.0 frameworks. The integration of automated text analysis and semantic context captures broad trends, contributing both methodologically and substantively at the intersection of AI and sustainability. Despite these advancements, the study underscores ethical concerns, including data privacy, security, and algorithmic biases. Interdisciplinary collaboration among healthcare professionals, engineers, environmental scientists, and AI experts is crucial to developing ethical, scalable AI solutions. The study suggests future research focus on AI transparency, scaling across diverse sectors, and integrating advanced techniques such as neurosymbolic AI and quantum neural networks to enhance system reliability. These insights offer practical implications, reinforcing the potential of AI and big data to address global challenges sustainably while calling for balanced attention to ethical and regulatory dimensions.  © 2013 IEEE.
KW  - artificial intelligence
KW  - big data
KW  - generative AI
KW  - healthcare
KW  - industrial innovation
KW  - resilient energy
KW  - resilient infrastructure
KW  - Sustainable development goal
KW  - Artificial intelligence algorithms
KW  - Energy
KW  - Generative artificial intelligence
KW  - Healthcare
KW  - Industrial innovation
KW  - Modeling analyzes
KW  - Resilient energy
KW  - Resilient infrastructure
KW  - Sustainable energy
KW  - Topic Modeling
KW  - Sustainable development goals
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - CONF
AU  - Kiourtis, A.
AU  - Mavrogiorgou, A.
AU  - Makridis, G.
AU  - Kyriazis, D.
AU  - Soldatos, J.
AU  - Fatouros, G.
AU  - Ntalaperas, D.
AU  - Papageorgiou, X.
AU  - Almeida, B.
AU  - Guedes, J.
AU  - Malo, P.
AU  - Oliveira, J.
AU  - Scholze, S.
AU  - Rosinha, A.
AU  - Reis, J.
AU  - Falsetta, M.
TI  - XR5.0: Human-Centric AI-Enabled Extended Reality Applications for Industry 5.0
PY  - 2024
T2  - Conference of Open Innovation Association, FRUCT
SP  - 314
EP  - 323
DO  - 10.23919/FRUCT64283.2024.10749931
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210828189&doi=10.23919%2fFRUCT64283.2024.10749931&partnerID=40&md5=aabd3ea5f365c979c4c6ee7699229ebf
AB  - Applications for Extended Reality (XR) are rapidly expanding across a wide range of industries, including gaming, entertainment, and healthcare. Accompanying this trend is the field of digital manufacturing, which encompasses a broad range of applications such as quick product design, remote maintenance, production process simulation, employee safety, and training. Industrial personnel may benefit from ergonomic and user-friendly cyber-representations of production processes using XR applications, particularly in the industrial arena. These cyber-representations are utilized to create augmented environments for training, simulation, and testing. The wave of Industry 5.0 (I5.0) applications that are certain to be human-centric and emphasize trustworthy human-machine collaboration cannot be supported by current systems because of several issues, such as the requirement for individualized XR visualizations and new methods for world-building, content production, and flow control aspects of XR systems. The XR5.0 project is presented in this publication with the goal of addressing these issues and offering a revolutionary Person-Centric and AI-based XR paradigm that will be customized to the needs and characteristics of I5.0 applications. The project outlines the organizing concepts and guidelines for utilizing XR in I5.0 applications, with a focus on the creation of cutting-edge "XR-made-in-Europe"technology that complements human-centered manufacturing techniques and upholds European ideals. The associated applications consider the workers' environment through the incorporation of human-centered digital twins (DTs), which make up the "digital image"of the workers. This allows for the simultaneous design and implementation of an innovative fusion of cutting-edge AI paradigms and XR technology. The added value of the XR5.0 project is discussed, and potential use cases and user journeys are analyzed, leading to a discussion of the project's revolutionary benefits and additional steps that should be taken. © 2024 FRUCT Oy.
KW  - Augmented reality
KW  - Crushed stone plants
KW  - Entertainment industry
KW  - Smart manufacturing
KW  - Cutting edges
KW  - Digital manufacturing
KW  - Employee safety
KW  - Employee training
KW  - Human-centric
KW  - Process simulations
KW  - Production process
KW  - Remote maintenance
KW  - User friendly
KW  - Workers'
KW  - Industry 4.0
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Wu, T.
AU  - Yu, J.
AU  - Jiang, Q.
AU  - Fan, Q.
TI  - An Unmanned System-Guided Crowd Evacuation Method in Complex and Large-Scale Evacuation Environments
PY  - 2025
T2  - IEEE Transactions on Automation Science and Engineering
VL  - 22
SP  - 1864
EP  - 1877
DO  - 10.1109/TASE.2024.3371102
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187340643&doi=10.1109%2fTASE.2024.3371102&partnerID=40&md5=f0f2bb12376b5c99e3d9329f2f8dfebe
AB  - With the continuous expansion of the city scale and urbanization, urban road networks are becoming increasingly complex. Moreover, severe and extreme weather events, earthquakes, and other natural disasters occur frequently. Therefore, how to effectively and quickly evacuate urban crowd in dynamic environments is an urgent issue. To carry out the above objective, an unmanned system-guided crowd evacuation method is proposed in the current study. In the proposed method, the robot can perceive the environment in a timely and accurate manner to generate the evacuation map via advanced information technologies such as the Internet of Things or urban brain. Subsequently, an improved elliptic tangent graph approach based on global and local information (ETG-GLI) is utilized to plan a feasible and short evacuation path in large-scale scenarios. Finally, a novel crowd evacuation model based on the social force model is proposed to simulate the actual crowd evacuation process in complex and large-scale environments. To test the performance of the proposed path planning method, 25 different scenarios are proposed to simulate complex urban crowd evacuation environments. The experimental results show that the proposed algorithm outperforms other competitors in terms of path planning ability and computational time. Three actual evacuation cases with 324 pedestrians are modeled to further test the performance of the proposed algorithm. The simulation results demonstrate that the unmanned system-guided crowd evacuation method can find a shorter evacuation path for reducing the evacuation time in three complex and large-scale environments when compared with three other methods. Therefore, the proposed algorithm is a highly effective and promising approach to provide useful decision support and guidance for actual urban planning and urban emergence management. Note to Practitioners - In modern cities, the population density is high and the road network is complex. To evacuate the crowd in a timely and safe manner, planning feasible and short paths in large-scale and complex environments is a critical and challenging task. Therefore, the present study aims to provide a novel method to plan high-quality evacuation routes to guide the pedestrian flow. The performance of the proposed approach is validated in 25 test scenarios and 3 real-world instances. Experimental results demonstrate that the proposed algorithm performs well in terms of path length and computation time. Moreover, the proposed crowd evacuation model can simulate the actual process of crowd evacuation. © 2024 IEEE.
KW  - crowd evacuation
KW  - ellipse tangent
KW  - large-scale environment
KW  - path planning
KW  - Unmanned system
KW  - Air navigation
KW  - Complex networks
KW  - Decision support systems
KW  - Disasters
KW  - Population statistics
KW  - Roads and streets
KW  - City scale
KW  - Crowd evacuation
KW  - Ellipse tangent
KW  - Evacuation models
KW  - Large-scale environment
KW  - Large-scales
KW  - Performance
KW  - Severe weather events
KW  - Unmanned system
KW  - Urban road networks
KW  - Motion planning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Munir, M.S.
AU  - Shetty, S.
AU  - Rawat, D.B.
TI  - Trustworthy Artificial Intelligence Framework for Proactive Detection and Risk Explanation of Cyber Attacks in Smart Grid
PY  - 2023
T2  - Proceedings - Winter Simulation Conference
SP  - 636
EP  - 647
DO  - 10.1109/WSC60868.2023.10408676
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185371663&doi=10.1109%2fWSC60868.2023.10408676&partnerID=40&md5=76c9a5f212e371070498bb5c920c8d65
AB  - The rapid growth of distributed energy resources (DERs), such as renewable energy sources, generators, consumers, and prosumers in the smart grid infrastructure, poses significant cybersecurity and trust challenges to the grid controller. Consequently, it is crucial to identify adversarial tactics and measure the strength of the attacker's DER. To enable a trustworthy smart grid controller, this work investigates a trustworthy artificial intelligence (AI) mechanism for proactive identification and explanation of the cyber risk caused by the control/status message of DERs. Thus, proposing and developing a trustworthy AI framework to facilitate the deployment of any AI algorithms for detecting potential cyber threats and analyzing root causes based on Shapley value interpretation while dynamically quantifying the risk of an attack based on Ward's minimum variance formula. The experiment with a state-of-the-art dataset establishes the proposed framework as a trustworthy AI by fulfilling the capabilities of reliability, fairness, explainability, transparency, reproducibility, and accountability.  © 2023 IEEE.
KW  - Artificial intelligence
KW  - Cybersecurity
KW  - Network security
KW  - Renewable energy
KW  - Artificial intelligence algorithms
KW  - Cyber security
KW  - Cyber threats
KW  - Cyber-attacks
KW  - Distributed Energy Resources
KW  - Grid infrastructures
KW  - Rapid growth
KW  - Renewable energy source
KW  - Root cause
KW  - Smart grid
KW  - Smart power grids
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CHAP
AU  - Karunaratne, G.
AU  - Hersche, M.
AU  - Cherubini, G.
AU  - Sebastian, A.
AU  - Rahimi, A.
TI  - Few-shot continual learning based on vector symbolic architectures
PY  - 2023
T2  - Frontiers in Artificial Intelligence and Applications
VL  - 369
SP  - 522
EP  - 546
DO  - 10.3233/FAIA230156
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171782316&doi=10.3233%2fFAIA230156&partnerID=40&md5=c98668d5b2bdb3a7a7bd1412d2e2b0f9
AB  - Vector Symbolic Architecture (VSA) is a powerful computing model that is built on a rich algebra in which all representations - from atomic to composite structures - are high-dimensional holographic distributed vectors of the same, fixed dimensionality. VSA is mainly characterized by the following intriguing properties: (i) quasi-orthogonality of a randomly chosen vector to other random vectors with very high probability, aka concentration of measure; (ii) exponential growth of the number of such quasi-orthogonal vectors with the dimensionality, which provides a sufficiently large capacity to accommodate novel concepts over time; (iii) availability of these vectors to be composed, decomposed, probed, and transformed in various ways using a set of well-defined operations. Motivated by these properties, this chapter presents a summary of recently developed methodologies on the integration of VSA with deep neural networks that enabled impactful applications to few-shot [1] and continual [2, 3] learning. Resorting to VSA-based embedding allows deep neural networks to quickly learn from few training samples by storing them in an explicit memory, where many more class categories can be continually expressed in the abstract vector space of VSA with fixed dimensions, without causing interference among the learned classes. Experiments on various image datasets show that the considered neuro-symbolic AI approach outperforms pure deep neural network baselines with remarkable accuracy, scalability, and compute/memory efficiency. © 2023 The authors and IOS Press. All rights reserved.
KW  - Abstracting
KW  - Deep neural networks
KW  - Network architecture
KW  - Vector spaces
KW  - Composites structures
KW  - Computing model
KW  - Concentration of measure
KW  - Continual learning
KW  - High probability
KW  - High-dimensional
KW  - Higher-dimensional
KW  - Property
KW  - Quasi-orthogonality
KW  - Random vectors
KW  - Vectors
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Chowdhury, R.R.
AU  - Kapila, R.
AU  - Panse, A.
AU  - Zhang, X.
AU  - Teng, D.
AU  - Kulkarni, R.
AU  - Hong, D.
AU  - Gupta, R.K.
AU  - Shang, J.
TI  - ZeroHAR: Sensor Context Augments Zero-Shot Wearable Action Recognition
PY  - 2025
T2  - Proceedings of the AAAI Conference on Artificial Intelligence
VL  - 39
IS  - 15
SP  - 16046
EP  - 16054
DO  - 10.1609/aaai.v39i15.33762
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003999732&doi=10.1609%2faaai.v39i15.33762&partnerID=40&md5=12429bd7198a691632d20595abde4040
AB  - Wearable Human Action Recognition (wHAR) uses motion sensor data to identify human movements, which is essential for mobile and wearable devices. However, traditional wHAR systems are only trained on a limited set of activities. Hence, they fail to generalize to diverse human motions, prompting Zero-Shot Learning (ZSL). Existing ZSL methods for wHAR focus solely on augmenting labels, such as representing them as attribute matrices, images, videos, or text. We propose ZeroHAR that enhances ZSL by not just focusing on activity labels, but also augmenting motion data with sensor context features. Our approach incorporates information about the sensor type, the Cartesian axis of the data, and the sensor’s body position, providing the model with crucial spatial and biomechanical insights. This helps the model to generalize better to new actions. First, we train the model by aligning the latent space of the motion time series with its corresponding sensor context, while distancing it from unrelated sensor contexts. Then, we train the model using the target activity descriptions. We tested our method against eight baselines on five benchmark HAR datasets with various sensors, placements, and activities. Our model shows exceptional generalizability across the 18 motion time series classification benchmark datasets, outperforming the best baselines by 262% in the zero-shot setting. Copyright © 2025, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.
KW  - Action recognition
KW  - Action recognition systems
KW  - Human motions
KW  - Human movements
KW  - Human-action recognition
KW  - Learning methods
KW  - matrix
KW  - Motion sensors
KW  - Sensors data
KW  - Wearable devices
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Dhekane, S.G.
AU  - Ploetz, T.
TI  - Transfer Learning in Sensor-Based Human Activity Recognition: A Survey
PY  - 2025
T2  - ACM Computing Surveys
VL  - 57
IS  - 8
C7  - 205
SP  - 1
EP  - 39
DO  - 10.1145/3717608
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003624953&doi=10.1145%2f3717608&partnerID=40&md5=babfa08ac221f2153a3a19a6595a0cbd
AB  - Sensor-based human activity recognition (HAR) has been an active research area for many years, resulting in practical applications in smart environments, assisted living, fitness, healthcare, and more. Recently, deep-learning-based end-to-end training has pushed the state-of-the-art performance in domains such as computer vision and natural language, where large amounts of annotated data are available. However, large quantities of annotated data are typically not available for sensor-based HAR. Moreover, the real-world settings on which HAR is performed differ in terms of sensor modalities, classification tasks, and target users. To address this problem, transfer learning has been explored extensively. In this survey, we focus on these transfer learning methods in the application domains of smart home and wearables-based HAR. In particular, we provide a problem-solution perspective by categorizing and presenting the works in terms of their contributions and the challenges they address. We present an overview of the state of the art for both application domains. Based on our analysis of 246 papers, we highlight the gaps in the literature and provide a roadmap for addressing these. This survey provides a reference to the HAR community by summarizing the existing works and providing a promising research agenda.  © 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.
KW  - Additional Key Words and PhrasesHuman activity recognition
KW  - domain adaptation
KW  - transfer learning
KW  - Active learning
KW  - Deep learning
KW  - Smart homes
KW  - Transfer learning
KW  - Activity recognition
KW  - Additional key word and phraseshuman activity recognition
KW  - Applications domains
KW  - Domain adaptation
KW  - End to end
KW  - Human activity recognition
KW  - Key words
KW  - Research areas
KW  - Smart environment
KW  - Transfer learning
KW  - Assisted living
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Pakkala, D.
AU  - Känsäkoski, N.
AU  - Heikkilä, T.
AU  - Backman, J.
AU  - Pääkkönen, P.
TI  - On design of cognitive situation-adaptive autonomous mobile robotic applications
PY  - 2025
T2  - Computers in Industry
VL  - 167
C7  - 104263
DO  - 10.1016/j.compind.2025.104263
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217923921&doi=10.1016%2fj.compind.2025.104263&partnerID=40&md5=4e0fa9b566106d15207f10f996ac0dbc
AB  - Fostered by the recent development in artificial intelligence technologies, digitalization in industries is proceeding towards intelligent automation of various physical work processes with autonomous robotic applications, in dynamic and non-deterministic environments, and in collaboration with human workers. The article presents an explorative case study on designing a cognitive situation-adaptive Autonomous Mobile Robotics (AMR) application for material hauling, in a simulated underground mining context. The goal of the research is to synthesize and present new design knowledge for improving situation-adaptation capabilities of AMR applications, which are increasingly required as the operational environments for the AMRs become dynamic, non-deterministic, and include people working on the same area with the robots. The research applies design science research methodology, and evaluates the results empirically via a prototype system, which is demonstrated in laboratory setting simulating an underground tunnel network. As an outstanding contribution, the results contribute a novel, nascent, and empirically evaluated design approach, which proposes three design aspects combining design and engineering activities across the systems engineering, knowledge engineering, computer science and robotics disciplines. Empirical evaluation is made via design, development, and demonstration of a system architecture and prototype system of a cognitive situation-adaptive AMR application, which is used in synthesis and evaluation of the design approach. The three design aspects proposed by the approach are 1) Context of operation, 2) Knowledge-driven behaviour, and 3) Knowledge driven operation. Also design challenges, future research and development needs, and innovation potential on designing of cognitive situation-adaptive AMR applications for industrial use are identified and discussed. © 2025 The Authors
KW  - Autonomous adaptation
KW  - Cognitive robotics
KW  - Design
KW  - Neurosymbolic AI
KW  - Design for manufacturability
KW  - Industrial robots
KW  - Intelligent robots
KW  - Knowledge engineering
KW  - Machine design
KW  - Microrobots
KW  - Mobile robots
KW  - Artificial intelligence technologies
KW  - Autonomous adaptation
KW  - Cognitive robotics
KW  - Design approaches
KW  - Deterministics
KW  - Intelligent automation
KW  - Mobile robotic
KW  - Neurosymbolic AI
KW  - Prototype system
KW  - Robotics applications
KW  - Robot applications
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Gupta, P.K.
AU  - Mazumdar, B.D.
AU  - Pillai, S.N.
TI  - Data Protection in Enhanced EXplainable Digital Twins: Insights from Hybrid AI
PY  - 2025
T2  - 2025 2nd International Conference on Computational Intelligence, Communication Technology and Networking, CICTN 2025
SP  - 324
EP  - 329
DO  - 10.1109/CICTN64563.2025.10932525
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002697843&doi=10.1109%2fCICTN64563.2025.10932525&partnerID=40&md5=34f726809b2ca80cff95888298f4f0bc
AB  - Deep Learning (DL) based artificial intelligence (AI) is becoming pervasive in almost all the day to day applications. These DL algorithms require large amounts of data, which can be easily collected nowadays by deploying sensors in the environment of the system under observation. These DL algorithms however, suffer from drawbacks such as being criticised as 'black-boxes', being biased to generating predictions based on past data and ignoring the human expertise. Hence, an architecture of Enhanced eXplainable Digital Twins (EXDTs) was proposed. EXDTs remove 'black-boxness' of DL algorithms by using the XAI approaches. Further, the digital twins (DTs) underlying the EXDTs are constructed through the sensor data and depict the real-time simulatability. Also, to improve the explainability and use the human expertise/experience, EXDTs use the domain experts' qualitative data. EXDTs are a class of Hybrid AI systems, that use the numeric data for underlying DL algorithms and subjective knowledge of the domain expert. This multimodal data in EXDTs opens up new attacks fronts for data manipulation and change the EXDTs' outputs. In this manuscript, we discuss about the data protection in EXDTs, by simulating various types of attacks and suggesting possible ways the system can counter them. We feel our proposed framework is useful for the involved stakeholders in various domains like precision agriculture, healthcare, manufacturing, etc. © 2025 IEEE.
KW  - Data Protection
KW  - Deep Learning
KW  - Digital Twins
KW  - Enhanced eXplainable Digital Twins
KW  - eXplainable AI
KW  - Black boxes
KW  - Deep learning
KW  - Domain experts
KW  - Enhanced explainable digital twin
KW  - Explainable artificial intelligence
KW  - Human expertise
KW  - Hybrid artificial intelligences
KW  - Large amounts of data
KW  - Prediction-based
KW  - Sensors data
KW  - Contrastive Learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Nilsson, J.
AU  - Javed, S.
AU  - Albertsson, K.
AU  - Delsing, J.
AU  - Liwicki, M.
AU  - Sandin, F.
TI  - AI Concepts for System of Systems Dynamic Interoperability
PY  - 2024
T2  - Sensors
VL  - 24
IS  - 9
C7  - 2921
DO  - 10.3390/s24092921
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192703355&doi=10.3390%2fs24092921&partnerID=40&md5=4c4442137f438648ec40544e7d9fe704
AB  - Interoperability is a central problem in digitization and System of Systems (SoS) engineering, which concerns the capacity of systems to exchange information and cooperate. The task to dynamically establish interoperability between heterogeneous cyber-physical systems (CPSs) at run-time is a challenging problem. Different aspects of the interoperability problem have been studied in fields such as SoS, neural translation, and agent-based systems, but there are no unifying solutions beyond domain-specific standardization efforts. The problem is complicated by the uncertain and variable relations between physical processes and human-centric symbols, which result from, e.g., latent physical degrees of freedom, maintenance, re-configurations, and software updates. Therefore, we surveyed the literature for concepts and methods needed to automatically establish SoSs with purposeful CPS communication, focusing on machine learning and connecting approaches that are not integrated in the present literature. Here, we summarize recent developments relevant to the dynamic interoperability problem, such as representation learning for ontology alignment and inference on heterogeneous linked data; neural networks for transcoding of text and code; concept learning-based reasoning; and emergent communication. We find that there has been a recent interest in deep learning approaches to establishing communication under different assumptions about the environment, language, and nature of the communicating entities. Furthermore, we present examples of architectures and discuss open problems associated with artificial intelligence (AI)-enabled solutions in relation to SoS interoperability requirements. Although these developments open new avenues for research, there are still no examples that bridge the concepts necessary to establish dynamic interoperability in complex SoSs, and realistic testbeds are needed. © 2024 by the authors.
KW  - AI for cyber-physical systems
KW  - dynamic interoperability
KW  - representation learning
KW  - system of systems
KW  - Deep learning
KW  - Degrees of freedom (mechanics)
KW  - Dynamics
KW  - Embedded systems
KW  - Interoperability
KW  - Learning systems
KW  - System of systems
KW  - Artificial intelligence for cybe-physical system
KW  - Central problems
KW  - Cybe-physical systems
KW  - Cyber-physical systems
KW  - Digitisation
KW  - Dynamic interoperability
KW  - Representation learning
KW  - System Dynamics
KW  - System of systems engineering
KW  - System-of-systems
KW  - article
KW  - artificial intelligence
KW  - deep learning
KW  - digitization
KW  - feature learning (machine learning)
KW  - human
KW  - learning
KW  - machine learning
KW  - reasoning
KW  - software
KW  - standardization
KW  - Cyber Physical System
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - CONF
AU  - Usmani, A.
AU  - Khan, M.J.
AU  - Breslin, J.G.
AU  - Curry, E.
TI  - Towards Multimodal Knowledge Graphs for Data Spaces
PY  - 2023
T2  - ACM Web Conference 2023 - Companion of the World Wide Web Conference, WWW 2023
SP  - 1494
EP  - 1499
DO  - 10.1145/3543873.3587665
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159563778&doi=10.1145%2f3543873.3587665&partnerID=40&md5=c08d5e3c0fb5e245c25bbc49177a4bde
AB  - Multimodal knowledge graphs have the potential to enhance data spaces by providing a unified and semantically grounded structured representation of multimodal data produced by multiple sources. With the ability to integrate and analyze data in real-time, multimodal knowledge graphs offer a wealth of insights for smart city applications, such as monitoring traffic flow, air quality, public safety, and identifying potential hazards. Knowledge enrichment can enable a more comprehensive representation of multimodal data and intuitive decision-making with improved expressiveness and generalizability. However, challenges remain in effectively modelling the complex relationships between and within different types of modalities in data spaces and infusing common sense knowledge from external sources. This paper reviews the related literature and identifies major challenges and key requirements for effectively developing multimodal knowledge graphs for data spaces, and proposes an ontology for their construction.  © 2023 Owner/Author.
KW  - data spaces
KW  - knowledge graphs
KW  - multimodal data
KW  - smart city
KW  - Air quality
KW  - Decision making
KW  - Flow graphs
KW  - Graphic methods
KW  - Knowledge graph
KW  - Data space
KW  - Decisions makings
KW  - Knowledge graphs
KW  - Multi-modal
KW  - Multi-modal data
KW  - Multiple source
KW  - Potential hazards
KW  - Public safety
KW  - Real- time
KW  - Traffic flow
KW  - Smart city
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 8
ER  -

TY  - JOUR
AU  - Reyes, J.A.P.
AU  - Rajagopal, A.
TI  - Rules of engagement: ethical issues and value chain introspection in Artificial Intelligence systems
PY  - 2025
T2  - Quality and Quantity
VL  - 59
IS  - Suppl 1
SP  - 463
EP  - 487
DO  - 10.1007/s11135-024-01990-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003024710&doi=10.1007%2fs11135-024-01990-y&partnerID=40&md5=f5af975791932bf218265bb0983ef2f5
AB  - The increasing use of artificial intelligence (AI) to improve business analytics has brought with it a strong discussion concerning the ethics of the value chains. This study adopts a multidisciplinary approach by applying mixed methods research aimed at determining its benefits in the corporate environment. The study also contrasts the benefits with the potential harms caused by the use of AI in terms of governance, justice, and people’s freedoms in the enterprise. The study is based on the maxims of technology acceptance model, reliability theory, and theory of justice, which drive the formulation of research propositions and empirical hypotheses. Data was collected from 158 middle and senior management employees implementing AI tech in various areas of the firm and 24 users of AI technology within the geographical expanse of Mexico. The results of the study indicate that the stakeholders influence the use of AI and stimulate technological adaptation process through generating awareness, availability, and repeat buying behavior among consumers. The study also indicates that the algorithms associated with the learning models of online systems in the footwear industry are particularly programmed to optimize the customer experience and to adopt sustainable practices that reduce social and environmental impact. © The Author(s), under exclusive licence to Springer Nature B.V. 2024.
KW  - Artificial intelligence
KW  - Business analytics
KW  - Organizational framework
KW  - Sustainability
KW  - Value chain
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Raju, K.N.
AU  - Mohanty, S.N.
TI  - IMPROVING PREDICTION OF DEPRESSION AN ANALYTICAL COMPARISON BETWEEN HYBRID AI, MACHINE LEARNING AND DEEP LEARNING APPROACHES
PY  - 2025
T2  - Proceedings on Engineering Sciences
VL  - 7
IS  - 1
SP  - 459
EP  - 472
DO  - 10.24874/PES07.01D.003
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000045271&doi=10.24874%2fPES07.01D.003&partnerID=40&md5=4a1e2875b45eac55acd1f8c04f972f08
AB  - This research includes an original comparative evaluation of machine learning (ML) and deep learning (DL) tactics, further developing through the building of integrated artificial intelligence frameworks. Our goal is to improve forecasting approaches for depression, and this research presents a novel approach to this attempt. We initiated a comprehensive investigation into the factors that influence depression outcomes by utilising a dataset that encompasses 2,000 subjects. This dataset was enriched with a variety of data points, which included demographic, socio-economic, behavioural, and clinical indicators. Additionally, we incorporated pre-and post-intervention scores from the Montgomery-Åsberg Depression Rating Scale (MADRS). Together with an intense process of feature determination utilising Recursive Feature Elimination (RFE) and Principal Component Analysis (PCA), we synced a wide range of elements, ranging from fundamental demographic information to sophisticated clinical results. This was accomplished by conducting detailed data gathering. Through the use of a comprehensive hyperparameter refining step, our research route was supported, which ensured that the ability of each model to accurately forecast was improved. This study provides a substantial addition by conducting an in-depth analysis of individual machine learning and deep learning models and comparing them to the integrated artificial intelligence solutions that we have built. The findings indicate that the later models significantly improve the capability to reliably forecast depression, attaining levels of accuracy that have never been seen before. The combined models show a remarkable capacity to negotiate the various intricacies of depression's multiple nature, reaching faultless accuracy in our testing. This ability is achieved by combining machine learning and deep learning. The research that we have conducted demonstrates that integrated artificial intelligence systems have the ability to exceed the limitations of standalone models. This synthesis of machine learning and deep learning methodologies exemplifies this promise. As a result of these improvements, the approach to predictive analytics for mental health diseases like depression is undergoing a fundamental shift that will prove to be transformational. This study not only establishes a new benchmark for multidisciplinary research at the intersection of biology, psychology, and artificial intelligence, but it also provides the framework for the future generation of prediction tools that will be used in the field of mental health treatment. In addition to paving the way for tailored and preventative mental health therapies, the far-reaching implications of our results signal the beginning of a new era in the treatment and comprehension of mental health. © 2025 Published by Faculty of Engineeringg.
KW  - Comparative Analysis
KW  - Deep Learning (DL)
KW  - Depression
KW  - Hybrid AI Models
KW  - Machine Learning (ML)
KW  - Predictive Analytics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Belle, V.
TI  - Actions, Continuous Distributions and Meta-Beliefs
PY  - 2023
T2  - Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS
VL  - 2023-May
SP  - 418
EP  - 426
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171301291&partnerID=40&md5=9db364b30871dccc05286452ab4fd518
AB  - In this work, we propose a new modal logical language for reasoning about noisy actions and sensors in an epistemic setting. In the reasoning about actions literature, there are only a few frameworks for modelling probabilistic noise, and even less in dealing with continuous probability distributions. In the first model of its kind, we show how a rich theory of actions with beliefs, meta-beliefs and only knowing can be defined over discrete, continuous and mixed discrete-continuous distributions. © 2023 International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.
KW  - Logic
KW  - Modal Logic
KW  - Probability
KW  - Situation Calculus
KW  - Autonomous agents
KW  - Multi agent systems
KW  - Continuous distribution
KW  - Continuous probability distribution
KW  - Discrete/continuous
KW  - Logic
KW  - Logical language
KW  - Modal logic
KW  - Probabilistics
KW  - Reasoning about actions
KW  - Situation calculus
KW  - Probability distributions
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Zhang, T.
AU  - Xu, D.
AU  - Alfarraj, O.
AU  - Yu, K.
AU  - Guizani, M.
AU  - Rodrigues, J.J.P.C.
TI  - Design of Tiny Contrastive Learning Network With Noise Tolerance for Unauthorized Device Identification in Internet of UAVs
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 12
SP  - 20912
EP  - 20929
DO  - 10.1109/JIOT.2024.3376529
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189156177&doi=10.1109%2fJIOT.2024.3376529&partnerID=40&md5=df115b7eefe1fcbf1bc46afe6563d923
AB  - Artificial intelligence enhanced Internet of unmanned aerial vehicles (UAVs) is a promising network to achieve the complicated vehicular tasks and construct intelligent communication networks. One of the critical tasks is to guarantee a secure network access while achieving tradeoff between accuracy and latency through lightweight deployment on resource-limited and hardware-constrained UAVs. To address this issue, a novel noise-tolerant radio frequency fingerprinting (NT-RFF) based on tiny machine learning (TinyML) scheme is proposed, which amalgamates contrastive learning and data augmentation, aiming to improve the generalization ability of unauthorized device identification (UDI). Particularly, we first exploit the augmentation technique to enhance the legitimate training data sets under the circumstance of varying signal-to-noise ratios, facilitating an enhanced and diversified data sets. Second, a synthesis of contrastive learning and supervised learning is employed to attain comprehensive global learning. We design a new contrastive loss criteria to capture relevant information from the samples collected over the air. Besides, we design a categorical cross-entropy loss criteria by which supervisory information can be leveraged from associated labels. Finally, quantification is utilized to enhance model efficiency and achieve an optimal balance between accuracy and latency within computing and energy resource-limited UAVs. Experimental results demonstrate that the proposed tiny NT-RFF which only contains about 25-30% quantitative parameters can maintain excellent performance and improve the UDI accuracy greatly compared with the traditional machine learning-based RFF schemes. Moreover, the remarkable results showcase that our proposed framework attains a substantial increase in identification accuracy compared to the data augmentation and contrastive learning-based RFF and DASL-RFF methods, exhibiting improvements of 14.16% and 5.17%, respectively.  © 2014 IEEE.
KW  - Contrastive learning
KW  - data augmentation
KW  - tiny machine learning (TinyML)
KW  - unauthorized device identification (UDI)
KW  - unmanned aerial vehicles (UAVs)
KW  - Antennas
KW  - Economic and social effects
KW  - Energy resources
KW  - Job analysis
KW  - Learning systems
KW  - Object recognition
KW  - Personnel training
KW  - Signal to noise ratio
KW  - Aerial vehicle
KW  - Computational modelling
KW  - Contrastive learning
KW  - Data augmentation
KW  - Features extraction
KW  - Machine-learning
KW  - Objects recognition
KW  - Security
KW  - Task analysis
KW  - Tiny machine learning
KW  - Unauthorized device identification
KW  - Unmanned aerial vehicle
KW  - Internet of things
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Islam, A.
AU  - Chang, K.
TI  - Navigating the future of wireless networks: A multidimensional survey on semantic communications
PY  - 2024
T2  - ICT Express
VL  - 10
IS  - 4
SP  - 747
EP  - 773
DO  - 10.1016/j.icte.2024.06.001
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195852475&doi=10.1016%2fj.icte.2024.06.001&partnerID=40&md5=5f7aab564f1b765c03fb8821390d2c53
AB  - This paper offers an in-depth exploration of semantic communications, focusing on its integral role in wireless networks. We dissect its foundational architecture and the key elements that enable seamless AI integration. Our research categorizes semantic communications into various multimedia and task types, evaluating their applicability in both single and multitasking environments. We also investigate resource allocation and goal-oriented strategies, supported by empirical case studies. The paper concludes by spotlighting emerging trends, including AI, IoT, and 5G beyond. It identifies pressing challenges such as standardization, security, and efficiency. Our work provides a holistic understanding of contemporary semantic communications paradigms. © 2024 The Author(s)
KW  - AI
KW  - Knowledge-based systems
KW  - Multimedia Communications
KW  - Semantic communications
KW  - Wireless networks
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Sridhar, K.
AU  - Dutta, S.
AU  - Weimer, J.
AU  - Lee, I.
TI  - Guaranteed Conformance of Neurosymbolic Models to Natural Constraints
PY  - 2023
T2  - Proceedings of Machine Learning Research
VL  - 211
SP  - 76
EP  - 89
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172939541&partnerID=40&md5=49310a8059fe6950d0ee36b6d33f63a3
AB  - Deep neural networks have emerged as the workhorse for a large section of robotics and control applications, especially as models for dynamical systems. Such data-driven models are in turn used for designing and verifying autonomous systems. They are particularly useful in modeling medical systems where data can be leveraged to individualize treatment. In safety-critical applications, it is important that the data-driven model is conformant to established knowledge from the natural sciences. Such knowledge is often available or can often be distilled into a (possibly black-box) model. For instance, an F1 racing car should conform to Newton's laws (which are encoded within a unicycle model). In this light, we consider the following problem - given a model M and a state transition dataset, we wish to best approximate the system model while being a bounded distance away from M. We propose a method to guarantee this conformance. Our first step is to distill the dataset into a few representative samples called memories, using the idea of a growing neural gas. Next, using these memories we partition the state space into disjoint subsets and compute bounds that should be respected by the neural network in each subset. This serves as a symbolic wrapper for guaranteed conformance. We argue theoretically that this only leads to a bounded increase in approximation error; which can be controlled by increasing the number of memories. We experimentally show that on three case studies (Car Model, Drones, and Artificial Pancreas), our constrained neurosymbolic models conform to specified models (each encoding various constraints) with order-of-magnitude improvements compared to the augmented Lagrangian and vanilla training methods. © 2023 I.L.
KW  - Deep neural networks
KW  - medical devices
KW  - prototypes
KW  - robotics
KW  - Artificial organs
KW  - Constrained optimization
KW  - Dynamical systems
KW  - Robotics
KW  - Safety engineering
KW  - Black box modelling
KW  - Control applications
KW  - Data-driven model
KW  - Medical Devices
KW  - Medical systems
KW  - Newton's Laws
KW  - Prototype
KW  - Racing cars
KW  - Robotics applications
KW  - Safety critical applications
KW  - Deep neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Suchan, J.
AU  - Bhatt, M.
AU  - Varadarajan, S.
TI  - Commonsense visual sensemaking for autonomous driving – On generalised neurosymbolic online abduction integrating vision and semantics
PY  - 2021
T2  - Artificial Intelligence
VL  - 299
C7  - 103522
DO  - 10.1016/j.artint.2021.103522
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106549406&doi=10.1016%2fj.artint.2021.103522&partnerID=40&md5=0f712891d2bc5ba875109dfd61ca5e11
AB  - We demonstrate the need and potential of systematically integrated vision and semantics solutions for visual sensemaking in the backdrop of autonomous driving. A general neurosymbolic method for online visual sensemaking using answer set programming (ASP) is systematically formalised and fully implemented. The method integrates state of the art in visual computing, and is developed as a modular framework that is generally usable within hybrid architectures for realtime perception and control. We evaluate and demonstrate with community established benchmarks KITTIMOD, MOT-2017, and MOT-2020. As use-case, we focus on the significance of human-centred visual sensemaking —e.g., involving semantic representation and explainability, question-answering, commonsense interpolation— in safety-critical autonomous driving situations. The developed neurosymbolic framework is domain-independent, with the case of autonomous driving designed to serve as an exemplar for online visual sensemaking in diverse cognitive interaction settings in the backdrop of select human-centred AI technology design considerations. © 2021 The Author(s)
KW  - Answer set programming
KW  - Autonomous driving
KW  - Cognitive vision
KW  - Commonsense reasoning
KW  - Declarative spatial reasoning
KW  - Deep semantics
KW  - Human-centred computing and design
KW  - Knowledge representation and reasoning
KW  - Spatial cognition and AI
KW  - Standardisation in driving technology
KW  - Visual abduction
KW  - Artificial intelligence
KW  - Logic programming
KW  - Safety engineering
KW  - Semantics
KW  - Answer set programming
KW  - Autonomous driving
KW  - Cognitive interaction
KW  - Domain independents
KW  - Hybrid architectures
KW  - Question Answering
KW  - Semantic representation
KW  - Visual sensemaking
KW  - Autonomous vehicles
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 25
ER  -

TY  - CONF
AU  - Lin, B.
TI  - Knowledge Management System with NLP-Assisted Annotations: A Brief Survey and Outlook
PY  - 2022
T2  - CEUR Workshop Proceedings
VL  - 3318
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141396326&partnerID=40&md5=a70e94281ffccc165f58c90b20c66e18
AB  - Knowledge management systems (KMS) are in high demand for industrial researchers, chemical or research enterprises, or evidence-based decision making. However, existing systems have limitations in categorizing and organizing paper insights or relationships. Traditional databases are usually disjoint with logging systems, which limit its utility in generating concise, collated overviews. In this work, we briefly survey existing approaches of this problem space and propose a unified framework that utilizes relational databases to log hierarchical information to facilitate the research and writing process, or generate useful knowledge from references or insights from connected concepts. Our framework of bidirectional knowledge management system (BKMS) enables novel functionalities encompassing improved hierarchical note-taking, AI-assisted brainstorming, and multi-directional relationships. Potential applications include managing inventories and changes for manufacture or research enterprises, or generating analytic reports with evidence-based decision making. © 2022 Copyright for this paper by its authors.
KW  - insight annotation
KW  - knowledge management
KW  - machine learning
KW  - natural language processing
KW  - relational databases
KW  - Decision making
KW  - Industrial research
KW  - Knowledge acquisition
KW  - Machine learning
KW  - Natural language processing systems
KW  - Decisions makings
KW  - Evidence- based decisions
KW  - High demand
KW  - Insight annotation
KW  - Knowledge management system
KW  - Language processing
KW  - Machine-learning
KW  - Natural language processing
KW  - Natural languages
KW  - Relational Database
KW  - Knowledge management
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Sun, X.
AU  - Shoukry, Y.
TI  - Neurosymbolic Motion and Task Planning for Linear Temporal Logic Tasks
PY  - 2024
T2  - IEEE Transactions on Robotics
VL  - 40
SP  - 2749
EP  - 2768
DO  - 10.1109/TRO.2024.3392079
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191301448&doi=10.1109%2fTRO.2024.3392079&partnerID=40&md5=82fc6464d400711ab1e16024600ac11b
AB  - This article presents a neurosymbolic framework to solve motion planning problems for mobile robots involving temporal goals. The temporal goals are described using temporal logic formulas, such as bounded linear temporal logic (LTL) and co-safe LTL to capture complex tasks. The proposed framework trains neural network (NN)-based planners that enjoy strong correctness guarantees when applying to unseen tasks, i.e., the exact task (including workspace, temporal logic formula, and errors in the dynamical models of the robot) is not available during the training of NNs. Our approach to achieving theoretical guarantees and computational efficiency is based on two insights. First, we incorporate a symbolic model into the training of NNs such that the resulting NN-based planner inherits the interpretability and correctness guarantees of the symbolic model. Moreover, the symbolic model serves as a discrete 'memory,' which is necessary for satisfying temporal logic formulas. Second, we train a library of NNs offline and combine a subset of the trained NNs into a single NN-based planner at runtime when a task is revealed. In particular, we develop a novel constrained NN training procedure, named formal NN training, to enforce that each NN in the library represents a 'symbol' in the symbolic model. As a result, our neurosymbolic framework enjoys the scalability and flexibility benefits of machine learning and inherits the provable guarantees from control-theoretic and formal-methods techniques. We demonstrate the effectiveness of our framework in both simulations and on an actual robotic vehicle and show that our framework can generalize to unseen tasks where state-of-the-art meta-reinforcement learning techniques fail.  © 2004-2012 IEEE.
KW  - Formal methods
KW  - meta-reinforcement learning
KW  - neural networks (NNs)
KW  - Computational efficiency
KW  - Computer circuits
KW  - Formal methods
KW  - Job analysis
KW  - Motion planning
KW  - Reinforcement learning
KW  - Robot programming
KW  - Temporal logic
KW  - Computational modelling
KW  - Linear temporal logic
KW  - Meta-reinforcement learning
KW  - Network-based
KW  - Neural-networks
KW  - Reinforcement learnings
KW  - Symbolic modeling
KW  - Task analysis
KW  - Temporal logic formula
KW  - Vehicle's dynamics
KW  - Neural networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Shahbazi, Z.
AU  - Byun, Y.-C.
TI  - Analysis of the Security and Reliability of Cryptocurrency Systems Using Knowledge Discovery and Machine Learning Methods
PY  - 2022
T2  - Sensors
VL  - 22
IS  - 23
C7  - 9083
DO  - 10.3390/s22239083
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143827082&doi=10.3390%2fs22239083&partnerID=40&md5=e1d39d45073f7f948219c6f3cbe3f040
AB  - Cryptocurrency, often known as virtual or digital currency, is a safe platform and a key component of the blockchain that has recently attracted much interest. Utilizing blockchain technology, bitcoin transactions are recorded in blocks that provide detailed information on all financial transactions. Artificial intelligence (AI) has significant applicability in several industries because of the abundance and processing capacity of large data. One of the main issues is the absence of explanations for AI algorithms in the current decision-making standards. For instance, there is no deep-learning-based reasoning or control for the system’s input or output processes. More particularly, the bias for adversarial attacks on the process interface and learning characterizes existing AI systems. This study suggests an AI-based trustworthy architecture that uses decentralized blockchain characteristics such as smart contracts and trust oracles. The decentralized consensuses of AI predictors are also decided by this system using AI, enabling secure cryptocurrency transactions, and utilizing the blockchain technology and transactional network analysis. By utilizing AI for a thorough examination of a network, this system’s primary objective is to improve the performance of the bitcoin network in terms of transactions and security. In comparison to other state-of-the-art systems, the results demonstrate that the proposed system can achieve very accurate output. © 2022 by the authors.
KW  - artificial intelligence
KW  - blockchain
KW  - cryptocurrency
KW  - knowledge discovery
KW  - machine learning
KW  - Artificial Intelligence
KW  - Blockchain
KW  - Knowledge Discovery
KW  - Machine Learning
KW  - Reproducibility of Results
KW  - Bitcoin
KW  - Decision making
KW  - Deep learning
KW  - Learning systems
KW  - Network security
KW  - Reliability analysis
KW  - 'current
KW  - Artificial intelligence algorithms
KW  - Block-chain
KW  - Discovery learning
KW  - Financial transactions
KW  - Large data
KW  - Machine learning methods
KW  - Machine-learning
KW  - Processing capacities
KW  - Security and reliabilities
KW  - artificial intelligence
KW  - knowledge discovery
KW  - machine learning
KW  - reproducibility
KW  - Blockchain
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - JOUR
AU  - Yan, R.
AU  - Julius, A.A.
TI  - Interpretable seizure detection with signal temporal logic neural network
PY  - 2022
T2  - Biomedical Signal Processing and Control
VL  - 78
C7  - 103998
DO  - 10.1016/j.bspc.2022.103998
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134844986&doi=10.1016%2fj.bspc.2022.103998&partnerID=40&md5=7bbb855c7bb7eef97188f3d6c238cc67
AB  - In this work, we develop a novel neuro-symbolic model for automated seizure detection using multi-views of data representation. Firstly, the spectral and line length features are extracted using a multi-view feature extraction technique. Next, a signal temporal logic neural network (STONE) that combines the benefits of neural networks and temporal logics is constructed to classify the seizure and nonseizure data. STONE is designed in such a way that each neuron has a symbolic representation corresponding to a component in a weighted signal temporal logic (wSTL) formula. Compared with traditional STL inference algorithms, STONE is end-to-end differentiable such that the learning can be accomplished through back-propagation. In addition, STONE improves the interpretability of seizure detection models as the outcome of STONE is a wSTL formula that is interpretable and human-readable. Importantly, the wSTL formula reveals the reasoning behind seizure as a description of the evolution of EEG signals. STONE is tested on two popular EEG databases and demonstrated to achieve promising detection performance in terms of accuracy, sensitivity, and specificity when compared with existing state-of-the-art models. Furthermore, STONE can provide a human-readable formula as a description of the seizure characteristics, and the formula is also visualizable for easy interpretation of the classifier, which is a missing property in existing seizure detection methods. © 2022 Elsevier Ltd
KW  - Electroencephalogram (EEG)
KW  - Epileptic seizure detection
KW  - Interpretable machine learning
KW  - Multi-view feature extraction
KW  - Signal temporal logic neural network
KW  - Backpropagation
KW  - Biomedical signal processing
KW  - Computer circuits
KW  - Electroencephalography
KW  - Extraction
KW  - Inference engines
KW  - Neural networks
KW  - Temporal logic
KW  - Electroencephalogram
KW  - Epileptic seizure detection
KW  - Features extraction
KW  - Interpretable machine learning
KW  - Machine-learning
KW  - Multi-view feature extraction
KW  - Multi-views
KW  - Neural-networks
KW  - Seizure-detection
KW  - Signal temporal logic neural network
KW  - Article
KW  - back propagation
KW  - bandwidth
KW  - binary classification
KW  - child
KW  - clinical article
KW  - comparative study
KW  - controlled study
KW  - diagnostic accuracy
KW  - electroencephalogram
KW  - electroencephalography
KW  - empirical mode decomposition
KW  - feature extraction
KW  - female
KW  - Fourier transform
KW  - human
KW  - interrater reliability
KW  - male
KW  - nerve cell network
KW  - pediatric patient
KW  - receiver operating characteristic
KW  - seizure
KW  - semantics
KW  - sensitivity and specificity
KW  - signal temporal logic neural network
KW  - Feature extraction
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Kliestik, T.
AU  - Vochozka, M.
AU  - Vasić, M.
TI  - Btiometric Sensor Technologies, Visual Imagery and Predictive Modeling Tools, and Ambient Sound Recognition Software in the Economic Infrastructure of the Metaverse
PY  - 2022
T2  - Review of Contemporary Philosophy
VL  - 21
SP  - 72
EP  - 88
DO  - 10.22381/RCP2120225
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142239188&doi=10.22381%2fRCP2120225&partnerID=40&md5=1c7eef842be0af4da43bd16b3e66b2e3
AB  - We draw on a substantial body of theoretical and empirical research on metaverse assets and services in interactive virtual environments. In this research, prior findings were cumulated indicating that predictive and retail analytics and data sharing technologies optimize consumer purchase behaviors. We carried out a quantitative literature review of ProQuest, Scopus, and the Web of Science throughout April 2022, with search terms including “the economic infrastructure of the metaverse” + “biometric sensor technologies,” “visual imagery and predictive modeling tools,” and “ambient sound recognition software.” As we analyzed research published in 2021 and 2022, only 141 papers met the eligibility criteria. By removing controversial or unclear findings (scanty/unimportant data), results unsupported by replication, undetailed content, or papers having quite similar titles, we decided on 25, chiefly empirical, sources. Data visualization tools: Dimensions (bibliometric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AMSTAR, Distiller SR, ROBIS, and SRDR. © 2022, Addleton Academic Publishers. All rights reserved.
KW  - ambient sound recognition software
KW  - biometric sensor technologies
KW  - customer predictive analytics
KW  - geolocation data
KW  - immersive technologies
KW  - metaverse commerce
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 18
ER  -

TY  - JOUR
AU  - Issa, M.A.
AU  - Chen, H.
AU  - Wang, J.
AU  - Imani, M.
TI  - CyberRL: Brain-Inspired Reinforcement Learning for Efficient Network Intrusion Detection
PY  - 2025
T2  - IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems
VL  - 44
IS  - 1
SP  - 241
EP  - 250
DO  - 10.1109/TCAD.2024.3418392
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000384637&doi=10.1109%2fTCAD.2024.3418392&partnerID=40&md5=28588f6e8f8eeb6ef046dcada9cf68ae
AB  - Due to the rapidly evolving landscape of cybersecurity, the risks in securing cloud networks and devices are attesting to be an increasingly prevalent research challenge. Reinforcement learning (RL) is a subfield of machine learning that has demonstrated its ability to detect cyberattacks, as well as its potential to recognize new ones. Many of the popular RL algorithms at present rely on deep neural networks, which are computationally very expensive to train. An alternative approach to this class of algorithms is hyperdimensional computing (HDC), which is a robust, computationally efficient learning paradigm that is ideal for powering resource-constrained devices. In this article, we present CyberRL, a HDC algorithm for learning cybersecurity strategies for intrusion detection in an abstract Markov game environment. We demonstrate that CyberRL is advantageous compared to its deep learning equivalent in computational efficiency, reaching up to 1.9 × speedup in training time for multiple devices, including low-powered devices. We also present its enhanced learning quality and superior defense and attack security strategies with up to 12.8 × improvement. We implement our framework on Xilinx Alveo U50 FPGA and achieve approximately 700 × speedup and energy efficiency improvements compared to the CPU execution.  © 1982-2012 IEEE.
KW  - Brain-inspired computing
KW  - cybersecurity
KW  - hyperdimensional computing (HDC)
KW  - intrusion detection
KW  - reinforcement learning (RL)
KW  - Brain
KW  - Computer aided design
KW  - Computer games
KW  - Deep neural networks
KW  - Energy efficiency
KW  - Learning algorithms
KW  - Reinforcement learning
KW  - Risk assessment
KW  - Timing circuits
KW  - Biological neural networks
KW  - Brain-inspired computing
KW  - Computational modelling
KW  - Cyber security
KW  - Design automations
KW  - Hyperdimensional computing
KW  - Intrusion-Detection
KW  - Q-learning
KW  - Reinforcement learnings
KW  - Task analysis
KW  - Computational efficiency
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Jagatheesaperumal, S.K.
AU  - Yang, Z.
AU  - Yang, Q.
AU  - Huang, C.
AU  - Xu, W.
AU  - Shikh-Bahaei, M.
AU  - Zhang, Z.
TI  - Semantic-Aware Digital Twin for Metaverse: A Comprehensive Review
PY  - 2023
T2  - IEEE Wireless Communications
VL  - 30
IS  - 4
SP  - 38
EP  - 46
DO  - 10.1109/MWC.003.2200616
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172684961&doi=10.1109%2fMWC.003.2200616&partnerID=40&md5=37add53aeab61dd000c9b98d8193f912
AB  - To facilitate the deployment of digital twins in Metaverse, the paradigm with semantic awareness has been proposed as a means for enabling accurate and task-oriented information extraction with inherent intelligence. However, this framework requires all devices in the Metaverse environment to be directly linked with the semantic model to enable faithful interpretation of messages. In contrast, this article introduces the digital twin frame-work, considering a smart industrial application, which enables semantic communication in conjugation with the Metaverse enabling technologies. The fundamentals of this framework are demonstrated on an industrial shopfloor management use case with a digital twin so as to improve its performance through semantic communication. An overview of semantic communication, Metaverse, and digital twins is presented. Integration of these technologies with the basic architecture as well as the impact on future industrial applications is also presented. Overall, this article showcases how semantic awareness can be an effective candidate in the implementation of digital twins for Metaverse applications.  © 2002-2012 IEEE.
KW  - Enabling technologies
KW  - Frame-work
KW  - Metaverses
KW  - Performance
KW  - Semantic communication
KW  - Semantic modelling
KW  - Semantic-aware
KW  - Shopfloors
KW  - Task-oriented
KW  - Semantics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 21
ER  -

TY  - JOUR
AU  - Rafiq, M.
AU  - Alshammari, N.S.
AU  - Alhasson, H.F.
AU  - AlHammadi, D.A.
AU  - Alshehri, M.
AU  - Jalal, A.
AU  - Liu, H.
TI  - A Deep Learning Framework for Healthy LifeStyle Monitoring and Outdoor Localization
PY  - 2025
T2  - IEEE Access
C7  - 0b00006493fa34b0
DO  - 10.1109/ACCESS.2025.3573439
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006834044&doi=10.1109%2fACCESS.2025.3573439&partnerID=40&md5=ee11147099b046868bad03b01cc82442
AB  - The green research field of ubiquitous computing has been able to draw and hold academics’ interest for a while. Recognition and localization of human locomotion have also been widely developed as ubiquitous computing applications. Personal safety, behavior analysis, entertainment, and healthcare monitoring all utilize these apps.A key component of several fields, such as robots, sports, healthcare, and security, is human locomotion recognition (HLR). Researchers and engineers have been trying to use the increasing popularity of wearable technology, especially environmental sensors and Inertial Measurement Units (IMUs), to identify and categorize human locomotion activities in an accurate and efficient manner.The capabilities of smartphones and wearable technology have increased due to advancements in sensing technology. Inertial sensors like gyroscopes and accelerometers are now frequently seen in smartphones. These sensors can now be utilized for a wide range of purposes, while their original purpose was to improve gadget features. Using smartphone IMU, ambient, GPS, and audio sensor data from two publicly available benchmark datasets—the Extrasensory dataset and the Domino dataset—this study proposes a sophisticated approach for human locomotion and localization detection. In the preprocessing stage, a Chebyshev Type 2 filter was used for windowing and segmentation, while a Hamming window was applied. Feature extraction was divided into two parts: for actions, the extracted features included Fast Fourier Transform (FFT), State Space Correlation Entropy (SSCE), Maximum Lyapunov Exponent (MLE), and Auto Regression; for localization-based features, Recursive Feature Elimination (RFE), step count, heading angle, and step length were employed. Kernel Fisher Discriminant Analysis was applied for feature optimization, and a deep neural network was utilized for feature classification. The proposed system achieved an overall classification accuracy of 88.4% on the Extrasensory dataset and 86.4% on the Domino dataset, outperforming several existing state-of-the-art methods. These results highlight the effectiveness of the preprocessing pipeline and feature optimization techniques in enhancing recognition and localization performance. The experimental evaluation confirms the robustness of the system across diverse activities and environments, making it suitable for real-world ubiquitous computing applications. © 2013 IEEE.
KW  - GPS sensor
KW  - Human locomotion recognition
KW  - Machine learning
KW  - smart IMU
KW  - smartphone
KW  - smartwatch
KW  - Feature Selection
KW  - Nutrition
KW  - Polynomial regression
KW  - Sports medicine
KW  - Computing applications
KW  - GPS sensor
KW  - Human locomotion recognition
KW  - Human locomotions
KW  - Inertial measurements units
KW  - Localisation
KW  - Machine-learning
KW  - Smart inertial measurement unit
KW  - Smart phones
KW  - Smartwatch
KW  - Ambient intelligence
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Gama, J.
AU  - Ribeiro, R.P.
AU  - Mastelini, S.
AU  - Davari, N.
AU  - Veloso, B.
TI  - From fault detection to anomaly explanation: A case study on predictive maintenance
PY  - 2024
T2  - Journal of Web Semantics
VL  - 81
C7  - 100821
DO  - 10.1016/j.websem.2024.100821
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193543680&doi=10.1016%2fj.websem.2024.100821&partnerID=40&md5=6eaaf243a7eb94034b98fbebaee58970
AB  - Predictive Maintenance applications are increasingly complex, with interactions between many components. Black-box models are popular approaches based on deep-learning techniques due to their predictive accuracy. This paper proposes a neural-symbolic architecture that uses an online rule-learning algorithm to explain when the black-box model predicts failures. The proposed system solves two problems in parallel: (i) anomaly detection and (ii) explanation of the anomaly. For the first problem, we use an unsupervised state-of-the-art autoencoder. For the second problem, we train a rule learning system that learns a mapping from the input features to the autoencoder's reconstruction error. Both systems run online and in parallel. The autoencoder signals an alarm for the examples with a reconstruction error that exceeds a threshold. The causes of the signal alarm are hard for humans to understand because they result from a non-linear combination of sensor data. The rule that triggers that example describes the relationship between the input features and the autoencoder's reconstruction error. The rule explains the failure signal by indicating which sensors contribute to the alarm and allowing the identification of the component involved in the failure. The system can present global explanations for the black box model and local explanations for why the black box model predicts a failure. We evaluate the proposed system in a real-world case study of Metro do Porto and provide explanations that illustrate its benefits. © 2024
KW  - Explainable AI
KW  - Online anomaly detection
KW  - Predictive maintenance
KW  - Alarm systems
KW  - Anomaly detection
KW  - Deep learning
KW  - E-learning
KW  - Errors
KW  - Fault detection
KW  - Learning algorithms
KW  - Maintenance
KW  - Online systems
KW  - Auto encoders
KW  - Black box modelling
KW  - Case-studies
KW  - Explainable AI
KW  - Faults detection
KW  - Input features
KW  - Learning techniques
KW  - Online anomaly detection
KW  - Predictive maintenance
KW  - Reconstruction error
KW  - Learning systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Panpaliya, M.
AU  - Ranjan, N.
AU  - Algude, A.
TI  - A Review based on Overview of Complex Event Processing (CEP) in Various Applications Utilizing Various Tools
PY  - 2024
T2  - 15th International Conference on Advances in Computing, Control, and Telecommunication Technologies, ACT 2024
VL  - 1
SP  - 1450
EP  - 1456
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208816772&partnerID=40&md5=be14bf0f8db31e1b1569913c134e8191
AB  - In the new years, there is a monstrous flood of progressive information attributable to the developing amount of dispersed use of programming tools that consistently creates a huge quantity of information streams. The notable innovation is known as Complex Event Processing (CEP) which can manage enormous measures of information from different sources relying upon the consistency of information to produce a precise outcome to deal with dynamic information continuously. Subsequently, understanding existing CEP techniques and instruments is trying to create a vigorous and compelling CEP framework. Here, in this review paper, we have considered nearly 25-50 research papers related to CEP systems. According to existing research papers, some of the limitations were found by using the CEP engine and tools. To overcome that, we have explained new leading tools compared with existing tools. © Grenze Scientific Society, 2024.
KW  - Complex event processing (CEP)
KW  - hybrid parallelization
KW  - machine learning
KW  - Complex event processing
KW  - Complex events
KW  - Dynamic information
KW  - Event Processing
KW  - Hybrid parallelization
KW  - Information streams
KW  - Machine-learning
KW  - Measures of information
KW  - Programming tools
KW  - Research papers
KW  - Reviews
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Cuțitoi, A.-C.
TI  - Machine Vision Algorithms, Sensory Data Mining Techniques, and Geospatial Mapping Tools in the Blockchain-based Virtual Economy
PY  - 2022
T2  - Review of Contemporary Philosophy
VL  - 21
SP  - 223
EP  - 238
DO  - 10.22381/RCP21202214
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142222071&doi=10.22381%2fRCP21202214&partnerID=40&md5=4d35515e7bf36b2fc6d352fc25be0378
AB  - The present study systematically reviews the existing research on immersive virtual reality experiences in the retail metaverse. My findings indicate that real-time sensor data and machine vision algorithms enhance customer engagement behaviors across virtual marketplaces and immersive interconnected virtual worlds. I contribute to the literature by clarifying that big data analytics, operational modeling tools, customer monitoring systems, and semantic vector search technology shape consumption patterns and buying habits in immersive virtual worlds. Throughout March 2022, a quantitative literature review of the Web of Science, Scopus, and ProQuest databases was performed, with search terms including “the blockchain-based virtual economy” + “machine vision algorithms,” “sensory data mining techniques,” and “geospatial mapping tools.” As research published between 2021 and 2022 was inspected, only 155 articles satisfied the eligibility criteria. By taking out controversial or ambiguous findings (insufficient/irrelevant data), outcomes unsubstantiated by replication, too general material, or studies with nearly identical titles, I selected 27 mainly empirical sources. Data visualization tools: Dimensions (bibliometric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AMSTAR, Dedoose, Distiller SR, and SRDR. © 2022, Addleton Academic Publishers. All rights reserved.
KW  - ambient scene detection tools
KW  - augmented reality shopping tools
KW  - customer behavior analytics
KW  - immersive metaverse experiences
KW  - sensory data mining techniques
KW  - visual analytics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 11
ER  -

TY  - JOUR
AU  - McIntosh, T.R.
AU  - Susnjak, T.
AU  - Liu, T.
AU  - Watters, P.
AU  - Xu, D.
AU  - Liu, D.
AU  - Nowrozy, R.
AU  - Halgamuge, M.N.
TI  - From COBIT to ISO 42001: Evaluating cybersecurity frameworks for opportunities, risks, and regulatory compliance in commercializing large language models
PY  - 2024
T2  - Computers and Security
VL  - 144
C7  - 103964
DO  - 10.1016/j.cose.2024.103964
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197935196&doi=10.1016%2fj.cose.2024.103964&partnerID=40&md5=26f04eb3f8012468586c4df44a04d4df
AB  - This study investigated the integration readiness of four predominant cybersecurity Governance, Risk and Compliance (GRC) frameworks – NIST CSF 2.0, COBIT 2019, ISO 27001:2022, and the latest ISO 42001:2023 – for the opportunities, risks, and regulatory compliance when adopting Large Language Models (LLMs), using qualitative content analysis and expert validation. Our analysis, with both LLMs and human experts in the loop, uncovered potential for LLM integration together with inadequacies in LLM risk oversight of those frameworks. Comparative gap analysis has highlighted that the new ISO 42001:2023, specifically designed for Artificial Intelligence (AI) management systems, provided most comprehensive facilitation for LLM opportunities, whereas COBIT 2019 aligned most closely with the European Union AI Act. Nonetheless, our findings suggested that all evaluated frameworks would benefit from enhancements to more effectively and more comprehensively address the multifaceted risks associated with LLMs, indicating a critical and time-sensitive need for their continuous evolution. We propose integrating human-expert-in-the-loop validation processes as crucial for enhancing cybersecurity frameworks to support secure and compliant LLM integration, and discuss implications for the continuous evolution of cybersecurity GRC frameworks to support the secure integration of LLMs. © 2024 The Author(s)
KW  - AI governance
KW  - Cyber resilience
KW  - Cybersecurity frameworks
KW  - Information security
KW  - Large language models
KW  - Risk management
KW  - Computational linguistics
KW  - Integration
KW  - Regulatory compliance
KW  - Risk assessment
KW  - Risk management
KW  - Artificial intelligence governance
KW  - Cybe resilience
KW  - Cyber security
KW  - Cybersecurity framework
KW  - Governance risks
KW  - Human expert
KW  - Language model
KW  - Large language model
KW  - Risk and Compliance Framework
KW  - Risks management
KW  - Cybersecurity
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 16
ER  -

TY  - CONF
AU  - Tahat, A.
AU  - Hardin, D.
AU  - Petz, A.
AU  - Alexander, P.
TI  - Proof Repair Utilizing Large Language Models: A Case Study on the Copland Remote Attestation Proofbase
PY  - 2025
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 
VL  - 15217 LNCS
SP  - 145
EP  - 166
DO  - 10.1007/978-3-031-75434-0_10
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215782629&doi=10.1007%2f978-3-031-75434-0_10&partnerID=40&md5=4037ae8024bd845d612a1ee1745965c0
AB  - Large Language Model (LLM) Artificial Intelligence (AI) systems have generated significant enthusiasm in the computer science research community for their potential in various computer language processing tasks, such as source code generation and source-to-source translation. We are particularly interested in using LLMs for automated theorem proving, specifically for proof repair. To this end, we introduce CoqDog Copilot, which leverages the neuro-symbolic interplay between generative AI and the Coq theorem prover to form a productive “generate-and-test” loop, incrementally improving proofs based on failure information and human hints until valid proofs are achieved. Our research introduces innovative solutions to critical challenges in developing CoqDog Copilot, including addressing context limitations, enhancing the soundness of recommendation systems, defining effective metrics for measuring proof repair progress, and designing a statistically robust evaluation system for conversational quality assessment. We present a comprehensive evaluation of CoqDog Copilot’s performance in proof repair across multiple samples from the Copland Coq proofbase, which consists of a total of 21,000 lines of Coq code. We have attained in excess of 60% accuracy for proof generation using GPT-4 in one ‘shot’, with approximately 30% more lemmas proved given one additional user prompt (yielding 90% correctness overall). With three ‘shots’, the overall proof correctness rate increases to 97%. We can generate Coq proofs with up to 50 proof steps using this technique. Our LLM-generated proofbase currently consists of over 1,400 lines of Copland Coq source. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
KW  - Computer aided language translation
KW  - Computer systems programming
KW  - Theorem proving
KW  - Artificial intelligence systems
KW  - Automated theorem proving
KW  - Case-studies
KW  - Computer science research
KW  - Language model
KW  - Language processing
KW  - Remote attestation
KW  - Research communities
KW  - Source code generation
KW  - Source-to-source translations
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Xia, K.
AU  - Saidy, C.
AU  - Kirkpatrick, M.
AU  - Anumbe, N.
AU  - Sheth, A.
AU  - Harik, R.
TI  - Towards semantic integration of machine vision systems to aid manufacturing event understanding
PY  - 2021
T2  - Sensors
VL  - 21
IS  - 13
C7  - 4276
DO  - 10.3390/s21134276
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108208029&doi=10.3390%2fs21134276&partnerID=40&md5=71c60ab9650a548029c32d635a0722cd
AB  - A manufacturing paradigm shift from conventional control pyramids to decentralized, service-oriented, and cyber-physical systems (CPSs) is taking place in today’s 4th industrial revolution. Generally accepted roles and implementation recipes of cyber systems are expected to be standardized in the future of manufacturing industry. The authors intend to develop a novel CPS-enabled control architecture that accommodates: (1) intelligent information systems involving domain knowledge, empirical model, and simulation; (2) fast and secured industrial communication networks; (3) cognitive automation by rapid signal analytics and machine learning (ML) based feature extraction; (4) interoperability between machine and human. Semantic integration of process indicators is fundamental to the success of such implementation. This work proposes an automated semantic integration of data-intensive process signals that is deployable to industrial signal-based control loops. The proposed system rapidly infers manufacturing events from image-based data feeds, and hence triggers process control signals. Two image inference approaches are implemented: cloud-based ML model query and edge-end object shape detection. Depending on use cases and task requirements, these two approaches can be designated with different event detection tasks to provide a comprehensive system self-awareness. Coupled with conventional industrial sensor signals, machine vision system can rapidly understand manufacturing scenes, and feed extracted semantic information to a manufacturing ontology developed by either expert or ML-enabled cyber systems. Moreover, extracted signals are interpreted by Programmable Logical Controllers (PLCs) and field devices for cognitive automation towards fully autonomous industrial systems. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.
KW  - Cognitive automation
KW  - Computer vision
KW  - Cyber-physical systems
KW  - Semantic segmentation
KW  - Computer Simulation
KW  - Humans
KW  - Machine Learning
KW  - Semantics
KW  - Automation
KW  - Cognitive systems
KW  - Computer vision
KW  - Control systems
KW  - Electronic data interchange
KW  - Embedded systems
KW  - Integration
KW  - Interoperability
KW  - Machinery
KW  - Object detection
KW  - Semantics
KW  - Cyber physical systems (CPSs)
KW  - Industrial communication networks
KW  - Industrial revolutions
KW  - Intelligent information systems
KW  - Manufacturing industries
KW  - Manufacturing ontology
KW  - Manufacturing paradigm
KW  - Programmable logical controller
KW  - computer simulation
KW  - human
KW  - machine learning
KW  - semantics
KW  - Process control
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 20
ER  -

TY  - CONF
AU  - Liu, L.
AU  - Zhang, C.
AU  - He, W.
AU  - Wang, H.
AU  - Zhang, Y.
AU  - Li, H.
TI  - Transformer Anomaly Detection Using Deep Belief Network with Dynamic Adaptive Knowledge Transfer and Interval Type-2 Fuzzy Set for Uncertain Parameters
PY  - 2024
T2  - 2024 IEEE International Conference on DC Technologies and Systems, DCTS 2024
SP  - 189
EP  - 194
DO  - 10.1109/DCTS62535.2024.10939995
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003097939&doi=10.1109%2fDCTS62535.2024.10939995&partnerID=40&md5=9fd1147e1d1ec549f15824ca3d81c034
AB  - Power transformers are key and expensive components in power systems. Precise evaluation of the transformer state is critically essential. This article presents a transformer fault diagnosis technique utilizing a deep belief network (DBN) enhanced with dynamic adaptive knowledge transfer (DAKT) and interval type 2 uncertain parameter fuzzy set (IT2F) structure. Firstly, in accordance with the compaction aspects of chaotic phase space and the Lyapunov index in chaos theory as quantitative judgment, the optimal analysis data selection method is obtained, which reduces invalid data and improves calculation accuracy. Subsequently, a neuro-symbolic framework is introduced to elucidate the operational dynamics of the profound architecture, and a novel sparse deep belief network leveraging adaptive knowledge transition is constructed utilizing the knowledge integration technique of rule amalgamation and elimination. This network possesses a more sparse topology and superior learning efficacy. Secondly, a new enhanced deep learning algorithm-interval type 2 uncertain parameter fuzzy set is introduced the parameters and offsets of the deep belief network, which can better handle the uncertainty between the input data and model parameters. Strengthen the robustness and generalization capability of the model. Comparative analysis with shallow machine learning methods and deep learning methods shows that the average recognition rate of the proposed DAKT-IT2F-DBN method is 97.43%, with good robustness and performance exceeding other fault diagnosis methods. © 2024 IEEE.
KW  - Interval type 2 uncertain parameter fuzzy set
KW  - knowledge transfer
KW  - Sparse deep belief network
KW  - Transformer diagnosis
KW  - Chaos theory
KW  - Deep learning
KW  - Distribution transformers
KW  - Fuzzy set theory
KW  - Fuzzy sets
KW  - Anomaly detection
KW  - Deep belief networks
KW  - Dynamic-adaptive
KW  - Interval type 2 uncertain parameter fuzzy set
KW  - Interval type-2 fuzzy sets
KW  - Knowledge transfer
KW  - Power
KW  - Sparse deep belief network
KW  - Transformer diagnosis
KW  - Uncertain parameters
KW  - Phase space methods
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Hua, H.
AU  - Li, D.
AU  - Li, R.
AU  - Zhang, P.
AU  - Renz, J.
AU  - Cohn, A.
TI  - Towards Explainable Action Recognition by Salient Qualitative Spatial Object Relation Chains
PY  - 2022
T2  - Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022
VL  - 36
SP  - 5710
EP  - 5718
DO  - 10.1609/aaai.v36i5.20513
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147546910&doi=10.1609%2faaai.v36i5.20513&partnerID=40&md5=2c609693bf80de010db207d83b4576b6
AB  - In order to be trusted by humans, Artificial Intelligence agents should be able to describe rationales behind their decisions. One such application is human action recognition in critical or sensitive scenarios, where trustworthy and explainable action recognizers are expected. For example, reliable pedestrian action recognition is essential for self-driving cars and explanations for real-time decision making are critical for investigations if an accident happens. In this regard, learning-based approaches, despite their popularity and accuracy, are disadvantageous due to their limited interpretability. This paper presents a novel neuro-symbolic approach that recognizes actions from videos with human-understandable explanations. Specifically, we first propose to represent videos symbolically by qualitative spatial relations between objects called qualitative spatial object relation chains. We further develop a neural saliency estimator to capture the correlation between such object relation chains and the occurrence of actions. Given an unseen video, this neural saliency estimator is able to tell which object relation chains are more important for the action recognized. We evaluate our approach on two real-life video datasets, with respect to recognition accuracy and the quality of generated action explanations. Experiments show that our approach achieves superior performance on both aspects to previous symbolic approaches, thus facilitating trustworthy intelligent decision making. Our approach can be used to augment state-of-the-art learning approaches with explainability. © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.
KW  - Artificial intelligence
KW  - Action recognition
KW  - Artificial intelligence agent
KW  - Human-action recognition
KW  - Interpretability
KW  - Learning-based approach
KW  - Object-relations
KW  - Real time decision-making
KW  - Real-time decision making
KW  - Spatial objects
KW  - Spatial relations
KW  - Decision making
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Huk, M.
TI  - Billiards-Based Generation of Multi-task, Dense Subitizing Detection Diagrams
PY  - 2025
T2  - Lecture Notes in Computer Science
VL  - 15684 LNAI
SP  - 18
EP  - 31
DO  - 10.1007/978-981-96-6005-6_2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004254417&doi=10.1007%2f978-981-96-6005-6_2&partnerID=40&md5=4a6608153aaf01e86036b56d8c00fc6b
AB  - In this paper, a method to efficiently generate multi-task, dense subitizing detection diagrams is proposed. It is inspired by the billiards game and implemented with use of intentionally simplified two-dimensional physics simulation. The observed advantage of proposed Billiards Subitizing Diagrams Generation (BSDG) over greedy search and two variants of simulated annealing suggests that it can serve as a search method useful in solving many problems which can be related with billiards and other similar games. Proposed solution can be further improved by the use of computation parallelization and possibly by relating it to theoretical foundations of the circle packaging problem. But even in its current form, BSDG can be used to generate valuable, large data sets of images dedicated to the analysis of the subitizing effect in machine learning models. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.
KW  - billiards simulation
KW  - data generation
KW  - machine learning
KW  - search algorithm
KW  - Subitizing effect
KW  - Learning algorithms
KW  - Mapping
KW  - Multi-task learning
KW  - Billiard simulation
KW  - Data generation
KW  - Greedy search
KW  - Machine-learning
KW  - Multi tasks
KW  - Physics simulation
KW  - Search Algorithms
KW  - Search method
KW  - Subitizing effect
KW  - Two-dimensional
KW  - Simulated annealing
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Zhang, H.
AU  - Zhang, Y.
AU  - Wang, Z.
AU  - Zhang, S.
AU  - Li, H.
AU  - Chen, M.
TI  - A novel knowledge-driven flexible human–robot hybrid disassembly line and its key technologies for electric vehicle batteries
PY  - 2023
T2  - Journal of Manufacturing Systems
VL  - 68
SP  - 338
EP  - 353
DO  - 10.1016/j.jmsy.2023.04.005
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162904156&doi=10.1016%2fj.jmsy.2023.04.005&partnerID=40&md5=840bbc1012ddc6bbfc65ca0fd08e878f
AB  - Based on the unique problems and challenges in the disassembly scenario of waste electric vehicle batteries (EVBs), we propose a knowledge-driven flexible human–robot hybrid disassembly line. The disassembly line can not only split the EVB disassembling tasks layer by layer to the primitive-level subtasks based on knowledge but also intelligently generate the optimal disassembling primitive sequence to complete the disassembling task. To further elaborate on the key technologies of the above-mentioned disassembly line, we focus on the implementation of the high-accuracy screw disassembly and disassembly planning system based on NeuroSymbolic. Implementation of the high-accuracy screw disassembly is realized by a new design of the disassembly actuator, high-accuracy screw position and pose estimation based on visual perception, and robust insertion based on force perception. The disassembly planning system is constructed by defining disassembly primitives and introducing neural predicates which can take the sensor data as input and output the symbolic states. Experiments show that our system can effectively solve the screw disassembling task in complex disassembly scenarios. © 2023 The Society of Manufacturing Engineers
KW  - Disassembling task planning
KW  - Electric vehicle battery
KW  - Multimodal perception
KW  - NeuroSymbolic
KW  - Position and pose estimation
KW  - Electric lines
KW  - Hybrid vehicles
KW  - Screws
KW  - Solid wastes
KW  - Disassembling task planning
KW  - Disassembly line
KW  - Electric vehicle batteries
KW  - High-accuracy
KW  - Human robots
KW  - Multimodal perception
KW  - Neurosymbolic
KW  - Position and pose estimation
KW  - Robot hybrid
KW  - Task planning
KW  - Secondary batteries
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 24
ER  -

TY  - JOUR
AU  - Xiang, W.
AU  - Yu, K.
AU  - Han, F.
AU  - Fang, L.
AU  - He, D.
AU  - Han, Q.-L.
TI  - Advanced Manufacturing in Industry 5.0: A Survey of Key Enabling Technologies and Future Trends
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 2
SP  - 1055
EP  - 1068
DO  - 10.1109/TII.2023.3274224
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159844255&doi=10.1109%2fTII.2023.3274224&partnerID=40&md5=3e7543d7417724fb1f9e48bc8ca3d986
AB  - A revolution in advanced manufacturing has been driven by digital technology in the fourth industrial revolution, also known as Industry 4.0, and has resulted in a substantial increase in profits for the industry. In a new paradigm of Industry 5.0, advanced manufacturing will step further and be capable of offering customized products and a better user experience. A number of key enabling technologies are expected to play crucial roles in assisting Industry 5.0 in meeting higher demands of data acquisition and processing, communications, and collaborative robots in the advanced manufacturing process. The aim of this survey is to provide novel insights into advanced manufacturing in Industry 5.0 by summarizing the latest progress of key enabling technologies, such as artificial intelligence of things (AIoT), beyond 5G communications, and collaborative robotics. Finally, key directions for future research to enable this vision to become a reality, such as the industrial metaverse, are outlined.  © 2005-2012 IEEE.
KW  - Advanced manufacturing
KW  - artificial intelligence of things (AIoT)
KW  - beyond 5G communications
KW  - collaborative robots (CoBots)
KW  - digital twin
KW  - industrial metaverse
KW  - Industry 5.0
KW  - 5G mobile communication systems
KW  - Collaborative robots
KW  - Data acquisition
KW  - Industrial research
KW  - Industry 4.0
KW  - Advanced manufacturing
KW  - Artificial intelligence of thing
KW  - Beyond 5g communication
KW  - Digital technologies
KW  - Enabling technologies
KW  - Future trends
KW  - Industrial metaverse
KW  - Industry 5.0
KW  - Metaverses
KW  - Technology trends
KW  - Data handling
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 109
ER  -

TY  - CHAP
AU  - Angelell, L.A.
TI  - The AI Plan-ning Engine
PY  - 2024
T2  - The Encyclopedia of COVID: Volumes 1-18
VL  - 1-18
SP  - 4605
EP  - 4695
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216631858&partnerID=40&md5=95749a87171d354aba156271f9432221
AB  - Chapter 4 explains how military planning techniques and AI technologies improve unified action plan-ning using a complex system-of-systems (SoS) to rapidly, faster than real time: (1) Understand the operational environment; (2) Define the problem(s); (3) Visualize the end state (ends); and (4) Intervene with optimal operational approaches (ways and means) to achieve individual and unified mission end states. As the virus is the enemy, it makes sense to employ the best military methodologies to defeat it. Here, we focus on the integration of Modelling Simulation Analytics Looping (MSAL), cloud computing, data fabrics, and Artificial Intelligence (AI) technologies into an AI Pandemic Prevention and Response Plan-ning Engine (PPRPE) platform. This platform enables the modelling and simulation (M&S)1 of complex SoS in multi-domain operating (MDO) environments. The platform will use an Operational Design framework to help decisionmakers understand Situational Awareness2 within and across diverse Operating Environments (OE). The Operational Design framework will apply (1) data-fabric technology to collect multisource data; (2) natural language processing (NLP) to automatically extract entities and their mentioned relationships; (3) Analytic methods to model SoS entities, such as socioeconomics, socio-politics, food supply chains (SC), social well-being, etc.) involved in a crisis like COVID-19; and (4) Ingest the data into a knowledge management system (KMS). The KMS information will be graphically depicted in a User Defined Operational Picture (UDOP) that represents the real-world, in our case, the pandemic prevention and response environment. In the Model Analysis Looping (MAL) process, the mission environment is translated into Static, Dynamic, and Behavioral Models (in military parlance, the mission models) as a set of interconnected graphical paths, capabilities, and behaviors that describe relationships between systems of the mission environment under test. AI agents and multi-agent orchestrators will be trained on Operational Art capabilities. During operation design and joint planning, the AI agents and multi-agent orchestrators will augment decisionmakers abilities to define the mission goals and generate the supporting operation plans (OPLAN) and operation orders (OPORD), defining mission threads3 that represent a sequence of nodes and actions, given a set of decisive conditions to achieve mission objectives. Of course, all of these features will be applied to human collaboration to optimize coordinated pandemic prevention and (if not prevented) response. As will be described, the decisionmakers and AI agents will collaborate through Simulation-Analysis-Loop (SAL) scenarios to test each likely course of action (COA) across multiple domains in a dynamic wargaming4 environment. The SAL wargaming environment will use goal-based action-and-to reward AI agents to execute tasks following along mission threads in which simulation forecasts probability of success, sensitivity and uncertainty. Through SAL, decision-makers can understand the impact of local as well as macro uncertainty, risks and performance, and they can weigh and then make trade-offs to derive optimal COAs that achieve mission goals. AI planners will optimize the selected COA across authorized budgets and resources to create a unified action plan. The AI PPRPE platform will be used to assess the execution of the unified action plan by participants in different phases and time across multiple OEs. This information will be feedback to the AI agents and decisionmakers enabling them to continuously update their COAs, reduce uncertainty, and improve probability of success in achieving their intended pandemic prevention and response goals. © 2024 by Nova Science Publishers, Inc.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Rahman, M.A.
TI  - A Survey on Security and Privacy of Multimodal LLMs - Connected Healthcare Perspective
PY  - 2023
T2  - 2023 IEEE Globecom Workshops, GC Wkshps 2023
SP  - 1807
EP  - 1812
DO  - 10.1109/GCWkshps58843.2023.10465035
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190065892&doi=10.1109%2fGCWkshps58843.2023.10465035&partnerID=40&md5=5fc4e906fbb27c2b581fd5b5dc34d3c3
AB  - Recently, large language and vision language models have shown tremendous success and industry acceptance for healthcare applications. While the firstgeneration models mostly showed advancement in language models, the second generation now offers multi-modal inputs such as audio, image/video, sensory data, and depth, which makes these more suitable toward healthcare applications. However, security and privacy of these multimodal large AI models is largely ignored due to lack of regulatory and compliance applied on these AI models. The healthcare industry requires robust security and privacy of AI models, privacypreserving, and regulation-compliant large language models as it is applied on end users. In this paper, we survey different multimodal large language models and their security and privacy concerns that need to be addressed before these language models can be democratized and accepted by the medical industry. The survey covers different security and privacy threats and vulnerabilities that have been raised by researchers and government bodies and defensive actions such as federated learning, differential privacy, and monitoring LLM processes that have been suggested as remedial actions.  © 2023 IEEE.
KW  - AI
KW  - Deep Learning
KW  - Internet of Medical Things
KW  - Computational linguistics
KW  - Health care
KW  - Regulatory compliance
KW  - Audio images
KW  - Connected healthcares
KW  - Deep learning
KW  - Health care application
KW  - Internet of medical thing
KW  - Language model
KW  - Multi-modal
KW  - Second generation
KW  - Security and privacy
KW  - Sensory data
KW  - Deep learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 11
ER  -

TY  - JOUR
AU  - Xu, X.
AU  - Lai, Y.
AU  - Zhang, X.
AU  - Dong, X.
TI  - Abnormal Logical Representation Learning for Intrusion Detection in Industrial Control Systems
PY  - 2024
T2  - IEEE Transactions on Industrial Informatics
VL  - 20
IS  - 8
SP  - 10624
EP  - 10635
DO  - 10.1109/TII.2024.3396348
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193294660&doi=10.1109%2fTII.2024.3396348&partnerID=40&md5=5a3f3360b952131b18ce6a2b334d32b1
AB  - As security threats to industrial control systems become more prevalent, it is imperative to deploy effective intrusion-detection systems. However, the existing methods are insufficient for addressing contemporary attacks. Rule-based methods are heavily dependent on manual settings, and the covertness of attacks poses challenges to rule effectiveness. Machine and deep learning methods exhibit low interpretability owing to their complex designs, and the semantic gap between the model and the actual operational interpretation limits their applicability. To mitigate these shortcomings, we propose an abnormal logical representation learning (ALRL) intrusion detection method for industrial control systems. ALRL contains a specific lightweight neural network and employs knowledge distillation to achieve high classification ability. More importantly, it can generate effective and concise intrusion detection rules directly from the learned knowledge of the model. The hierarchical model structure and residual connections ensure high interpretability of the rules. Experiments conducted on two publicly available industrial control datasets demonstrate that ALRL can classify attacks with an excellent performance. In addition, the logical rules generated by ALRL can effectively detect all types of attacks and exhibit good interpretability.  © 2005-2012 IEEE.
KW  - Control logic
KW  - industrial control system (ICS)
KW  - intrusion detection
KW  - model interpretability
KW  - rule generation
KW  - Classification (of information)
KW  - Computation theory
KW  - Deep learning
KW  - Distillation
KW  - Feature extraction
KW  - Hierarchical systems
KW  - Neural networks
KW  - Semantics
KW  - Signal encoding
KW  - Computational modelling
KW  - Control logic
KW  - Encodings
KW  - Features extraction
KW  - Industrial control system
KW  - Industrial control systems
KW  - Interpretability
KW  - Intrusion-Detection
KW  - Model interpretability
KW  - Neural-networks
KW  - Representation learning
KW  - Rule generation
KW  - Intrusion detection
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Zafeiropoulos, N.
AU  - Bitilis, P.
AU  - Tsekouras, G.E.
AU  - Kotis, K.
TI  - Evaluating Ontology-Based PD Monitoring and Alerting in Personal Health Knowledge Graphs and Graph Neural Networks
PY  - 2024
T2  - Information (Switzerland)
VL  - 15
IS  - 2
C7  - 100
DO  - 10.3390/info15020100
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185540883&doi=10.3390%2finfo15020100&partnerID=40&md5=6bbc38242e9eb0568772e4f4e2069a94
AB  - In the realm of Parkinson’s Disease (PD) research, the integration of wearable sensor data with personal health records (PHR) has emerged as a pivotal avenue for patient alerting and monitoring. This study delves into the complex domain of PD patient care, with a specific emphasis on harnessing the potential of wearable sensors to capture, represent and semantically analyze crucial movement data and knowledge. The primary objective is to enhance the assessment of PD patients by establishing a robust foundation for personalized health insights through the development of Personal Health Knowledge Graphs (PHKGs) and the employment of personal health Graph Neural Networks (PHGNNs) that utilize PHKGs. The objective is to formalize the representation of related integrated data, unified sensor and PHR data in higher levels of abstraction, i.e., in a PHKG, to facilitate interoperability and support rule-based high-level event recognition such as patient’s missing dose or falling. This paper, extending our previous related work, presents the Wear4PDmove ontology in detail and evaluates the ontology within the development of an experimental PHKG. Furthermore, this paper focuses on the integration and evaluation of PHKG within the implementation of a Graph Neural Network (GNN). This work emphasizes the importance of integrating PD-related data for monitoring and alerting patients with appropriate notifications. These notifications offer health experts precise and timely information for the continuous evaluation of personal health-related events, ultimately contributing to enhanced patient care and well-informed medical decision-making. Finally, the paper concludes by proposing a novel approach for integrating personal health KGs and GNNs for PD monitoring and alerting solutions. © 2024 by the authors.
KW  - Graph Neural Networks
KW  - knowledge graphs
KW  - ontology
KW  - Parkinson’s Disease
KW  - Decision making
KW  - Graph neural networks
KW  - Knowledge graph
KW  - Ontology
KW  - Petroleum reservoir evaluation
KW  - Wearable sensors
KW  - Disease monitoring
KW  - Disease research
KW  - Graph neural networks
KW  - Knowledge graphs
KW  - Ontology's
KW  - Ontology-based
KW  - Parkinson’s disease
KW  - Patient care
KW  - Personal health
KW  - Personal health record
KW  - Data integration
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Sanyal, S.
AU  - Manna, R.K.
AU  - Roy, K.
TI  - EV-Planner: Energy-Efficient Robot Navigation via Event-Based Physics-Guided Neuromorphic Planner
PY  - 2024
T2  - IEEE Robotics and Automation Letters
VL  - 9
IS  - 3
SP  - 2080
EP  - 2087
DO  - 10.1109/LRA.2024.3350982
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182364962&doi=10.1109%2fLRA.2024.3350982&partnerID=40&md5=6931d89542d4f355be0e850e0ae1e114
AB  - Vision-based object tracking is an essential precursor to performing autonomous aerial navigation in order to avoid obstacles. Biologically inspired neuromorphic event cameras are emerging as a powerful alternative to frame-based cameras, due to their ability to asynchronously detect varying intensities (even in poor lighting conditions), high dynamic range, and robustness to motion blur. Spiking neural networks (SNNs) have gained traction for processing events asynchronously in an energy-efficient manner. On the other hand, physics-based artificial intelligence (AI) has gained prominence recently, as they enable embedding system knowledge via physical modeling inside traditional analog neural networks (ANNs). In this letter, we present an event-based physics-guided neuromorphic planner (EV-Planner) to perform obstacle avoidance using neuromorphic event cameras and physics-based AI. We consider the task of autonomous drone navigation where the mission is to detect moving gates and fly through them while avoiding a collision. We use event cameras to perform object detection using a shallow spiking neural network in an unsupervised fashion. Utilizing the physical equations of the brushless DC motors present in the drone rotors, we train a lightweight energy-aware physics-guided neural network (PgNN) with depth inputs. This predicts the optimal flight time responsible for generating near-minimum energy paths. We spawn the drone in the Gazebo simulator and implement a sensor-fused vision-to-planning neuro-symbolic framework using Robot Operating System (ROS). Simulation results for safe collision-free flight trajectories are presented with performance analysis, ablation study and potential future research directions.  © 2016 IEEE.
KW  - Event cameras
KW  - neuromorphic vision
KW  - physics-based AI
KW  - spiking neural networks
KW  - vision-based navigation
KW  - Air navigation
KW  - Aircraft detection
KW  - Antennas
KW  - Brushless DC motors
KW  - Energy efficiency
KW  - Fault tolerance
KW  - Flight simulators
KW  - Motion planning
KW  - Neural networks
KW  - Object detection
KW  - Robot Operating System
KW  - Robot programming
KW  - Robot vision
KW  - Unmanned aerial vehicles (UAV)
KW  - Visual servoing
KW  - Biological neural networks
KW  - Event camera
KW  - Neural-networks
KW  - Neuromorphic
KW  - Neuromorphic visions
KW  - Physic-based artificial intelligence
KW  - Physics-based
KW  - Robot vision systems
KW  - Spiking neural network
KW  - Vision based navigation
KW  - Cameras
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Zhu, S.
AU  - Zhang, Y.
TI  - Probabilistic Access Policies with Automated Reasoning Support
PY  - 2024
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14683 LNCS
SP  - 443
EP  - 466
DO  - 10.1007/978-3-031-65633-0_20
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200786970&doi=10.1007%2f978-3-031-65633-0_20&partnerID=40&md5=f1bb9f2d20ad79ae58c640575e9e83a8
AB  - Existing access policy languages like Cedar equipped with SMT-based automated reasoning capabilities are effective in providing formal guarantees about the policies. However, this scheme only supports access control based on deterministic information. Observing that certain information useful for access control can be described by random variables, we are motivated to develop a new paradigm of access control in which access policies contain rules about uncertainty, or more precisely, probabilities of random events. To compute these probabilities, we rely on probabilistic programming languages. Additionally, we show that the probabilistic part of these policies can be encoded in linear real arithmetic, which enables practical automated reasoning tasks such as proving relative permissiveness between policies. We demonstrate the advantages of the proposed probabilistic policies over the existing paradigm through two case studies on real-world datasets with a prototype implementation. © The Author(s) 2024.
KW  - access control
KW  - access policy
KW  - automated reasoning
KW  - domain-specific language
KW  - probability theory
KW  - SMT
KW  - uncertainty
KW  - Automation
KW  - Problem oriented languages
KW  - Access policies
KW  - Automated reasoning
KW  - Deterministics
KW  - Domains specific languages
KW  - Policy language
KW  - Probabilistic programming language
KW  - Probabilistics
KW  - Probability theory
KW  - Reasoning capabilities
KW  - Uncertainty
KW  - Access control
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Qiu, J.
AU  - Jiang, Y.
AU  - Miao, Y.
AU  - Luo, W.
AU  - Pan, L.
AU  - Zheng, X.
TI  - A survey of coverage-guided greybox fuzzing with deep neural models
PY  - 2025
T2  - Information and Software Technology
VL  - 186
C7  - 107797
DO  - 10.1016/j.infsof.2025.107797
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007513204&doi=10.1016%2fj.infsof.2025.107797&partnerID=40&md5=7c6453fc99c4cdc60bc75691e7649d06
AB  - Coverage-guided greybox fuzzing (CGF) has emerged as a powerful technique for software vulnerability detection, yet traditional techniques often struggle with the increasing complexity of modern software systems and the vastness of input spaces. Deep neural networks (DNNs) have begun to fundamentally transform CGF by addressing these limitations through automated feature extraction, adaptive input generation, and intelligent path prioritization. However, despite these advancements, critical gaps persist in understanding the state-of-the-art landscape. Existing studies often lack rigorous benchmarks to evaluate scalability and generalizability, fail to address the interpretability of neural-guided decisions, and overlook the integration of emerging paradigms such as large language models (LLMs) and neurosymbolic reasoning. This survey systematically bridges these gaps by providing a comprehensive taxonomy of DNN-driven CGF techniques, analyzing their strengths and limitations across key fuzzing stages—seed generation, selection, and mutation. We find that although DNNs have significantly improved fuzzing efficiency, challenges such as semantically invalid seeds, high computational overhead, and limited cross-domain adaptability remain unresolved. Most importantly, we identify two transformative directions with the potential to redefine CGF: (1) LLM-powered fuzzing, which combines generative AI with domain-specific fine-tuning to produce context-aware inputs; and (2) neurosymbolic integration, which merges the precision of symbolic execution with the scalability of neural networks to tackle path explosion. By synthesizing these insights, this survey not only clarifies the state-of-the-art but also outlines a roadmap for developing robust, explainable, and widely applicable intelligent fuzzers. The future of CGF lies in hybrid models that integrate data-driven learning with formal methods, paving the way for autonomous vulnerability discovery in an era of increasingly complex software systems. © 2025 The Authors
KW  - Code coverage
KW  - Deep learning
KW  - Greybox fuzzing
KW  - Large language models
KW  - Software vulnerability
KW  - Computer software selection and evaluation
KW  - Formal specification
KW  - Code coverage
KW  - Deep learning
KW  - Grey-box
KW  - Greybox fuzzing
KW  - Language model
KW  - Large language model
KW  - Neural modelling
KW  - Neural-networks
KW  - Software vulnerabilities
KW  - State of the art
KW  - Deep neural networks
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Vasileiou, Z.
AU  - Meditskos, G.
AU  - Vrochidis, S.
AU  - Bassiliades, N.
TI  - An Explainable Multimodal Fusion Approach for Mass Casualty Incidents
PY  - 2022
T2  - Communications in Computer and Information Science
VL  - 1633 CCIS
SP  - 375
EP  - 379
DO  - 10.1007/978-3-031-14343-4_35
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136989595&doi=10.1007%2f978-3-031-14343-4_35&partnerID=40&md5=a28529d6b1549ad3c1c7222cd3857f97
AB  - During a Mass Casualty Incident, it is essential to make effective decisions to save lives and nursing the injured. This paper presents a work in progress on the design and development of an explainable decision support system, intended for the medical personnel and care givers, that capitalises on multiple modalities to achieve situational awareness and pre-hospital life support. Our novelty is two-fold: first, we use state-of-the-art techniques for combining static and time-series data in deep recurrent neural networks, and second we increase the trustworthiness of the system by enriching it with neurosymbolic explainable capabilities. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Deep neural network
KW  - Explainable AI
KW  - Mass casualty incident management
KW  - Neurosymbolic XAI
KW  - Pre-hospital life support
KW  - Decision support systems
KW  - Hospitals
KW  - Recurrent neural networks
KW  - Design and Development
KW  - Explainable AI
KW  - Incident Management
KW  - Life supports
KW  - Mass casualty incident management
KW  - Mass casualty incidents
KW  - Medical personnel
KW  - Multi-modal fusion
KW  - Neurosymbolic XAI
KW  - Pre-hospital life support
KW  - Deep neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Majerová, J.
AU  - Pera, A.
TI  - Haptic and Biometric Sensor Technologies, Spatio-Temporal Fusion Algorithms, and Virtual Navigation Tools in the Decentralized and Interconnected Metaverse
PY  - 2022
T2  - Review of Contemporary Philosophy
VL  - 21
SP  - 105
EP  - 121
DO  - 10.22381/RCP2120227
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142301786&doi=10.22381%2fRCP2120227&partnerID=40&md5=56baec264b2a39e2a191022bd436f78d
AB  - The objective of this paper is to systematically review spatial computing algorithms, synthetic data tools, and customer behavior analytics configuring virtual retail experiences. The findings and analyses highlight that metaverse engagement metrics integrates computer vision algorithms, visual analytics, and cognitive technologies in the digital asset-based virtual economy. Throughout April 2022, a quantitative literature review of the Web of Science, Scopus, and ProQuest databases was performed, with search terms including “the decentralized and interconnected metaverse” + “haptic and biometric sensor technologies,” “spatio-temporal fusion algorithms,” and “virtual navigation tools.” As research published between 2021 and 2022 was inspected, only 138 articles satisfied the eligibility criteria. By taking out controversial or ambiguous findings (insufficient/irrelevant data), outcomes unsubstantiated by replication, too general material, or studies with nearly identical titles, we selected 27 mainly empirical sources. Data visualization tools: Dimensions (bibliometric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AMSTAR, Dedoose, Distiller SR, and SRDR. © 2022, Addleton Academic Publishers. All rights reserved.
KW  - customer behavior analytics
KW  - metaverse economy
KW  - natural language processing and geospatial mapping tools
KW  - sensing and computing technologies
KW  - simulation modeling algorithms
KW  - virtual mapping and visual surveillance tools
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 11
ER  -

TY  - CONF
TI  - Proceedings of the 3rd International Workshop on Self-Supervised Learning, IWSSL 2022
PY  - 2022
T2  - Proceedings of Machine Learning Research
VL  - 192
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171476071&partnerID=40&md5=48e1aeb0de8f6b85c287456f40685836
AB  - The proceedings contain 10 papers. The topics discussed include: the future of AI research: ten defeasible ‘axioms of intelligence’; novel primitive decompositions for real-world physical reasoning; intelligence: from definition to design; explicit general analogy for autonomous transversal learning; symbolic guidance for constructivist learning by neural model; simultaneous localization and active phenomenon inference (SLAPI); reasoning-learning systems based on non-axiomatic reasoning system theory; neurosymbolic learning on activity summarization of video data; the holon system: artificial general intelligence as ‘work on command’; and hybrid AI for IoT actionable insights & real-time data-driven networks.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Hudson, J.
TI  - Virtual Immersive Shopping Experiences in Metaverse Environments: Predictive Customer Analytics, Data Visualization Algorithms, and Smart Retailing Technologies
PY  - 2022
T2  - Linguistic and Philosophical Investigations
VL  - 21
SP  - 236
EP  - 251
DO  - 10.22381/lpi21202215
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135577450&doi=10.22381%2flpi21202215&partnerID=40&md5=0c280ec6036fd6a82233598079c13dc5
AB  - In this article, I cumulate previous research findings indicating that smart connected devices can assist data-driven decisions in retail livestreaming by articulating personalized shopping experiences as regards digital ownership across extended reality environments. I contribute to the literature on virtual immersive shopping experiences in metaverse environments by showing that contextual aware-ness and real-time performance data can typify immersive retail experiences, improving brand recognition. Throughout February 2022, I performed a quantitative literature review of the Web of Science, Scopus, and ProQuest databases, with search terms including “metaverse” + “virtual immersive shopping experiences,” “predictive customer analytics,” “data visualization algorithms,” and “smart retailing technologies.” As I inspected research published between 2021 and 2022, only 83 articles satisfied the eligibility criteria. By eliminating controversial findings, outcomes unsubstantiated by replication, too imprecise material, or having similar titles, I decided upon 16, generally empirical, sources. Data visualization tools: Dimensions (bibliometric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AMSTAR, Distiller SR, MMAT, and ROBIS. © 2022, Addleton Academic Publishers. All rights reserved.
KW  - customer analytics
KW  - immersive
KW  - metaverse
KW  - shopping
KW  - virtual
KW  - visualization
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 18
ER  -

TY  - JOUR
AU  - Perkins, J.
TI  - Object Recognition and Virtual Retail Algorithms, Metaverse and Immersive Technologies, and Simulation Modeling and Spatial Data Acquisition Tools in Extended Reality Environments
PY  - 2022
T2  - Analysis and Metaphysics
VL  - 21
SP  - 142
EP  - 158
DO  - 10.22381/AM2120229
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146447079&doi=10.22381%2fAM2120229&partnerID=40&md5=2755fc4c1094dcf15c046d2c5571445f
AB  - The objective of this paper is to systematically review predictive maintenance and spatial data acquisition tools, metaverse technologies, and vision and navigation systems. The findings and analyses highlight that metaverse live shopping develops on behavior analysis and prediction tools, data stream clustering algorithms, and mobile geofencing technology in virtual mall environments. Throughout July 2022, a quantitative literature review of the Web of Science, Scopus, and ProQuest databases was performed, with search terms including “metaverse” + “object recognition and virtual retail algorithms,” “immersive technologies,” and “simulation modeling and spatial data acquisition tools.” As research published between 2021 and 2022 was inspected, only 139 articles satisfied the eligibility criteria. By taking out controversial or ambiguous findings (insufficient/irrelevant data), outcomes unsubstantiated by replication, too general material, or studies with nearly identical titles, I selected 27 mainly empirical sources. Data visualization tools: Dimensions (bibliometric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AMSTAR, Dedoose, Distiller SR, and SRDR. © 2022, Addleton Academic Publishers. All rights reserved.
KW  - immersive technologies
KW  - metaverse
KW  - object recognition
KW  - simulation modeling
KW  - spatial data
KW  - virtual retail
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Zhang, F.
AU  - Tan, Y.
TI  - Potential and Challenges for GPT Robots
ST  - 生成式预训练模型机器人及其潜力与挑战
PY  - 2024
T2  - Zhongguo Jixie Gongcheng/China Mechanical Engineering
VL  - 35
IS  - 7
SP  - 1241
EP  - 1252
DO  - 10.3969/j.issn.1004-132X.2024.07.012
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201499997&doi=10.3969%2fj.issn.1004-132X.2024.07.012&partnerID=40&md5=cb5c5876ea5eecd340f46ce4a69206a7
AB  - The fusion of robots and ChatGPT might create "silicon intelligence entity" with human-like intelligence and advantages, defined as "GPT-R". The characteristics, technological trends, and applications of GPT-R were explored in industrial and human life domains, with a focus on the integration of ChatGPT and robot intelligence. The challenges of GPT-R in physical abilities, intelligence, and coexistence with humans were analyzed, and the corresponding strategies from robotic body and intelligence of GPT-R, law and security issue, and social rules were proposed. The GPT-R, which integrated ChatGPT and robotics technology, will be expected to have increasingly broad applications and market potential, and will become one of the crucial directions in the future development of the integration of artificial intelligence and robotics. © 2024 Chinese Mechanical Engineering Society. All rights reserved.
KW  - artificial intelligence
KW  - coexistence development
KW  - GPT-R(generative pre-traincd transformer-robot)
KW  - silicon intelligent entity
KW  - Industrial robots
KW  - Intelligent robots
KW  - Robot applications
KW  - Coexistence development
KW  - Generative pre-traincd transformer-robot
KW  - Human lives
KW  - Human-like intelligence
KW  - Life domain
KW  - Robot intelligences
KW  - Security issues
KW  - Silicon intelligent entity
KW  - Technological applications
KW  - Technological trends
KW  - Economic and social effects
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Khan, A.
AU  - Hetznecker, A.
AU  - Drath, R.
AU  - Greiner, T.
TI  - Enhanced Symbolic Artificial Intelligence Mechanism for External Magnetic Interference Classification in Magnetostrictive Position Sensors
PY  - 2024
T2  - Proceedings of the IEEE International Conference on Industrial Technology
DO  - 10.1109/ICIT58233.2024.10540815
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195804496&doi=10.1109%2fICIT58233.2024.10540815&partnerID=40&md5=fed4a8eb8f5305658da0732a9186699c
AB  - In order to fulfill the requirements of precision and reliability, sensors in the context of Industry 4.0 must possess self-x capabilities such as self-monitoring. Magnetostrictive Position Sensors (MPS) are used for position and velocity measurement of objects with ultra-precision. They utilize the Time-of-Flight (ToF) technique through the reception of a structure-borne sound wave generated by a magnetic field within the sensor system. However, the precision of these sensors can be compromised by unwanted External Magnetic Interference (EMI) that interacts with the generation of the structure-borne sound wave. This research contribution introduces an innovative solution which employs an enhanced symbolic Artificial Intelligence (AI) mechanism to identify and classify EMI directly from the received sound waves (signals) during the self-monitoring process. It is emphasized that contrary to conventional methods, no extra magnetometer is used for the EMI classification. In this proposed method, Fisher's discriminant analysis is employed to identify significant regions in the sensor signals for feature extraction as a first step. Subsequently, these regions are leveraged for the application of symbolic AI. The simulation results show that the proposed symbolic AI method can significantly enhance the classification accuracy by careful extraction of the relevant features. This method also provides explainability as compared to a neural network approach.  © 2024 IEEE.
KW  - Discriminant analysis
KW  - Extraction
KW  - Magnetostrictive devices
KW  - Innovative solutions
KW  - Magnetic interference
KW  - Magnetic-field
KW  - Measurements of
KW  - Position sensors
KW  - Self-monitoring
KW  - Sensor systems
KW  - Structure borne sound
KW  - Time-of-flight techniques
KW  - Ultra precision
KW  - Artificial intelligence
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Al Shukairi, H.
AU  - Cardoso, R.C.
TI  - ML-MAS: A Hybrid AI Framework for Self-Driving Vehicles
PY  - 2023
T2  - Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS
VL  - 2023-May
SP  - 1191
EP  - 1199
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171275755&partnerID=40&md5=5a6f48180cb6592673cc5fe49ab0beea
AB  - Machine Learning (ML) techniques have been shown to be widely successful in environments that require processing a large amount of perception data, such as in fully autonomous self-driving vehicles. Nevertheless, in such a complex domain, ML-only approaches have several limitations. In this paper, we propose a hybrid Artificial Intelligence (AI) framework for fully autonomous self-driving vehicles that uses rule-based agents from symbolic AI to supplement the ML models in their decision-making. Our framework is evaluated using routes from the CARLA simulation environment, and has been shown to improve the driving score of the ML models. © 2023 International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.
KW  - BDI agents
KW  - CARLA
KW  - deep learning
KW  - Hybrid AI
KW  - self-driving vehicles
KW  - Autonomous agents
KW  - Autonomous vehicles
KW  - Deep learning
KW  - Learning systems
KW  - Multi agent systems
KW  - BDI Agent
KW  - CARLA
KW  - Deep learning
KW  - Hybrid artificial intelligences
KW  - Large amounts
KW  - Machine learning models
KW  - Machine learning techniques
KW  - Machine-learning
KW  - Self drivings
KW  - Self-driving vehicle
KW  - Decision making
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Paul, J.
AU  - Ponce, L.
AU  - Zhang, M.
AU  - Garcia, L.
TI  - Towards Cross-Physical-Domain Threat Inference for Industrial Control System Defense Adaptation
PY  - 2024
T2  - RICSS 2024 - Proceedings of the 2024 Workshop on Re-design Industrial Control Systems with Security, Co-Located with: CCS 2024
SP  - 57
EP  - 64
DO  - 10.1145/3689930.3695210
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214112183&doi=10.1145%2f3689930.3695210&partnerID=40&md5=9c42630e1297fd84012e0ff916f24ef0
AB  - Safety-critical Industrial Control Systems (ICS) are increasingly targeted by Advanced Persistent Threats (APTs), exemplified by attacks like Stuxnet, the Ukraine power grid breaches, and recent U.S. water treatment facility intrusions. These sophisticated attacks often target common sensors and actuator abstractions across different ICS environments. While frameworks like MITRE ATT&CK for ICS categorize attacker Tactics, Techniques, and Procedures (TTPs), they fall short in assessing the physical impact on operational technology (OT). To bridge this gap, we introduce OTThreat, a novel ontology that extends the Semantic Sensor Network (SSN) framework by incorporating cyber attack abstractions and the safety properties they target. Our approach enables the mapping of similar physical processes across different ICS domains, facilitating the adaptation of existing mitigations to new threats. We implement and validate a proof-of-concept threat inference framework on three ICS use cases representing different physical domains, including water treatment ICS and oil treatment ICS, that share common sensor and actuator abstractions and demonstrate how both threat assessment and potential mitigations for discovered threats can be adapted across physical domains. © 2024 Copyright held by the owner/author(s).
KW  - industrial control systems
KW  - knowledge graphs
KW  - Computer viruses
KW  - Energy security
KW  - Inference engines
KW  - Invariance
KW  - Liquefied petroleum gas
KW  - Ontology
KW  - Petroleum tar
KW  - Actuator abstraction
KW  - Industrial control systems
KW  - Knowledge graphs
KW  - Physical domain
KW  - Power grids
KW  - Sensor abstraction
KW  - Sensors and actuators
KW  - Stuxnet
KW  - Ukraine
KW  - Water treatment facilities
KW  - Industrial water treatment
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Fatima, A.
AU  - Reddy C, K.K.
AU  - Doss, S.
AU  - Joshi, H.
TI  - From neurons to algorithms: Enhancing machine learning with neuroscientific insights
PY  - 2025
T2  - Federated Learning for Neural Disorders in Healthcare 6.0
SP  - 96
EP  - 119
DO  - 10.1201/9781003591085-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002956576&doi=10.1201%2f9781003591085-4&partnerID=40&md5=fd909d178caa6664a6469065e927caa1
AB  - This chapter explores the intersection of neuroscience and artificial intelligence (AI), focusing on how the functioning of biological neurons informs the development of artificial neural networks (ANNs) in machine learning. Biological neurons communicate through action potentials and synaptic transmission, processes that inspire the design of artificial neurons in AI. However, artificial neurons significantly simplify the complexity of their biological counterparts, which impacts their adaptability and energy efficiency. By drawing from insights in neuroscience, such as spike-timing-dependent plasticity and hierarchical processing, AI models can be enhanced to perform more dynamic tasks while maintaining computational efficiency. This chapter compares biological and artificial neurons, examines neuroscience-inspired learning mechanisms, and discusses the implications of such insights for AI development, particularly in creating models that are more energy-efficient and capable of real-time adaptation. © 2025 selection and editorial matter, Kishor Kumar Reddy C and Anindya Nag.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Xu, W.
AU  - Liu, M.
AU  - Sokolsky, O.
AU  - Lee, I.
AU  - Kong, F.
TI  - LLM-Enabled Cyber-Physical Systems: Survey, Research Opportunities, and Challenges
PY  - 2024
T2  - Proceedings - 2024 IEEE International Workshop on Foundation Models for Cyber-Physical Systems and Internet of Things, FMSys 2024
SP  - 50
EP  - 55
DO  - 10.1109/FMSys62467.2024.00013
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199907263&doi=10.1109%2fFMSys62467.2024.00013&partnerID=40&md5=d5afc5f064bac796b6b41f9f4a3bdead
AB  - Cyber-Physical Systems (CPS) integrate computational elements with physical processes via sensors and actuators. While CPS is expected to have human-level intelligence, traditional machine learning which is trained on specific and isolated datasets seems insufficient to meet such expectation. In recent years, Large Language Models (LLMs), like GPT-4, have experienced explosive growth and show significant improvement in reasoning and language comprehension capabilities which promotes LLM -enabled CPS. In this paper, we present a comprehensive review of these studies about LLM -enabled CPS. First, we overview LLM-enabled CPS and the roles that LLM plays in CPS. Second, we categorize existing works in terms of the application domain and discuss their key contributions. Third, we present commonly-used metrics and benchmarks for LLM -enabled CPS evaluation. Finally, we discuss future research opportunities and corresponding challenges of LLM -enabled CPS.  © 2024 IEEE.
KW  - cyber-physical systems
KW  - large language model
KW  - machine learning
KW  - Computational linguistics
KW  - Embedded systems
KW  - Machine learning
KW  - Computational elements
KW  - Cybe-physical systems
KW  - Cyber-physical systems
KW  - Language model
KW  - Large language model
KW  - Machine-learning
KW  - Research challenges
KW  - Research opportunities
KW  - Survey research
KW  - System survey
KW  - Cyber Physical System
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Xu, Z.
AU  - Xiao, T.
AU  - He, W.
AU  - Wang, Y.
AU  - Jiang, Z.
TI  - Spatial Knowledge-Infused Hierarchical Learning: An Application in Flood Mapping on Earth Imagery
PY  - 2023
T2  - GIS: Proceedings of the ACM International Symposium on Advances in Geographic Information Systems
C7  - 48
DO  - 10.1145/3589132.3625591
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178389323&doi=10.1145%2f3589132.3625591&partnerID=40&md5=239ee360f9c1ec25ee36fcc5be93e88c
AB  - Deep learning for Earth imagery plays an increasingly important role in geoscience applications such as agriculture, ecology, and natural disaster management. Still, progress is often hindered by the limited training labels. Given Earth imagery with limited training labels, a base deep neural network model, and a spatial knowledge base with label constraints, our problem is to infer the full labels while training the neural network. The problem is challenging due to the sparse and noisy input labels, spatial uncertainty within the label inference process, and high computational costs associated with a large number of sample locations. Existing works on neuro-symbolic models focus on integrating symbolic logic into neural networks (e.g., loss function, model architecture, and training label augmentation), but these methods do not fully address the challenges of spatial data (e.g., spatial uncertainty, the trade-off between spatial granularity and computational costs). To bridge this gap, we propose a novel Spatial Knowledge-Infused Hierarchical Learning (SKI-HL) framework that iteratively infers sample labels within a multi-resolution hierarchy. Our framework consists of a module to selectively infer labels in different resolutions based on spatial uncertainty and a module to train neural network parameters with uncertainty-aware multi-instance learning. Extensive experiments on real-world flood mapping datasets show that the proposed model outperforms several baseline methods. The code is available at https://github.com/ZelinXu2000/SKI-HL.  © 2023 ACM.
KW  - knowledge-infused learning
KW  - neural-symbolic system
KW  - spatial data mining
KW  - Computation theory
KW  - Data mining
KW  - Deep neural networks
KW  - Disaster prevention
KW  - Disasters
KW  - Economic and social effects
KW  - Floods
KW  - Knowledge based systems
KW  - Learning systems
KW  - Mapping
KW  - Computational costs
KW  - Flood mapping
KW  - Geoscience applications
KW  - Hierarchical learning
KW  - Knowledge-infused learning
KW  - Neural-networks
KW  - Neural-symbolic systems
KW  - Spatial data mining
KW  - Spatial knowledge
KW  - Spatial uncertainty
KW  - Iterative methods
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - CONF
AU  - Piplai, A.
AU  - Joshi, A.
AU  - Finin, T.
TI  - Offline RL+CKG: A hybrid AI model for cybersecurity tasks
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3433
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166486550&partnerID=40&md5=8789877d260f5f1a58e19983fd779bf9
AB  - AI models for cybersecurity have to detect and defend against constantly evolving cyber threats. Much effort is spent building defenses for zero days and unseen variants of known cyber-attacks. Current AI models for cybersecurity struggle with these yet unseen threats due to the constantly evolving nature of threat vectors, vulnerabilities, and exploits. This paper shows that cybersecurity AI models will be improved and more general if we include semi-structured representations of background knowledge. This could include information about the software and systems, as well as information obtained from observing the behavior of malware samples captured and detonated in honeypots. We describe how we can transfer this knowledge into forms that the RL models can directly use for decision-making purposes. © 2023 CEUR-WS. All rights reserved.
KW  - Conservative Q-Learning
KW  - Cybersecurity knowledge graphs
KW  - Hybrid AI
KW  - Offline reinforcement learning
KW  - Cybersecurity
KW  - Decision making
KW  - Knowledge graph
KW  - Malware
KW  - Network security
KW  - Conservative Q-learning
KW  - Cyber security
KW  - Cyber threats
KW  - Cybersecurity knowledge graph
KW  - Hybrid AI
KW  - Knowledge graphs
KW  - Offline
KW  - Offline reinforcement learning
KW  - Q-learning
KW  - Reinforcement learnings
KW  - Reinforcement learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Dritsas, E.
AU  - Trigka, M.
TI  - Machine Learning in E-Commerce: Trends, Applications, and Future Challenges
PY  - 2025
T2  - IEEE Access
VL  - 13
SP  - 99048
EP  - 99067
DO  - 10.1109/ACCESS.2025.3572865
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006707772&doi=10.1109%2fACCESS.2025.3572865&partnerID=40&md5=63489b62f9f0c63230c0d366a39f16bf
AB  - The rapid evolution of e-commerce has been significantly influenced by the integration of machine learning (ML) and data science techniques. The present survey provides a comprehensive overview of how ML methods are applied across various functional domains in e-commerce, including personalized recommendations, dynamic pricing, fraud detection, customer segmentation, and behavioral analysis. We categorize and evaluate a wide range of ML paradigms, namely supervised, unsupervised, reinforcement, and hybrid learning, as well as emerging approaches such as neurosymbolic artificial intelligence (AI), federated learning (FL), and quantum ML (QML). Key challenges related to scalability, interpretability, cold-start problems, data sparsity, and privacy are critically analyzed. Additionally, we highlight underexplored areas, such as continual learning (CL) and multi-agent architectures in commerce. The survey incorporates comparative tables, real-world use cases, and a taxonomy of methods to support both academic and industrial perspectives. Ultimately, by analyzing trends and gaps in the literature, we provide a forward-looking research roadmap that bridges ML innovations with the evolving demands of e-commerce ecosystems. © 2013 IEEE.
KW  - e-commerce
KW  - Machine learning
KW  - optimization
KW  - personalization
KW  - predictive analytics
KW  - recommendation systems
KW  - Federated learning
KW  - Mobile commerce
KW  - Reinforcement learning
KW  - Supervised learning
KW  - Unsupervised learning
KW  - E- commerces
KW  - Functional domains
KW  - Future challenges
KW  - Machine data
KW  - Machine learning methods
KW  - Machine-learning
KW  - Optimisations
KW  - Personalization and optimization
KW  - Personalizations
KW  - Personalized recommendation
KW  - Marketplaces
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Semerikov, S.O.
AU  - Vakaliuk, T.A.
AU  - Kanevska, O.B.
AU  - Moiseienko, M.V.
AU  - Donchev, I.I.
AU  - Kolhatin, A.O.
TI  - LLM on the edge: the new frontier
PY  - 2025
T2  - CEUR Workshop Proceedings
VL  - 3943
SP  - 137
EP  - 161
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001105452&partnerID=40&md5=a227591166e307bb2866203271bbbd3d
AB  - The advent of large language models (LLMs) has revolutionized natural language processing, enabling unprecedented capabilities in text generation, reasoning, and human-machine interaction. However, their deployment on resource-constrained edge devices presents significant challenges due to high computational complexity, large model sizes, and stringent latency and privacy requirements. This survey provides a comprehensive examination of the emerging field of edge-based LLMs, exploring the techniques, frameworks, hardware solutions, and real-world applications that enable their efficient deployment at the edge. We review key strategies such as model quantization, pruning, knowledge distillation, and adapter tuning, alongside edge-cloud collaborative architectures like EdgeShard, Edge-LLM, and PAC. Additionally, we analyze hardware acceleration solutions, including Cambricon-LLM, AxLaM, and DTATrans/DTQAtten, and their role in overcoming resource limitations. The survey highlights diverse applications, from IoT and smart cities to personalized services and multi-modal intelligence, supported by case studies of real-world deployments. Finally, we discuss open challenges – such as resource efficiency, privacy, security, and scalability – and propose future research directions to advance this transformative technology. © 2025 Copyright for this paper by its authors.
KW  - edge computing
KW  - edge-cloud collaboration
KW  - hardware acceleration
KW  - IoT applications
KW  - large language models (LLMs)
KW  - model compression
KW  - multi-modal intelligence
KW  - personalized services
KW  - privacy-preserving AI
KW  - resource efficiency
KW  - Cloud platforms
KW  - Differential privacy
KW  - Mobile edge computing
KW  - Edge clouds
KW  - Edge computing
KW  - Edge-cloud collaboration
KW  - Hardware acceleration
KW  - IoT application
KW  - Language model
KW  - Large language model
KW  - Model compression
KW  - Multi-modal
KW  - Multi-modal intelligence
KW  - Personalized service
KW  - Privacy preserving
KW  - Privacy-preserving AI
KW  - Resource efficiencies
KW  - Natural language processing systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Carey, B.
TI  - Metaverse Technologies, Behavioral Predictive Analytics, and Customer Location Tracking Tools in Blockchain-based Virtual Worlds
PY  - 2022
T2  - Review of Contemporary Philosophy
VL  - 21
SP  - 188
EP  - 204
DO  - 10.22381/RCP21202212
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142299322&doi=10.22381%2fRCP21202212&partnerID=40&md5=b95017b6e81bc71b9ab6f12ac36c2a89
AB  - Despite the relevance of virtual items, blockchain token-based digital assets, and 3D immersive content, only limited research has been conducted on this topic. In this article, I cumulate previous research findings indicating that data modeling tools optimize customer engagement behaviors and purchasing habits in immersive virtual worlds. I contribute to the literature on shopping habits and be-haviors in metaverse live shopping across immersive 3D worlds by showing that personalized digital shopping experiences can be attained by use of customer engagement tools in immersive virtual spaces. Throughout March 2022, I performed a quantitative literature review of the Web of Science, Scopus, and ProQuest data-bases, with search terms including “blockchain-based virtual worlds” + “metaverse technologies,” “behavioral predictive analytics,” and “customer location tracking tools.” As I inspected research published between 2021 and 2022, only 152 articles satisfied the eligibility criteria. By eliminating controversial findings, outcomes unsubstantiated by replication, too imprecise material, or having similar titles, I decided upon 30, generally empirical, sources. Data visualization tools: Dimensions (bibliometric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AXIS, Dedoose, Distiller SR, and MMAT. © 2022, Addleton Academic Publishers. All rights reserved.
KW  - data modeling tools
KW  - decentralized metaverse
KW  - geospatial mapping tools
KW  - immersive 3D virtual environments
KW  - spatial computing technology
KW  - virtual retail algorithms
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 15
ER  -

TY  - JOUR
AU  - Zhang, T.
AU  - Zhao, T.
AU  - Qin, Y.
AU  - Liu, S.
TI  - Artificial intelligence in intelligent vehicles: recent advances and future directions
PY  - 2023
T2  - Journal of the Chinese Institute of Engineers, Transactions of the Chinese Institute of Engineers,Series A
VL  - 46
IS  - 8
SP  - 905
EP  - 911
DO  - 10.1080/02533839.2023.2262759
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173968075&doi=10.1080%2f02533839.2023.2262759&partnerID=40&md5=3fb2c777973f5e696625a289a5a860ce
AB  - AI has been widely used in intelligent transportation systems, autonomous driving and automated vehicles in particular. Intelligent vehicles in the future will be a combination of Internet of things and AI, and AI is the key for intelligent vehicles. The maturer the intelligent vehicles are, the more advanced the AI techniques will be applied in intelligent vehicles. In this paper, we perform a survey on the progress of AI applications in automated vehicles, including perception, autonomous driving, and test, and then discuss challenges of intelligent vehicles and recent advances in AI and prospective applications in the future transportation ecosystem, intelligent vehicles in particular. © 2023 The Chinese Institute of Engineers.
KW  - artificial intelligence
KW  - automated vehicles
KW  - Intelligent vehicles
KW  - object detection
KW  - Yuan, Shyan-Ming
KW  - Yuan, Shyan-Ming
KW  - Autonomous vehicles
KW  - Intelligent systems
KW  - Intelligent vehicle highway systems
KW  - AI applications
KW  - AI techniques
KW  - Automated vehicles
KW  - Autonomous driving
KW  - Intelligent transportation systems
KW  - Objects detection
KW  - Prospective applications
KW  - Yuan, shyan-ming
KW  - Object detection
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - CONF
AU  - Firmani, D.
AU  - Leotta, F.
AU  - Mathew, J.G.
AU  - Rossi, J.
AU  - Balzotti, L.
AU  - Song, H.
AU  - Roman, D.
AU  - Dautov, R.
AU  - Husom, E.J.
AU  - Sen, S.
AU  - Balionyte-Merle, V.
AU  - Morichetta, A.
AU  - Dustdar, S.
AU  - Metsch, T.
AU  - Frascolla, V.
AU  - Khalid, A.
AU  - Landi, G.
AU  - Brenes, J.
AU  - Toma, I.
AU  - Szabó, R.
AU  - Schaefer, C.
AU  - Udroiu, C.
AU  - Ulisses, A.
AU  - Pietsch, V.
AU  - Akselsen, S.
AU  - Munch-Ellingsen, A.
AU  - Pavlova, I.
AU  - Kim, H.-G.
AU  - Kim, C.
AU  - Allen, B.
AU  - Kim, S.
AU  - Paulson, E.
TI  - INTEND: Intent-Based Data Operation in the Computing Continuum
PY  - 2024
T2  - CEUR Workshop Proceedings
VL  - 3692
SP  - 43
EP  - 50
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195193195&partnerID=40&md5=87ea2bcbd6ea011d80a7a170786762c5
AB  - The European Commission (EC) Digital Decade strategy to gain by 2030 autonomy in the digital economy requires more and more data to be processed in the Cloud-Edge-IoT computing continuum, instead of only in the central cloud. This requires advanced automation and intelligence of the continuum. At the same time, recent breakthroughs in Artificial Intelligence (AI) research have shown unprecedented results in handling creative tasks. Such human-like intelligence will eventually disrupt how people use the cloud and continuum. The European Union (EU) -funded project INTEND aims at bringing such human-like intelligence into the cognitive continuum, to achieve the novel concept of intent-based data operation. The project will deliver 11 novel software tools, which integrate into an INTEND toolbox. The outputs pave the way of migrating EU’s data industry from cloud to the continuum, and implement EC’s strategy of human-centric AI in the domain of data processing and computing continuum. © 2024 Copyright for this paper by its authors.
KW  - International law
KW  - Artificial intelligence research
KW  - Creatives
KW  - Data operations
KW  - Digital economy
KW  - European Commission
KW  - European union
KW  - Human-centric
KW  - Human-like intelligence
KW  - Novel concept
KW  - Software-tools
KW  - Data handling
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
TI  - 2024 20th CSI International Symposium on Artificial Intelligence and Signal Processing, AISP 2024
PY  - 2024
T2  - 2024 20th CSI International Symposium on Artificial Intelligence and Signal Processing, AISP 2024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190389824&partnerID=40&md5=50e63b8522beae76f9959f41f9217f0a
AB  - The proceedings contain 110 papers. The topics discussed include: neurosymbolic ai-based framework for sports ball identification concerning toddlers; transfer learning-based emotion detection system in cultivating workplace harmony; optimizing monocular 3D object detection on KITTI: harnessing power of right images; enhancing service quality in healthcare systems through deep learning; a two-stage sign language recognition method focusing on the semantic features of label text; smart parking systems: comprehensive review based on technological perspective; advancements in artificial intelligence algorithms for precise diabetes prediction and analysis in the healthcare landscape: a systematic and analytical investigation; hemodialysis arteriovenous fistula survival: analysis of medication impact during the maintenance phase using data mining; and addressing security challenges in wireless body area sensor networks: a comprehensive analysis and solutions.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Blasch, E.
AU  - Chen, G.
AU  - Chen, Y.
AU  - Zheng, Y.
AU  - Grewe, L.
AU  - Kadar, I.
AU  - Savakis, A.
TI  - Digital Twin Meets Information Fusion: Panel Summary
PY  - 2024
T2  - Proceedings of SPIE - The International Society for Optical Engineering
VL  - 13057
C7  - 130570F
DO  - 10.1117/12.3014996
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197749137&doi=10.1117%2f12.3014996&partnerID=40&md5=be324502661d72e9cd928f8959318c9f
AB  - Within the recent years, the concept of Digital Twins (DT) emerged to support digital engineering physical-systems design in the processing and analysis of device components, data flows, and networked systems. As an element of systems engineering, the DT serves as a method for life cycle management for operations and maintenance through monitoring, diagnostics, and prognostics. Key to DT methods is the use of distributed sensors to monitor the system and determine the functioning with the use of physical design information, such as a series of distributed edge sensors and the layout of a physical electrical grid. While industries like industrial manufacturing, electrical power, space systems, and healthcare maintenance have embraced DT; other groups are utilizing the concept for analysis. Given that a large number of sensors are used to gather data on the health of system, it is natural that data fusion, estimation theory, and signals processing support digital twin fusion (DTwF); but there are a variety of challenges such as big data, distribution fusion, and edge analytics. The panel will discuss areas in which data and information fusion techniques enhance DT applications. © 2024 SPIE.
KW  - Cyber awareness
KW  - Data Fusion Information Group Model
KW  - Deep Learning
KW  - digital twin fusion (DTwF)
KW  - Digital Twins
KW  - Information Fusion
KW  - User Refinement
KW  - Data flow analysis
KW  - Data fusion
KW  - E-learning
KW  - Information fusion
KW  - Life cycle
KW  - Cybe awareness
KW  - Data flow systems
KW  - Data fusion information group model
KW  - Deep learning
KW  - Digital engineering
KW  - Digital twin fusion
KW  - Group modelling
KW  - Networked systems
KW  - Physical systems
KW  - User refinement
KW  - Deep learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Teixeira, A.R.
AU  - Ferreira, J.V.
AU  - Ramos, A.L.
TI  - Intelligent Supply Chain Management: A Systematic Literature Review on Artificial Intelligence Contributions
PY  - 2025
T2  - Information (Switzerland)
VL  - 16
IS  - 5
C7  - 399
DO  - 10.3390/info16050399
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006516459&doi=10.3390%2finfo16050399&partnerID=40&md5=1803b12288b57aec77b9269513957ede
AB  - This systematic literature review investigates the recent applications of artificial intelligence (AI) in supply chain management (SCM), particularly in the domains of resilience, process optimization, sustainability, and implementation challenges. The study is motivated by gaps identified in previous reviews, which often exclude literature published after 2020 and lack an integrated analysis of AI’s contributions across multiple supply chain phases. The review aims to provide an updated synthesis of AI technologies—such as machine learning, deep learning, and generative AI—and their practical implementation between 2021 and 2024. Following the PRISMA framework, a rigorous methodology was applied using the Scopus database, complemented by bibliometric and content analyses. A total of 66 studies were selected based on predefined inclusion criteria and evaluated for methodological quality and thematic relevance. The findings reveal a diverse classification of AI applications across strategic and operational SCM phases and highlight emerging techniques like explainable AI, neurosymbolic systems, and federated learning. The review also identifies persistent barriers such as data governance, ethical concerns, and scalability. Future research should focus on hybrid AI–human collaboration, transparency through explainable models, and integration with technologies such as IoT and blockchain. This review contributes to the literature by offering a structured synthesis of AI’s transformative impact on SCM and by outlining key research directions to guide future investigations and managerial practice. © 2025 by the authors.
KW  - artificial intelligence
KW  - PRISMA methodology
KW  - supply chain management
KW  - sustainability
KW  - systematic literature review
KW  - Ethical technology
KW  - Federated learning
KW  - Supply chain management
KW  - Artificial intelligence technologies
KW  - Chain management
KW  - Integrated analysis
KW  - Machine-learning
KW  - Multiple supplies
KW  - PRISMA methodology
KW  - Process implementation
KW  - Process optimisation
KW  - Process sustainability
KW  - Systematic literature review
KW  - Deep learning
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Başarslan, M.S.
AU  - Kayaalp, F.
TI  - MBi-GRUMCONV: A novel Multi Bi-GRU and Multi CNN-Based deep learning model for social media sentiment analysis
PY  - 2023
T2  - Journal of Cloud Computing
VL  - 12
IS  - 1
C7  - 5
DO  - 10.1186/s13677-022-00386-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146117025&doi=10.1186%2fs13677-022-00386-3&partnerID=40&md5=0d3a496c61657845cbc66a66f5ca6b54
AB  - Today, internet and social media is used by many people, both for communication and for expressing opinions about various topics in many domains of life. Various artificial intelligence technologies-based approaches on analysis of these opinions have emerged natural language processing in the name of different tasks. One of these tasks is Sentiment analysis, which is a popular method aiming the task of analyzing people’s opinions which provides a powerful tool in making decisions for people, companies, governments, and researchers. It is desired to investigate the effect of using multi-layered and different neural networks together on the performance of the model to be developed in the sentiment analysis task. In this study, a new, deep learning-based model was proposed for sentiment analysis on IMDB movie reviews dataset. This model performs sentiment classification on vectorized reviews using two methods of Word2Vec, namely, the Skip Gram and Continuous Bag of Words, in three different vector sizes (100, 200, 300), with the help of 6 Bidirectional Gated Recurrent Units and 2 Convolution layers (MBi-GRUMCONV). In the experiments conducted with the proposed model, the dataset was split into 80%-20% and 70%-30% training-test sets, and 10% of the training splits were used for validation purposes. Accuracy and F1 score criteria were used to evaluate the classification performance. The 95.34% accuracy of the proposed model has outperformed the studies in the literature. As a result of the experiments, it was found that Skip Gram has a better contribution to classification success. © 2023, The Author(s).
KW  - Deep Learning
KW  - Natural Language Processing
KW  - Sentiment Analysis
KW  - Word Embedding
KW  - Word2Vec
KW  - Deep learning
KW  - Learning systems
KW  - Multilayer neural networks
KW  - Network layers
KW  - Social networking (online)
KW  - Statistical tests
KW  - Deep learning
KW  - Embeddings
KW  - Language processing
KW  - Learning models
KW  - Natural language processing
KW  - Natural languages
KW  - Sentiment analysis
KW  - Social media
KW  - Word embedding
KW  - Word2vec
KW  - Sentiment analysis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 50
ER  -

TY  - JOUR
AU  - Mantenoglou, P.
AU  - Artikis, A.
AU  - Paliouras, G.
TI  - Online event recognition over noisy data streams
PY  - 2023
T2  - International Journal of Approximate Reasoning
VL  - 161
C7  - 108993
DO  - 10.1016/j.ijar.2023.108993
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167581551&doi=10.1016%2fj.ijar.2023.108993&partnerID=40&md5=3650cce130231c87fe748350b2aff096
AB  - Composite event recognition (CER) systems process streams of sensor data and infer composite events of interest by means of pattern matching. Data uncertainty is frequent in CER applications and results in erroneous detection. To support streaming applications, we present oPIECbd, an extension of oPIEC with a bounded memory, leveraging interval duration statistics to resolve memory conflicts. oPIECbd may achieve comparable predictive accuracy to batch reasoning, avoiding the prohibitive cost of such reasoning. Furthermore, the use of interval duration statistics allows oPIECbd to outperform significantly earlier versions of bounded oPIEC. The empirical evaluation demonstrates the efficacy of oPIECbd on a benchmark activity recognition dataset, as well as real data streams from the field of maritime situational awareness. © 2023 Elsevier Inc.
KW  - Event calculus
KW  - Human activity recognition
KW  - Maritime situational awareness
KW  - Probabilistic logic programming
KW  - Temporal pattern matching
KW  - Uncertainty
KW  - Logic programming
KW  - Petroleum reservoir evaluation
KW  - Probabilistic logics
KW  - Event calculus
KW  - Event recognition
KW  - Human activity recognition
KW  - Maritime situational awareness
KW  - Pattern-matching
KW  - Probabilistic logic programming
KW  - Situational awareness
KW  - Temporal pattern
KW  - Temporal pattern matching
KW  - Uncertainty
KW  - Pattern matching
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Ahmad, J.
AU  - Gueaieb, W.
AU  - El Saddik, A.
AU  - De Masi, G.
AU  - Karray, F.
TI  - KNOWLEDGE-INFUSED LEARNING FOR FINE-GRAINED PLANT DISEASE RECOGNITION
PY  - 2024
T2  - Proceedings - International Conference on Image Processing, ICIP
SP  - 395
EP  - 401
DO  - 10.1109/ICIP51287.2024.10648166
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216882759&doi=10.1109%2fICIP51287.2024.10648166&partnerID=40&md5=a09f3ebcac3e791b9e09c1f1cc665f9f
AB  - Domain knowledge exists in various forms, including text, ontologies, graphs, images, audio, and videos. In plant disease detection, most works solely utilize images with disease labels, neglecting textual descriptions of visual disease symptoms used by human experts for diagnosis. These text descriptions and sample images aid expert identification of visual symptoms. We propose a novel method that leverages text descriptions and image data by modeling domain-specific knowledge about visual symptoms in leaf images as separate feature channels. Each channel corresponds to specific features whose absence or presence in the image influences model predictions. We introduce a channel attention-guided fusion module for weighting each channel based on the input and corresponding output. The combined feature channels are transformed into a standardized 3-channel input format, which can then be processed by any pre-trained convolutional neural network (CNN) as input for feature extraction and subsequent classification. Furthermore, intermediate activations of the channel attention layer combined with the weights from the fusion layer make model predictions explainable. Experimental results on three publicly available datasets of apple and cucumber leaf diseases demonstrate improvements of up to 5% utilizing various state-of-the-art CNN architectures, indicating the efficacy of incorporating textual disease descriptions using the proposed approach. © 2024 IEEE.
KW  - channel attention
KW  - disease detection
KW  - explainability
KW  - feature extraction
KW  - knowledge-infusion
KW  - Multilayer neural networks
KW  - Channel attention
KW  - Convolutional neural network
KW  - Disease detection
KW  - Explainability
KW  - Features extraction
KW  - Fine grained
KW  - Knowledge-infusion
KW  - Model prediction
KW  - Plant disease
KW  - Visual symptoms
KW  - Convolutional neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Jiang, W.
AU  - Zhang, D.
AU  - Wang, R.
AU  - Zhang, Z.
TI  - A study on connectivity path search in fractured-vuggy reservoirs based on multi-agent system
PY  - 2025
T2  - Advanced Engineering Informatics
VL  - 65
C7  - 103160
DO  - 10.1016/j.aei.2025.103160
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216490060&doi=10.1016%2fj.aei.2025.103160&partnerID=40&md5=e67c457211cfa3d7dfb5b7de4fee92b1
AB  - Due to the complex and heterogeneous spatial structure of fractured-vuggy reservoirs caused by multiple tectonic movements, understanding inter-well connectivity paths is challenging. Explicit connectivity paths are crucial for designing injection and production schemes and enhancing oil recovery. Traditional methods often fail to adequately characterize geological structures, making it difficult to represent preferential pathways. This study proposes a novel algorithm that integrates seismic multi-attribute data and reinforcement learning to automatically search for 3D inter-well connectivity paths. A multi-agent deep reinforcement learning model based on actor-critic is employed, with each agent representing a flow direction in the multi-phase carbonate rock system. Game theory is used to identify connectivity paths that align with geological structures, while fluid flow laws are incorporated into the reward function to improve search accuracy. A multi-head self-attention mechanism is introduced to capture global state information and the correlation between fluid flows in different directions. Variational Bayesian estimation is utilized to improve search efficiency by leveraging prior geological data. The algorithm is applied to a typical oilfield in China, where it successfully identifies connectivity paths. The results are validated by comparing the identified paths with tracer concentration production curves, showing improved accuracy in representing the spatial distribution characteristics of the reservoir. © 2025 Elsevier Ltd
KW  - Deep reinforcement learning
KW  - Fractured-vuggy reservoir
KW  - Multi-agent system
KW  - Path search
KW  - Variational Bayesian estimation
KW  - Injection (oil wells)
KW  - Natural fractures
KW  - Oil well flooding
KW  - Petroleum reservoir evaluation
KW  - Reinforcement learning
KW  - Bayesian estimations
KW  - Fluid-flow
KW  - Fractured-vuggy reservoirs
KW  - Geological structures
KW  - Multiagent systems (MASs)
KW  - Path search
KW  - Reinforcement learnings
KW  - Variational bayesian
KW  - Variational bayesian estimation
KW  - Well connectivities
KW  - Deep reinforcement learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Peng, Y.
AU  - Wang, Z.
AU  - Zhang, Y.
AU  - Zhang, S.
AU  - Cai, N.
AU  - Wu, F.
AU  - Chen, M.
TI  - Revolutionizing Battery Disassembly: The Design and Implementation of a Battery Disassembly Autonomous Mobile Manipulator Robot(BEAM-1)
PY  - 2024
T2  - IEEE International Conference on Intelligent Robots and Systems
SP  - 6367
EP  - 6374
DO  - 10.1109/IROS58592.2024.10802225
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216499555&doi=10.1109%2fIROS58592.2024.10802225&partnerID=40&md5=47a7513a076b95bb93c0f91d8675976d
AB  - The efficient disassembly of end-of-life electric vehicle batteries(EOL-EVBs) is crucial for green manufacturing and sustainable development. The current pre-programmed disassembly conducted by the Autonomous Mobile Manipulator Robot(AMMR) struggles to meet the disassembly requirements in dynamic environments, complex scenarios, and unstructured processes. In this paper, we propose a Battery Disassembly AMMR(BEAM-1) system based on NeuralSymbolic AI. It detects the environmental state by leveraging a combination of multi-sensors and neural predicates and then translates this information into a quasi-symbolic space. In real-time, it identifies the optimal sequence of action primitives through LLM-heuristic tree search, ensuring high-precision execution of these primitives. Additionally, it employs positional speculative sampling using intuitive networks and achieves the disassembly of various bolt types with a meticulously designed end-effector. Importantly, BEAM-1 is a continuously learning embodied intelligence system capable of subjective reasoning like a human, and possessing intuition. A large number of real scene experiments have proved that it can autonomously perceive, decide, and execute to complete the continuous disassembly of bolts in multiple, multi-category, and complex situations, with a success rate of 98.78%. This research attempts to use NeuroSymbolic AI to give robots real autonomous reasoning, planning, and learning capabilities. BEAM-1 realizes the revolution of battery disassembly. Its framework can be easily ported to any robotic system to realize different application scenarios, which provides a ground-breaking idea for the design and implementation of future embodied intelligent robotic systems. © 2024 IEEE.
KW  - Industrial robots
KW  - Integrated circuit design
KW  - Intelligent robots
KW  - Manipulators
KW  - Mobile robots
KW  - Modular robots
KW  - Robot applications
KW  - Robot programming
KW  - Structural analysis
KW  - 'current
KW  - 1-systems
KW  - Autonomous mobile manipulator
KW  - Design and implementations
KW  - Dynamic environments
KW  - Electric vehicle batteries
KW  - End of lives
KW  - Environmental state
KW  - Green manufacturing
KW  - Mobile manipulator robot
KW  - End effectors
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Bianchi, F.
AU  - Castellini, A.
AU  - Farinelli, A.
AU  - Marzari, L.
AU  - Meli, D.
AU  - Trotti, F.
AU  - Veronese, C.
TI  - Developing safe and explainable autonomous agents: from simulation to the real world
PY  - 2024
T2  - CEUR Workshop Proceedings
VL  - 3762
SP  - 89
EP  - 94
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205594744&partnerID=40&md5=4bc2a589212e5679fa6333a65df1c6b7
AB  - Responsible artificial intelligence is the next challenge of research to foster the deployment of autonomous systems in the real world. In this paper, we focus on safe and explainable design and deployment of autonomous agents, e.g., robots. In particular, we present our recent contributions to: i) safe and explainable planning, leveraging on safe Reinforcement Learning (RL) and neurosymbolic planning; ii) effective deployment of RL policies via model-based control; iii) formal verification of the safety of deep RL policies; and iv) explainable anomaly detection of complex real systems. © 2024 Copyright for this paper by its authors.
KW  - Formal verification of neural networks
KW  - Neurosymbolic AI
KW  - Planning under uncertainty
KW  - Safe Reinforcement Learning
KW  - Adversarial machine learning
KW  - Autonomous agents
KW  - Reinforcement learning
KW  - Formal verification of neural network
KW  - Learning policy
KW  - Model based controls
KW  - Neural-networks
KW  - Neurosymbolic AI
KW  - Planning under uncertainty
KW  - Real-world
KW  - Reinforcement learnings
KW  - Safe reinforcement learning
KW  - Via modeling
KW  - Deep reinforcement learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Yang, W.
AU  - Chi, X.
AU  - Zhao, L.
AU  - Xiong, Z.
AU  - Jiang, W.
TI  - Task-Driven Semantic-Aware Green Cooperative Transmission Strategy for Vehicular Networks
PY  - 2023
T2  - IEEE Transactions on Communications
VL  - 71
IS  - 10
SP  - 5783
EP  - 5798
DO  - 10.1109/TCOMM.2023.3300869
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166742428&doi=10.1109%2fTCOMM.2023.3300869&partnerID=40&md5=6770c2083d19f6361e96d3ddf6e61813
AB  - Considering the infrastructure deployment cost and energy consumption, it is unrealistic to provide seamless coverage of the vehicular network. The presence of uncovered areas tends to hinder the prevalence of the in-vehicle services with large data volume. To this end, we propose a predictive cooperative multi-relay transmission strategy (PreCMTS) for the intermittently connected vehicular networks, fulfilling the 6G vision of semantic and green communications. Specifically, we introduce a task-driven knowledge graph (KG)-assisted semantic communication system, and model the KG into a weighted directed graph from the viewpoint of transmission. Meanwhile, we identify three predictable parameters about the individual vehicles to perform the following anticipatory analysis. Firstly, to facilitate semantic extraction, we derive the closed-form expression of the achievable throughput within the delay requirement. Then, for the extracted semantic representation, we formulate the mutually coupled problems of semantic unit assignment and predictive relay selection as a combinatorial optimization problem, to jointly optimize the energy efficiency and semantic transmission reliability. To find a favorable solution within limited time, we proposed a low-complexity algorithm based on Markov approximation. The promising performance gains of the PreCMTS are demonstrated by the simulations with realistic vehicle traces generated by the SUMO traffic simulator.  © 1972-2012 IEEE.
KW  - Markov approximation
KW  - proactive cooperative transmission
KW  - semantic-aware
KW  - store-carry-forward
KW  - Vehicular network
KW  - Acceleration
KW  - Approximation algorithms
KW  - Combinatorial optimization
KW  - Computational complexity
KW  - Cooperative communication
KW  - Directed graphs
KW  - Energy efficiency
KW  - Energy utilization
KW  - Job analysis
KW  - Motion planning
KW  - Motor transportation
KW  - Reliability analysis
KW  - Throughput
KW  - Vehicular ad hoc networks
KW  - Cooperative transmission
KW  - Delay
KW  - Markov approximation
KW  - Proactive cooperative transmission
KW  - Relay
KW  - Semantic-aware
KW  - Store carry forwards
KW  - Task analysis
KW  - Vehicular Adhoc Networks (VANETs)
KW  - Vehicular networks
KW  - Semantics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - JOUR
AU  - Gao, Y.
AU  - Yu, D.
AU  - Wang, S.
AU  - Wang, H.
TI  - Large Language Model Powered Site Selection Recommender System
ST  - 大语言模型驱动的选址推荐系统
PY  - 2024
T2  - Jisuanji Yanjiu yu Fazhan/Computer Research and Development
VL  - 61
IS  - 7
SP  - 1681
EP  - 1696
DO  - 10.7544/issn1000-1239.202330629
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199375173&doi=10.7544%2fissn1000-1239.202330629&partnerID=40&md5=6a98a7d890b07f71eee7b364899fb337
AB  - Site selection, as a core link in business decisions and urban infrastructure planning, plays a significant role in whether physical stores and urban infrastructure can perform as expected. The existing site selection recommender system’s data service orchestration is rather fixed and unable to make timely adjustments to different user needs. Its application scenarios are limited, and the system’s flexibility and scalability in human-computer interaction are poor. Recently, large language models (LLMs) such as GPT-4 have demonstrated powerful capabilities in intent understanding, task orchestration, code generation, and tool usage. They can accomplish tasks that traditional recommendation models struggle to balance, providing new opportunities for reshaping the recommendation process and implementing integrated recommendation services. However, site selection recommendation not only shares the common challenges of traditional recommendations but also presents unique challenges due to its reliance on spatial data. Against this backdrop, we propose a LLM-powered site selection recommendation system. Firstly, we expand the scenarios of site selection recommendation and propose a scene recommendation task of finding suitable store types based on location, combining collaborative filtering algorithms and spatial pre-training models. Secondly, we construct a site selection decision engine driven by a large language model. The language model itself has many defects in dealing with space-related tasks, such as the lack of spatial awareness, inability to understand specific locations, and the tendency to fabricate place names and addresses. In this paper, we propose a mechanism for handling spatial tasks within the language model framework. By utilizing geocoding, reverse geocoding, and address resolution tools, we enhance the model’s spatial awareness and prevent address fabrication issues. In combination with site selection recommendation models, scenario recommendation models, external knowledge bases, and map visualization, we accomplish diverse tasks in site selection recommendations. We achieve intelligent planning, execution, and attribution for site selection tasks, enhance the interaction experience of spatial service systems, and provide new design and implementation ideas for future AI-driven site selection recommender systems. © 2024 Science Press. All rights reserved.
KW  - agent
KW  - geospatial analysis
KW  - large language model
KW  - recommender system
KW  - site selection recommendation
KW  - Collaborative filtering
KW  - Computational linguistics
KW  - Human computer interaction
KW  - Site selection
KW  - Urban growth
KW  - Business decisions
KW  - Geo coding
KW  - Geo-spatial analysis
KW  - Infrastructure planning
KW  - Language model
KW  - Large language model
KW  - Physical stores
KW  - Site selection recommendation
KW  - Spatial awareness
KW  - Urban infrastructure
KW  - Recommender systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Lohner, A.
AU  - Compagno, F.
AU  - Francis, J.
AU  - Oltramari, A.
TI  - Enhancing Vision-Language Models with Scene Graphs for Traffic Accident Understanding
PY  - 2024
T2  - IAVVC 2024 - IEEE International Automated Vehicle Validation Conference, Proceedings
DO  - 10.1109/IAVVC63304.2024.10786395
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216417619&doi=10.1109%2fIAVVC63304.2024.10786395&partnerID=40&md5=f169dc89084105557c667819881d37f5
AB  - Recognizing a traffic accident is an essential part of any autonomous driving or road monitoring system. An accident can appear in a wide variety of forms, and understanding what type of accident is taking place may be useful to prevent it from reoccurring. This work focuses on classifying traffic scenes into specific accident types. We approach the problem by representing a traffic scene as a graph, where objects such as cars can be represented as nodes, and relative distances and directions between them as edges. This representation of a traffic scene is referred to as a scene graph, and can be used as input for an accident classifier. Better results are obtained with a classifier that fuses the scene graph input with visual and textual representations. This work introduces a multi-stage, multimodal pipeline that pre-processes videos of traffic accidents, encodes them as scene graphs, and aligns this representation with vision and language modalities before executing the classification task. When trained on 4 classes, our method achieves a balanced accuracy score of 57.77% on an (unbalanced) subset of the popular Detection of Traffic Anomaly (DoTA) benchmark, representing an increase of close to 5 percentage points from the case where scene graph information is not taken into account.  © 2024 IEEE.
KW  - Autonomous Driving
KW  - Foundation Models
KW  - Neuro-symbolism
KW  - Perception
KW  - Vision-Language Models
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Alfano, G.
AU  - Greco, S.
AU  - Mandaglio, D.
AU  - Parisi, F.
AU  - Shahbazian, R.
AU  - Trubitsyna, I.
TI  - Decentralized federated learning meets Physics-Informed Neural Networks
PY  - 2025
T2  - Knowledge-Based Systems
VL  - 323
C7  - 113717
DO  - 10.1016/j.knosys.2025.113717
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005862622&doi=10.1016%2fj.knosys.2025.113717&partnerID=40&md5=45182288a1e491f93c48f0d53dce98f4
AB  - The integration of domain knowledge into the learning process of artificial intelligence (AI) has received significant attention in the last few years. Most of the approaches proposed so far have focused on centralized machine learning scenarios, with less emphasis on how domain knowledge can be effectively integrated in decentralized settings. In this paper, we address this gap by evaluating the effectiveness of domain knowledge integration in distributed settings, specifically in the context of Decentralized Federated Learning (DFL). We propose the Physics-Informed DFL (PIDFL) architecture by integrating domain knowledge expressed as differential equations. We introduce a serverless data aggregation algorithm for PIDFL, prove its convergence, and discuss its computational complexity. We performed comprehensive experiments across various datasets and demonstrated that PIDFL significantly reduces average loss across diverse applications. The proposed PIDFL framework achieves on average over 40% lower test loss compared with the baseline DFLA, and outperforms benchmark approaches (FedAvg, SegGos, and Scaffold) across a variety of datasets. This highlights the potential of PIDFL and offers a promising avenue for improving decentralized learning through domain knowledge integration. © 2025 Elsevier B.V.
KW  - Deep learning
KW  - Federated learning
KW  - Heterogeneous data
KW  - Physics Informed Neural Networks (PINNs)
KW  - Deep neural networks
KW  - Domain Knowledge
KW  - Supervised learning
KW  - Centralised
KW  - Decentralised
KW  - Deep learning
KW  - Domain knowledge
KW  - Heterogeneous data
KW  - Knowledge integration
KW  - Learning process
KW  - Machine-learning
KW  - Neural-networks
KW  - Physic informed neural network
KW  - Federated learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Sun, B.
AU  - Hassan, M.
TI  - HW/SW Collaborative Techniques for Accelerating TinyML Inference Time at No Cost
PY  - 2024
T2  - Proceedings - 2024 27th Euromicro Conference on Digital System Design, DSD 2024
SP  - 512
EP  - 520
DO  - 10.1109/DSD64264.2024.00074
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211899281&doi=10.1109%2fDSD64264.2024.00074&partnerID=40&md5=b19a646356e55bed9e0aba0ecd7ae353
AB  - With the unprecedented boom in TinyML development, optimizing Artificial Intelligence (AI) inference on resource-constrained microcontrollers (M CU s) is of paramount importance. Most of the existing works focus on peak memory or computation reduction. The tasks are partitioned in the patch-based or device-based during the execution. However, it comes with a price of the latency and communication overhead. In this paper, we propose several techniques to accelerate the Convolutional Neural Networks (CNN s) inference process. These techniques are both architecture- and application-aware. From the application perspective, 1) we maximize computation reuse through instruction reordering, 2) fuse several linear layers together to improve computation patterns, and 3) enable memory reuse of intermediate buffers for improving memory behavior. From the architecture perspective, we propose techniques that take into account knowledge about underlying architecture of the MCU including 1) cache-aware and 2) multi-core parallelism-aware techniques. Those solutions only require the general MCUs features thus demonstrating board generalization across various networks and devices. These techniques come at no additional cost. It improve the inference latency without any compromise of the model accuracy or the model size. Our evaluation on a use-case from the health-care domain with real-data set for four CNNs - LeNet, AlexNet, ResNet20, and SqueezeNet - show that we achieve up to 71 % reduction in inference latency. © 2024 IEEE.
KW  - Acceleration
KW  - Blood Pressure Monitoring
KW  - Convolutional Neural Networks
KW  - HW &SW Co-Optimizations For TinyML Inference Time Acceleration
KW  - HW &SW Optimization
KW  - PPG
KW  - tinyML
KW  - Cache memory
KW  - Matrix algebra
KW  - Microcontrollers
KW  - Parallel architectures
KW  - Blood-pressure monitoring
KW  - Co-optimization
KW  - Collaborative technique
KW  - Convolutional neural network
KW  - HW &SW co-optimization for tinyml inference time acceleration
KW  - HW &SW optimization
KW  - Memory reduction
KW  - Optimisations
KW  - PPG
KW  - Tinyml
KW  - Convolutional neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Yu, X.
AU  - Thomas, A.
AU  - Moreno, I.G.
AU  - Gutierrez, L.
AU  - Rosing, T.S.
TI  - Intelligence Beyond the Edge using Hyperdimensional Computing
PY  - 2024
T2  - Proceedings - 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks, IPSN 2024
SP  - 1
EP  - 13
DO  - 10.1109/IPSN61024.2024.00005
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198550174&doi=10.1109%2fIPSN61024.2024.00005&partnerID=40&md5=eadcc110af5a050129457734ddfe6404
AB  - On-device learning has emerged as a prevailing trend that avoids the slow response time and costly communication of cloud-based learning. The ability to learn continuously and indefinitely in a changing environment, and with resource constraints, is critical for real sensor deployments. However, existing designs are inadequate for practical scenarios with (i) streaming data input, (ii) lack of supervision and (iii) limited on-board resources. In this paper, we design and deploy the first on-device lifelong learning system called LifeHD for general IoT applications with limited supervision. LifeHD is designed based on a novel neurally-inspired and lightweight learning paradigm called Hyperdimensional Computing (HDC). We utilize a two-tier associative memory organization to intelligently store and manage high-dimensional, low-precision vectors, which represent the historical patterns as cluster centroids. We additionally propose two variants of LifeHD to cope with scarce labeled inputs and power constraints. We implement LifeHD on off-the-shelf edge platforms and perform extensive evaluations across three scenarios. Our measurements show that LifeHD improves the unsupervised clustering accuracy by up to 74.8% compared to the state-of-the-art NN-based unsupervised lifelong learning baselines with as much as 34.3x better energy efficiency. Our code is available at https://github.com/Orienfish/LifeHD. © 2024 IEEE.
KW  - Edge Computing
KW  - Hyperdimensional Computing
KW  - Lifelong Learning
KW  - Associative processing
KW  - Edge computing
KW  - Energy efficiency
KW  - Changing environment
KW  - Cloud-based
KW  - Data input
KW  - Edge computing
KW  - Hyperdimensional computing
KW  - Learn+
KW  - Life long learning
KW  - Resource Constraint
KW  - Sensors deployments
KW  - Streaming data
KW  - Learning systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Khan, M.J.
AU  - Breslin, J.G.
AU  - Curry, E.
TI  - KnowZRel: Common Sense Knowledge-based Zero-Shot Relationship Retrieval for Generalised Scene Graph Generation
PY  - 2025
T2  - IEEE Transactions on Artificial Intelligence
DO  - 10.1109/TAI.2025.3544177
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218738870&doi=10.1109%2fTAI.2025.3544177&partnerID=40&md5=a697e9d52441422ee60edf4c654ed110
AB  - A scene graph is a key image representation in visual reasoning. The generalisability of Scene Graph Generation (SGG) methods is crucial for reliable reasoning and real-world applicability. However, imbalanced training datasets limit this, underrepresenting meaningful visual relationships. Current SGG methods using external knowledge sources face limitations due to these imbalances or restricted relationship coverage, impacting their reasoning and generalisation capabilities. We propose a novel neurosymbolic approach that integrates data-driven object detection with heterogeneous knowledge graph-based object refinement and zero-shot relationship retrieval, highlighting the loosely coupled synergy between neural and symbolic components. This combination addresses the limitations of imbalanced training datasets in scene graph generation and enables effective prediction of unseen visual relationships. Objects are detected using a region-based deep neural network and refined based on their positional and structural similarity, followed by retrieval of pairwise visual relationships using a heterogeneous knowledge graph. The redundant and irrelevant visual relationships are discarded based on the similarity of relationship labels and node embeddings. Finally, the visual relationships are interlinked to generate the scene graph. The employed heterogeneous knowledge graph combines diverse knowledge sources, offering rich common sense knowledge about objects and their interactions in the world. Our method, evaluated using the benchmark Visual Genome dataset and zero-shot recall (zR@K) metric, shows a 59.96% improvement over existing state-of-the-art methods, highlighting its effectiveness in generalised SGG. The object refinement step effectively improved the object detection performance by 57.1%. Additional evaluation using the GQA dataset confirms the cross-dataset generalisability of our method. We also compared various knowledge sources and embedding models to determine an optimal combination for zero-shot SGG. The source code is available at https://github.com/jaleedkhan/zsrr-sgg.  © 2020 IEEE.
KW  - common sense knowledge
KW  - image representation
KW  - neurosymbolic integration
KW  - scene graph
KW  - scene understanding
KW  - unseen relationships
KW  - visual reasoning
KW  - zero-shot retrieval
KW  - Deep neural networks
KW  - Economic and social effects
KW  - Graph embeddings
KW  - Graphitization
KW  - Image representation
KW  - Network embeddings
KW  - Zero-shot learning
KW  - Commonsense knowledge
KW  - Graph generation
KW  - Image representations
KW  - Neurosymbolic integration
KW  - Scene understanding
KW  - Scene-graphs
KW  - Shot retrieval
KW  - Unseen relationship
KW  - Visual reasoning
KW  - Zero-shot retrieval
KW  - Knowledge graph
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Zhang, Y.
AU  - Zhang, H.
AU  - Wang, Z.
AU  - Zhang, S.
AU  - Li, H.
AU  - Chen, M.
TI  - Development of an Autonomous, Explainable, Robust Robotic System for Electric Vehicle Battery Disassembly
PY  - 2023
T2  - IEEE/ASME International Conference on Advanced Intelligent Mechatronics, AIM
VL  - 2023-June
SP  - 409
EP  - 414
DO  - 10.1109/AIM46323.2023.10196256
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168411131&doi=10.1109%2fAIM46323.2023.10196256&partnerID=40&md5=e413cc32836e3df3f7a26beb73562144
AB  - The vigorous growth of the electric vehicle industry calls for efficient disassembly of used electric vehicle batteries (EVBs). Screw disassembly by robots remains a challenge due to the uncertainties in this task. In this paper, we designed an architecture of NeuroSymbolic task and motion planning, which uses neural predicates to map the sensor into a quasi-symbolic state and schedules action primitives autonomously based on current state and goal state. This architecture guarantees autonomy and explainability which is important in human-robot hybrid disassembly pipeline. In primitive implementation, a customized end-effector, accurate vision-based and force-based pose estimation are enabled to ensure the robustness of the system. The experiment shows that the proposed system can achieve 100% success rate in lab environment. We will deploy and evaluate it in the real factory environment in the future.  © 2023 IEEE.
KW  - Electric vehicles
KW  - Robot programming
KW  - Secondary batteries
KW  - Electric vehicle batteries
KW  - Human robots
KW  - Motion-planning
KW  - On currents
KW  - On-currents
KW  - Robotic systems
KW  - Symbolic state
KW  - Task planning
KW  - Uncertainty
KW  - Vehicle industry
KW  - Motion planning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - JOUR
AU  - Roy, S.
AU  - Chergui, H.
AU  - Verikoukis, C.
TI  - Toward Bridging the FL Performance-Explainability Tradeoff: A Trustworthy 6G RAN Slicing Use-Case
PY  - 2024
T2  - IEEE Transactions on Vehicular Technology
VL  - 73
IS  - 7
SP  - 10529
EP  - 10538
DO  - 10.1109/TVT.2024.3364363
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187261376&doi=10.1109%2fTVT.2024.3364363&partnerID=40&md5=fd050e652fa834ef8cef94eb0568242b
AB  - In the context of sixth-generation (6G) networks, where diverse network slices coexist, the adoption of AI-driven zero-touch management and orchestration (MANO) becomes crucial. However, ensuring the trustworthiness of AI black-boxes in real deployments is challenging. Explainable AI (XAI) tools can play a vital role in establishing transparency among the stakeholders in the slicing ecosystem. But there is a trade-off between AI performance and explainability, posing a dilemma for trustworthy 6G network slicing because the stakeholders require both highly performing AI models for efficient resource allocation and explainable decision-making to ensure fairness, accountability, and compliance. To balance this trade off and inspired by the closed loop automation and XAI methodologies, this paper presents a novel explanation-guided in-hoc federated learning (FL) approach where a constrained resource allocation model and an explainer exchange - in a closed loop (CL) fashion - soft attributions of the features as well as inference predictions to achieve a transparent 6G network slicing resource management in a RAN-Edge setup under non-independent identically distributed (non-IID) datasets. In particular, we quantitatively validate the faithfulness of the explanations via the so-called attribution-based confidence metric that is included as a constraint to guide the overall training process in the run-time FL optimization task. In this respect, Integrated-Gradient (IG) as well as Input × Gradient and SHAP are used to generate the attributions for our proposed in-hoc scheme, wherefore simulation results under different methods confirm its success in tackling the performance-explainability trade-off and its superiority over the unconstrained Integrated-Gradient post-hoc FL baseline.  © 1967-2012 IEEE.
KW  - 6G
KW  - closed-loop
KW  - federated learning
KW  - game theory
KW  - in-hoc
KW  - post-hoc
KW  - proxy-Lagrangian
KW  - resource allocation
KW  - XAI
KW  - ZSM
KW  - 5G mobile communication systems
KW  - Biological systems
KW  - Constrained optimization
KW  - Decision making
KW  - Economic and social effects
KW  - Game theory
KW  - Natural resources management
KW  - Queueing networks
KW  - 6g
KW  - 6g mobile communication
KW  - Biological system modeling
KW  - Closed-loop
KW  - Federated learning
KW  - In-hoc
KW  - Lagrangian
KW  - Mobile communications
KW  - Optimisations
KW  - Post-hoc
KW  - Proxy-lagrangian
KW  - Resource management
KW  - Resources allocation
KW  - XAI
KW  - ZSM
KW  - Resource allocation
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 9
ER  -

TY  - CONF
AU  - Schmidt, W.J.
AU  - Grangel-González, I.
AU  - Huschle, T.
AU  - Wagner, L.
AU  - Kharlamov, E.
AU  - Paschke, A.
TI  - LLM-Supported Mapping Generation for Semantic Manufacturing Treasure Hunting
PY  - 2025
T2  - Lecture Notes in Computer Science
VL  - 15719 LNCS
SP  - 84
EP  - 101
DO  - 10.1007/978-3-031-94578-6_5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007703821&doi=10.1007%2f978-3-031-94578-6_5&partnerID=40&md5=e810816f32a8b3c78e90cae303e622a2
AB  - In large manufacturing companies, such as Bosch, that operate thousands of production lines with each comprising up to dozens of production machines and other equipment, even simple inventory questions such as of location and quantities of a particular equipment type require non-trivial solutions. Addressing these questions requires to integrate multiple heterogeneous data sets which is time consuming and error prone and demands domain as well as knowledge experts. Knowledge graphs (KGs) are practical for consolidating inventory data by bringing it into the same format and linking inventory items. However, the KG creation and maintenance itself pose challenges as mappings are needed to connect data sets and ontologies. In this work, we address these challenges by exploring LLM-supported and context-enhanced YARRRML mapping generation. Facing large ontologies in the manufacturing domain and token limitations in LLM prompts, we further evaluate ontology reduction methods in our approach. Our work provides a valuable support when creating YARRRML manufacturing mappings as well as supporting data and schema updates. We evaluate our approach both quantitatively against reference mappings created manually by experts and qualitatively with expert feedback. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
KW  - Knowledge Graph Construction
KW  - LLM
KW  - Manufacturing
KW  - Mapping Generation
KW  - Ontology Reduction
KW  - YARRRML
KW  - Layered manufacturing
KW  - Metal forming
KW  - Papermaking
KW  - Photomapping
KW  - Refining
KW  - % reductions
KW  - Data set
KW  - Graph construction
KW  - Knowledge graph construction
KW  - Knowledge graphs
KW  - LLM
KW  - Mapping generations
KW  - Ontology reduction
KW  - Ontology's
KW  - YARRRML
KW  - Fabrication
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Zhao, Q.
AU  - Zou, H.
AU  - Bennis, M.
AU  - Debbah, M.
TI  - Semantic Communications
PY  - 2024
T2  - Artificial Intelligence for Future Networks
SP  - 131
EP  - 149
DO  - 10.1002/9781394227952.ch4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214171403&doi=10.1002%2f9781394227952.ch4&partnerID=40&md5=a73b82890a8329ab8c1efcefea60683b
AB  - Semantic communication transforms the transmitter and receiver pairs into teacher and student agents, which interact with each other through a semantic representation of the underlying information structure. Such representation must satisfy key properties of minimalism (least sufficient bits), generalizability (across different domains) and efficiency (high fidelity generation). Machine learning plays a key role in semantic communication, where generative artificial intelligence (AI) shows strong capabilities in semantic understanding and reasoning. In this chapter, we provide a holistic view on the role of semantic communication as a powerhouse of native AI networks in 6G and beyond, followed by technical insights into the mathematical theories and technologies of semantic communications leveraging machine learning and generative AI. © 2025 by The Institute of Electrical and Electronics Engineers, Inc. All rights reserved.
KW  - 6G
KW  - Emergent protocol
KW  - Generative AI
KW  - Large language model
KW  - Semantic communication
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Delfosse, Q.
AU  - Sztwiertnia, S.
AU  - Rothermel, M.
AU  - Stammer, W.
AU  - Kersting, K.
TI  - Interpretable Concept Bottlenecks to Align Reinforcement Learning Agents
PY  - 2024
T2  - Advances in Neural Information Processing Systems
VL  - 37
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000528063&partnerID=40&md5=528b16e1c5308889dc795d1f10ce0386
AB  - Goal misalignment, reward sparsity and difficult credit assignment are only a few of the many issues that make it difficult for deep reinforcement learning (RL) agents to learn optimal policies. Unfortunately, the black-box nature of deep neural networks impedes the inclusion of domain experts for inspecting the model and revising suboptimal policies. To this end, we introduce Successive Concept Bottleneck Agents (SCoBots), that integrate consecutive concept bottleneck (CB) layers. In contrast to current CB models, SCoBots do not just represent concepts as properties of individual objects, but also as relations between objects which is crucial for many RL tasks. Our experimental results2 provide evidence of SCoBots' competitive performances, but also of their potential for domain experts to understand and regularize their behavior. Among other things, SCoBots enabled us to identify a previously unknown misalignment problem in the iconic video game, Pong, and resolve it. Overall, SCoBots thus result in more human-aligned RL agents. © 2024 Neural information processing systems foundation. All rights reserved.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Yu, Y.
AU  - Wang, H.
AU  - Zong, L.
AU  - Chen, B.
AU  - Li, Y.
AU  - Yu, X.
TI  - ChatMolData: A Multimodal Agent for Automatic Molecular Data Processing
PY  - 2025
T2  - Advanced Intelligent Systems
DO  - 10.1002/aisy.202401089
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006855098&doi=10.1002%2faisy.202401089&partnerID=40&md5=879feee034737f90054403675c8f9ed6
AB  - In recent years, the development of large language models (LLMs) has revolutionized various fields of natural science. However, their application in dealing with various molecular data remains constrained due to the reliance on single-modality inputs and outputs. ChatMolData, a novel LLM-based multimodal agent designed to handle diverse molecular data forms, including molecular databases, images, structure-specific files, and unstructured and structured documents, is introduced. ChatMolData integrates the capabilities of LLMs (e.g., GPT-4 and GPT-3.5) with the robust toolset that supports data retrieval, structuring, prediction, visualization, and search tasks. The agent employs a systematic cycle of reasoning and action to efficiently process complex tasks in molecular science. The evaluation demonstrates that ChatMolData achieves over 90% accuracy for 128 diverse tasks, effectively bridging the gap between experimenters and computational tools. Moreover, it is anticipated that the multimodal-agent strategy provides a pathway to expand data size and improve data accessibility, ultimately promoting molecular research and innovation. © 2025 The Author(s). Advanced Intelligent Systems published by Wiley-VCH GmbH.
KW  - cheminformatics
KW  - data mining
KW  - large language models
KW  - multimodal agents
KW  - Data streams
KW  - Data structures
KW  - Data visualization
KW  - Natural language processing systems
KW  - Sorting
KW  - Cheminformatics
KW  - Database images
KW  - Image Structures
KW  - Input and outputs
KW  - Language model
KW  - Large language model
KW  - Model-based OPC
KW  - Molecular data
KW  - Molecular database
KW  - Multi-modal agent
KW  - Data reduction
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Purohit, D.
AU  - Chudasama, Y.
AU  - Rivas, A.
AU  - Vidal, M.-E.
TI  - SPaRKLE : Symbolic caPtuRing of knowledge for Knowledge graph enrichment with LEarning
PY  - 2023
T2  - K-CAP 2023 - Proceedings of the 12th Knowledge Capture Conference 2023
SP  - 44
EP  - 52
DO  - 10.1145/3587259.3627547
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180366887&doi=10.1145%2f3587259.3627547&partnerID=40&md5=d94901430851931191e17afb9df5c46d
AB  - Knowledge graphs (KGs) naturally capture the convergence of data and knowledge, making them expressive frameworks for describing and integrating heterogeneous data in a coherent and interconnected manner. However, based on the Open World Assumption (OWA), the absence of information within KGs does not indicate falsity or non-existence; it merely reflects incompleteness. Inductive learning over KGs involves predicting new relationships based on existing statements in the KG, using either numerical or symbolic learning models. The Partial Completeness Assumption (PCA) heuristic efficiently guides inductive learning methods for Link Prediction (LP) by refining predictions about absent KG relationships. Nevertheless, numeric techniques- like KG embedding models- alone may fall short in accurately predicting missing information, particularly when it comes to capturing implicit knowledge and complex relationships. We propose a hybrid method named SPaRKLE that seamlessly integrates symbolic and numerical techniques, leveraging the PCA heuristic to capture implicit knowledge and enrich KGs. We empirically compare SPaRKLE with state-of-the-art KG embedding and symbolic models, using established benchmarks. Our experimental outcomes underscore the efficacy of this hybrid approach, as it harnesses the strengths of both paradigms. SPaRKLE is publicly available on GitHub1. © 2023 Owner/Author.
KW  - Inductive Learning
KW  - Knowledge Graphs
KW  - Symbolic Learning
KW  - Graph embeddings
KW  - Heuristic methods
KW  - Knowledge graph
KW  - Knowledge management
KW  - Numerical methods
KW  - Graph embeddings
KW  - Heterogeneous data
KW  - Implicit knowledge
KW  - Inductive learning
KW  - Inductive learning methods
KW  - Knowledge graphs
KW  - Learning models
KW  - Non-existence
KW  - Open world assumption
KW  - Symbolic learning
KW  - Forecasting
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - CONF
AU  - Diveev, A.
AU  - Shmalko, E.
TI  - Synthesized optimal control based on machine learning
PY  - 2021
T2  - Journal of Physics: Conference Series
VL  - 1727
IS  - 1
C7  - 012006
DO  - 10.1088/1742-6596/1727/1/012006
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101679226&doi=10.1088%2f1742-6596%2f1727%2f1%2f012006&partnerID=40&md5=718c11bdf06dc82ceb485213ca462ade
AB  - The article discusses symbolic regression methods as a machine learning technology. The technique is tested on a complex problem of control systems synthesis. A new type of control based on changing the position of a stable equilibrium point is proposed. The implementation of such control requires the construction of a double feedback loop. The inner contour ensures the stability of the control object relative to some point in the state space. The outer contour provides optimal controlof the stable equilibrium point position. To implement control, symbolic regression methods are used as machine learning technologies. It is shown that such a control is the least sensitive to external disturbances and model uncertainties. © Published under licence by IOP Publishing Ltd.
KW  - Big data
KW  - Control system synthesis
KW  - Regression analysis
KW  - Turing machines
KW  - Uncertainty analysis
KW  - Complex problems
KW  - Double feedback loop
KW  - External disturbances
KW  - Machine learning technology
KW  - Model uncertainties
KW  - Optimal controls
KW  - Stable equilibrium points
KW  - Symbolic regression
KW  - Machine learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Achuthan, K.
AU  - Ramanathan, S.
AU  - Srinivas, S.
AU  - Raman, R.
TI  - Advancing cybersecurity and privacy with artificial intelligence: current trends and future research directions
PY  - 2024
T2  - Frontiers in Big Data
VL  - 7
C7  - 1497535
DO  - 10.3389/fdata.2024.1497535
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212710944&doi=10.3389%2ffdata.2024.1497535&partnerID=40&md5=7ab5443b251712910644860e5fd2dcda
AB  - Introduction: The rapid escalation of cyber threats necessitates innovative strategies to enhance cybersecurity and privacy measures. Artificial Intelligence (AI) has emerged as a promising tool poised to enhance the effectiveness of cybersecurity strategies by offering advanced capabilities for intrusion detection, malware classification, and privacy preservation. However, this work addresses the significant lack of a comprehensive synthesis of AI's use in cybersecurity and privacy across the vast literature, aiming to identify existing gaps and guide further progress. Methods: This study employs the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework for a comprehensive literature review, analyzing over 9,350 publications from 2004 to 2023. Utilizing BERTopic modeling, 14 key themes in AI-driven cybersecurity were identified. Topics were clustered and validated through a combination of algorithmic and expert-driven evaluations, focusing on semantic relationships and coherence scores. Results: AI applications in cybersecurity are concentrated around intrusion detection, malware classification, federated learning in privacy, IoT security, UAV systems and DDoS mitigation. Emerging fields such as adversarial machine learning, blockchain and deep learning are gaining traction. Analysis reveals that AI's adaptability and scalability are critical for addressing evolving threats. Global trends indicate significant contributions from the US, India, UK, and China, highlighting geographical diversity in research priorities. Discussion: While AI enhances cybersecurity efficacy, challenges such as computational resource demands, adversarial vulnerabilities, and ethical concerns persist. More research in trustworthy AI, standardizing AI-driven methods, legislations for robust privacy protection amongst others is emphasized. The study also highlights key current and future areas of focus, including quantum machine learning, explainable AI, integrating humanized AI and deepfakes. Copyright © 2024 Achuthan, Ramanathan, Srinivas and Raman.
KW  - artificial intelligence
KW  - cryptography
KW  - cybersecurity
KW  - ethics
KW  - explainable AI
KW  - privacy
KW  - quantum
KW  - topic modeling
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - JOUR
AU  - King, T.
AU  - Zhou, Y.
AU  - Röddiger, T.
AU  - Beigl, M.
TI  - MicroNAS for memory and latency constrained hardware aware neural architecture search in time series classification on microcontrollers
PY  - 2025
T2  - Scientific Reports
VL  - 15
IS  - 1
C7  - 7575
DO  - 10.1038/s41598-025-90764-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000217173&doi=10.1038%2fs41598-025-90764-z&partnerID=40&md5=eec3e0fdceed31de1f788b8bc65b8abc
AB  - The use and research of neural networks on very small processor systems are currently still limited. One of the main reasons is that the design of microcontroller-architecture-aware ML models that take into account user-defined constraints on memory consumption and run-time are very difficult to implement. Therefore, we adapt the concept of differentiable neural architecture search (DNAS) to solve the time series classification problem on resource-constrained microcontrollers (MCUs). This paper explores and demonstrates for the first time that this problem can be solved using Neural Architecture Search (NAS). The key of our specific hardware-aware approach, MicroNAS, is an integration of a DNAS approach, Latency Lookup Tables, Dynamic Convolutions and a novel search space specifically designed for time series classification on MCUs. The resulting system is hardware-aware and can generate neural network architectures that satisfy user-defined limits on execution latency and peak memory consumption. To support our findings, we evaluate MicroNAS under different latency and peak memory constraints. The experiments highlight the ability of MicroNAS to find trade-offs between latency and classification performance across all dataset and microcontroller combinations. As an example, on the UCI-HAR dataset, MicroNAS achieves an accuracy of 94.62% when allowed 25 ms and 98.86% when allowed 50 ms when running on the Nucleo-L552ZE-Q. The much more powerful Arduino Portenta, on the other hand, achieves an accuracy of 95.88% with an allowance of 3 ms and 99.37% when allowed 25 ms displaying the ability of MicroNAS to adapt to different microcontrollers. MicroNAS is also able to find architectures which perform similarly to state-of-the-art systems designed to run on desktop computers (99.62% vs. 99.65% accuracy on the UCI-HAR dataset and 97.83% vs. 97.46% accuracy on the SkodaR dataset). © The Author(s) 2025.
KW  - article
KW  - classification
KW  - controlled study
KW  - desktop computer
KW  - human experiment
KW  - latent period
KW  - machine learning
KW  - memory
KW  - nerve cell
KW  - nerve cell network
KW  - normal human
KW  - time series analysis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Nagpal, P.
AU  - Aggarwal, S.
AU  - Sharma, A.
AU  - Datta, A.
AU  - Kuzieva, N.
AU  - Gurusamy, M.
TI  - Revolutionizing Human Resources for Safer Automotive Work Environments
PY  - 2025
T2  - AI's role in enhanced automotive safety
SP  - 501
EP  - 514
DO  - 10.4018/979-8-3373-0442-7.ch032
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006521694&doi=10.4018%2f979-8-3373-0442-7.ch032&partnerID=40&md5=0558df82aeed727f2cb1cee6ac3742c2
AB  - The automotive sector must be guaranteed to reduce injuries and enhance worker wellbeing. Based on historical incident data and real-time sensor data, this research suggests a Random Forest classifier with Principal Component Analysis for feature extraction to forecast workplace safety hazards. By reducing dimensionality, PCA increases computational efficiency while maintaining important safety-related characteristics. Because of its resilience in managing a variety of safety characteristics, such as worker tiredness levels, machine performance, and environmental factors, the Random Forest classifier was selected. To anticipate high-risk areas and identify possible hazards, the model is trained using historical workplace accident statistics. According to the results, this AI-powered strategy improves predictive accuracy and helps HR put proactive safety measures like early hazard detection and efficient shift scheduling into place. This research shows how machine learning has the ability to completely transform human resource safety management in the automotive industry © 2025 by IGI Global Scientific Publishing. All rights reserved.
KW  - Compensation (personnel)
KW  - Automotive sector
KW  - Automotives
KW  - Incident data
KW  - Principal-component analysis
KW  - Random forest classifier
KW  - Real time sensors
KW  - Sensors data
KW  - Wellbeing
KW  - Work environments
KW  - Workers'
KW  - Health hazards
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Mentzas, G.
AU  - Fikardos, M.
AU  - Lepenioti, K.
AU  - Apostolou, D.
TI  - Exploring the landscape of trustworthy artificial intelligence: Status and challenges
PY  - 2024
T2  - Intelligent Decision Technologies
VL  - 18
IS  - 2
SP  - 837
EP  - 854
DO  - 10.3233/IDT-240366
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196891627&doi=10.3233%2fIDT-240366&partnerID=40&md5=b79737218d7eef392c723e5e38553969
AB  - Artificial Intelligence (AI) has pervaded everyday life, reshaping the landscape of business, economy, and society through the alteration of interactions and connections among stakeholders and citizens. Nevertheless, the widespread adoption of AI presents significant risks and hurdles, sparking apprehension regarding the trustworthiness of AI systems by humans. Lately, numerous governmental entities have introduced regulations and principles aimed at fostering trustworthy AI systems, while companies, research institutions, and public sector organizations have released their own sets of principles and guidelines for ensuring ethical and trustworthy AI. Additionally, they have developed methods and software toolkits to aid in evaluating and improving the attributes of trustworthiness. The present paper aims to explore this evolution by analysing and supporting the trustworthiness of AI systems. We commence with an examination of the characteristics inherent in trustworthy AI, along with the corresponding principles and standards associated with them. We then examine the methods and tools that are available to designers and developers in their quest to operationalize trusted AI systems. Finally, we outline research challenges towards end-to-end engineering of trustworthy AI by-design. © 2024 – The authors.
KW  - human-AI
KW  - methods
KW  - principles
KW  - responsible AI
KW  - trust
KW  - Trustworthy artificial intelligence
KW  - Artificial intelligence
KW  - Economic and social effects
KW  - Artificial intelligence systems
KW  - Company research
KW  - Economy and society
KW  - Human-artificial intelligence
KW  - Method
KW  - Principle
KW  - Research institutions
KW  - Responsible artificial intelligence
KW  - Trust
KW  - Trustworthy artificial intelligence
KW  - Ethical technology
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - JOUR
AU  - Islam, M.S.
AU  - Kabir, M.N.
AU  - Ghani, N.A.
AU  - Zamli, K.Z.
AU  - Zulkifli, N.S.A.
AU  - Rahman, M.M.
AU  - Moni, M.A.
TI  - "Challenges and future in deep learning for sentiment analysis: a comprehensive review and a proposed novel hybrid approach"
PY  - 2024
T2  - Artificial Intelligence Review
VL  - 57
IS  - 3
C7  - 62
DO  - 10.1007/s10462-023-10651-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185476548&doi=10.1007%2fs10462-023-10651-9&partnerID=40&md5=70625801cd432f02ba1f9202d7464651
AB  - Social media is used to categorise products or services, but analysing vast comments is time-consuming. Researchers use sentiment analysis via natural language processing, evaluating methods and results conventionally through literature reviews and assessments. However, our approach diverges by offering a thorough analytical perspective with critical analysis, research findings, identified gaps, limitations, challenges and future prospects specific to deep learning-based sentiment analysis in recent times. Furthermore, we provide in-depth investigation into sentiment analysis, categorizing prevalent data, pre-processing methods, text representations, learning models, and applications. We conduct a thorough evaluation of recent advances in deep learning architectures, assessing their pros and cons. Additionally, we offer a meticulous analysis of deep learning methodologies, integrating insights on applied tools, strengths, weaknesses, performance results, research gaps, and a detailed feature-based examination. Furthermore, we present in a thorough discussion of the challenges, drawbacks, and factors contributing to the successful enhancement of accuracy within the realm of sentiment analysis. A critical comparative analysis of our article clearly shows that capsule-based RNN approaches give the best results with an accuracy of 98.02% which is the CNN or RNN-based models. We implemented various advanced deep-learning models across four benchmarks to identify the top performers. Additionally, we introduced the innovative CRDC (Capsule with Deep CNN and Bi structured RNN) model, which demonstrated superior performance compared to other methods. Our proposed approach achieved remarkable accuracy across different databases: IMDB (88.15%), Toxic (98.28%), CrowdFlower (92.34%), and ER (95.48%). Hence, this method holds promise for automated sentiment analysis and potential deployment. © The Author(s) 2024.
KW  - Attention
KW  - Capsule network
KW  - Classifiers
KW  - Deep learning
KW  - Neural network (NN)
KW  - Sentiment analysis (SA)
KW  - Data handling
KW  - Deep neural networks
KW  - Learning systems
KW  - Attention
KW  - Capsule network
KW  - Deep learning
KW  - Hybrid approach
KW  - Learning models
KW  - Neural network
KW  - Neural-networks
KW  - Performance
KW  - Sentiment analyse
KW  - Sentiment analysis
KW  - Sentiment analysis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 41
ER  -

TY  - JOUR
AU  - Watson, R.
TI  - The Virtual Economy of the Metaverse: Computer Vision and Deep Learning Algorithms, Customer Engagement Tools, and Behavioral Predictive Analytics
PY  - 2022
T2  - Linguistic and Philosophical Investigations
VL  - 21
SP  - 41
EP  - 56
DO  - 10.22381/lpi2120223
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135560682&doi=10.22381%2flpi2120223&partnerID=40&md5=d8b300f0d6f9304770fc5fdaa24168e4
AB  - The purpose of this study is to examine the virtual economy of the metaverse in terms of computer vision and deep learning algorithms, customer engagement tools, and behavioral predictive analytics. In this article, I cumulate previous research findings indicating that tailored services in the virtual economy focus on customer retention, increased brand recognition, and optimized digital shopping experiences, by tracking consumer sentiment, behavior, and engagement, thus improving business competitiveness. I contribute to the literature on optimized purchase behavior as regards items traded in the metaverse by showing that customer engagement and product data management can optimize brand visibility and per-formance, increasing average order and customer lifetime value. Throughout February 2022, I performed a quantitative literature review of the Web of Science, Scopus, and ProQuest databases, with search terms including “metaverse” + “virtual economy,” “computer vision algorithms,” “deep learning algorithms,” “customer engagement tools,” and “behavioral predictive analytics.” As I inspected research published between 2021 and 2022, only 82 articles satisfied the eligibility criteria. By eliminating controversial findings, outcomes unsubstantiated by replication, too imprecise material, or having similar titles, I decided upon 16, generally empirical, sources. Data visualization tools: Dimensions (bibliometric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AXIS, Dedoose, MMAT, and SRDR. © 2022, Addleton Academic Publishers. All rights reserved.
KW  - algorithm
KW  - analytics
KW  - customer
KW  - economy
KW  - metaverse
KW  - virtual
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 37
ER  -

TY  - JOUR
AU  - Pacheco-Velazquez, E.
AU  - Rodes-Paragarino, V.
AU  - Marquez-Uribe, A.
TI  - Exploring educational simulation platform features for addressing complexity in Industry 4.0: a qualitative analysis of insights from logistics experts
PY  - 2024
T2  - Frontiers in Education
VL  - 9
C7  - 1331911
DO  - 10.3389/feduc.2024.1331911
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188508399&doi=10.3389%2ffeduc.2024.1331911&partnerID=40&md5=c2bcd2e4d188ba8dc87236a4a93b8553
AB  - Introduction: This study explores the transformative impact of Industry 4.0 on industrial operations, emphasizing the integration of advanced technologies like AI, IoT, and Big Data Analytics to enhance process optimization, automation, and connectivity. Despite its potential for efficiency, Industry 4.0 introduces significant complexities, challenging existing operational and decision-making frameworks. Addressing these challenges, the research investigates the role of simulation platforms in logistics, seeking to identify their critical attributes for effective complexity management. It highlights the need for innovative tools in system evaluation, performance measurement, and skill development, aiming to equip the workforce with essential Industry 4.0 competencies. Through qualitative insights from logistics experts, the study aims to offer practical recommendations for educators and industry professionals, contributing to the design and implementation of educational simulations that align with the intricate demands of Industry 4.0 logistics. Methods: This study employs a qualitative content analysis approach to develop an Industry 4.0-adapted logistics simulator, leveraging the Asteraceae framework for digital game co-design and pedagogical reflection. Data were collected from six industry and academia experts through semi-structured interviews, designed around the framework’s key steps to explore simulator design, decision-making, impact, and skill development. Utilizing convenience sampling, the research engaged participants with experience in educational logistics platforms and simulators. Interviews were conducted online, with ethical considerations including informed consent. Transcription used OpenAI’s API for accuracy, followed by manual review. The analysis combined qualitative content with frequency analysis, employing Atlas.ti software to identify and code key simulation features as informed by expert insights. This methodology underscores a comprehensive approach to understanding and innovating logistics education for Industry 4.0, aiming to equip learners with necessary competencies through targeted simulation tools. Results: The study’s findings emphasize the critical role of simulation tools in Industry 4.0 logistics for risk mitigation, operational planning, and decision-making. Experts pointed out the significant benefits of simulations in providing safe spaces for experimentation, especially valuable for SMEs with limited access to advanced technologies. They advocated for simulators to incorporate current technological and e-commerce trends, suggesting a customizable business model based on diverse logistics requirements. Key insights included the necessity for adaptable simulation architectures to handle various operational variables, the importance of integrating multidisciplinary competencies like data analytics and strategic management, and the role of performance metrics in evaluating simulations and logistics operations. The analysis revealed essential features for an educational logistics simulator, highlighting the importance of operational knowledge, predictive analytics, and the need for a comprehensive tool that integrates technology, strategy, operations, and data analysis. This approach aims to equip users with the skills necessary for navigating the complexities of modern logistics, promoting a deep understanding of systems thinking and complex reasoning skills. Discussion: The discussion centers on the essential requirement for a multidisciplinary approach in creating an educational logistics simulator for Industry 4.0, emphasizing the need for technological adaptability and operational efficiency. It highlights the importance of integrating advanced technologies and collaborative paradigms to enhance logistics operations and improve decision-making processes. The utility of simulation-based learning as a pedagogical tool is acknowledged, with an emphasis on its role in developing complex thinking and practical skills relevant to the digital transformation of the logistics sector. The discussion suggests that educational simulations are poised to play a pivotal role in preparing the workforce for Industry 4.0 challenges by bridging technological advancements and pedagogical strategies. However, it also points to the limitations of the current study, such as its sampling method and regional focus, and calls for future research to explore broader applications and the integration of comprehensive strategies to ensure the educational simulator’s effectiveness and relevance in a global context. Copyright © 2024 Pacheco-Velazquez, Rodes-Paragarino and Marquez-Uribe.
KW  - complex thinking
KW  - educational innovation
KW  - higher education
KW  - Industry 4.0
KW  - logistics education
KW  - serious games
KW  - simulators
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Zhang, Q.
TI  - Secure Preschool Education Using Machine Learning and Metaverse Technologies
PY  - 2023
T2  - Applied Artificial Intelligence
VL  - 37
IS  - 1
C7  - 2222496
DO  - 10.1080/08839514.2023.2222496
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162709505&doi=10.1080%2f08839514.2023.2222496&partnerID=40&md5=6ddbaaf38a41a53cbf7faf11314b5273
AB  - The metaverse concept represents a revolutionary advancement in technology that merges various aspects of our physical world into a cohesive and interconnected digital realm. Through the utilization of advanced mixed reality technologies, individuals are granted the ability to immerse themselves completely in a three-dimensional internet experience, thereby unlocking a myriad of unprecedented opportunities and functionalities. By seamlessly integrating virtual reality, augmented reality, and the internet, the metaverse facilitates a parallel universe that caters to a diverse range of activities. One of its key strengths lies in the social aspect, enabling people to connect and interact with friends, family, and even strangers in a virtual environment that mirrors real-world interactions. These interactions can take place through lifelike avatars, enabling individuals to engage in conversations, activities, and collaborations as if they were physically present. Furthermore, the metaverse empowers educational institutions to leverage its capabilities for immersive and interactive learning experiences. By utilizing machine learning algorithms and metaverse technologies, preschool education can be transformed into a secure and enriching environment for young learners. Machine learning algorithms can adapt and personalize educational content based on individual students’ needs and progress, ensuring a tailored and effective learning experience. Within the metaverse, preschoolers can explore virtual worlds, participate in interactive simulations, and engage in educational games designed to enhance their cognitive and social development. These experiences can be designed to align with educational frameworks and curricula, providing a structured and engaging learning environment. However, as the metaverse evolves and new features are introduced, it is vital to address potential cybersecurity concerns. The seamless integration of various technologies and the vast amount of user data being generated within the metaverse necessitate robust security measures. Cybersecurity protocols must be implemented to safeguard user identities, protect personal data, and ensure a secure digital environment. Implementing encryption techniques, multi-factor authentication, and advanced access controls can help mitigate security risks within the metaverse. Regular security audits and vulnerability assessments should be conducted to identify and address potential weaknesses. Additionally, continuous monitoring and threat detection systems are essential to detect and respond to any malicious activities or unauthorized access attempts. By prioritizing cybersecurity within the metaverse, preschool education can fully harness the potential of machine learning and metaverse technologies while providing a safe and enriching environment for young learners. This approach ensures that children can explore, learn, and interact within the metaverse with confidence and without compromising their privacy or security. © 2023 The Author(s). Published with license by Taylor & Francis Group, LLC.
KW  - Computer aided instruction
KW  - E-learning
KW  - Economic and social effects
KW  - Engineering education
KW  - Learning algorithms
KW  - Learning systems
KW  - Machine learning
KW  - Mixed reality
KW  - Social aspects
KW  - Cyber security
KW  - Diverse range
KW  - Learning experiences
KW  - Machine learning algorithms
KW  - Machine-learning
KW  - Metaverses
KW  - Mixed reality technologies
KW  - Parallel universe
KW  - Physical world
KW  - Preschool education
KW  - Augmented reality
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 40
ER  -

TY  - JOUR
AU  - Yuan, Q.
AU  - Fu, X.
AU  - Li, Z.
AU  - Luo, G.
AU  - Li, J.
AU  - Yang, F.
TI  - GraphComm: Efficient Graph Convolutional Communication for Multiagent Cooperation
PY  - 2021
T2  - IEEE Internet of Things Journal
VL  - 8
IS  - 22
SP  - 16359
EP  - 16369
DO  - 10.1109/JIOT.2021.3097947
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111023495&doi=10.1109%2fJIOT.2021.3097947&partnerID=40&md5=4670b822374d89740edbc5cb6d903b44
AB  - Artificial intelligence-empowered smart things (e.g., robots, autonomous vehicles, and unmanned aerial vehicles) have been transforming the world. The 'brains' of smart things can be abstracted as the agents or cybertwins residing on end devices and edge servers. The next-generation communication networks (i.e., 6G) will become the nervous system for these agents and natively support multiagent cooperation. By sharing local observations and intentions via communication channels, the agents could better understand the environments and make right decisions. Due to the limited channel bandwidth, the communication is considered as a bottleneck of multiagent cooperation. In this article, we propose a graph convolutional communication method (GraphComm) for multiagent cooperation to relive the bottleneck. Specifically, a variational information bottleneck is used to encode the observations and intentions compactly. Furthermore, a graph information bottleneck with the attention-based neighbor sampling mechanism is utilized to improve the effectiveness and robustness of the multiround communication process. The experimental results show that GraphComm can improve the effectiveness, robustness, and efficiency of communication in multiagent cooperative tasks as compared to baseline methods. © 2014 IEEE.
KW  - Deep reinforcement learning
KW  - graph convolution
KW  - information bottleneck (IB)
KW  - multiagent communication
KW  - Antennas
KW  - Convolution
KW  - Multi agent systems
KW  - Communication method
KW  - Communication process
KW  - Graph information
KW  - Information bottleneck
KW  - Local observations
KW  - Multi agent cooperation
KW  - Next generation communication network
KW  - Sampling mechanisms
KW  - Cooperative communication
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 13
ER  -

TY  - CONF
AU  - Zhukov, A.
AU  - Benois-Pineau, J.
AU  - Rivero, A.
AU  - Zemmari, A.
AU  - Mosbah, M.
AU  - Crispiani, D.
TI  - A Hybrid AI system for fusion of object and context information: application to the rail line defect detection
PY  - 2024
T2  - Proceedings - International Workshop on Content-Based Multimedia Indexing
DO  - 10.1109/CBMI62980.2024.10859237
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218212777&doi=10.1109%2fCBMI62980.2024.10859237&partnerID=40&md5=27b72ee722e271c697f2d272b17bd137
AB  - A hybrid artificial intelligence (Hybrid AI) which represents a convergence of a classical (symbolic) AI with recent machine learning approaches has become a very quickly developing research axis. The combination of rule-based reasoning and statistical learning is required whenever the domain knowledge has to be incorporated in the decision system. In this work we present a system on the basis of Deep Neural Networks (DNNs) as object detectors, such as You Only Look Once version 8 (YOLOv8), transformers and logical rules which link objects and their context in the problem of rail line defect detection. Fusion of information is performed at the intermediate level - in the feature space, mixing sets of elements of this space delimited due to the object and context element detectors. Combination of objects and context elements is performed accordingly to the domain-defined rules, and fusion is ensured by a vision transformer. Experiments have been conducted on the domain-recorded dataset of rail defects. The proposed hybrid system outperforms base-line objects detection up to 0.28 of accuracy increase. © 2024 IEEE.
KW  - deep learning
KW  - hybrid AI
KW  - image
KW  - neural networks
KW  - object detection
KW  - Contrastive Learning
KW  - Deep neural networks
KW  - Context elements
KW  - Deep learning
KW  - Defect detection
KW  - Hybrid AI
KW  - Hybrid artificial intelligence systems
KW  - Image
KW  - Line defects
KW  - Neural-networks
KW  - Objects detection
KW  - Rail lines
KW  - Adversarial machine learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Xing, C.
AU  - Lv, J.
AU  - Luo, T.
AU  - He, X.
AU  - Zhang, Z.
TI  - An N-ary Based Reliable Semantic Communication System With A Correction and Reasoning Approach
PY  - 2025
T2  - IEEE Internet of Things Journal
DO  - 10.1109/JIOT.2025.3571962
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006000855&doi=10.1109%2fJIOT.2025.3571962&partnerID=40&md5=3aaabda9c0d9abf653f1598f5991f9b3
AB  - Semantic communication systems enhance communication efficiency and task performance by understanding the semantics of transmitted information, offering broad application prospects. Nevertheless, existing semantic communication systems struggle to handle information with complex relational semantics. Motivated by this limitation, this paper proposes the n-ary relation semantic communication system with correction and reasoning (NRSC-CR). In NRSC-CR, semantic information is extracted from transmitted texts into n-ary relations. To enhance robustness against wireless channel influence, a correction algorithm based on the rationality of primary triplets and auxiliary information pairs (CPA) is introduced at the receiver. Furthermore, by deeply learning the interactions within and between n-ary relations, a reasoning algorithm based on global and local dependency (RGL) is proposed to address the performance degradation caused by excessive influence under low signal-to-noise ratio (SNR) conditions. Extensive simulation results show that the proposed NRSC-CR has advantages in understanding complex relational semantics, channel robustness, and data transmission efficiency. © 2014 IEEE.
KW  - n-ary relation
KW  - Semantic communication
KW  - semantic correction
KW  - semantic reasoning
KW  - Communication task
KW  - Communications systems
KW  - Correction approaches
KW  - N-ary relation
KW  - Reasoning approach
KW  - Relation semantics
KW  - Relational semantics
KW  - Semantic communication
KW  - Semantic correction
KW  - Semantic reasoning
KW  - Data communication systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Wheeler, D.
AU  - Natarajan, B.
TI  - Engineering Semantic Communication: A Survey
PY  - 2023
T2  - IEEE Access
VL  - 11
SP  - 13965
EP  - 13995
DO  - 10.1109/ACCESS.2023.3243065
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148447873&doi=10.1109%2fACCESS.2023.3243065&partnerID=40&md5=710534a527e3580ed7c2a5462679f136
AB  - As the global demand for data has continued to rise exponentially, some have begun turning to the idea of semantic communication as a means of efficiently meeting this demand. Pushing beyond the boundaries of conventional communication systems, semantic communication focuses on the accurate recovery of the meaning conveyed from source to receiver, as opposed to the accurate recovery of transmitted symbols. In this survey, we aim to provide a comprehensive view of the history and current state of semantic communication and the techniques for engineering this higher level of communication. A survey of the current literature reveals four broad approaches to engineering semantic communication. We term the earliest of these approaches classical semantic information, which seeks to extend information-theoretic results to include semantic information. A second approach makes use of knowledge graphs to achieve semantic communication, and a third utilizes the power of modern deep learning techniques to facilitate this communication. The fourth approach focuses on the significance of information, rather than its meaning, to achieve efficient, goal-oriented communication. We discuss each of these four approaches and their corresponding studies in detail, and provide some challenges and opportunities that pertain to each approach. Finally, we introduce a novel approach to semantic communication, which we term context-based semantic communication. Inspired by the way in which humans naturally communicate with one another, this context-based approach provides a general, optimization-based design framework for semantic communication systems. Together, this survey provides a useful guide for the design and implementation of semantic communication systems. © 2013 IEEE.
KW  - 6G
KW  - beyond-5G
KW  - semantic communication
KW  - semantic information theory
KW  - 5G mobile communication systems
KW  - Deep learning
KW  - Semantic Web
KW  - 5g mobile communication
KW  - 6g
KW  - 6g mobile communication
KW  - Beyond-5g
KW  - Communications systems
KW  - Mobile communications
KW  - Receiver
KW  - Semantic communication
KW  - Semantic information theories
KW  - Semantic-Web
KW  - Symbol
KW  - Information theory
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 34
ER  -

TY  - CONF
AU  - Han, C.
AU  - Fu, X.
AU  - Liang, Y.
TI  - Link Prediction and Node Classification on Citation Network
PY  - 2023
T2  - 2023 IEEE International Conference on Sensors, Electronics and Computer Engineering, ICSECE 2023
SP  - 428
EP  - 431
DO  - 10.1109/ICSECE58870.2023.10263374
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175085091&doi=10.1109%2fICSECE58870.2023.10263374&partnerID=40&md5=e8be6baf1e4de2220645d15bb14e1575
AB  - In this project, we use Graph Convolutional Networks model to do link prediction and node classification on citation network. Then we compare the performance of this model to benchmark methods, including common neighbors, jaccard coefficient, multilayer perceptron and support vector machine. However, GCN can be difficult to interpret and explain. In order to improve the explainability of the model, we add attention mechanism to original GCN and extract top-5 attention weights and their corresponding edges. In this way, we can better understand the model's decision making process.  © 2023 IEEE.
KW  - graph attention network
KW  - graph convolutional network
KW  - link prediction
KW  - node classification
KW  - Benchmarking
KW  - Convolution
KW  - Convolutional neural networks
KW  - Decision making
KW  - Graph theory
KW  - Support vector machines
KW  - Citation networks
KW  - Convolutional networks
KW  - Graph attention network
KW  - Graph convolutional network
KW  - Jaccard coefficients
KW  - Link nodes
KW  - Link prediction
KW  - Network models
KW  - Node classification
KW  - Performance
KW  - Forecasting
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Kliestik, T.
AU  - Novak, A.
AU  - Lăzăroiu, G.
TI  - Live Shopping in the Metaverse: Visual and Spatial Analytics, Cognitive Artificial Intelligence Techniques and Algorithms, and Immersive Digital Simulations
PY  - 2022
T2  - Linguistic and Philosophical Investigations
VL  - 21
SP  - 187
EP  - 202
DO  - 10.22381/lpi21202212
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135593284&doi=10.22381%2flpi21202212&partnerID=40&md5=cf1122e1d541cd3095877e00f76f8cc6
AB  - The purpose of this study is to examine live shopping in the metaverse in terms of visual and spatial analytics, cognitive artificial intelligence techniques and algorithms, and immersive digital simulations. In this article, we cumulate previous research findings indicating that retail analytics can build brand awareness and improve operational performance across shared virtual environments by customizing user experiences. We contribute to the literature on retail business models in the metaverse environment by showing that cognitive artificial intelligence techniques and algorithms can be pivotal in virtual commerce by enhancing digital shopping experience through location data. Throughout March 2022, we performed a quantitative literature review of the Web of Science, Scopus, and ProQuest databases, with search terms including “metaverse” + “live shopping,” “visual analytics,” “spatial analytics,” “cognitive artificial intelligence techniques and algorithms,” and “immersive digital simulations.” As we inspected research published between 2021 and 2022, only 89 articles satisfied the eligibility criteria. By eliminating controversial findings, outcomes unsubstantiated by replication, too imprecise material, or having similar titles, we decided upon 20, generally empirical, sources. Data visualization tools: Dimensions (bibliometric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AXIS, Dedoose, MMAT, and SRDR. © 2022, Addleton Academic Publishers. All rights reserved.
KW  - analytics
KW  - immersive
KW  - metaverse
KW  - shopping
KW  - spatial
KW  - visual
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 65
ER  -

TY  - JOUR
AU  - Hassan, E.
AU  - Bettayeb, M.
AU  - Halawani, Y.
AU  - Genssler, P.R.
AU  - Tesfai, H.
AU  - Zweiri, Y.
AU  - Amrouch, H.
AU  - Hadjileontiadis, L.J.
AU  - Saleh, H.
AU  - Mohammad, B.
TI  - TransHD: Spatial Transformer Features Extraction for HDC Synergetic Learning
PY  - 2025
T2  - IEEE Transactions on Artificial Intelligence
DO  - 10.1109/TAI.2025.3570283
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005870782&doi=10.1109%2fTAI.2025.3570283&partnerID=40&md5=2b0dd0ff17b426656994b4588eb18772
AB  - Artificial intelligence (AI) relies on pattern recognition and classification algorithms to achieve accurate and efficient decision-making. Convolutional neural networks (CNNs) are the state-of-the-art for processing 2D image data, but their high computational and data requirements limit their use in resource-constrained environments. Hyperdimensional computing (HDC) offers a lightweight alternative, excelling in 1D tasks, but struggles to achieve competitive accuracy for 2D image classification. Hybrid frameworks combining HDC with CNNs have been proposed to improve accuracy but inherit the computational demands of deep learning, making them unsuitable for edge and IoT devices. To address this, we propose TransHD, a framework integrating lightweight spatial transformer networks (STNs) with HDC to enhance image classification performance while maintaining efficiency. TransHD achieves up to 9% higher accuracy than base HDC models on MNIST and Fashion-MNIST using only 30% of the training data, and reduces computational complexity by 2.5x through optimized STN feature map usage. On resource-constrained platforms like the Raspberry Pi 4, TransHD accelerates inference times by 3.4x and improves energy efficiency by 3.2x, with an accuracy trade-off of approximately 3% compared to CNNs. This study demonstrates the potential of combining HDC with STNs to develop efficient AI solutions for IoT and edge computing, where low energy consumption and computational efficiency are critical. © 2020 IEEE.
KW  - Brain-inspired Computing
KW  - Hyperdimensional Computing
KW  - Image Classification
KW  - Spatial Transformers
KW  - Deep neural networks
KW  - Feature Selection
KW  - HDCP
KW  - Image annotation
KW  - Image coding
KW  - Optical character recognition
KW  - Photointerpretation
KW  - 2D images
KW  - Brain-inspired computing
KW  - Convolutional neural network
KW  - Features extraction
KW  - Hyperdimensional computing
KW  - Images classification
KW  - Pattern recognition algorithms
KW  - Pattern recognition and classification
KW  - Spatial transformer
KW  - Synergetics
KW  - Convolutional neural networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Khan, M.J.
AU  - Breslin, J.G.
AU  - Curry, E.
TI  - Common Sense Knowledge Infusion for Visual Understanding and Reasoning: Approaches, Challenges, and Applications
PY  - 2022
T2  - IEEE Internet Computing
VL  - 26
IS  - 4
SP  - 21
EP  - 27
DO  - 10.1109/MIC.2022.3176500
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130448844&doi=10.1109%2fMIC.2022.3176500&partnerID=40&md5=1f89d34d3e04fb82ab8dfb9c703b4573
AB  - Visual understanding involves detecting objects in a scene and investigating rich semantic relationships between the objects, which is required for downstream visual reasoning tasks. The scene graph is widely used for structured scene representation, however, the performance of the scene graph generation for visual reasoning is limited due to challenges posed by imbalanced datasets and insufficient attention toward common sense knowledge infusion. Most of the existing approaches use statistical or language priors for knowledge infusion. Common Sense knowledge infusion using heterogeneous knowledge graphs can help in improving the accuracy, robustness, and generalizability of the scene graph generation and enable explainable higher level reasoning by providing rich and diverse background and factual knowledge about the concepts in visual scenes. In this article, we present the background and applications of the scene graph generation and the initial approaches and key challenges in common sense knowledge infusion using heterogeneous knowledge graphs for visual understanding and reasoning.  © 1997-2012 IEEE.
KW  - Job analysis
KW  - Object detection
KW  - Semantics
KW  - Commonsense knowledge
KW  - Commonsense reasoning
KW  - Features extraction
KW  - Graph generation
KW  - Heterogeneous Knowledge
KW  - Knowledge graphs
KW  - Reasoning approach
KW  - Scene-graphs
KW  - Task analysis
KW  - Visual reasoning
KW  - Semantic Web
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 9
ER  -

TY  - CONF
AU  - Erduran, Ö.I.
TI  - Cognitive Learning Agents for Autonomous Mobility on Demand Systems
PY  - 2022
T2  - CEUR Workshop Proceedings
VL  - 3457
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171293894&partnerID=40&md5=ca19d30696000f7b30578d577cbd9879
AB  - In my PhD thesis, the concept of Cognitive Agents with extended Learning capabilities for Autonomous Mobility on Demand (AMoD) scenarios is investigated. Specifically, the focus is set on the Ride-hailing concept with a fleet of autonomously driving vehicles. The Agent-based approach provides the possibility to consider cognitive agent architectures for different types of agents in the given scenario. In this regard, the vehicle agents are built up based on the Belief-Desire-Intention (BDI) architecture. My dissertation combines two paradigms that are considered significant research areas, namely Machine learning (ML) and Agent-oriented Programming (AOP). Therefore, a structured overview of the research made so far is provided pointing out significant areas in the AMoD application scenario which are worthwhile to work on. For each of the areas, I describe why the setting and combination of MAS and ML are relevant and interesting for in-depth investigation. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
KW  - Agent-Oriented Programming
KW  - BDI Agent
KW  - Machine Learning
KW  - Mobility on Demand
KW  - Multi-Agent System
KW  - Neuro-Symbolic AI
KW  - Autonomous agents
KW  - Cognitive systems
KW  - Fleet operations
KW  - Intelligent agents
KW  - Intelligent systems
KW  - Machine learning
KW  - Agent-oriented programming
KW  - Autonomous mobilities
KW  - Beliefs-desires-intentions agents
KW  - Cognitive learning
KW  - Learning agents
KW  - Machine-learning
KW  - Mobility on demand
KW  - Neuro-symbolic AI
KW  - On demands
KW  - On-demand systems
KW  - Multi agent systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Honarparvar, S.
AU  - Ashena, Z.B.
AU  - Saeedi, S.
AU  - Liang, S.
TI  - A Systematic Review of Event-Matching Methods for Complex Event Detection in Video Streams
PY  - 2024
T2  - Sensors
VL  - 24
IS  - 22
C7  - 7238
DO  - 10.3390/s24227238
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210449714&doi=10.3390%2fs24227238&partnerID=40&md5=496fd038811098ac197ccacbf7af25eb
AB  - Complex Event Detection (CED) in video streams involves numerous challenges such as object detection, tracking, spatio–temporal relationship identification, and event matching, which are often complicated by environmental variations, occlusions, and tracking losses. This systematic review presents an analysis of CED methods for video streams described in publications from 2012 to 2024, focusing on their effectiveness in addressing key challenges and identifying trends, research gaps, and future directions. A total of 92 studies were categorized into four main groups: training-based methods, object detection and spatio–temporal matching, multi-source solutions, and others. Each method’s strengths, limitations, and applicability are discussed, providing an in-depth evaluation of their capabilities to support real-time video analysis and live camera feed applications. This review highlights the increasing demand for advanced CED techniques in sectors like security, safety, and surveillance and outlines the key opportunities for future research in this evolving field. © 2024 by the authors.
KW  - complex event detection
KW  - event processing
KW  - object detection in videos
KW  - video processing
KW  - Data streams
KW  - Footage counters
KW  - Object detection
KW  - Object recognition
KW  - Complex event detection
KW  - Event detection in video
KW  - Event matching
KW  - Event Processing
KW  - Matching methods
KW  - Object detection in video
KW  - Objects detection
KW  - Spatio-temporal relationships
KW  - Systematic Review
KW  - Video processing
KW  - camera
KW  - drug analysis
KW  - epidemiology
KW  - human
KW  - research gap
KW  - review
KW  - systematic review
KW  - videorecording
KW  - Video streaming
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Guo, S.
AU  - Wang, Y.
AU  - Zhang, N.
AU  - Su, Z.
AU  - Luan, T.H.
AU  - Tian, Z.
AU  - Shen, X.
TI  - A Survey on Semantic Communication Networks: Architecture, Security, and Privacy
PY  - 2024
T2  - IEEE Communications Surveys and Tutorials
DO  - 10.1109/COMST.2024.3516819
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212429143&doi=10.1109%2fCOMST.2024.3516819&partnerID=40&md5=b173398b1e3cf256b55dd804b4988f38
AB  - With the rapid advancement and deployment of intelligent agents and artificial general intelligence (AGI), a fundamental challenge for future networks is enabling efficient communications among agents. Unlike traditional human-centric, data-driven communication networks, the primary goal of agent-based communication is to facilitate coordination among agents. Therefore, task comprehension and collaboration become the key objectives of communications, rather than data synchronization. Semantic communication (SemCom) aims to align information and knowledge among agents to expedite task comprehension. While significant research has been conducted on SemCom for two-agent systems, the development of semantic communication networks (SemComNet) for multi-agent systems remains largely unexplored. In this paper, we provide a comprehensive and up-to-date survey of SemComNet, focusing on their fundamentals, security, and privacy aspects. We introduce a novel three-layer architecture for multi-agent interaction, comprising the control layer, semantic transmission layer, and cognitive sensing layer. We explore working modes and enabling technologies, and present a taxonomy of security and privacy threats, along with state-of-the-art defense mechanisms. Finally, we outline future research directions, paving the way toward intelligent, robust, and energy-efficient SemComNet. This survey represents the first comprehensive analysis of SemComNet, offering detailed insights into its core principles as well as associated security and privacy challenges.  © 2024 IEEE.
KW  - artificial intelligence
KW  - privacy
KW  - security
KW  - Semantic communication
KW  - trust
KW  - Latent semantic analysis
KW  - Multi agent systems
KW  - Artificial general intelligences
KW  - Communications networks
KW  - Future networks
KW  - Network privacy
KW  - Networks security
KW  - Privacy
KW  - Security
KW  - Security and privacy
KW  - Semantic communication
KW  - Trust
KW  - Differential privacy
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - CONF
AU  - Adhikary, A.
AU  - Munir, M.S.
AU  - Raha, A.D.
AU  - Qiao, Y.
AU  - Hong, C.S.
TI  - Artificial Intelligence Framework for Target Oriented Integrated Sensing and Communication in Holographic MIMO
PY  - 2023
T2  - Proceedings of IEEE/IFIP Network Operations and Management Symposium 2023, NOMS 2023
DO  - 10.1109/NOMS56928.2023.10154354
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164671886&doi=10.1109%2fNOMS56928.2023.10154354&partnerID=40&md5=777c0902830cc9ce5252933743f0b009
AB  - The future sixth-generation (6G) wireless communication networks are expected to provide massive connectivity with lower power requirements for generating the desired beamforming. Therefore, holographic MIMO assisted integrated sensing and communication framework is proposed that ensures lower power requirements to activate the minimum number of grids from the holographic grid array (HGA) for the effective beamforming. An optimization problem is formulated that maximizes the signal to noise-interference ratio (SNIR) of the users which in turn maximizes the utility function for sensing (UFS) considering the beampattern gains, distances, and sensing-communication loss. A novel artificial intelligence (AI) framework is proposed to solve the formulated problem which is a NP-hard problem. First, a variational autoencoder (VAE) based scheme is developed to solve the challenges of determining the exact location of the users and complete data distribution. Then, a sequential neural network-based mechanism is devised to allocate the communication resources to the heterogeneous users for the desired beamforming based on the results obtained from VAE. Finally, simulation results demonstrate that the proposed algorithms confirm 23% power savings compared to long short-term memory (LSTM) method to perform effective beamforming for serving the users. © 2023 IEEE.
KW  - holographic beamforming
KW  - holographic MIMO
KW  - Integrated sensing and communication
KW  - sensing utility function
KW  - sixth-generation
KW  - Holography
KW  - Long short-term memory
KW  - MIMO systems
KW  - Signal to noise ratio
KW  - Auto encoders
KW  - Holographic beamforming
KW  - Holographic MIMO
KW  - Integrated sensing
KW  - Integrated sensing and communication
KW  - Low Power
KW  - Power requirement
KW  - Sensing utility function
KW  - Sixth-generation
KW  - Utility functions
KW  - Beamforming
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 16
ER  -

TY  - JOUR
AU  - Barry, P.
AU  - Doskey, S.
AU  - Handley, H.
AU  - Tolk, A.
AU  - Wijesinghe, S.
TI  - Digital collaborators for complex systems development: a research agenda
PY  - 2022
T2  - International Journal of System of Systems Engineering
VL  - 12
IS  - 2
SP  - 103
EP  - 113
DO  - 10.1504/ijsse.2022.124974
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138114686&doi=10.1504%2fijsse.2022.124974&partnerID=40&md5=783570159cdeab0219c0cbdd6e14567b
AB  - Increasingly complex systems exist in dynamic environments where the system needs to evolve in ways that are faster than it is possible to identify, much less comprehend, through human observation alone. To build such complex systems, system engineering teams should be augmented with real-time digital collaborators, not only in the design process, but in the management of the system itself. These digital collaborators will likely aid engineering managers by providing risk-based alternatives, identifying hidden risks, and exposing hidden patterns in the human behaviour of stakeholders. However, there are fundamental research questions that must be addressed for industry to employ digital collaborators. Resolving these questions can enable the evolution of today's current development paradigms to a future where Artificial Intelligence and humans seamlessly work as partners in developing new systems. These questions are codified into a research agenda to aid academia and industry in prioritising initiatives that can help accelerate advancement of digital collaborators in the engineering of systems.  © 2022 Inderscience Enterprises Ltd.
KW  - adaptive systems
KW  - artificial intelligence
KW  - collective intelligence
KW  - complex systems
KW  - intelligent systems
KW  - multi-agent intelligence
KW  - sociotechnical systems
KW  - systems engineering
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Jiang, Y.
AU  - Wang, W.
AU  - Ding, J.
AU  - Lu, X.
AU  - Jing, Y.
TI  - Leveraging Digital Twin Technology for Enhanced Cybersecurity in Cyber–Physical Production Systems
PY  - 2024
T2  - Future Internet
VL  - 16
IS  - 4
C7  - 134
DO  - 10.3390/fi16040134
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191387617&doi=10.3390%2ffi16040134&partnerID=40&md5=4976f4bddc605319f66bc823b2ebbc2d
AB  - The convergence of cyber and physical systems through cyber–physical systems (CPSs) has been integrated into cyber–physical production systems (CPPSs), leading to a paradigm shift toward intelligent manufacturing. Despite the transformative benefits that CPPS provides, its increased connectivity exposes manufacturers to cyber-attacks through exploitable vulnerabilities. This paper presents a novel approach to CPPS security protection by leveraging digital twin (DT) technology to develop a comprehensive security model. This model enhances asset visibility and supports prioritization in mitigating vulnerable components through DT-based virtual tuning, providing quantitative assessment results for effective mitigation. Our proposed DT security model also serves as an advanced simulation environment, facilitating the evaluation of CPPS vulnerabilities across diverse attack scenarios without disrupting physical operations. The practicality and effectiveness of our approach are illustrated through its application in a human–robot collaborative assembly system, demonstrating the potential of DT technology. © 2024 by the authors.
KW  - asset visibility
KW  - cybersecurity
KW  - cyber–physical system (CPS)
KW  - dependence analysis
KW  - digital twin (DT)
KW  - manufacturing system
KW  - mitigation prioritization
KW  - Network security
KW  - Visibility
KW  - Asset visibility
KW  - Cybe-physical systems
KW  - Cyber physicals
KW  - Cyber security
KW  - Cyber-physical systems
KW  - Cybe–physical system
KW  - Dependence analysis
KW  - Digital twin
KW  - Mitigation prioritization
KW  - Prioritization
KW  - Cybersecurity
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - CONF
AU  - Kansal, M.
AU  - Singh, P.
AU  - Soharia, A.
AU  - Tripathi, A.
AU  - Yadav, A.
AU  - Sen, C.
TI  - A Brief Survey on Metaverse: Its Concepts, Applications and Challenges
PY  - 2023
T2  - 2023 3rd International Conference on Advancement in Electronics and Communication Engineering, AECE 2023
SP  - 470
EP  - 475
DO  - 10.1109/AECE59614.2023.10428474
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186511717&doi=10.1109%2fAECE59614.2023.10428474&partnerID=40&md5=31fb9d269026733caaa95209fa88ff6f
AB  - In the past few years Metaverse has gained attention due to the growth of online gaming and virtual reality platforms and also the use of technological advance devices such as AR/VR. This paper offers a comprehensive analysis and thorough comprehension of the Metaverse, encompassing a detailed exploration of its history, key attributes, and future applications. The key features include immersive experiences, social interactions, and virtual spaces. This research has also scrutinized the technical challenges and its social appraisal. After examining earlier research papers, this paper has followed the origins of the metaverse term and found that it emerged from the science fiction book Snow Crash and a virtual world called Second Life. There are several definitions proposed by various scholars and industry experts who have discussed the evolving nature of the metaverse of the course of time. Finally, this paper provides a deep analysis of the metaverse concept, its future benefits and the risk, and also concludes the paper including its limitations and challenges. At the end this research will finally conclude the paper by discussing its future and its unrealised impact on society, also how it will change the socio-economic structures. © 2023 IEEE.
KW  - 3D space
KW  - avatar
KW  - extended reality
KW  - metaverse
KW  - sustainability
KW  - Virtual world
KW  - Economics
KW  - Interactive computer graphics
KW  - Risk assessment
KW  - Sustainable development
KW  - Three dimensional computer graphics
KW  - 3D spaces
KW  - Avatar
KW  - Comprehensive analysis
KW  - Extended reality
KW  - Future applications
KW  - Key attributes
KW  - Metaverses
KW  - On-line gaming
KW  - Technological advances
KW  - Virtual worlds
KW  - Virtual reality
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Dammalapati, K.
AU  - Sankara Babu, B.
AU  - Gopala Krishna, P.
AU  - Subba Ramaiah, V.
TI  - A research on software engineering research in machine learning
PY  - 2021
T2  - Handbook of Research on Innovations and Applications of AI, IoT, and Cognitive Technologies
SP  - 359
EP  - 371
DO  - 10.4018/978-1-7998-6870-5.ch024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118517678&doi=10.4018%2f978-1-7998-6870-5.ch024&partnerID=40&md5=8869a55ac0a72f5fb0542018772e9cb5
AB  - With rapid growth of various well-known methods implemented by the engineers in the software field in order to create a development in automated tasks for manufacturers and researchers working worldwide, the researchers in the field of software engineering (SE) root for concepts of machine learning (ML), a subfield that utilizes deep learning (DL) for the development of such SE tasks. In essence, these systems would highly cope with the featured automation with inbuilt capabilities in engineering to develop the software simulation models. Nevertheless, it is very tough to condense the present scenario in research of situations that necessitate failures, successes, and openings in DL for software-based technology. The survey works for renowned technology of SE and DL held for the latest journals and conferences leading to the span of 85 issued papers throughout 23 distinctive tasks for SE. © 2021 by IGI Global.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Bilal, M.
AU  - Steindl, G.
AU  - Thoma, M.
AU  - Kastner, W.
TI  - A Methodology to Convert Tacit Knowledge into Explicit Knowledge - Smart Building Use Case
PY  - 2024
T2  - 2024 International Conference on Computer and Applications, ICCA 2024
DO  - 10.1109/ICCA62237.2024.10927754
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002213869&doi=10.1109%2fICCA62237.2024.10927754&partnerID=40&md5=4c7ccb00c4dcb381164a681c834a4424
AB  - Managing energy in smart buildings involves complex interactions best understood by domain experts. This work introduces the Tacit Knowledge Tree (TKT) methodology, which is a 4-stage framework to capture and structure tacit knowledge into semi-structured formats. TKT maps causal relationships of events to enhance cyber-physical system explainability and decision-making. TKT has been applied to a smart building use case for evaluation.  © 2024 IEEE.
KW  - Causal Relations
KW  - Causality Chain
KW  - Cyber-physical system
KW  - Knowledge Management
KW  - Smart Building
KW  - Tacit Knowledge
KW  - Intelligent buildings
KW  - Causal relations
KW  - Causality chain
KW  - Cybe-physical systems
KW  - Cyber-physical systems
KW  - Domain experts
KW  - Energy
KW  - Explicit knowledge
KW  - Knowledge tree
KW  - Semi-structured
KW  - Tacit knowledge
KW  - Smart homes
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Bratu, S.
AU  - Sabău, R.I.
TI  - Digital Commerce in the Immersive Metaverse Environment: Cognitive Analytics Management, Real-Time Purchasing Data, and Seamless Connected Shopping Experiences
PY  - 2022
T2  - Linguistic and Philosophical Investigations
VL  - 21
SP  - 170
EP  - 186
DO  - 10.22381/lpi21202211
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135582257&doi=10.22381%2flpi21202211&partnerID=40&md5=ad66b1d78fbce51b34c3a0786c8e227f
AB  - In this article, we cumulate previous research findings indicating that data visualization tools and retail analytics can build consumer relationships in online marketplaces and immersive digital environments as regards virtual stores. We contribute to the literature on digital commerce in the immersive metaverse environment by showing that computer vision algorithms and sentiment analytics can be decisive in changing customer habits and purchasing decisions by improving immersive virtual experiences. Throughout February 2022, we performed a quantitative literature review of the Web of Science, Scopus, and ProQuest databases, with search terms including “metaverse” + “digital commerce,” “cognitive analytics management,” “real-time purchasing data,” and “seamless connected shopping experiences.” As we inspected research published between 2021 and 2022, only 89 articles satisfied the eligibility criteria. By eliminating controversial findings, outcomes unsubstantiated by replication, too imprecise material, or having similar titles, we decided upon 20, generally empirical, sources. Data visualization tools: Dimensions (bibliometric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AXIS, Dedoose, ROBIS, and SRDR. © 2022, Addleton Academic Publishers. All rights reserved.
KW  - cognitive analytics
KW  - digital commerce
KW  - immersive
KW  - metaverse
KW  - shopping
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 19
ER  -

TY  - JOUR
AU  - Wang, L.
AU  - Wu, W.
AU  - Zhou, F.
AU  - Qin, Z.
AU  - Wu, Q.
TI  - Cross-Layer Security for Semantic Communications: Metrics and Optimization
PY  - 2025
T2  - IEEE Transactions on Vehicular Technology
DO  - 10.1109/TVT.2025.3552777
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000458366&doi=10.1109%2fTVT.2025.3552777&partnerID=40&md5=9d6a2d8cdfa53993a0c206e7d983368f
AB  - Different from traditional secure communication that focuses on symbolic protection at the physical layer, semantic secure communication requires further attention to semantic-level task performance at the application layer. There is a research gap on how to comprehensively evaluate and optimize the security performance of semantic communication. In order to fill this gap, a unified semantic security metric, the cross-layer semantic secure rate (CLSSR), is defined to estimate cross-layer security requirements at both the physical layer and the application layer. Then, we formulate the maximization problem of the CLSSR with the mixed integer nonlinear programming (MINLP). We propose a hierarchical AI-native semantic secure communication network with a reinforcement learning (RL)-based semantic resource allocation scheme, aiming to ensure the cross-layer semantic security (CL-SS). Finally, we prove the convergence of our proposed intelligent resource allocation, and the simulation results demonstrate that our proposed CLSS method outperforms the traditional physical layer semantic security (PL-SS) method in terms of both task reliability and CLSSR.  © 1967-2012 IEEE.
KW  - cross-layer security
KW  - intelligent resource allocation
KW  - reinforcement learning
KW  - Semantic secure communication
KW  - Integer linear programming
KW  - Secure communication
KW  - Cross layer
KW  - Cross-layer securities
KW  - Intelligent resource
KW  - Intelligent resource allocation
KW  - Physical layers
KW  - Reinforcement learnings
KW  - Resources allocation
KW  - Semantic communication
KW  - Semantic secure communication
KW  - Semantic security
KW  - Reinforcement learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Wang, Y.
AU  - Hu, Y.
AU  - Du, H.
AU  - Luo, T.
AU  - Niyato, D.
TI  - Multi-Agent Reinforcement Learning for Covert Semantic Communications over Wireless Networks
PY  - 2023
T2  - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings
VL  - 2023-June
DO  - 10.1109/ICASSP49357.2023.10095748
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177593338&doi=10.1109%2fICASSP49357.2023.10095748&partnerID=40&md5=60b7fba0c89b9402bf26c6dfa7e00d1d
AB  - In this paper, a covert semantic communication framework is proposed for image transmission over wireless networks. In the proposed framework, devices extract and selectively transmit semantic information of image data to a base station (BS). The semantic information consists of the objects in the image and a set of attributes of each object. A warden selects a device to detect and eavesdrops the semantic information. To ensure the security of semantic communications, a jammer, acts as the defender, requires to find a vulnerable device and transmits jamming signals to the vulnerable device. The metric to measure the performance of the covert semantic communications is defined as the difference in the average accuracy of the BS and the warden answering a set of questions for each image. To maximize the performance of covert semantic communications, each device and the jammer must jointly optimize their transmit power, determine the vulnerable device to be protected, and determine the partial semantic information that each device needs to transmit. To solve this problem, we propose a multi-agent policy gradient (MAPG) algorithm. The proposed algorithm enables each device and the jammer to cooperatively discover the vulnerable devices as well as find the semantic information transmission and power control policies that maximize the performance of the covert semantic communication system. Simulation results show that the proposed algorithm can improve the communication performance by up to 14.5% compared to the independent reinforcement learning. © 2023 IEEE.
KW  - Jamming
KW  - Multi agent systems
KW  - Power control
KW  - Reinforcement learning
KW  - Semantic Web
KW  - Wireless networks
KW  - Communication framework
KW  - Image data
KW  - Jammers
KW  - Jamming signals
KW  - Multi-agent reinforcement learning
KW  - Performance
KW  - Semantic communication
KW  - Semantics Information
KW  - Set of questions
KW  - Transmit power
KW  - Semantics
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - CHAP
AU  - Malik, N.
AU  - Jindal, K.
AU  - Verma, S.
AU  - Gupta, S.
TI  - Metaverse dynamics: Exploring industry impacts and educational frontiers
PY  - 2024
T2  - Educational Perspectives on Digital Technologies in Modeling and Management
SP  - 195
EP  - 218
DO  - 10.4018/979-8-3693-2314-4.ch010
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187627320&doi=10.4018%2f979-8-3693-2314-4.ch010&partnerID=40&md5=8e6d9272e995f36cb241c2157e6fc007
AB  - Recently, the word "Metaverse" has gained popularity, largely due to the COVID-19 pandemic and the rapid development of technology. It relates to lifelike experiences that people can have in immersive virtual settings. This research study offers a thorough analysis of the historical background, evolution, current applications, and anticipated developments of the Metaverse. It investigates the transformative potential of the Metaverse in the field of education, embracing immersive learning environments, virtual research facilities, and extensive study resources in order to improve educational outcomes holistically. It also explores the fascinating potential of the Metaverse in other fields, giving users the opportunity to transcend temporal and spatial limitations for richer and more immersive experiences. This research study focuses on the potential effects of the metaverse on our future and society by doing in-depth literature research, examining trends, and providing useful views. © 2024, IGI Global. All rights reserved.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Adhikary, A.
AU  - Raha, A.D.
AU  - Qiao, Y.
AU  - Ejigu, G.F.
AU  - Kang, S.M.
AU  - Huh, E.-N.
AU  - Hong, C.S.
TI  - Intelligent Omni Surface-Assisted Cell-Free Massive MIMO System for 6G Wireless Network
PY  - 2023
T2  - International Conference on Advanced Technologies for Communications
SP  - 376
EP  - 381
DO  - 10.1109/ATC58710.2023.10318879
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179125802&doi=10.1109%2fATC58710.2023.10318879&partnerID=40&md5=cb5b170ebcb8076a2ac1a927b1973460
AB  - The coming 6G wireless communication system requires an intelligent networking system with higher network capacity. Therefore, we consider an intelligent omni surface (IOS)-assisted cell-free massive MIMO (ICFMM) system that extends the network coverage by providing services on both sides of the IOS with minimized power. The base stations and IOSs cooperatively serve the users in the ICFMM system and require a smaller number of IOS compared to the intelligent reflecting surfaces. An optimization problem is formulated that maximizes the channel capacity of the users, which in turn maximizes the signal-to-interference-noise ratio and achievable rate of the users. A gated recurrent unit (GRU)-based artificial intelligence (AI) framework is proposed to solve the formulated NP-hard problem, which allocates the required power for the users on both sides of the IOS based on user requirements. Finally, simulation results show that our proposed GRU-based AI framework ensures a cumulative SINR improvement of 1.58 dB and a cumulative achievable rate improvement of 8.61 bps/Hz compared to the long short-term memory method. Therefore, simulation results evaluate the performance of the proposed framework and demonstrate efficient power allocation for the intended users.  © 2023 IEEE.
KW  - 6G
KW  - Cell-free massive MIMO
KW  - intelligent omni-surface
KW  - power allocation.
KW  - 5G mobile communication systems
KW  - Computational complexity
KW  - Energy efficiency
KW  - Signal interference
KW  - Signal to noise ratio
KW  - Wireless networks
KW  - 6g
KW  - Cell-free
KW  - Cell-free massive MIMO
KW  - Intelligent networking
KW  - Intelligent omni-surface
KW  - Power
KW  - Power allocation.
KW  - Power allocations
KW  - Unit-based
KW  - Wireless communication system
KW  - MIMO systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Qureshi, T.S.
AU  - Shahid, M.H.
AU  - Farhan, A.A.
AU  - Alamri, S.
TI  - A systematic literature review on human activity recognition using smart devices: advances, challenges, and future directions
PY  - 2025
T2  - Artificial Intelligence Review
VL  - 58
IS  - 9
C7  - 276
DO  - 10.1007/s10462-025-11275-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007836562&doi=10.1007%2fs10462-025-11275-x&partnerID=40&md5=c032932c7d755cba02dac2d52878e94d
AB  - With improvement in AI and deep learning, Human Activity Recognition (HAR) has started to play an important role in many real-world applications. These range from healthcare and elderly care to security to enhancing user experience in smart environments. Smart devices with their ubiquity and multi-modal sensors, provide critical data that can be used to improve the quality of life and efficiency of services. Given the rapid technological advancements and recent developments in the field, it is essential to examine the current state of Human Activity Recognition (HAR), highlighting its strengths as well as the challenges it continues to face. This study presents a systematic review of the literature (SLR) of HAR that is conducted through a detailed study of articles published from 2021 to 2024 using open data sets. This study explores major databases i.e., Springer, IEEE Xplore, Science Direct, Taylor & Francis, and ACM to access the recent advancements in HAR that are facilitated by smartphones and smartwatches. Our SLR looks at the most commonly used datasets i.e. WISDM, PAMAP2, UCI-HAR, Opportunity, and MHealth. Moreover, this SLR compares the performance of commonly used deep learning techniques i.e. Convolutional Neural Networks (CNN), Long Short Term Memory (LSTM), Transformers and Ensemble models on these datasets. The objectives of this study are threefold i.e. to identify recent studies that employ deep learning techniques for Human Activity Recognition (HAR) tasks, to review publicly available open datasets commonly used in HAR research during 2021 to 2024, and to identify common challenges and limitations in current HAR research while proposing potential future research directions. © The Author(s) 2025.
KW  - Deep learning techniques
KW  - Human activity recognition
KW  - Open datasets
KW  - Smart devices
KW  - Systematic literature review
KW  - Deep neural networks
KW  - Human engineering
KW  - mHealth
KW  - 'current
KW  - Deep learning technique
KW  - Elderly care
KW  - Human activity recognition
KW  - Learning techniques
KW  - Open dataset
KW  - Real-world
KW  - Smart devices
KW  - Systematic literature review
KW  - Systematic Review
KW  - Convolutional neural networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Duong, C.
AU  - Raghuram, V.C.
AU  - Lee, A.
AU  - Mao, R.
AU  - Mengaldo, G.
AU  - Cambria, E.
TI  - Neurosymbolic AI for Mining Public Opinions about Wildfires
PY  - 2024
T2  - Cognitive Computation
VL  - 16
IS  - 4
SP  - 1531
EP  - 1553
DO  - 10.1007/s12559-023-10195-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171197253&doi=10.1007%2fs12559-023-10195-8&partnerID=40&md5=95f1eb7816f943fd5cecfb5cc8b8765b
AB  - Wildfires are among the most threatening hazards to life, property, well-being, and the environment. Studying public opinions about wildfires can help monitor the perception of the impacted communities. Nevertheless, wildfire research is relatively limited compared to other climate-related hazards. This article presents our data mining work on public opinions about wildfires in Australia from 2014 to 2021. Three key aspects are analyzed: the topic of concern, sentiment polarization, and perceived emotions. We propose a data filtering approach to acquire golden samples to train a supervised model for emotion quantification to achieve the last target. The results show that the new model produces a more accurate emotion estimation than the existing lexicon approach. Through data analysis, we find that people have seen wildfires as one of the impacts of climate change; trends of tweets can reflect the damage of wildfires in real life. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.
KW  - Neurosymbolic AI
KW  - Sentiment analysis
KW  - Wildfires
KW  - Behavioral research
KW  - Climate change
KW  - Data mining
KW  - Fires
KW  - Hazards
KW  - Australia
KW  - Data filtering
KW  - Emotion estimation
KW  - Neurosymbolic AI
KW  - Property
KW  - Public opinions
KW  - Sentiment analysis
KW  - Well being
KW  - Wildfire
KW  - Sentiment analysis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - JOUR
AU  - Arrotta, L.
AU  - Civitarese, G.
AU  - Chen, X.
AU  - Cumin, J.
AU  - Bettini, C.
TI  - Multi-subject human activities: A survey of recognition and evaluation methods based on a formal framework
PY  - 2025
T2  - Expert Systems with Applications
VL  - 267
C7  - 126178
DO  - 10.1016/j.eswa.2024.126178
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212534373&doi=10.1016%2fj.eswa.2024.126178&partnerID=40&md5=8f7e8fd5c18399cc983ac8b11dc3896f
AB  - Human Activity Recognition (HAR) in smart environments is a well-explored research domain, given its diverse applications which include healthcare, surveillance, building management, and many more. While the majority of HAR research focuses on recognizing the activities of a single subject, in real-world scenarios smart environments are often populated by multiple subjects that may be engaged in both independent and joint activities. This gives rise to the challenge of Multi-Subject HAR, which is an open and complex problem. This survey paper aims to offer researchers and practitioners a comprehensive analysis of Multi-Subject HAR, encompassing its potential applications, sensing solutions, methods, datasets, evaluation metrics, and ongoing challenges. In addition to presenting the latest research works in this area and identifying open issues, our major contributions consist of a comprehensive problem formalization and a thorough discussion of the evaluation metrics to assess different dimensions of multi-subject HAR systems. © 2024 The Authors
KW  - Ambient intelligence
KW  - Group activity recognition
KW  - Human activity recognition
KW  - Multi-subject HAR
KW  - Ambients
KW  - Evaluation methods
KW  - Evaluation metrics
KW  - Group activity recognition
KW  - Human activities
KW  - Human activity recognition
KW  - Multi-subject human activity recognition
KW  - Recognition methods
KW  - Smart environment
KW  - Ambient intelligence
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Al-Ghaili, A.M.
AU  - Kasim, H.
AU  - Al-Hada, N.M.
AU  - Hassan, Z.B.
AU  - Othman, M.
AU  - Tharik, J.H.
AU  - Kasmani, R.M.
AU  - Shayea, I.
TI  - A Review of Metaverse's Definitions, Architecture, Applications, Challenges, Issues, Solutions, and Future Trends
PY  - 2022
T2  - IEEE Access
VL  - 10
SP  - 125835
EP  - 125866
DO  - 10.1109/ACCESS.2022.3225638
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144054690&doi=10.1109%2fACCESS.2022.3225638&partnerID=40&md5=60a1640d10c44dcc07d4a2ef3bb6902a
AB  - Metaverse is a vision enabling to constitute an environment in which someone could see real and virtualized worlds. The Metaverse is a product (or something similar as we do not yet know its final form) of such technologies. In this circumstance, when applications that utilize the Metaverse are used, there seem to be no transportation charges, and there is no cap on amounts of individuals, users, players, learners, or trainee who can take part. Hence, and due to such a feature, the Metaverse has attracted various researchers from different fields where it has been exploited by them to contribute to those fields and research areas. As for example, it is possible to teach various target audiences by offering different events and classes from any location in the globe. In order for a participant to utilize the Metaverse, there are necessary conditions to be considered as well as other settings to be initialized. In line of this, virtual reality, augmented reality, availability of required sensors, smart glasses, headsets, and few others are considered some examples of such conditions and settings that the Metaverse requires. Despite the advantages that Metaverse offers us, there are a number of considerations that must be taken into account while developing it by interested researchers. One of these concerns is the Metaverse privacy regarding the participants (represented as avatars inside the Metaverse environment). Another issue is that since the Metaverse is still in its early stages, many attempts have to be made from interested researchers who engage to develop it to enhancing it. This review aims to survey related articles that concern the Metaverse and its development providing a review of the chronological stages throughout the history of the development of Metaverse. It aims also to list a number of recent technological advances allowing the Metaverse. Besides, Metaverse's definitions, properties, architecture, and applications have been discussed and listed in this review. The novelty of this article is that it has suggested a framework to a number of issues that are still paid attention for potential solutions by researchers aiming to contribute to researchers and designers to consider such an issue and its corresponding solution for future research works and enhancement. Challenges faced by researchers and other relevant concerned issues related to Metaverse have been in detail discussed and highlighted. Besides, future trends have been clarified.  © 2013 IEEE.
KW  - augmented reality
KW  - games
KW  - graphics
KW  - Internet of Things (IoT)
KW  - Metaverse
KW  - metaverse privacy
KW  - virtual reality
KW  - web 3.0
KW  - Architecture
KW  - Augmented reality
KW  - Interactive computer graphics
KW  - Internet of things
KW  - Network architecture
KW  - Condition
KW  - Future trends
KW  - Game
KW  - Graphic
KW  - Internet of thing
KW  - Metaverse privacy
KW  - Metaverses
KW  - Research areas
KW  - Web 3.0
KW  - Virtual reality
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 107
ER  -

TY  - CONF
AU  - Kotal, A.
AU  - Luton, B.
AU  - Joshi, A.
TI  - KiNETGAN: Enabling Distributed Network Intrusion Detection through Knowledge-Infused Synthetic Data Generation
PY  - 2024
T2  - Proceedings - 2024 IEEE 44th International Conference on Distributed Computing Systems Workshops, ICDCSW 2024
SP  - 140
EP  - 145
DO  - 10.1109/ICDCSW63686.2024.00026
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204298482&doi=10.1109%2fICDCSW63686.2024.00026&partnerID=40&md5=3fdaae3e511765e775a9f3ea93ebc5f3
AB  - In the realm of IoT/CPS systems connected over mobile networks, traditional intrusion detection methods analyze network traffic across multiple devices using anomaly detection techniques to flag potential security threats. However, these methods face significant privacy challenges, particularly with deep packet inspection and network communication analysis. This type of monitoring is highly intrusive, as it involves examining the content of data packets, which can include personal and sensitive information. Such data scrutiny is often governed by stringent laws and regulations, especially in environments like smart homes where data privacy is paramount. Synthetic data offers a promising solution by mimicking real network behavior without revealing sensitive details. Generative models such as Generative Adversarial Networks (GANs) can produce synthetic data, but they often struggle to generate realistic data in specialized domains like network activity. This limitation stems from insufficient training data, which impedes the model's ability to grasp the domain's rules and constraints adequately. Moreover, the scarcity of training data exacerbates the problem of class imbalance in intrusion detection methods. To address these challenges, we propose a Privacy-Driven framework that utilizes a knowledge-infused Generative Adversarial Network for generating synthetic network activity data (KiNETGAN). This approach enhances the resilience of distributed intrusion detection while addressing privacy concerns. Our Knowledge Guided GAN produces realistic representations of network activity, validated through rigorous experimentation. We demonstrate that KiNETGAN maintains minimal accuracy loss in downstream tasks, effectively balancing data privacy and utility.  © 2024 IEEE.
KW  - GAN
KW  - Knowledge Guided Learning
KW  - Mobile and IoT system
KW  - Synthetic data
KW  - Adversarial machine learning
KW  - Differential privacy
KW  - Generative adversarial networks
KW  - Adversarial networks
KW  - Distributed networks
KW  - Intrusion detection method
KW  - Knowledge guided learning
KW  - Mobile and IoT system
KW  - Network activities
KW  - Network intrusion detection
KW  - Synthetic data
KW  - Synthetic data generations
KW  - Training data
KW  - Network intrusion
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CHAP
AU  - Khusru Akhtar, M.A.
AU  - Kumar, M.
TI  - Conscious artificial intelligence: Exploring machine awareness
PY  - 2024
T2  - Integration of Artificial Intelligence and Machine Learning Methods for Smart Internet of Things Systems and its Applications
SP  - 23
EP  - 67
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202003679&partnerID=40&md5=4cf514313ccb2f132bbf9d61e1d8ba72
AB  - This chapter delves into the extraordinary realm of conscious artificial intelligence (AI) and its extensive implications. It explores the significance, challenges, and possible outcomes that arise when machines own awareness. The notion of machine awareness is introduced, paving the means for an in-depth examination of various theories of consciousness and a stimulating examination of the intersection of AI and consciousness. The chapter examines the hurdles encountered in the quest for machine consciousness. One of the key challenges is defining consciousness in terms that can be understood and replicated by machines. Additionally, unravelling the paradox of subjective experience presents an exciting and complex puzzle. However, researchers are actively discovering diverse approaches to making conscious AI. These comprise simulating cognitive processes and mixing emotional intelligence, pushing the limits of what is possible and opening up new vistas for advancement. Ethical considerations take center point as the chapter probes into the responsible development and deployment of conscious AI. Discussions cover the importance of ethical AI practices, with considerations of machine rights, accountability, and transparency. The societal effect of conscious AI is also methodically examined, recognizing the necessity for widespread acceptance and incorporation. The chapter discovers the moral, legal, and social extents that must be navigated to safeguard the harmonious coexistence of conscious AI through human society. Looking to the future, the chapter speculates on the potential directions that lie ahead. It highlights the thrilling advancements occurring in neuroscience and AI, envisioning a future where these fields converge to deepen our understanding of consciousness. The chapter contemplates in what way AI can act as an influential tool for exploring and unravelling the complications of human consciousness, offering new visions and standpoints. With an emphasis on the growing arena of conscious AI, this chapter offers readers on a thought-provoking journey into the intricacies and potentials that arise at the intersection of human consciousness, AI, and machine learning. It explores the limits of methodical exploration and ethical considerations, shedding light on the profound impact that conscious AI can have on our lives and society. © 2024 Nova Science Publishers, Inc. All rights reserved.
KW  - Conscious AI
KW  - Machine awareness
KW  - Machine rights
KW  - Responsible ai
KW  - Self-awareness
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Kim, J.
AU  - Kim, K.
AU  - Sohn, M.
AU  - Park, G.
TI  - Deep Model-Based Security-Aware Entity Alignment Method for Edge-Specific Knowledge Graphs
PY  - 2022
T2  - Sustainability (Switzerland)
VL  - 14
IS  - 14
C7  - 8877
DO  - 10.3390/su14148877
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136352118&doi=10.3390%2fsu14148877&partnerID=40&md5=de34c71cce441e44976e8438046c408f
AB  - This paper proposes a deep model-based entity alignment method for the edge-specific knowledge graphs (KGs) to resolve the semantic heterogeneity between the edge systems’ data. To do so, this paper first analyzes the edge-specific knowledge graphs (KGs) to find unique characteristics. The deep model-based entity alignment method is developed based on their unique characteristics. The proposed method performs the entity alignment using a graph which is not topological but data-centric, to reflect the characteristics of the edge-specific KGs, which are mainly composed of the instance entities rather than the conceptual entities. In addition, two deep models, namely BERT (bidirectional encoder representations from transformers) for the concept entities and GAN (generative adversarial networks) for the instance entities, are applied to model learning. By utilizing the deep models, neural network models that humans cannot interpret, it is possible to secure data on the edge systems. The two learning models trained separately are integrated using a graph-based deep learning model GCN (graph convolution network). Finally, the integrated deep model is utilized to align the entities in the edge-specific KGs. To demonstrate the superiority of the proposed method, we perform the experiment and evaluation compared to the state-of-the-art entity alignment methods with the two experimental datasets from DBpedia, YAGO, and wikidata. In the evaluation metrics of Hits@k, mean rank (MR), and mean reciprocal rank (MRR), the proposed method shows the best predictive and generalization performance for the KG entity alignment. © 2022 by the authors.
KW  - data privacy and security
KW  - deep model
KW  - edge computing
KW  - entity alignment
KW  - knowledge graph
KW  - experiment
KW  - heterogeneity
KW  - knowledge
KW  - learning
KW  - managed realignment
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Raza, A.
AU  - Yousaf, M.H.
AU  - Ahmad, W.
AU  - Velastin, S.A.
AU  - Viriri, S.
TI  - Human fall detection using pose estimation: From traditional machine learning to vision transformers
PY  - 2025
T2  - Engineering Applications of Artificial Intelligence
VL  - 143
C7  - 109809
DO  - 10.1016/j.engappai.2024.109809
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215416496&doi=10.1016%2fj.engappai.2024.109809&partnerID=40&md5=2200eec083d124660b564f4b6342147f
AB  - Human activity recognition research for healthcare has drawn global attention in recent era. Recent advancements have led to various approaches capable of detecting diverse movements like walking, running, jumping, and falling. Fall detection is crucial due to its potential fatality, especially for older individuals. Sensors are widely employed to perceive environmental changes, and they can be integrated into wearable devices like phones, necklaces, or wristbands. However, these devices may be uncomfortable or unsuitable for continuous use. Video imagery, in principle, surpasses wearable sensors for fall detection. The proposed method uses video frames to identify falls, reducing the need for environmental sensors. We present an empirical analysis of vision-based human fall detection, employing multiple techniques to estimate human poses including a transformer-based pose estimation technique. These techniques yield foundational features used for training diverse networks, including machine learning classifiers to vision transformers. Our methodology achieves cutting-edge outcomes across the UR-Fall, UP-Fall, and Le2i fall detection datasets. © 2025 The Authors
KW  - Deep learning
KW  - Fall detection
KW  - Human pose estimation
KW  - Machine learning
KW  - Contrastive Learning
KW  - Deep learning
KW  - Machine vision
KW  - Deep learning
KW  - Environmental change
KW  - Fall detection
KW  - Human activity recognition
KW  - Human fall detection
KW  - Human pose estimations
KW  - Machine-learning
KW  - Pose-estimation
KW  - Video imagery
KW  - Wearable devices
KW  - Wearable sensors
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Bhuyan, B.P.
AU  - Singh, T.P.
AU  - Tomar, R.
AU  - Meraihi, Y.
AU  - Ramdane-Cherif, A.
TI  - A Monadic Second-Order Temporal Logic framework for hypergraphs
PY  - 2024
T2  - Neural Computing and Applications
VL  - 36
IS  - 35
SP  - 22081
EP  - 22118
DO  - 10.1007/s00521-024-10365-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205596732&doi=10.1007%2fs00521-024-10365-1&partnerID=40&md5=a2e08afe7a6a55247565d3df63cbc65f
AB  - This study introduces a novel computational framework integrating monadic second-order temporal logic (MSOTL) with hypergraph models to enhance the predictive analysis and prediction of complex systems, with a specific focus on urban agriculture. Traditional graph-based models often fail to capture the intricate, high-order temporal dynamics inherent in such systems. By leveraging the expressive power of MSOTL within a hypergraph context, our approach enables a more nuanced representation of temporal and relational data, leading to improved predictive accuracy and deeper analytical insights. The framework was applied to a comprehensive dataset of urban agricultural practices, incorporating data from diverse farming sites across multiple countries. Our results demonstrate the model’s capability to outperform existing methods in predicting agricultural outcomes by effectively capturing both the spatial and temporal complexities of urban farming data. The study not only advances the theoretical understanding of hypergraph-based temporal logic modeling but also offers an application for urban agricultural planning and management. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.
KW  - Hypergraph representation
KW  - Monadic second-order temporal logic
KW  - Neuro-symbolic artificial intelligence
KW  - Predictive modeling
KW  - Urban agriculture
KW  - Prediction models
KW  - Computational framework
KW  - Graph-based models
KW  - Hyper graph
KW  - Hypergraph model
KW  - Hypergraph representations
KW  - Monadic second-order temporal logic
KW  - Neuro-symbolic artificial intelligence
KW  - Predictive models
KW  - Second orders
KW  - Urban agricultures
KW  - Temporal logic
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Zauskova, A.
AU  - Miklencicova, R.
AU  - Popescu, G.H.
TI  - Visual Imagery and Geospatial Mapping Tools, Virtual Simulation Algorithms, and Deep Learning-based Sensing Technologies in the Metaverse Interactive Environment
PY  - 2022
T2  - Review of Contemporary Philosophy
VL  - 21
SP  - 122
EP  - 137
DO  - 10.22381/RCP2120228
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142216349&doi=10.22381%2fRCP2120228&partnerID=40&md5=e728cbb32ca1fccbc1bb9efbe4b2e260
AB  - In this article, we cumulate previous research findings indicating that metaverse live shopping and 3D immersive content develop on remote sensing technologies, spatial cognition algorithms, and customer experience analytics. We contribute to the literature on virtual consumer engagement and digital shopping journeys in the metaverse economy by showing that metaverse live shopping and 3D immersive content develop on remote sensing technologies, spatial cognition algorithms, and customer experience analytics. Throughout March 2022, we performed a quantitative literature review of the Web of Science, Scopus, and ProQuest databases, with search terms including “the metaverse interactive environment” + “visual imagery and geospatial mapping tools,” “virtual simulation algorithms,” and “deep learning-based sensing technologies.” As we inspected research published between 2021 and 2022, only 131 articles satisfied the eligibility criteria. By eliminating controversial findings, outcomes unsubstantiated by replication, too imprecise material, or having similar titles, we decided upon 23, generally empirical, sources. Data visualization tools: Dimensions (bibliometric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AXIS, Dedoose, ROBIS, and SRDR. © 2022, Addleton Academic Publishers. All rights reserved.
KW  - blockchain-based virtual economy
KW  - customer behavior analytics
KW  - image processing computational algorithms
KW  - operational modeling and image recognition tools
KW  - sensory data mining techniques
KW  - simulation modeling and cognitive artificial intelligence algorithms
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 38
ER  -

TY  - JOUR
AU  - Smirnov, A.
AU  - Ponomarev, A.
AU  - Shilov, N.
AU  - Levashova, T.
AU  - Teslya, N.
TI  - A CONCEPTION OF COLLABORATIVE DECISION SUPPORT SYSTEMS: APPROACH AND PLATFORM ARCHITECTURE
ST  - КОНЦЕПЦИЯ ПОСТРОЕНИЯ КОЛЛАБОРАТИВНЫХ СИСТЕМ ПОДДЕРЖКИ ПРИНЯТИЯ РЕШЕНИЙ: ПОДХОД И АРХИТЕКТУРА ПЛАТФОРМЫ
PY  - 2024
T2  - Informatics and Automation
VL  - 23
IS  - 4
SP  - 1139
EP  - 1172
DO  - 10.15622/ia.23.4.8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198640476&doi=10.15622%2fia.23.4.8&partnerID=40&md5=c3587202baa35f52879dfdd25777be12
AB  - The paper describes a general conception of collaborative decision support systems, in which teams providing decision support a) are formed flexibly in accordance with the problem and b) consist of both human experts and intelligent agents implementing AI methods and techniques. An analysis of the key problems of creating collaborative decision support systems based on the collaboration of humans and AI is carried out, the following problems are highlighted: ensuring interoperability (mutual understanding) between heterogeneous team members, reconciling differing positions of participants, ensuring trust between participants, ensuring the effectiveness of joint actions planning and maintaining a balance between predefined workflows and self-organization. Principles for constructing such systems have been formed, offering solutions to the identified problems. In particular, it is proposed to employ an ontology-oriented representation of information about the problem (in the form of multi-aspect ontology), a set of methods for monitoring team activities, reputation scheme, elements of explainable AI, as well as mechanisms of limited self-organization. The proposed concept forms the basis of a software platform for the development of collaborative decision support systems, the main architectural provisions of which are also presented in the paper. The use of the platform is illustrated by an example from the field of rational management of road infrastructure and the creation of a collaborative DSS for the development of measures to reduce road accidents. © 2024 St. Petersburg Federal Research Center of the Russian Academy of Sciences. All rights reserved.
KW  - collaborative systems
KW  - decision support system
KW  - guided self-organization
KW  - human-computer interaction
KW  - ontologies
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Thomas, C.K.
AU  - Saad, W.
TI  - Reliable Beamforming at Terahertz Bands: Are Causal Representations the Way Forward?
PY  - 2023
T2  - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings
VL  - 2023-June
DO  - 10.1109/ICASSP49357.2023.10096153
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173699375&doi=10.1109%2fICASSP49357.2023.10096153&partnerID=40&md5=69fdf1706523ecd27384afd60f13561a
AB  - Future wireless services, such as the metaverse require high information rate, reliability, and low latency. Multi-user wireless systems can meet such requirements by utilizing the abundant terahertz bandwidth with a massive number of antennas, creating narrow beamforming solutions. However, existing solutions lack proper modeling of channel dynamics, resulting in inaccurate beamforming solutions in high-mobility scenarios. Herein, a dynamic, semantically aware beamforming solution is proposed for the first time, utilizing novel artificial intelligence algorithms in variational causal inference to compute the time-varying dynamics of the causal representation of multi-modal data and the beamforming. Simulations show that the proposed causality-guided approach for Terahertz (THz) beamforming outperforms classical MIMO beamforming techniques. © 2023 IEEE.
KW  - Inference engines
KW  - Modal analysis
KW  - Variational techniques
KW  - Channel dynamics
KW  - Higher information rate
KW  - Low latency
KW  - Metaverses
KW  - Multiusers
KW  - Proper models
KW  - Tera Hertz
KW  - Terahertz band
KW  - Wireless services
KW  - Wireless systems
KW  - Beamforming
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Køien, G.M.
TI  - The Road to a Trustworthy 6G; On the Need for a “Zero Trust 6G” Paradigm
PY  - 2024
T2  - Journal of Mobile Multimedia
VL  - 20
IS  - 1
SP  - 87
EP  - 109
DO  - 10.13052/jmm1550-4646.2014
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194918907&doi=10.13052%2fjmm1550-4646.2014&partnerID=40&md5=f80390791b2e84cb4b8445867e04742e
AB  - The high-level aspects of 6G are slowly being agreed upon. It is safe to assume that 6G will bring many enhancements to 5G, including pervasive application of Artificial Intelligence (AI) and Machine Learning (ML) services. The “softwareization” trend is likely to continue and become even more prevalent. Security and trustworthiness are recognized goals for 6G. Accordingly, we predict that Zero Trust principles will become fully integrated in the 6G architecture. While necessary, this will not be sufficient. With the “softwareization” in mind, we postulate a need for increased focus on software development and deployment practices. Thus, we propose to extend the Zero Trust paradigm to encompass software development assurance and bring about a Zero Trust 6G regime. This will also be in line with the current developments for improved accountability for software and services. © 2024 River Publishers.
KW  - 6G security
KW  - accountability
KW  - softwareization
KW  - “Zero Trust 6G” concepts
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Yang, W.-C.
AU  - Marra, G.
AU  - Rens, G.
AU  - De Raedt, L.
TI  - Safe Reinforcement Learning via Probabilistic Logic Shields
PY  - 2023
T2  - IJCAI International Joint Conference on Artificial Intelligence
VL  - 2023-August
SP  - 5739
EP  - 5749
DO  - 10.24963/ijcai.2023/637
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170386139&doi=10.24963%2fijcai.2023%2f637&partnerID=40&md5=d8a4e2e85290fa0c46a1f0ac322704b7
AB  - Safe Reinforcement learning (Safe RL) aims at learning optimal policies while staying safe. A popular solution to Safe RL is shielding, which uses a logical safety specification to prevent an RL agent from taking unsafe actions. However, traditional shielding techniques are difficult to integrate with continuous, end-to-end deep RL methods. To this end, we introduce Probabilistic Logic Policy Gradient (PLPG). PLPG is a model-based Safe RL technique that uses probabilistic logic programming to model logical safety constraints as differentiable functions. Therefore, PLPG can be seamlessly applied to any policy gradient algorithm while still providing the same convergence guarantees. In our experiments, we show that PLPG learns safer and more rewarding policies compared to other state-of-the-art shielding techniques. © 2023 International Joint Conferences on Artificial Intelligence. All rights reserved.
KW  - Computer circuits
KW  - Inductive logic programming (ILP)
KW  - Reinforcement learning
KW  - Shielding
KW  - End to end
KW  - Logical safeties
KW  - Model-based OPC
KW  - Optimal policies
KW  - Policy gradient
KW  - Probabilistic logic programming
KW  - Reinforcement learning techniques
KW  - Reinforcement learnings
KW  - Safety specifications
KW  - Shielding techniques
KW  - Probabilistic logics
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - CHAP
AU  - Angelelli, L.A.
TI  - THE AI PLAN-NING ENGINE
PY  - 2022
T2  - The COVID-19 Disaster. Volume II: Prevention and Response to Pandemics Using Artificial Intelligence
SP  - 157
EP  - 254
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136037579&partnerID=40&md5=0ecc444db46684bf483cb8825d95767f
AB  - Chapter 4 explains how military planning techniques and AI technologies improve unified action plan-ning using a complex system of systems (SoS) to rapidly: (1) Understand the operational environment; (2) Define the problem(s); (3) Visualize the end state (ends); and (4) Intervene with optimal operational approaches (ways and means) to achieve individual and unified mission end states. Here, we focus on applying the military decision-making process (MDMP) supported by an integration of Modelling Simulation Analytics Looping (MSAL), cloud computing, data fabrics, and Artificial Intelligence (AI) technologies into an AI Pandemic Prevention and Response Plan-ning Engine (PPRPE) platform. This platform enables the modelling and simulation (M&S)1 of complex SoS in multidomain operating (MDO) environments. The platform will use an Operational Design framework to help decisionmakers understand Situational Awareness2 within and across diverse Operating Environments (OE). The Operational Design framework will apply (1) data-fabric technology to collect multisource data; (2) natural language processing (NLP) to automatically extract entities and their mentioned relationships from unstructured data; (3) analytic methods to model SoS entities, such as socioeconomics, socio-politics, food supply chains (SC), social well-being, etc.) involved in a crisis like COVID-19; and (4) ingest the data into a knowledge management system (KMS). The KMS information will be graphically depicted in a User Defined Operational Picture (UDOP) that represents the real-world, in our case, the pandemic prevention and response environment. In the Model Analysis Looping (MAL) process, the mission environment is translated into Static, Dynamic, and Behavioral Models (the mission models) as a set of interconnected graphical paths, capabilities, and behaviors that describe relationships between systems of the mission environment under test. AI agents and multi-agent orchestrators will be trained on Operational Art capabilities. During operation design and joint planning, the AI agents and multi-agent orchestrators will augment decisionmakers abilities to define the mission goals and generate the supporting operation plans (OPLAN) and operation orders (OPORD). The PPRPE platform will define them as mission threads3 represented by a sequence of nodes and actions, given a set of decisive conditions to achieve mission objectives. Of course, all of these features will be applied to human collaboration to optimize coordinated pandemic prevention and (if not prevented) response. As will be described, the decisionmakers and AI agents will collaborate through Simulation-Analysis-Loop (SAL) scenarios to test each likely course of action (COA) across multiple domains in a dynamic wargaming4 environment. The SAL wargaming environment will use goal-based action-and-to reward AI agents to execute tasks following along mission threads in which simulation forecasts probability of success, sensitivity and uncertainty. Through SAL, decision-makers can understand the impact of local as well as macro uncertainty, risks and performance, and they can weigh and then make trade-offs to derive optimal COAs that achieve mission goals. AI planners will optimize the selected COA across authorized budgets and resources to create a unified action plan. The AI PPRPE platform will be used to assess the execution of the unified action plan by participants in different phases and time across multiple OEs. This information will be fed back to the AI agents and decisionmakers enabling them to continuously update their COAs, reduce uncertainty, and improve probability of success in achieving their intended pandemic prevention and response goals. © 2022 by Nova Science Publishers, Inc.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Schreiberhuber, K.
TI  - Semantics-Enabled System Transparency: User-Centered Explanations in Cyber-Physical Systems
PY  - 2024
T2  - CEUR Workshop Proceedings
VL  - 3884
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214847005&partnerID=40&md5=920dceb62016079942462d341e865d24
AB  - A Cyber Physical System (CPS) helps tackle complex problems in various domains, e.g., smart grids or smart buildings. As the complexity of such systems’ behaviours often reduces user understanding and trust, this research proposal aims to enhance system transparency and user-centered explanations in such CPSs. Despite the increasing adoption of CPS across various domains, existing solutions for explaining system behaviors remain limited in scope and effectiveness. We propose a domain-independent framework, leveraging Semantic Web Technologies (SWT), to tackle this challenge. The framework aims to bridge the gap between system complexity and user comprehension by providing user-centered explanations tailored to different user types, advancing transparency, understanding, and usability in CPS deployments. Furthermore, by extending the application domain of SWT to Explainable Cyber Physical System (ExpCPS), this research contributes to the broader semantic web community. Preliminary results have shown the feasibility of the approach in a small use case, based on the newly developed ExpCPS ontology and a rule-based explanation module to derive causal paths from explicit knowledge. Future work will focus on extending these solutions as well as research on the design and evaluation of user-centered explanations. © 2024 Copyright for this paper by its authors.
KW  - Causality Representation
KW  - Cyber-Physical System
KW  - Explainability
KW  - user-centered Explanations
KW  - Decentralized systems
KW  - Causality representation
KW  - Complex problems
KW  - Cybe-physical systems
KW  - Cyber-physical systems
KW  - Explainability
KW  - Semantic Web technology
KW  - Smart grid
KW  - System behaviors
KW  - User-centered explanation
KW  - User-centred
KW  - Latent semantic analysis
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Zhang, Q.
AU  - Zhu, M.
AU  - Li, J.
AU  - Bao, J.
AU  - Zhang, D.
AU  - Chen, L.
TI  - Abductive learning-guided uncertainty modeling for time series anomaly detection
PY  - 2025
T2  - Knowledge-Based Systems
VL  - 324
C7  - 113878
DO  - 10.1016/j.knosys.2025.113878
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007442154&doi=10.1016%2fj.knosys.2025.113878&partnerID=40&md5=c221580bd3ee582066f1ddef32eeaaec
AB  - Time series anomaly detection is essential for enhancing the reliability of complex equipment. With the continuous advancements in digitalization, digital twin technology has emerged as a promising approach for addressing this challenge. Nevertheless, as production processes are dynamically optimized or equipment undergoes adjustments, the behavior of digital twin systems evolves correspondingly. This evolution introduces inherent uncertainties into the time-series data, thereby compromising the effectiveness and accuracy of conventional anomaly detection methods. To address this challenge, this research proposes a knowledge-driven uncertainty-modeling framework for time-series anomaly detection. The framework utilizes both numerical time-series data and textual domain knowledge, integrating them into a unified symbolic representation space. Specifically, the proposed framework involves two key steps: (1) discretizing the continuous time-series data into symbolic sequences and (2) employing a logical reasoning agent to transform domain-specific textual rules into anomalous symbols, thereby constructing a symbolic anomaly library. Subsequently, the anomalous symbols are applied as a sliding window to the symbolized time series data, locating anomalous segments and producing labelled data. For the noise and periodicity inherent in time-series data, the framework employs Gaussian processes (GP) augmented with Fourier transforms to effectively capture stochastic noise and recurring patterns. Finally, a TimesNet network enhanced with Gaussian processes is trained for supervised anomaly detection. Comprehensive experimental evaluations demonstrate the superiority of the proposed approach. Compared to the baseline TimesNet model, the framework achieves an 8.4% improvement in F1-score and a 10.36% increase in recall, showcasing its effectiveness in enhancing anomaly detection performance under uncertain and dynamic conditions. © 2025 Elsevier B.V.
KW  - Abductive learning
KW  - Domain knowledge
KW  - Industrial anomaly detection
KW  - Symbolic representation
KW  - Time series data
KW  - Anomaly detection
KW  - Continuous time systems
KW  - Stochastic systems
KW  - Supervised learning
KW  - Abductive learning
KW  - Anomaly detection
KW  - Complex equipment
KW  - Domain knowledge
KW  - Gaussian Processes
KW  - Industrial anomaly detection
KW  - Symbolic representation
KW  - Time-series data
KW  - Times series
KW  - Uncertainty models
KW  - Domain Knowledge
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Sun, Q.
AU  - Wang, Y.
AU  - Gong, F.
TI  - RKR-GAT: recurrent knowledge-aware recommendation with graph attention network
PY  - 2025
T2  - Knowledge and Information Systems
VL  - 67
IS  - 7
SP  - 5851
EP  - 5871
DO  - 10.1007/s10115-025-02391-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001992545&doi=10.1007%2fs10115-025-02391-9&partnerID=40&md5=a3987329b58b6c97295051107f0279f6
AB  - Knowledge graph-based recommender systems have attracted increasing attention in recent years. By extracting the semantics of entities and relationships, these recommender systems enable a more comprehensive understanding of user preferences. However, existing methods overlook the impact of low-quality links in knowledge graphs, which leads to user preference propagation bias and affects recommendation accuracy. In this paper, we propose RKR-GAT, a recurrent knowledge-aware recommendation algorithm based on a graph attention network (GAT). Specifically, RKR-GAT integrates user–item graphs and the knowledge graph into a unified graph and learns node embeddings using a graph attention network. To alleviate the issue of user preference propagation bias, we design a new path filtering module to reject low-quality connections and adaptively retain valid reasoning paths between users and items in the knowledge graph. Furthermore, RKR-GAT combines recurrent neural networks with a self-attention mechanism to efficiently analyze the semantics of the paths to generate more accurate recommendations while providing explainability. Ultimately, experimental results on three public datasets demonstrate the better performance of RKR-GAT compared to state-of-the-art baselines. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2025.
KW  - Graph neural network
KW  - Knowledge graphs
KW  - Recommender system
KW  - Graph algorithms
KW  - Graph embeddings
KW  - Graph neural networks
KW  - Graphitization
KW  - Network theory (graphs)
KW  - Recurrent neural networks
KW  - Wiener filtering
KW  - Embeddings
KW  - Graph neural networks
KW  - Graph-based
KW  - Knowledge graphs
KW  - Learn+
KW  - Low qualities
KW  - Quality connection
KW  - Recommendation accuracy
KW  - Recommendation algorithms
KW  - User's preferences
KW  - Knowledge graph
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Singh, B.
AU  - Kaunert, C.
AU  - Chandra, S.
TI  - Machine Learning for Safer Autonomous Vehicles: Tackling Traffic Detection and Collision in Smart Cities
PY  - 2025
T2  - Achieving Sustainability in Multi-Industry Settings With AI
SP  - 237
EP  - 258
DO  - 10.4018/979-8-3373-2530-9.ch008
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004513139&doi=10.4018%2f979-8-3373-2530-9.ch008&partnerID=40&md5=f6afaf4a62475d465bd945f55a49ba63
AB  - Machine learning is enhancing the transportation system and the robotic process automation and artificial intelligence are used in autos to provide intelligent automation (IA), which allows autonomous vehicles to undergo digital transformation. Smart automation has the power to completely replace human interaction, guaranteeing enhanced safety and intelligent vehicle movement. With a comparative study, this article analyzes current approaches that use IoT, AI, and machine learning in autonomous cars. It is critical to comprehend risk-reduction technology as the sector transitions from manual to automated processes. The study outlines the theoretical drawbacks and advantages of autonomous technology, highlighting artificial intel-ligence’s crucial role in vehicle management going forward. It makes recommendations for future lines of inquiry to further the advancement of autonomous car technology. This chapter focuses on the requirements for safety and the difficulties associated with autonomous cars, specifically with regard to object detection, cybersecurity and V2X privacy. © 2025 by IGI Global Scientific Publishing. All rights reserved.
KW  - Adversarial machine learning
KW  - Autonomous car
KW  - Autonomous Vehicles
KW  - Digital transformation
KW  - Intelligent automation
KW  - Machine-learning
KW  - Power
KW  - Process automation
KW  - Traffic collisions
KW  - Traffic detection
KW  - Transportation system
KW  - Intelligent robots
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Dmitrieva, E.
AU  - Balmiki, V.
AU  - Lakhanpal, S.
AU  - Lavanya, G.
AU  - Bhandari, P.
TI  - AI Evolution in Industry 4.0 and Industry 5.0: An Experimental Comparative Assessment
PY  - 2024
T2  - BIO Web of Conferences
VL  - 86
C7  - 01069
DO  - 10.1051/bioconf/20248601069
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183644510&doi=10.1051%2fbioconf%2f20248601069&partnerID=40&md5=c49f022ba5e6ee9b7f89199d2425fe74
AB  - This paper provides a thorough analysis of the development of artificial intelligence (AI) in the context of Industry 4.0 and the soon-to-be Industry 5.0. Important conclusions come from the data, such as the startling 900% increase in AI applications between 2010 and 2018, which corresponds to a 60% rise in the proportion of industrial enterprises using AI at that time. Moreover, our analysis shows that Industry 4.0's AI integration has resulted in a notable 200% cost reduction and a cumulative 400% boost in production efficiency. Our study delves into the rapid deployment of critical technologies like 5G connectivity and quantum computing within the framework of Industry 5.0. The usage of 5G connectivity has increased by 200% in only two years, while quantum computing has seen a staggering 1000% growth in acceptance over the course of eight years. These findings demonstrate the fast technological transition occurring in Industry 5.0. Furthermore, by 2033, the research predicts a startling 400% increase in human-machine cooperation and an anticipated 133% decrease in mistake rates. The research highlights how Industry 4.0's deep consequences of AI development and Industry 5.0's revolutionary possibilities will impact manufacturing in the future. © RTBS 2023.All rights reserved.
KW  - artificial intelligence
KW  - human-machine cooperation
KW  - Industry 4.0
KW  - Industry 5.0
KW  - technological adoption
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 9
ER  -

TY  - JOUR
AU  - Liang, D.
AU  - Chen, S.-H.
AU  - Chen, Z.
AU  - Wu, Y.
AU  - Chu, L.Y.L.
AU  - Xue, F.
TI  - 4D point cloud-based spatial-temporal semantic registration for monitoring mobile crane construction activities
PY  - 2024
T2  - Automation in Construction
VL  - 165
C7  - 105576
DO  - 10.1016/j.autcon.2024.105576
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196381828&doi=10.1016%2fj.autcon.2024.105576&partnerID=40&md5=917a671bd8619a1d825926bc261798c0
AB  - Existing construction activity-monitoring technologies, such as CCTV cameras and IoT devices, have limitations, such as lack of depth information, 3D measurement errors, or wireless signal vulnerability. The limitations are particularly problematic for activities related to mobile cranes due to their high mobility and flexibility. This paper presents a 4D point cloud (4DPC)-based spatial-temporal semantic registration method to overcome the limitations. The proposed method integrates spatial-temporal semantic registration into process site 4DPC with as-designed BIM semantics. Results from a one-hour on-site experiment demonstrated that the proposed method achieved 99.93–100% F1 accuracy in detecting BIM objects, and high resolution (centimeter-second granularity) of the trajectories of hoisting activities. This paper offers a two-fold contribution. First, spatial-temporal semantic registration represents an innovative approach to 4D point cloud (4DPC) processing. Secondly, the hoisting activities are comprehensively analyzed based on semantic registration, which can improve safety and productivity monitoring for smarter construction in the future. © 2024 Elsevier B.V.
KW  - 4D point cloud (4DPC)
KW  - Building information modeling (BIM)
KW  - Mobile cranes
KW  - Monitoring construction activities
KW  - Spatial-temporal semantic registration
KW  - Architectural design
KW  - Construction industry
KW  - Cranes
KW  - Object detection
KW  - 4d point cloud
KW  - Building information modeling
KW  - Building Information Modelling
KW  - Construction activities
KW  - Mobile cranes
KW  - Monitoring construction
KW  - Monitoring construction activity
KW  - Point-clouds
KW  - Spatial temporals
KW  - Spatial-temporal semantic registration
KW  - Temporal semantics
KW  - Semantics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Zhou, F.
AU  - Yuan, L.
AU  - Wu, Q.
AU  - Al-Dhahir, N.
TI  - Cognitive Semantic Communication: A New Communication Paradigm for 6G
PY  - 2025
T2  - IEEE Communications Magazine
VL  - 63
IS  - 6
SP  - 122
EP  - 129
DO  - 10.1109/MCOM.005.2400366
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214511165&doi=10.1109%2fMCOM.005.2400366&partnerID=40&md5=2095cf521cd57fc73b79cf058d22a8b5
AB  - With the commercialization of advanced modulation and coding techniques, the system capacity is gradually approaching the Shannon limit. Nevertheless, traditional communication based on the Shannon information theory is confronted with bottlenecks. Semantic communication (SemCom) is a highly promising paradigm for breaking bottlenecks. However, existing SemCom lacks flexibility, interpretability, and robustness. To overcome these deficiencies, cognitive SemComs exploit external knowledge to realize brain-like reasoning during semantic transmission, which improves spectrum efficiency and communication reliability. This article aims to survey the latest research results in this direction. Important implementation issues of cognitive SemCom are examined. Moreover, a software-defined radio testbed is built to demonstrate the feasibility of the cognitive SemCom prototype. Finally, to guide future research directions, key challenges and open issues are discussed. © 1979-2012 IEEE.
KW  - Cognitive radio
KW  - Information theory
KW  - Software prototyping
KW  - Coding techniques
KW  - Cognitive semantics
KW  - Commercialisation
KW  - Communication paradigm
KW  - Modulation and coding
KW  - Modulation techniques
KW  - Semantic communication
KW  - Shannon limit
KW  - Shannon's Information Theory
KW  - System Capacity
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Lee, Y.
AU  - Park, T.
AU  - Kang, Y.
AU  - Kim, J.
AU  - Kang, J.
TI  - ROK Defense M&S in the Age of Hyperscale AI: Concepts, Challenges, and Future Directions
PY  - 2025
T2  - IEEE Internet of Things Magazine
VL  - 8
IS  - 2
SP  - 32
EP  - 38
DO  - 10.1109/IOTM.001.2400157
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219569369&doi=10.1109%2fIOTM.001.2400157&partnerID=40&md5=e2fce2c062c8177b88e0bb57f46bc029
AB  - Integrating hyperscale AI into national defense M&S (Modeling and Simulation), under the expanding IoMDT (Internet of Military Defense Things) framework, is crucial for boosting strategic and operational readiness. We examine how IoMDT-driven hyperscale AI can provide high accuracy, speed, and the ability to simulate complex, interconnected battlefield scenarios in defense M&S. Countries like the United States and China are leading the adoption of these technologies, with varying levels of success. However, realizing the full potential of hyperscale AI requires overcoming challenges such as closed networks, sparse or "long-tail"data, complex decision-making processes, and a shortage of experts. Future directions highlight the need to adopt domestic foundation models, expand GPU/NPU investments, leverage large tech services, and employ open source solutions. These efforts will enhance national security, maintain a competitive edge, and spur broader technological and economic growth. With this blueprint, the Republic of Korea can strengthen its defense posture and stay ahead of emerging threats in modern warfare.  © 2018 IEEE.
KW  - Artificial intelligence
KW  - Investments
KW  - Complex decision
KW  - Decision-making process
KW  - Defense modeling and simulations
KW  - Foundation models
KW  - High-accuracy
KW  - Long tail
KW  - Military defense
KW  - National defence
KW  - Open-source solutions
KW  - Operational readiness
KW  - Decision making
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Xing, T.
AU  - Garcia, L.
AU  - Vilamala, M.R.
AU  - Cerutti, F.
AU  - Kaplan, L.
AU  - Preece, A.
AU  - Srivastava, M.
TI  - Neuroplex: Learning to detect complex events in sensor networks through knowledge injection
PY  - 2020
T2  - SenSys 2020 - Proceedings of the 2020 18th ACM Conference on Embedded Networked Sensor Systems
SP  - 489
EP  - 502
DO  - 10.1145/3384419.3431158
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097554607&doi=10.1145%2f3384419.3431158&partnerID=40&md5=9c18171baed401fee2bbf7a521ddeff1
AB  - Despite the remarkable success in a broad set of sensing applications, state-of-the-art deep learning techniques struggle with complex reasoning tasks across a distributed set of sensors. Unlike recognizing transient complex activities (e.g., human activities such as walking or running) from a single sensor, detecting more complex events with larger spatial and temporal dependencies across multiple sensors is extremely difficult, e.g., utilizing a hospital's sensor network to detect whether a nurse is following a sanitary protocol as they traverse from patient to patient. Training a more complicated model requires a larger amount of data-which is unrealistic considering complex events rarely happen in nature. Moreover, neural networks struggle with reasoning about serial, aperiodic events separated by large quantities in the spatial-temporal dimensions. We propose Neuroplex, a neural-symbolic framework that learns to perform complex reasoning on raw sensory data with the help of high-level, injected human knowledge. Neuroplex decomposes the entire complex learning space into explicit perception and reasoning layers, i.e., by maintaining neural networks to perform low-level perception tasks and neurally reconstructed reasoning models to perform high-level, explainable reasoning. After training the neurally reconstructed reasoning model using human knowledge, Neuroplex allows effective end-to-end training of perception models with an additional semantic loss using only sparse, high-level annotations. Our experiments and evaluation show that Neuroplex is capable of learning to efficiently and effectively detect complex events-which cannot be handled by state-of-the-art neural network models. During the training, Neuroplex not only reduces data annotation requirements by 100x, but also significantly speeds up the learning process for complex event detection by 4x. © 2020 Owner/Author.
KW  - complex event detection
KW  - mobile sensing
KW  - neural networks
KW  - neural symbolic system
KW  - resource-efficient learning
KW  - Deep learning
KW  - Embedded systems
KW  - Learning systems
KW  - Multilayer neural networks
KW  - Semantics
KW  - Sensor networks
KW  - Complex event detection
KW  - Learning process
KW  - Learning techniques
KW  - Low-level perception
KW  - Reasoning models
KW  - Sensing applications
KW  - Spatial temporals
KW  - Transient complexes
KW  - Complex networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 19
ER  -

TY  - CONF
AU  - Post, K.
AU  - Kuchida, R.
AU  - Olapade, M.
AU  - Yin, Z.
AU  - Nurmi, P.
AU  - Flores, H.
TI  - ContextLLM: Meaningful Context Reasoning from Multi-Sensor and Multi-Device Data Using LLMs
PY  - 2025
T2  - HOTMOBILE 2025 - Proceedings of the 2025 26th International Workshop on Mobile Computing Systems and Applications
SP  - 13
EP  - 18
DO  - 10.1145/3708468.3711892
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000213840&doi=10.1145%2f3708468.3711892&partnerID=40&md5=92b3983f546a85d6957a1fc86c83d0cb
AB  - Conventional context awareness and activity recognition models produce abstract outputs that offer limited insights into user behavior and situational context. These can be significantly enhanced by leveraging multi-sensor and multi-device data streams. However, the aggregation and modelling of context sensor data presents complex challenges that require advanced inference capabilities. We introduce ContextLLM, a context-driven solution powered by Large Language Models (LLMs), designed to transform sparse, abstract insights from various sensors and devices into a detailed, descriptive context. Through rigorous experiments using a well-established benchmark dataset for activity recognition, we demonstrate that ContextLLM can significantly enhance context understanding. However, our analysis also highlights how the quality and complexity of sensor data representations impact the LLM’s ability to accurately deduce context. Building on these findings, we develop a research agenda that outlines key challenges, and conclude with a discussion on the limitations and practical considerations of LLM-based reasoning in context-aware applications. © 2025 Copyright held by the owner/author(s).
KW  - Context modelling
KW  - Sensor data assistant
KW  - Wearable data
KW  - Data assimilation
KW  - Wearable sensors
KW  - Activity recognition
KW  - Context models
KW  - Device data
KW  - Language model
KW  - Multi sensor
KW  - Multi-devices
KW  - Sensor data assistant
KW  - Sensor device
KW  - Sensors data
KW  - Wearable data
KW  - Data aggregation
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Newell, M.
TI  - Spatial Cognition and Context Awareness Algorithms, Virtual Modeling and Remote Sensing Technologies, and Visual Perception and Data Mining Tools across the Economic Infrastructure of the Metaverse
PY  - 2022
T2  - Analysis and Metaphysics
VL  - 21
SP  - 91
EP  - 107
DO  - 10.22381/AM2120226
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146463402&doi=10.22381%2fAM2120226&partnerID=40&md5=f9fbf03535e9f205e9b265387ff92cf8
AB  - The present study systematically reviews the existing research on decision support and augmented reality shopping tools, biometric authentication features, and cognitive enhancement technologies in the retail metaverse. My findings clarify that shopping and spending habits integrate behavior analysis and prediction tools in immersive interconnected virtual worlds and across intelligent simulation environments, and I contribute to the literature by indicating that decentralized data analytics and biometric authentication features are pivotal in artificial intelligence-powered live shopping and virtual retail experiences in relation to digital assets. Throughout July 2022, a quantitative literature review of the Web of Science, Scopus, and ProQuest databases was performed, with search terms including “metaverse” + “spatial cognition and context awareness algorithms,” “virtual modeling and remote sensing technologies,” and “visual perception and data mining tools.” As research published between 2021 and 2022 was inspected, only 166 articles satisfied the eligibility criteria. By taking out controversial or ambiguous findings (insufficient/irrelevant data), outcomes unsubstantiated by replication, too general material, or studies with nearly identical titles, I selected 32 mainly empirical sources. Data visualization tools: Dimensions (bibliometric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AMSTAR, Dedoose, Distiller SR, and SRDR. © 2022, Addleton Academic Publishers. All rights reserved.
KW  - context awareness
KW  - metaverse
KW  - remote sensing
KW  - spatial cognition
KW  - virtual modeling
KW  - visual perception
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Sarwatt, D.S.
AU  - Lin, Y.
AU  - Ding, J.
AU  - Sun, Y.
AU  - Ning, H.
TI  - Metaverse for Intelligent Transportation Systems (ITS): A Comprehensive Review of Technologies, Applications, Implications, Challenges and Future Directions
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 7
SP  - 6290
EP  - 6308
DO  - 10.1109/TITS.2023.3347280
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182923382&doi=10.1109%2fTITS.2023.3347280&partnerID=40&md5=57eb92688f7dc82cc4187dd657ae21a7
AB  - Intelligent transportation systems (ITS) have made significant advancements in enhancing transportation safety, reliability, and efficiency. However, challenges persist in security, privacy, data management, and integration. Metaverse, an emerging technology enabling immersive and simulated experiences, presents promising solutions to overcome these challenges. By establishing secure communication channels, facilitating virtual simulations for safe testing and training, and enabling centralized data management with real-time analytics, metaverse offers a transformative approach to address these challenges. While metaverse has found extensive applications across industries, its potential in transportation remains largely untapped. This comprehensive review delves into the integration of the metaverse in ITS, exploring key technologies like virtual reality, digital twin, blockchain, and artificial intelligence, and their specific applications in the context of ITS. Real-world case studies, research projects, and initiatives are compiled to showcase the metaverse's potential for ITS. It also examines the societal, economic, and technological implications of metaverse integration in ITS and highlights the associated integration challenges. Lastly, future research directions are identified to unlock the metaverse's full potential in enhancing transportation systems.  © 2000-2011 IEEE.
KW  - Fundamental metaverse technologies
KW  - intelligent transportation system
KW  - metaverse
KW  - metaverse integration
KW  - E-learning
KW  - Information management
KW  - Integration
KW  - Intelligent systems
KW  - Intelligent vehicle highway systems
KW  - Virtual addresses
KW  - Fundamental metaverse technology
KW  - Intelligent transportation systems
KW  - Metaverse integration
KW  - Metaverses
KW  - Review of technologies
KW  - Technology application
KW  - X reality
KW  - Virtual reality
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 24
ER  -

TY  - JOUR
AU  - Meng, S.
AU  - Wu, S.
AU  - Zhang, J.
AU  - Cheng, J.
AU  - Zhou, H.
AU  - Zhang, Q.
TI  - Semantics-Empowered Space-Air-Ground-Sea Integrated Network: New Paradigm, Frameworks, and Challenges
PY  - 2025
T2  - IEEE Communications Surveys and Tutorials
VL  - 27
IS  - 1
SP  - 140
EP  - 183
DO  - 10.1109/COMST.2024.3416309
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196511222&doi=10.1109%2fCOMST.2024.3416309&partnerID=40&md5=1932ade4da186bb96ec181c1fa507a47
AB  - In the coming sixth generation (6G) communication era, to provide seamless and ubiquitous connections, the space-air-ground-sea integrated network (SAGSIN) is envisioned to address the challenges of communication coverage in areas with difficult conditions, such as the forest, desert, and sea. Considering the fundamental limitations of the SAGSIN including large-scale scenarios, highly dynamic channels, and limited device capabilities, traditional communications based on Shannon information theory cannot satisfy the communication demands. Moreover, bit-level reconstruction is usually redundant for many human-to-machine or machine-to-machine applications in the SAGSIN. Therefore, it is imperative to consider high-level communications towards semantics exchange, called semantic communications. In this survey, according to the interpretations of the term "semantics", including "significance", "meaning", and "effectiveness-related information", we review state-of-the-art works on semantic communications from three perspectives, which are 1) significance representation and protection, 2) meaning similarity measurement and meaning enhancement, and 3) ultimate effectiveness and effectiveness yielding. Sequentially, three types of semantic communication systems can be correspondingly introduced, namely the significance-oriented, meaning-oriented, and effectiveness/task-oriented semantic communication systems. Implementation of the above three types of systems in the SAGSIN necessitates a new perception-communication-computing-actuation-integrated paradigm (PCCAIP), where all the available perception, computing, and actuation techniques jointly facilitate significance-oriented sampling & transmission, semantic extraction & reconstruction, and task decision. Finally, we point out some future challenges on semantic communications in the SAGSIN. This survey provides a comprehensive review on the future semantic communications in the SAGSIN, and elaborates on the performance metrics and techniques related to semantic communications for references and further in-depth investigations. © 1998-2012 IEEE.
KW  - data significance
KW  - deep learning (DL)
KW  - perception-communication-computing-actuation integrated paradigm (PCCAIP)
KW  - semantic communications
KW  - Space-air-ground-sea integrated network (SAGSIN)
KW  - task-oriented communications
KW  - Computation theory
KW  - Data mining
KW  - Deep learning
KW  - Information theory
KW  - Machine-to-machine communication
KW  - Mobile telecommunication systems
KW  - 6g mobile communication
KW  - Air grounds
KW  - Communications systems
KW  - Data significance
KW  - Deep learning
KW  - Integrated networks
KW  - Integrated paradigms
KW  - Mobile communications
KW  - Perception-communication-computing-actuation integrated paradigm
KW  - Receiver
KW  - Semantic communication
KW  - Space-air-ground-sea integrated network
KW  - Task analysis
KW  - Task-oriented
KW  - Task-oriented communication
KW  - Semantics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 14
ER  -

TY  - JOUR
AU  - Khoramnejad, F.
AU  - Hossain, E.
TI  - Generative AI for the Optimization of Next-Generation Wireless Networks: Basics, State-of-the-Art, and Open Challenges
PY  - 2025
T2  - IEEE Communications Surveys and Tutorials
DO  - 10.1109/COMST.2025.3535554
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216852909&doi=10.1109%2fCOMST.2025.3535554&partnerID=40&md5=d2389fc9cfa6aa0fe6ce3a1c612c19d9
AB  - Next-generation (xG) wireless networks, with their complex and dynamic nature, present significant challenges to using traditional optimization techniques. Generative Artificial Intelligence (GAI) emerges as a powerful tool due to its unique strengths. Unlike traditional optimization techniques and other machine learning methods, GAI excels at learning from real-world network data, capturing its intricacies. This enables safe, offline exploration of various configurations and generation of diverse, unseen scenarios, empowering proactive, data-driven exploration and optimization for xG networks. Additionally, GAI's scalability makes it ideal for large-scale xG networks. This paper surveys how GAI-based models unlock optimization opportunities in xG wireless networks. We begin by providing a review of GAI models and some of the major communication paradigms of xG (e.g., Sixth Generation) wireless networks. We then delve into exploring how GAI can be used to improve resource allocation and enhance overall network performance. Additionally, we briefly review the networking requirements for supporting GAI applications in xG wireless networks. The paper further discusses the key challenges and future research directions in leveraging GAI for network optimization. Finally, a case study demonstrates the application of a diffusion-based GAI model for load balancing, carrier aggregation, and backhauling optimization in non-terrestrial networks, a core technology of xG networks. This case study serves as a practical example of how the combination of reinforcement learning and GAI can be implemented to address real-world network optimization problems.  © 2024 IEEE.
KW  - data-driven optimization
KW  - Generative AI
KW  - network-assisted generative AI
KW  - resource allocation
KW  - xG wireless networks
KW  - Queueing networks
KW  - Reinforcement learning
KW  - Resource allocation
KW  - Case-studies
KW  - Data-driven optimization
KW  - Generative AI
KW  - Intelligence models
KW  - Network-assisted generative AI
KW  - Optimisations
KW  - Optimization techniques
KW  - Real-world networks
KW  - Resources allocation
KW  - Xg wireless network
KW  - Generative adversarial networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Nzomo, M.
TI  - A Hybrid AI Framework for Sensor-Based Personal Health Monitoring towards Precision Health
PY  - 2024
T2  - Proceedings of the AAAI Conference on Artificial Intelligence
VL  - 38
IS  - 21
SP  - 23405
EP  - 23406
DO  - 10.1609/aaai.v38i21.30403
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189652198&doi=10.1609%2faaai.v38i21.30403&partnerID=40&md5=6e1f5f3b61d967718bedadc033a89a3b
AB  - Non-communicable diseases are on the rise globally, resulting in accelerated efforts to develop personal health monitoring systems for early detection, prediction, and prevention of diseases. This is part of the vision of precision health, an emerging paradigm that focuses on preventing disease before it strikes by encouraging people to actively monitor and work towards improving their health. A key facilitator of this is the use of wearable sensors that can collect and measure physiological data. Although many sensor-based health monitoring systems have been proposed, interoperability of health data and processes, prediction of future health states, and uncertainty management remain open challenges. This research aims to alleviate these challenges through the development of a reusable framework integrating both data-driven and knowledge-driven AI within a hybrid AI architecture. Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.
KW  - Artificial intelligence
KW  - Information management
KW  - Interoperability
KW  - Data prediction
KW  - Health data
KW  - Health monitoring
KW  - Health monitoring system
KW  - Health process
KW  - Health state
KW  - Non-communicable disease
KW  - Personal health
KW  - Physiological data
KW  - Process prediction
KW  - Wearable sensors
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Bocklandt, S.
AU  - Derkinderen, V.
AU  - Kimmig, A.
AU  - De Raedt, L.
TI  - Approximate Compression of CNF Concepts
PY  - 2025
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 
VL  - 15244 LNAI
SP  - 149
EP  - 164
DO  - 10.1007/978-3-031-78980-9_10
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219193083&doi=10.1007%2f978-3-031-78980-9_10&partnerID=40&md5=6000053e7baeb8ef061c5084b23cfe6c
AB  - We consider a novel concept-learning and merging task, motivated by two use-cases. The first is about merging and compressing music playlists, and the second about federated learning with data privacy constraints. Both settings involve multiple learned concepts that must be merged and compressed into a single interpretable and accurate concept description. Our concept descriptions are logical formulae in CNF, for which merging, i.e. disjoining, multiple CNFs may lead to very large concept descriptions. To make the concepts interpretable, we compress them relative to a dataset. We propose a new method named CoWC (Compression Of Weighted Cnf) that approximates a CNF by exploiting techniques of itemset mining and inverse resolution. CoWC compresses the CNF size while also considering the F1-score w.r.t. the dataset. Our empirical evaluation shows that CoWC outperforms alternative compression approaches. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
KW  - Concept learning
KW  - Formula compression
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Compression approach
KW  - Concept description
KW  - Concept learning
KW  - Empirical evaluations
KW  - F1 scores
KW  - Formula compression
KW  - Itemset mining
KW  - Logical formulas
KW  - Novel concept
KW  - Privacy constraints
KW  - Federated learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Tran, H.-D.
AU  - Choi, S.W.
AU  - Li, Y.
AU  - Okamoto, H.
AU  - Hoxha, B.
AU  - Fainekos, G.
TI  - ProbStar Temporal Logic for Verifying Complex Behaviors of Learning-enabled Systems
PY  - 2025
T2  - HSCC 2025 - Proceedings of the 28th International Conference on Hybrid Systems: Computation and Control, part of CPS-IoT Week
C7  - 19
DO  - 10.1145/3716863.3718035
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007503137&doi=10.1145%2f3716863.3718035&partnerID=40&md5=42022abace63857e2b5a743db7cdd13c
AB  - This paper introduces a novel quantitative verification framework for analyzing the temporal behaviors of learning-enabled systems (LES). Our approach employs ProbStar Temporal Logic (ProbStarTL) to specify LES temporal behaviors alongside advanced reachability and verification algorithms. Unlike existing qualitative methods focusing primarily on reach-avoid properties, our framework enables quantitative analysis of temporal properties. ProbStarTL, distinct from Signal Temporal Logic, operates on sequences of timed probabilistic star reachable sets, known as ProbStar signals. It features a clear syntax and dual qualitative and quantitative semantics. Our framework includes depth-first search algorithms for generating ProbStar traces and novel verification algorithms that transform ProbStarTL specifications into a computable disjunctive normal form for analysis. Our verification algorithms allow for both exact and approximate analyses. The exact scheme guarantees sound and complete results with precise satisfaction probabilities, while the approximate scheme offers sound results with maximum and minimum satisfaction probabilities at a reduced computational cost. The new verification framework is implemented using StarV, and its effectiveness is demonstrated through case studies on a learning-based adaptive cruise control system and an advanced emergency braking system. © 2025 Copyright held by the owner/author(s).
KW  - Probabilistics
KW  - Property
KW  - Qualitative method
KW  - Quantitative verification
KW  - Reachability
KW  - Reachable set
KW  - Temporal behavior
KW  - Temporal property
KW  - Verification algorithms
KW  - Verification framework
KW  - Temporal logic
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Mircică, N.
TI  - Immersive and Engaging Digital Content, Data Visualization Tools, and Location Analytics in a Decentralized Metaverse
PY  - 2022
T2  - Linguistic and Philosophical Investigations
VL  - 21
SP  - 89
EP  - 104
DO  - 10.22381/lpi2120226
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135621164&doi=10.22381%2flpi2120226&partnerID=40&md5=3070c827d8ff36247314b08c3e258aee
AB  - In this article, I cumulate previous research findings indicating that immersive technologies, automated machine learning, data visualization tools, and location analytics can assist in retaining repeat shoppers, influencing consumer patterns and driving user engagement in virtual retail stores. I contribute to the literature on the decentralized metaverse by showing that data sharing technologies and visual analytics can optimize operations and livestream video shopping experiences in retail and business locations as regards digital ownership in the blockchain-based virtual economy. Throughout March 2022, I performed a quantitative literature review of the Web of Science, Scopus, and ProQuest databases, with search terms including “metaverse” + “immersive digital content,” “engaging digital content,” “data visualization tools,” and “location analytics.” As I inspected research published between 2021 and 2022, only 76 articles satisfied the eligibility criteria. By eliminating controversial findings, outcomes unsubstantiated by replication, too imprecise material, or having similar titles, I decided upon 14, generally empirical, sources. Data visualization tools: Dimensions (bibliometric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AMSTAR, Distiller SR, MMAT, and ROBIS. © 2022, Addleton Academic Publishers. All rights reserved.
KW  - analytics
KW  - digital content
KW  - immersive
KW  - metaverse
KW  - retail
KW  - visualization
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 9
ER  -

TY  - CONF
AU  - Adhikary, A.
AU  - Raha, A.D.
AU  - Qiao, Y.
AU  - Park, Y.M.
AU  - Han, Z.
AU  - Hong, C.S.
TI  - A Power Allocation Framework for Holographic MIMO-Aided Energy-Efficient Cell-Free Networks
PY  - 2024
T2  - IEEE International Conference on Communications
SP  - 5546
EP  - 5552
DO  - 10.1109/ICC51166.2024.10622629
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198362227&doi=10.1109%2fICC51166.2024.10622629&partnerID=40&md5=0525aade05ba07730c388a52000eb53c
AB  - The 6G wireless communication networks need an intelligent networking system to meet the ever-increasing de-mands of various applications and mobile devices to ensure power savings, energy efficiency (EE), high integration of devices, and mass connection. To achieve these aims, an artificial intelligence (AI)-based holographic MIMO (HMIMO)-aided cell-free (CF) network is suggested to allocate desired power for beamforming by activating the required number of grids from the serving HMIMOs for serving the users. An optimization problem is developed to ensure effective power allocation that maximizes the EE of the system. A Transformer-based AI framework is proposed to solve the formulated NP-hard problem that distributes desired power for serving the users by activating the required number of grids from the required number of serving HMIMOs in the CF network. Finally, simulation results represent that the proposed power allocation framework outperforms the gated recurrent unit and long short-term memory-based mechanisms, achieving a combined power savings of 12.5% and 4.06%, and a combined EE improvement of 14.68% and 8.93%, correspondingly. Therefore, our suggested AI-based framework guarantees effective power allocation for beamforming to serve the users. © 2024 IEEE.
KW  - cell-free network
KW  - energy efficiency
KW  - Holographic MIMO
KW  - power allocation
KW  - Beamforming
KW  - Genes
KW  - Health risks
KW  - Mobile telecommunication systems
KW  - Risk analysis
KW  - Risk assessment
KW  - Cell-free
KW  - Cell-free network
KW  - Effective power
KW  - Energy
KW  - Energy efficient
KW  - Holographic MIMO
KW  - Number of Grids
KW  - Power
KW  - Power allocations
KW  - Power-saving
KW  - Long short-term memory
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Kaddoura, S.
AU  - Al Husseiny, F.
TI  - The rising trend of Metaverse in education: challenges, opportunities, and ethical considerations
PY  - 2023
T2  - PeerJ Computer Science
VL  - 9
C7  - e1252
DO  - 10.7717/peerj-cs.1252
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156263768&doi=10.7717%2fpeerj-cs.1252&partnerID=40&md5=90e67c669ac6e638908f714f08d032e1
AB  - Metaverse is invading the educational sector and will change human-computer interaction techniques. Prominent technology executives are developing novel ways to turn the Metaverse into a learning environment, considering the rapid growth of technology. Since the COVID-19 outbreak, people have grown accustomed to teleworking, telemedicine, and numerous other forms of distance interaction. Recently, the Metaverse has been the focus of many educators. With Facebook’s statement that it was rebranding and promoting itself as Meta, this field saw a surge in interest in the areas of computer science and education. There is a literature gap in studying the Metaverse’s role in education. This article is a systematic review following the PRISMA framework that reviews the role of the Metaverse in education to shrink the literature gap. It presents various educational uses to aid future research in this field. Additionally, it demonstrates how enabling technologies like extended reality (XR) and the internet of everything (IoE) will significantly impact educational services in the Metaverses of the future of teaching and learning. The article also outlines key challenges, ethical issues, and potential threats to using the Metaverse for education to offer a road map for future research that will investigate how the Metaverse will improve learning and teaching experiences. Subjects Human-Computer Interaction, Computer Education, Network Science and Online Social Networks, Social Computing, Internet of Things © 2023, Kaddoura and Al Husseiny Distributed under Creative Commons CC-BY 4.0. All rights reserved.
KW  - Augmented reality
KW  - Challenges
KW  - Education
KW  - Human computer interaction
KW  - Metaverse
KW  - Mixed reality
KW  - Virtual reality
KW  - Augmented reality
KW  - Computer aided instruction
KW  - Engineering education
KW  - Ethical technology
KW  - Human computer interaction
KW  - Internet of Everything
KW  - Social networking (online)
KW  - Social sciences computing
KW  - Challenge
KW  - Distance interaction
KW  - Educational sectors
KW  - Ethical considerations
KW  - Interaction techniques
KW  - Learning environments
KW  - Metaverses
KW  - Mixed reality
KW  - Rapid growth
KW  - Teleworking
KW  - Mixed reality
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 153
ER  -

TY  - CONF
AU  - Kumar, M.K.
AU  - Musnmusawi, M.
AU  - Kodati, S.
AU  - Suresh, G.R.
AU  - Suresh, T.
TI  - Optimized Low-Power Mixed-Signal Sensor Systems: Improved Cross-Domain Approach to Maintain Classification Accuracy
PY  - 2025
T2  - 3rd International Conference on Integrated Circuits and Communication Systems, ICICACS 2025
DO  - 10.1109/ICICACS65178.2025.10967955
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004729966&doi=10.1109%2fICICACS65178.2025.10967955&partnerID=40&md5=f46570a27c6114824570b8bf603df971
AB  - Optimizing the mixed-signal Systems-on-Chips (SoCs) is a difficult task, particularly while including analog developing blocks and Machine Learning (ML)-based algorithms that make overall performance hard to predict. These designs for minimizing energy consumption increases the lifetime from harvested energy from the environment. In this manuscript, a method is developed for optimizing difficult mixed-signal sensor system that includes three phases. Initially, Pareto-optimal local performance of individual circuits is modelled, developing the macro-model of mixed-signal system performance involving local nonidealities and identifying optimum group of system-level parameters utilizing numerical optimization. The method is employed for Electrocardiogram (ECG) sensor system with integrated arrhythmia classification with minimizing system energy consumption and constraints on inference accuracy. Various numerical optimization algorithms are compared to evaluate its performance for minimizing task are Bayesian Optimization and Gradient-based optimization. The experimental results obtained optimization in reasonable execution time of 9.5 h while compared to existing algorithms on complex mixed-signal system. © 2025 IEEE.
KW  - electrocardiogram
KW  - local nonidealities
KW  - machine learning
KW  - mixed-signal
KW  - pareto-optimal and systems-on-chips
KW  - Local nonideality
KW  - Machine-learning
KW  - Mixed signal
KW  - Nonideality
KW  - Pareto-optimal
KW  - Pareto-optimal and system-on-chip
KW  - Performance
KW  - Sensor systems
KW  - Signal sensors
KW  - Systems-on-Chip
KW  - Pareto principle
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Zhang, X.
AU  - Teng, D.
AU  - Chowdhury, R.R.
AU  - Li, S.
AU  - Hong, D.
AU  - Gupta, R.K.
AU  - Shang, J.
TI  - UniMTS: Unified Pre-training for Motion Time Series
PY  - 2024
T2  - Advances in Neural Information Processing Systems
VL  - 37
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000487976&partnerID=40&md5=135b7efbc61c4a17d88427994cd02573
AB  - Motion time series collected from low-power, always-on mobile and wearable devices such as smartphones and smartwatches offer significant insights into human behavioral patterns, with wide applications in healthcare, automation, IoT, and AR/XR. However, given security and privacy concerns, building large-scale motion time series datasets remains difficult, hindering the development of pre-trained models for human activity analysis. Typically, existing models are trained and tested on the same dataset, leading to poor generalizability across variations in device location, device mounting orientation, and human activity type. In this paper, we introduce UniMTS1, the first unified pre-training procedure for motion time series that generalizes across diverse device latent factors and activities. Specifically, we employ a contrastive learning framework that aligns motion time series with text descriptions enriched by large language models. This helps the model learn the semantics of time series to generalize across activities. Given the absence of large-scale motion time series data, we derive and synthesize time series from existing motion skeleton data with all-joint coverage. We use spatio-temporal graph networks to capture the relationships across joints for generalization across different device locations. We further design rotation-invariant augmentation to make the model agnostic to changes in device mounting orientations. Our model shows exceptional generalizability across 18 motion time series classification benchmark datasets, outperforming the best baselines by 340% in the zero-shot setting, 16.3% in the few-shot setting, and 9.2% in the full-shot setting. © 2024 Neural information processing systems foundation. All rights reserved.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Song, C.
AU  - Shin, S.-Y.
AU  - Shin, K.-S.
TI  - Exploring the Key Characteristics and Theoretical Framework for Research on the Metaverse
PY  - 2023
T2  - Applied Sciences (Switzerland)
VL  - 13
IS  - 13
C7  - 7628
DO  - 10.3390/app13137628
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165166332&doi=10.3390%2fapp13137628&partnerID=40&md5=d98ce24a36e6721f9a307a19a0e25bf0
AB  - This study presents an insightful examination of the conceptual and practical facets of the Metaverse by establishing a novel theoretical framework underpinned by an empirical case study of the Sandbox platform. Anchored in the principles of legality, virtual-reality integration, technological affinity, and community-driven innovation, the paper elucidates the inherent characteristics and potentialities of the Metaverse. Through meticulous research, the paper investigates the antecedents and evolution of the Metaverse, postulating an open, decentralized, and self-regulating ecosystem predicated on user-generated content and engagement. Furthermore, an in-depth case study of the Sandbox elucidates the practical applications, challenges, and opportunities associated with the operationalization of the Metaverse. The study showcases how avant-garde technologies such as blockchain, virtual reality, and artificial intelligence are instrumental in fostering immersive experiences, safeguarding virtual asset ownership, and facilitating tailored services. Moreover, the paper accentuates the indispensable role of community engagement and continuous innovation in cultivating a flourishing Metaverse environment. The analysis exposes that the burgeoning development of the Metaverse is intrinsically linked to the amalgamation of the virtual and the tangible, extending the frontiers of the digital economy. While shedding light on the virtues of the Metaverse, the study recognizes its nascent state and encourages further scholarly inquiry to comprehend and navigate its complexities. This research contributes significantly to the academic and practical understanding of the Metaverse, serving as a cornerstone for future investigations and technological advancements in this paradigm-shifting domain. © 2023 by the authors.
KW  - combination of virtual and real
KW  - digitalization of assets
KW  - governance by law
KW  - key characteristics
KW  - Metaverse
KW  - Rule of Technological Association
KW  - theoretical framework
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 27
ER  -

TY  - JOUR
AU  - Awasthi, A.
AU  - Goel, N.
TI  - An Approach for Efficient and Accurate Phishing Website Prediction Using Improved ML Classifier Performance for Feature Selection
PY  - 2024
T2  - International Journal of Experimental Research and Review
VL  - 40
IS  - Special Issue
SP  - 73
EP  - 89
DO  - 10.52756/ijerr.2024.v40spl.006
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198044131&doi=10.52756%2fijerr.2024.v40spl.006&partnerID=40&md5=f489fd107a1a6034d6957c25850cd6e5
AB  - The article discusses the use of machine learning (ML) to combat phishing websites, which are deceptive sites that mimic trusted entities to steal sensitive information. This is why the continued invention of methods of identifying and counteracting phishing threats is beneficial. Such attacks pose significant risks to the integrity of online security. To enhance the success rate and specificity of predicting phishing websites, this study proposes a new approach that utilizes machine learning algorithms. To enhance the methods mentioned above and achieve better results in classification and better prediction of customer behaviour, the main points exposed to further transformations are increasing classifier accuracy and selecting an optimal feature space. Traditional anti-phishing strategies like blacklisting and heuristic searches often have slow detection times and high false positive rates. The article introduces a novel feature selection method to extract highly correlated features from datasets, thereby enhancing classifier accuracy. Using six feature selection techniques on a phishing dataset, it evaluates eight classifiers, including SVM, Logistic Regression, Random Forest, and others. The study finds that the Random Forest classifier combined with the Chi-2 feature selection method significantly improves model accuracy, achieving up to 96.99%. © 2024 International Academic Publishing House (IAPH). All rights reserved.
KW  - Computer viruses
KW  - cybersecurity
KW  - Machine learning (ML)
KW  - Phishing Website Prediction
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Ossa, L.F.C.
AU  - Chamoso, P.
AU  - Arango-López, J.
AU  - Pinto-Santos, F.
AU  - Isaza, G.A.
AU  - Santa-Cruz-gonzález, C.
AU  - Ceballos-Marquez, A.
AU  - Hernández, G.
AU  - Corchado, J.M.
TI  - A hybrid model for COVID-19 monitoring and prediction
PY  - 2021
T2  - Electronics (Switzerland)
VL  - 10
IS  - 7
C7  - 799
DO  - 10.3390/electronics10070799
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103116424&doi=10.3390%2felectronics10070799&partnerID=40&md5=8a5a3298447a0c6bd5e3ba5edd63085d
AB  - COVID-19 is caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) and has a case-fatality rate of 2–3%, with higher rates among elderly patients and patients with comorbidities. Radiologically, COVID-19 is characterised by multifocal ground-glass opacities, even for patients with mild disease. Clinically, patients with COVID-19 present respiratory symptoms, which are very similar to other respiratory virus infections. Our knowledge regarding the SARS-CoV-2 virus is still very limited. These facts make it vitally important to establish mechanisms that allow to model and predict the evolution of the virus and to analyze the spread of cases under different circumstances. The objective of this article is to present a model developed for the evolution of COVID in the city of Manizales, capital of the Department of Caldas, Colombia, focusing on the methodology used to allow its application to other cases, as well as on the monitoring tools developed for this purpose. This methodology is based on a hybrid model which combines the population dynamics of the SIR model of differential equations with extrapolations based on recurrent neural networks. This combination provides self-explanatory results in terms of a coefficient that fluctuates with the restraint measures, which may be further refined by expert rules that capture the expected changes in such measures. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.
KW  - Compartmental models
KW  - COVID-19
KW  - Curve fitting
KW  - LSTM
KW  - Prediction
KW  - Recurrent neural network
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 21
ER  -

TY  - JOUR
AU  - Zhang, Z.
AU  - Yilmaz, L.
AU  - Liu, B.
TI  - A Critical Review of Inductive Logic Programming Techniques for Explainable AI
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 8
SP  - 10220
EP  - 10236
DO  - 10.1109/TNNLS.2023.3246980
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153399027&doi=10.1109%2fTNNLS.2023.3246980&partnerID=40&md5=8c4617a2b67fb84975eb39f51e80f7c2
AB  - Despite recent advances in modern machine learning algorithms, the opaqueness of their underlying mechanisms continues to be an obstacle in adoption. To instill confidence and trust in artificial intelligence (AI) systems, explainable AI (XAI) has emerged as a response to improve modern machine learning algorithms' explainability. Inductive logic programming (ILP), a subfield of symbolic AI, plays a promising role in generating interpretable explanations because of its intuitive logic-driven framework. ILP effectively leverages abductive reasoning to generate explainable first-order clausal theories from examples and background knowledge. However, several challenges in developing methods inspired by ILP need to be addressed for their successful application in practice. For example, the existing ILP systems often have a vast solution space, and the induced solutions are very sensitive to noises and disturbances. This survey paper summarizes the recent advances in ILP and a discussion of statistical relational learning (SRL) and neural-symbolic algorithms, which offer synergistic views to ILP. Following a critical review of the recent advances, we delineate observed challenges and highlight potential avenues of further ILP-motivated research toward developing self-explanatory AI systems. © 2012 IEEE.
KW  - Differentiable inductive logic programming (aILP)
KW  - explainable artificial intelligence (XAI)
KW  - ILP
KW  - machine learning
KW  - meta-interpretive learning (MIL)
KW  - neuro-symbolic AI
KW  - probabilistic ILP (PILP)
KW  - statistical relational learning (SRL)
KW  - Artificial intelligence
KW  - Computer circuits
KW  - Inductive logic programming (ILP)
KW  - Job analysis
KW  - Learning algorithms
KW  - Learning systems
KW  - > <tex-math notation="LaTeX">$\partial$</tex-math> </inline-formula>inductive logic programming)
KW  - Differentiable inductive logic programming (<inline-formula xmlns:ali="
KW  - Explainable artificial intelligence (XAI)
KW  - Flowchart
KW  - Inductive logic
KW  - Inductive logic programming
KW  - Logic-programming
KW  - Machine-learning
KW  - Meta-interpretive learning
KW  - Neuro-symbolic artificial intelligence
KW  - Probabilistic inductive logic programming
KW  - Statistical relational learning
KW  - Task analysis
KW  - Xmlns:mml="
KW  - Xmlns:xlink="
KW  - Xmlns:xsi="
KW  - abductive reasoning
KW  - adoption
KW  - algorithm
KW  - article
KW  - artificial intelligence
KW  - inductive reasoning
KW  - learning
KW  - machine learning
KW  - noise
KW  - trust
KW  - Semantics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Wong, J.
AU  - Nack, E.
AU  - Steelman, Z.
AU  - Erway, S.
AU  - Bastian, N.D.
TI  - A Methodology for Representing and Assessing Artificial Intelligence Decision Aids within Modeling and Simulation
PY  - 2024
T2  - Proceedings of SPIE - The International Society for Optical Engineering
VL  - 13051
C7  - 130510K
DO  - 10.1117/12.3013180
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197262821&doi=10.1117%2f12.3013180&partnerID=40&md5=acb30dfbc690600e52f7208b7e0c4b42
AB  - Artificial intelligence (AI) is quickly gaining relevance as a transformative technology. Its ability to rapidly fuse and synthesize data, accelerate processes, automate tasks, and augment decision-making has the potential to revolutionize multi-domain warfighting through data-centric operations and algorithmic warfare. As the military relies more on AI-enabled Decision Aids to increase the efficiency and effectiveness of decision-making, it highlights the need to effectively assess them before deployment. Modeling and simulation (M&S) environments are essential for assessing these rapidly evolving AI-enabled systems. Accepted analytical frameworks are needed to guide ways to represent and model AI sufficiently within M&S environments for accurate assessment. In this paper, we identify common characteristics within the main categories of AI and investigate how those characteristics can be best represented across the main categories of M&S. We provide two use cases to highlight an assessment of AI-enabled Decision Aids for cybersecurity and aeromedical evacuation problems. Our example use cases demonstrate how to leverage a framework for analytic assessment of AI within M&S environments. © 2024 SPIE.
KW  - Analytic Assessment Framework
KW  - Artificial Intelligence
KW  - Decision Aids
KW  - Modeling and Simulation
KW  - Decision making
KW  - Decision support systems
KW  - Analytic assessment framework
KW  - Data centric
KW  - Decision aids
KW  - Decisions makings
KW  - Intelligence decision
KW  - Model and simulation
KW  - Modeling environments
KW  - Multi-domains
KW  - Simulation environment
KW  - War fighting
KW  - Artificial intelligence
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Haresamudram, H.
AU  - Beedu, A.
AU  - Rabbi, M.
AU  - Saha, S.
AU  - Essa, I.
AU  - Ploetz, T.
TI  - Limitations in Employing Natural Language Supervision for Sensor-Based Human Activity Recognition - And Ways to Overcome Them
PY  - 2025
T2  - Proceedings of the AAAI Conference on Artificial Intelligence
VL  - 39
IS  - 1
SP  - 273
EP  - 281
DO  - 10.1609/aaai.v39i1.32004
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003907760&doi=10.1609%2faaai.v39i1.32004&partnerID=40&md5=a9352f4f4c7189cf20581fe530308883
AB  - Cross-modal contrastive pre-training between natural language and other modalities, e.g., vision and audio, has demonstrated astonishing performance and effectiveness across a diverse variety of tasks and domains. In this paper, we investigate whether such natural language supervision can be used for wearable sensor based Human Activity Recognition (HAR), and discover that-surprisingly-it performs substantially worse than standard end-to-end training and self-supervision. We identify the primary causes for this as: sensor heterogeneity and the lack of rich, diverse text descriptions of activities. To mitigate their impact, we also develop strategies and assess their effectiveness through an extensive experimental evaluation. These strategies lead to significant increases in activity recognition, bringing performance closer to supervised and self-supervised training, while also enabling the recognition of unseen activities and cross modal retrieval of videos. Overall, our work paves the way for better sensor-language learning, ultimately leading to the development of foundational models for HAR using wearables. © 2025, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.
KW  - Object detection
KW  - Object recognition
KW  - Self-supervised learning
KW  - Activity recognition
KW  - Cross-modal
KW  - End to end
KW  - Experimental evaluation
KW  - Human activity recognition
KW  - Language learning
KW  - Natural languages
KW  - Performance
KW  - Pre-training
KW  - Supervised trainings
KW  - Supervised learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Kral, P.
AU  - Janoskova, K.
AU  - Potcovaru, A.-M.
TI  - Digital Consumer Engagement on Blockchain-based Metaverse Platforms: Extended Reality Technologies, Spatial Analytics, and Immersive Multisensory Virtual Spaces
PY  - 2022
T2  - Linguistic and Philosophical Investigations
VL  - 21
SP  - 252
EP  - 267
DO  - 10.22381/lpi21202216
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135622761&doi=10.22381%2flpi21202216&partnerID=40&md5=42a2eaeef40843ddb16afbe501045d9f
AB  - Despite the relevance of digital consumer engagement on blockchain-based metaverse platforms, only limited research has been conducted on this topic. In this article, we cumulate previous research findings indicating that retail business analytics can assess interconnected virtual experiences by harnessing user data across 3D immersive environments. We contribute to the literature on shared virtual environments and immersive digital worlds by showing that customer behavior analytics can optimize purchase journeys and personalized shopping experiences by use of synthetic data, scale visualization, and physiological and behavioral biometrics. Throughout March 2022, we performed a quantitative literature review of the Web of Science, Scopus, and ProQuest databases, with search terms including “meta-verse” + “digital consumer engagement,” “extended reality technologies,” “spatial analytics,” and “immersive multisensory virtual spaces.” As we inspected research published between 2021 and 2022, only 89 articles satisfied the eligibility criteria. By eliminating controversial findings, outcomes unsubstantiated by replication, too imprecise material, or having similar titles, we decided upon 20, generally empirical, sources. Data visualization tools: Dimensions (bibliometric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AXIS, Dedoose, Distiller SR, and MMAT. © 2022, Addleton Academic Publishers. All rights reserved.
KW  - consumer
KW  - extended reality
KW  - immersive
KW  - metaverse
KW  - spatial analytics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 24
ER  -

TY  - CONF
AU  - Kotal, A.
AU  - Elluri, L.
AU  - Gupta, D.
AU  - Mandalapu, V.
AU  - Joshi, A.
TI  - Privacy-Preserving Data Sharing in Agriculture: Enforcing Policy Rules for Secure and Confidential Data Synthesis
PY  - 2023
T2  - Proceedings - 2023 IEEE International Conference on Big Data, BigData 2023
SP  - 5519
EP  - 5528
DO  - 10.1109/BigData59044.2023.10386276
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184985083&doi=10.1109%2fBigData59044.2023.10386276&partnerID=40&md5=2cc66a5fefaf8d118e2f744d1716dd9f
AB  - Big Data empowers the farming community with the information needed to optimize resource usage, increase productivity, and enhance the sustainability of agricultural practices. The use of Big Data in farming requires the collection and analysis of data from various sources such as sensors, satellites, and farmer surveys. While Big Data can provide the farming community with valuable insights and improve efficiency, there is significant concern regarding the security of this data as well as the privacy of the participants. Privacy regulations, such as the European Union's General Data Protection Regulation (GDPR), the EU Code of Conduct on agricultural data sharing by contractual agreement, and the proposed EU AI law, have been created to address the issue of data privacy and provide specific guidelines on when and how data can be shared between organizations. To make confidential agricultural data widely available for Big Data analysis without violating the privacy of the data subjects, we consider privacy-preserving methods of data sharing in agriculture. Synthetic data that retains the statistical properties of the original data but does not include actual individuals' information provides a suitable alternative to sharing sensitive datasets. Deep learning-based synthetic data generation has been proposed for privacy-preserving data sharing. However, there is a lack of compliance with documented data privacy policies in such privacy-preserving efforts. In this study, we propose a novel framework for enforcing privacy policy rules in privacy-preserving data generation algorithms. We explore several available agricultural codes of conduct, extract knowledge related to the privacy constraints in data, and use the extracted knowledge to define privacy bounds in a privacy-preserving generative model. We use our framework to generate synthetic agricultural data and present experimental results that demonstrate the utility of the synthetic dataset in downstream tasks. We also show that our framework can evade potential threats, such as re-identification and linkage issues, and secure data based on applicable regulatory policy rules.  © 2023 IEEE.
KW  - Big data in Agriculture
KW  - Data Privacy
KW  - Privacy Attacks
KW  - Privacy Policy
KW  - Codes (symbols)
KW  - Deep learning
KW  - Farms
KW  - Laws and legislation
KW  - Privacy-preserving techniques
KW  - Sensitive data
KW  - Big data in agriculture
KW  - Code of conduct
KW  - Confidential data
KW  - Data Sharing
KW  - Farming communities
KW  - Policy rules
KW  - Privacy Attacks
KW  - Privacy policies
KW  - Privacy preserving
KW  - Secure data
KW  - Data mining
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 8
ER  -

TY  - JOUR
AU  - Baaj, I.
AU  - Bouraoui, Z.
AU  - Cornuéjols, A.
AU  - Denœux, T.
AU  - Destercke, S.
AU  - Dubois, D.
AU  - Lesot, M.-J.
AU  - Marques-Silva, J.
AU  - Mengin, J.
AU  - Prade, H.
AU  - Schockaert, S.
AU  - Serrurier, M.
AU  - Strauss, O.
AU  - Vrain, C.
TI  - Synergies between machine learning and reasoning - An introduction by the Kay R. Amel group
PY  - 2024
T2  - International Journal of Approximate Reasoning
VL  - 171
C7  - 109206
DO  - 10.1016/j.ijar.2024.109206
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194169162&doi=10.1016%2fj.ijar.2024.109206&partnerID=40&md5=16aae00c3eb409feded482ed2807ad52
AB  - This paper proposes a tentative and original survey of meeting points between Knowledge Representation and Reasoning (KRR) and Machine Learning (ML), two areas which have been developed quite separately in the last four decades. First, some common concerns are identified and discussed such as the types of representation used, the roles of knowledge and data, the lack or the excess of information, or the need for explanations and causal understanding. Then, the survey is organised in seven sections covering most of the territory where KRR and ML meet. We start with a section dealing with prototypical approaches from the literature on learning and reasoning: Inductive Logic Programming, Statistical Relational Learning, and Neurosymbolic AI, where ideas from rule-based reasoning are combined with ML. Then we focus on the use of various forms of background knowledge in learning, ranging from additional regularisation terms in loss functions, to the problem of aligning symbolic and vector space representations, or the use of knowledge graphs for learning. Then, the next section describes how KRR notions may benefit to learning tasks. For instance, constraints can be used as in declarative data mining for influencing the learned patterns; or semantic features are exploited in low-shot learning to compensate for the lack of data; or yet we can take advantage of analogies for learning purposes. Conversely, another section investigates how ML methods may serve KRR goals. For instance, one may learn special kinds of rules such as default rules, fuzzy rules or threshold rules, or special types of information such as constraints, or preferences. The section also covers formal concept analysis and rough sets-based methods. Yet another section reviews various interactions between Automated Reasoning and ML, such as the use of ML methods in SAT solving to make reasoning faster. Then a section deals with works related to model accountability, including explainability and interpretability, fairness and robustness. Finally, a section covers works on handling imperfect or incomplete data, including the problem of learning from uncertain or coarse data, the use of belief functions for regression, a revision-based view of the EM algorithm, the use of possibility theory in statistics, or the learning of imprecise models. This paper thus aims at a better mutual understanding of research in KRR and ML, and how they can cooperate. The paper is completed by an abundant bibliography. © 2024
KW  - Accountability
KW  - Background knowledge
KW  - Explainability
KW  - Neurosymbolic AI
KW  - Rule-based models
KW  - Uncertainty
KW  - Data mining
KW  - Formal concept analysis
KW  - Fuzzy inference
KW  - Inductive logic programming (ILP)
KW  - Knowledge representation
KW  - Semantics
KW  - Uncertainty analysis
KW  - Vector spaces
KW  - Accountability
KW  - Background knowledge
KW  - Explainability
KW  - Inductive logic
KW  - Knowledge representation and reasoning
KW  - Machine learning methods
KW  - Machine-learning
KW  - Neurosymbolic AI
KW  - Rule-based models
KW  - Uncertainty
KW  - Machine learning
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
TI  - 39th IFIP International Conference on ICT Systems Security and Privacy Protection, SEC 2024
PY  - 2024
T2  - IFIP Advances in Information and Communication Technology
VL  - 710
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200775445&partnerID=40&md5=3fe863ee2ac8ecf45bcb7a691335496e
AB  - The proceedings contain 34 papers. The special focus in this conference is on ICT Systems Security and Privacy Protection. The topics include: Reduce to the MACs - Privacy Friendly Generic Probe Requests; PRIDA: PRIvacy-Preserving Data Aggregation with Multiple Data Customers; keep Your Memory Dump Shut: Unveiling Data Leaks in Password Managers; DryJIN: Detecting Information Leaks in Android Applications; bruteware: A Novel Family of Cryptoviral Attacks; towards Practical Hardware Fingerprinting for Remote Attestation; examining the Strength of Three Word Passwords; can Synthetic Data Preserve Manifold Properties?; “Alexa, How Do You Protect My Privacy?” A Quantitative Study of User Preferences and Requirements About Smart Speaker Privacy Settings; putting Authorization Servers on User-Owned Devices in User-Managed Access; identification of Cyber Threats and Vulnerabilities in Norwegian Distribution Networks; chain of Trust: Unraveling References Among Common Criteria Certified Products; lightArmor: A Lightweight Trusted Operating System Isolation Approach for Mobile Systems; satellite: Effective and Efficient Stack Memory Protection Scheme for Unsafe Programming Languages; Neurosymbolic Learning in the XAI Framework for Enhanced Cyberattack Detection with Expert Knowledge Integration; Transforming EU Governance: The Digital Integration Through EBSI and GLASS; malicious Insider Threat Detection Using Sentiment Analysis of Social Media Topics; a Structural-Semantic Approach Integrating Graph-Based and Large Language Models Representation to Detect Android Malware; Session Replication Attack Through QR Code Sniffing in Passkey CTAP Registration; GAD: A Real-Time Gait Anomaly Detection System with Online Adaptive Learning; queuing Theoretic Analysis of Dynamic Attribute-Based Access Control Systems; IPEQ: Querying Multi-attribute Records with Inner Product Encryption; hiding Your Awful Online Choices Made More Efficient and Secure: A New Privacy-Aware Recommender System; cognition Behind Access Control: A Usability Comparison of Rule- and Category-Based Mechanisms; obfuscating Code Vulnerabilities Against Static Analysis in Android Apps.
M3  - Conference review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Thomas, C.K.
AU  - Strinati, E.C.
AU  - Saad, W.
TI  - Reasoning with the Theory of Mind for Pragmatic Semantic Communication
PY  - 2024
T2  - Proceedings - IEEE Consumer Communications and Networking Conference, CCNC
SP  - 662
EP  - 668
DO  - 10.1109/CCNC51664.2024.10454639
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187442201&doi=10.1109%2fCCNC51664.2024.10454639&partnerID=40&md5=aa6d61ff4a4d66e518c9e9a1492b2690
AB  - In this paper, a pragmatic semantic communication framework that enables effective goal-oriented information sharing between two-intelligent agents is proposed. In particular, semantics is defined as the causal state that encapsulates the fundamental causal relationships and dependencies among different features extracted from data. The proposed framework leverages the emerging concept in machine learning (ML) called theory of mind (ToM). It employs a dynamic two-level (wireless and semantic) feedback mechanism to continuously fine-tune neural network components at the transmitter. Thanks to the ToM, the transmitter mimics the actual mental state of the receiver's reasoning neural network operating semantic interpretation. Then, the estimated mental state at the receiver is dynamically updated thanks to the proposed dynamic two-level feedback mechanism. At the lower level, conventional channel quality metrics are used to optimize the channel encoding process based on the wireless communication channel's quality, ensuring an efficient mapping of semantic representations to a finite constellation. Additionally, a semantic feedback level is introduced, providing information on the receiver's perceived semantic effectiveness with minimal overhead. Numerical evaluations demonstrate the framework's ability to achieve efficient communication with a reduced amount of bits while maintaining the same semantics, outperforming conventional systems that do not exploit the ToM-based reasoning. © 2024 IEEE.
KW  - Dynamics
KW  - Feedback control
KW  - Intelligent agents
KW  - Transmitters
KW  - Causal dependencies
KW  - Channel quality
KW  - Communication framework
KW  - Feedback mechanisms
KW  - Goal-oriented
KW  - Information sharing
KW  - Mental state
KW  - Neural-networks
KW  - Semantic communication
KW  - Theory of minds
KW  - Semantics
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - JOUR
AU  - Zhao, H.
AU  - Zhang, X.
AU  - Wang, C.
AU  - Yuan, W.
TI  - Classification Method of Aerobics Course Online Teaching Resources Based on Artificial Intelligence Technology
PY  - 2022
T2  - Wireless Communications and Mobile Computing
VL  - 2022
C7  - 8915705
DO  - 10.1155/2022/8915705
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125195793&doi=10.1155%2f2022%2f8915705&partnerID=40&md5=2ccd9a14185140cabeb2523f8f7a2b2a
AB  - In light of the current uneven distribution of aerobics course online resources, this paper presents research on the classification method of aerobics course online teaching resources based on artificial intelligence technology, constructs the display education resource management system based on artificial intelligence technology, realizes the classification of teaching information characteristics, and constructs the classification and evaluation algorithm of aerobiology course online resources. The online teaching resource classification of aerobics course achieves its design goal. Finally, the experiment shows that the artificial intelligence-based online teaching resource classification method for aerobics course is highly practicable and fully meets the research requirements.  © 2022 Hindawi Limited. All rights reserved.
KW  - Classification (of information)
KW  - Curricula
KW  - E-learning
KW  - Engineering education
KW  - Information management
KW  - Teaching
KW  - 'current
KW  - Artificial intelligence technologies
KW  - Classification methods
KW  - Education resource
KW  - Online resources
KW  - Online teaching
KW  - Resource classification
KW  - Resource management systems
KW  - Resources based
KW  - Teaching resources
KW  - Artificial intelligence
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Bartels, N.
AU  - Hahne, K.
TI  - Teaching Building Information Modeling in the Metaverse—An Approach Based on Quantitative and Qualitative Evaluation of the Students Perspective
PY  - 2023
T2  - Buildings
VL  - 13
IS  - 9
C7  - 2198
DO  - 10.3390/buildings13092198
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172804875&doi=10.3390%2fbuildings13092198&partnerID=40&md5=0a90cae537a08af94c58cac24eb06d0a
AB  - The teaching of civil engineering consists of different didactic approaches, such as lectures, group work or research-based teaching, depending on the respective courses. Currently, the metaverse is gaining importance in teaching and offers the possibility of a new teaching approach for civil engineering and especially for the teaching of courses from the areas of “Digital Design and Construction”. Although the advantages of teaching in the metaverse, such as location and time independence or a higher learning outcome, are mentioned in the literature, there are also challenges that must be considered when teaching in the metaverse. Against this background, this paper examines the implications of using the metaverse as a teaching tool in teaching “Digital Design and Construction”. The impact of teaching BIM in the metaverse is evaluated by (1) a literature review and workshops to evaluate use cases and demands for extended reality (XR) and the metaverse, (2) integrating XR and the metaverse in the courses and valuation by quantitative evaluations and (3) analyzing student papers of the courses and outcomes of a World Café. Due to these steps, this paper presents a novel approach by reflecting the students’ perspective. Furthermore, this paper presents a validated approach for integrating BIM and the metaverse in teaching. © 2023 by the authors.
KW  - augmented reality (AR)
KW  - building information modeling (BIM)
KW  - digital design and construction
KW  - education
KW  - extended reality (XR)
KW  - immersive teaching
KW  - metaverse
KW  - virtual reality (VR)
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 13
ER  -

TY  - JOUR
AU  - Roy, S.
AU  - Chergui, H.
AU  - Verikoukis, C.
TI  - Explanation-Guided Fair Federated Learning for Transparent 6G RAN Slicing
PY  - 2024
T2  - IEEE Transactions on Cognitive Communications and Networking
VL  - 10
IS  - 6
SP  - 2269
EP  - 2281
DO  - 10.1109/TCCN.2024.3400524
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193242365&doi=10.1109%2fTCCN.2024.3400524&partnerID=40&md5=044f0e0f072817f898b433810c969dbe
AB  - Future zero-touch artificial intelligence (AI)-driven 6G network automation requires building trust in the AI black boxes via explainable artificial intelligence (XAI), where it is expected that AI faithfulness would be a quantifiable service-level agreement (SLA) metric along with telecommunications key performance indicators (KPIs). This entails exploiting the XAI outputs to generate transparent and unbiased deep neural networks (DNNs). Motivated by closed-loop (CL) automation and explanation-guided learning (EGL), we design an explanation-guided federated learning (EGFL) scheme to ensure trustworthy predictions by exploiting the model explanation emanating from XAI strategies during the training run time via Jensen-Shannon (JS) divergence. Specifically, we predict per-slice RAN dropped traffic probability to exemplify the proposed concept while respecting fairness goals formulated in terms of the recall metric which is included as a constraint in the optimization task. Finally, the comprehensiveness score is adopted to measure and validate the faithfulness of the explanations quantitatively. Simulation results show that the proposed EGFL-JS scheme has achieved more than 50% increase in terms of comprehensiveness compared to different baselines from the literature, especially the variant EGFL-KL that is based on the Kullback-Leibler Divergence. It has also improved the recall score with more than 25% relatively to unconstrained-EGFL.  © 2015 IEEE.
KW  - 6G
KW  - fairness
KW  - FL
KW  - game theory
KW  - Jensen-Shannon
KW  - proxy-Lagrangian
KW  - recall
KW  - traffic drop
KW  - XAI
KW  - zero-touch
KW  - Benchmarking
KW  - Decision theory
KW  - Deep neural networks
KW  - Game theory
KW  - Job analysis
KW  - 6g
KW  - 6g mobile communication
KW  - Decisions makings
KW  - Fairness
KW  - Federated learning
KW  - FL
KW  - Jensen-shannon
KW  - Lagrangian
KW  - Mobile communications
KW  - Predictive models
KW  - Proxy-lagrangian
KW  - Recall
KW  - Shannon
KW  - Task analysis
KW  - Traffic drop
KW  - XAI
KW  - Zero-touch
KW  - Decision making
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Xu, Y.
AU  - Li, X.
AU  - Zeng, X.
AU  - Cao, J.
AU  - Jiang, W.
TI  - Application of blockchain technology in food safety control：current trends and future prospects
PY  - 2022
T2  - Critical Reviews in Food Science and Nutrition
VL  - 62
IS  - 10
SP  - 2800
EP  - 2819
DO  - 10.1080/10408398.2020.1858752
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104198487&doi=10.1080%2f10408398.2020.1858752&partnerID=40&md5=879c1a5b49a612e530158dfb3e95985a
AB  - Blockchain technology is a distributed ledger technology and is expected to face some difficulties and challenges in various industries due to its transparency, decentralization, tamper-proof nature, and encryption security. Food safety has been paid increasing attention in recent years with economic development. Based on a systematic literature critical analysis, the causes of food safety problems and the state-of-the-art blockchain technology overview, including the definition of blockchain, development history, classification, structure, characteristics, and main applications, the feasibility and application prospects of blockchain technology in plant food safety, animal food safety, and processed food safety were proposed in this review. Finally, the challenges of the blockchain technology itself and the difficulties in the application of food safety were analyzed. This study contributes to the extant literature in the field of food safety by discovering the excellent potential of blockchain technology and its implications for food safety control. Our results indicated that blockchain is a promising technology toward a food safety control, with many ongoing initiatives in food products, but many food-related issues, barriers, and challenges still exist. Nevertheless, it is expected to provide a feasible solution for controlling food safety risks. © 2020 Taylor & Francis Group, LLC.
KW  - adulteration
KW  - antibiotic
KW  - heavy metal
KW  - hormone
KW  - Pesticide
KW  - veterinary drugs
KW  - Blockchain
KW  - Food Safety
KW  - Technology
KW  - Blockchain
KW  - Cryptography
KW  - Food products
KW  - Safety engineering
KW  - Application prospect
KW  - Critical analysis
KW  - Development history
KW  - Encryption security
KW  - Feasible solution
KW  - Food safety control
KW  - Future prospects
KW  - State of the art
KW  - food safety
KW  - technology
KW  - Food safety
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 89
ER  -

TY  - CONF
AU  - Flood, R.
AU  - Casadio, M.
AU  - Aspinall, D.
AU  - Komendantskaya, E.
TI  - Generating Traffic-Level Adversarial Examples from Feature-Level Specifications
PY  - 2025
T2  - Lecture Notes in Computer Science
VL  - 15264 LNCS
SP  - 118
EP  - 127
DO  - 10.1007/978-3-031-82362-6_8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002716057&doi=10.1007%2f978-3-031-82362-6_8&partnerID=40&md5=edd0cef4f6b49c95d2b0272f845a46e8
AB  - Machine learning-based network intrusion detection methods often rely on statistical summaries of traffic, causing a disconnect between the traffic space and the feature space that is difficult to bridge [13]. Realistic adversarial attacks are hard to generate because natural well-formedness constraints at the traffic level aren’t respected at the feature level with usual adversarial attack generation methods. We use a novel attack generation method combining two tools: (1) a bespoke synthetic traffic generation suite, PackGen, and (2) a formal verification tool for neural networks, Vehicle [7]. PackGen produces aggregated Markov chain representations of network traffic which allows us to reconstruct valid packet sequences that are modified by realistic perturbations on an input specification. Vehicle’s formal specification language lets us represent granular threat models such as adversaries who can only manipulate packet timings. Unlike other methods, Vehicle’s formal verification is guaranteed to find counterexamples if they exist, which correspond with evasive adversarial examples. We feed these feature-level counterexamples into modified PackGen representations to generate PCAP files containing reconstructed, evasive network flows, generating adversarial examples that cross the gap between the traffic and feature spaces. We evaluate PackGen by replicating DoS traffic using a variety of timing distributions, before testing our full pipeline by producing evasive counterexamples, outperforming projected gradient descent. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
KW  - Adversarial Attacks
KW  - Formal Verification
KW  - Network Intrusion Detection
KW  - Adversarial machine learning
KW  - Generative adversarial networks
KW  - Magnetic levitation vehicles
KW  - Markov chains
KW  - Neural networks
KW  - Feature level
KW  - Feature space
KW  - Formal verification tools
KW  - Generation method
KW  - Machine-learning
KW  - Network intrusion detection
KW  - Network intrusion detection method
KW  - Statistical summary
KW  - Traffic generation
KW  - Traffic levels
KW  - Specification languages
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Senarathna, D.
AU  - Tragoudas, S.
TI  - Deep Neural Network-Based Accelerators for Repetitive Boolean Logic Evaluation
PY  - 2023
T2  - International System on Chip Conference
VL  - 2023-September
DO  - 10.1109/SOCC58585.2023.10256911
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174608048&doi=10.1109%2fSOCC58585.2023.10256911&partnerID=40&md5=3d0ef86fb945974f8ac9529355e9758d
AB  - This paper shows the learnability of complex Boolean Logic functions by Deep Neural Networks (DNNs) and the ability to accelerate logic evaluation using DNNs while ensuring very high accuracy. A Fully Connected Neural Network (FCNN) and a novel Convolutional Neural Network (CNN) were used in the experiments. Results are presented considering more than 5000 Boolean functions from ISCAS'89 and ITC'99 benchmarks. The FCNN showed an average accuracy of 96.6% while the CNN model had a superior average accuracy of 98.6%. The CNN executed on Graphics Processing Units (GPUs) was 69 times faster than a conventional logic simulator executed on a Central Processing Unit (CPU). It was approximately 190,000 times faster when utilizing Memristor Crossbar Arrays (MCAs) and the power consumption was 4,000 times less compared to the logic simulator. Moreover, the CNN implemented on MCAs was 2.3 times faster and consumed 5.6 times less power than Field Programmable Gate Array (FPGA) based logic evaluation. Experimental results of the complex Boolean function evaluations indicate the potential of developing DNN-based accelerators that outperform the existing conventional methods used to evaluate logic circuits.  © 2023 IEEE.
KW  - Boolean Logic Evaluation
KW  - Deep Learning
KW  - Deep Neural Network (DNN)
KW  - Memristor Crossbar Array (MCA)
KW  - Boolean functions
KW  - Complex networks
KW  - Computer circuits
KW  - Computer graphics
KW  - Field programmable gate arrays (FPGA)
KW  - Function evaluation
KW  - Graphics processing unit
KW  - Memristors
KW  - Program processors
KW  - Boolean logic
KW  - Boolean logic evaluation
KW  - Convolutional neural network
KW  - Crossbar arrays
KW  - Deep learning
KW  - Deep neural network
KW  - Fully connected neural network
KW  - Memristor
KW  - Memristor crossbar array
KW  - Network-based
KW  - Deep neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Khanzadeh, S.
AU  - Neto, E.C.P.
AU  - Iqbal, S.
AU  - Alalfi, M.
AU  - Buffett, S.
TI  - An exploratory study on domain knowledge infusion in deep learning for automated threat defense
PY  - 2025
T2  - International Journal of Information Security
VL  - 24
IS  - 1
C7  - 71
DO  - 10.1007/s10207-025-00987-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218221217&doi=10.1007%2fs10207-025-00987-4&partnerID=40&md5=9073ca4cd78f0601c5a04124f2314634
AB  - The wide adoption of interconnected services leads to the creation of supportive solutions and business opportunities. Conversely, this new paradigm is targeted by malicious activities, aiming to compromise systems’ confidentiality, integrity, and availability. However, advanced methods lack contextual awareness, which prevents their deployment to real-world systems. Considering that the process of making informed decisions stems from the expertise of analysts based on their experience, the use of cybersecurity domain knowledge has the potential to improve Deep Learning and Deep Reinforcement Learning operations in real scenarios. Therefore, the main goal of this research is to study and evaluate the use of Knowledge Infused Learning in the context of automated threat defense. We define how cybersecurity domain knowledge can be infused into Deep Learning and Reinforcement Learning, highlighting the main challenges and benefits. Besides, we present a roadmap to apply domain knowledge for red and blue teaming activities and discuss the implications of Knowledge Infused Learning in explainability, and actionable reporting. Finally, we list the open challenges to guide the development of next-generation security solutions. © Crown 2025.
KW  - Cybersecurity
KW  - Explainable Artificial Intelligence
KW  - Knowledge Infusion
KW  - Adversarial machine learning
KW  - Domain Knowledge
KW  - Federated learning
KW  - Business opportunities
KW  - Cyber security
KW  - Domain knowledge
KW  - Explainable artificial intelligence
KW  - Exploratory studies
KW  - Informed decision
KW  - Knowledge infusion
KW  - Malicious activities
KW  - Real-world system
KW  - Reinforcement learnings
KW  - Deep reinforcement learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Balica, R.-Ș.
AU  - Majerová, J.
AU  - Cuțitoi, A.-C.
TI  - Metaverse Applications, Technologies, and Infrastructure: Predictive Algorithms, Real-Time Customer Data Analytics, and Virtual Navigation Tools
PY  - 2022
T2  - Linguistic and Philosophical Investigations
VL  - 21
SP  - 219
EP  - 235
DO  - 10.22381/lpi21202214
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135579328&doi=10.22381%2flpi21202214&partnerID=40&md5=165f963275531465ff0c05f9229dbe5c
AB  - The aim of this systematic review is to synthesize and analyze meta-verse applications, technologies, and infrastructure in relation to predictive algorithms, real-time customer data analytics, and virtual navigation tools. With increasing evidence of metaverse live-video shopping events, there is an essential demand for comprehending whether consumer digital engagement as regards virtual assets improves immersive shopping journeys and experiences. In this research, prior findings were cumulated indicating that consumer journey analytics and data-driven decision making can determine purchase intentions across immersive 3D worlds and in virtual stores. We carried out a quantitative literature review of ProQuest, Scopus, and the Web of Science throughout March 2022, with search terms including “meta-verse” + “predictive algorithms,” “real-time customer data analytics,” and “virtual navigation tools.” As we analyzed research published between 2021 and 2022, only 86 papers met the eligibility criteria. By removing controversial or unclear findings (scanty/unimportant data), results unsupported by replication, undetailed content, or papers having quite similar titles, we decided on 20, chiefly empirical, sources. Data visualization tools: Dimensions (bibliometric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AXIS, Distiller SR, ROBIS, and SRDR. © 2022, Addleton Academic Publishers. All rights reserved.
KW  - customer
KW  - data analytics
KW  - metaverse
KW  - predictive algorithm
KW  - virtual
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 22
ER  -

TY  - JOUR
AU  - Megouo, T.G.P.
AU  - Pierre, S.
TI  - A Stacking Ensemble Machine Learning Model for Emergency Call Forecasting
PY  - 2024
T2  - IEEE Access
VL  - 12
SP  - 115820
EP  - 115837
DO  - 10.1109/ACCESS.2024.3445591
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201784102&doi=10.1109%2fACCESS.2024.3445591&partnerID=40&md5=3410d20ae55efb8aa18b4165facd3085
AB  - One of the greatest challenges of Emergency medical services providers is to handle the large number of Emergency Medical Service (EMS) calls coming from the population. An accurate forecast of EMS calls is involved in ambulance fleet dispatching and routing to minimize response times to emergency calls and enhance the efficacy of assistance. Yet, the demand for emergency services exhibits significant variability, posing a challenge in accurately predicting the future occurrence of emergency calls and their spatial-temporal distribution. Here, we propose a stacking ensemble machine learning model to forecast EMS calls, combining different base learners to enhance the overall performance of generalization. Additionally, we conducted experiments using Boruta, Lasso, RFFI and SHAP feature selection methods to identify the most informative attributes from the EMS dataset. The proposed ensemble model integrates a base layer and a meta layer. In the base layer, we applied four base learners: Decision Tree, Gradient Boosting Regression Tree, Light Gradient Boosting Machine and Random Forest. In the meta layer, we used an optimized Random Forest model to integrate the outputs of base learners. We evaluate the performance of our proposed model using the $R^{2}$ -score and four different error metrics. Based on a real data set including spatial, temporal and weather features, the findings of this study demonstrated that the proposed stacking-based ensemble model showed a better score and the minimum errors compared to the traditional single algorithms, online machine learning methods and voting ensemble methods. We achieved a higher score of 0.9954, mse of 0.8938, rmse of 0.9454, mae of 0.2923 and mape of 0.0724 compared to state-of-the-art models. This work is an aid for emergency managers in making well-informed decisions, improving outcomes for ambulance dispatch and routing, and enhancing ambulance response time.  © 2013 IEEE.
KW  - Ambulance demand forecasting
KW  - artificial intelligence
KW  - EMS call forecasting
KW  - ensemble machine learning
KW  - feature selection
KW  - offline/online machine learning
KW  - Adaptive boosting
KW  - Adversarial machine learning
KW  - Ambulances
KW  - Contrastive Learning
KW  - Fleet operations
KW  - Time series
KW  - Trees (mathematics)
KW  - Weather forecasting
KW  - Accuracy
KW  - Ambulance demand forecasting
KW  - Demand forecasting
KW  - Emergency medical service call forecasting
KW  - Emergency medical services
KW  - Ensemble machine learning
KW  - Features selection
KW  - Machine-learning
KW  - Medical services
KW  - Offline
KW  - Offline/online machine learning
KW  - Online machines
KW  - Predictive models
KW  - Stackings
KW  - Time-series analysis
KW  - Feature Selection
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Payne, L.
AU  - Xie, M.
TI  - Log File Anomaly Detection Using Knowledge Graph Completion
PY  - 2024
T2  - ACM International Conference Proceeding Series
SP  - 42
EP  - 48
DO  - 10.1145/3695719.3695726
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215529649&doi=10.1145%2f3695719.3695726&partnerID=40&md5=639ab0bbca5858adc3607985ae61c46e
AB  - Log files can be vital in detecting anomalous behavior in a computing system. However, the largely unstructured format of log files makes it difficult for computers to process them, and their large volume makes it infeasible for large-scale manual analysis. Previous research has suggested converting log messages into knowledge graph data for querying but does not consider anomaly detection as the downstream task. Other research has suggested using knowledge graph completion for anomaly detection, but it does not include the conversion of log messages to log data. This study fills in the gaps by presenting an end-to-end system that generates knowledge graph data from log messages and applies the knowledge graph completion task to binary classification for anomaly detection. Results are reported using both knowledge graph completion and classification metrics, and they demonstrate the feasibility of the proposed method. © 2024 Copyright held by the owner/author(s).
KW  - anomaly detection
KW  - knowledge graph
KW  - knowledge graph completion
KW  - link prediction
KW  - log file
KW  - Anomalous behavior
KW  - Anomaly detection
KW  - Computing system
KW  - Graph data
KW  - Knowledge graph completion
KW  - Knowledge graphs
KW  - Large volumes
KW  - Link prediction
KW  - Logfile
KW  - Knowledge graph
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Liu, H.
AU  - Wu, J.
AU  - Ma, J.
AU  - Yan, X.
AU  - Yang, N.
AU  - He, X.
AU  - He, Y.
AU  - Zhang, H.
AU  - Hsu, T.-H.
AU  - Qian, J.H.
AU  - Guo, J.
AU  - Hersam, M.C.
AU  - Wang, H.
TI  - A van der Waals interfacial junction transistor for reconfigurable fuzzy logic hardware
PY  - 2024
T2  - Nature Electronics
VL  - 7
IS  - 10
SP  - 876
EP  - 884
DO  - 10.1038/s41928-024-01256-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207275660&doi=10.1038%2fs41928-024-01256-3&partnerID=40&md5=0a2d9aec93ddf820bf44d960ef276c76
AB  - Edge devices face challenges when implementing deep neural networks due to constraints on their computational resources and power consumption. Fuzzy logic systems can potentially provide more efficient edge implementations due to their compactness and capacity to manage uncertain data. However, their hardware realization remains difficult, primarily because implementing reconfigurable membership function generators using conventional technologies requires high circuit complexity and power consumption. Here we report a multigate van der Waals interfacial junction transistor based on a molybdenum disulfide/graphene heterostructure that can generate tunable Gaussian-like and π-shaped membership functions. By integrating these generators with peripheral circuits, we create a reconfigurable fuzzy controller hardware capable of nonlinear system control. This fuzzy logic system can also be integrated with a few-layer convolution neural network to form a fuzzy neural network with enhanced performance in image segmentation. © The Author(s), under exclusive licence to Springer Nature Limited 2024.
KW  - Convolutional neural networks
KW  - Deep neural networks
KW  - Digital storage
KW  - Fuzzy control
KW  - Fuzzy neural networks
KW  - Junction gate field effect transistors
KW  - Multilayer neural networks
KW  - Reconfigurable hardware
KW  - Circuit complexity
KW  - Computational power
KW  - Computational resources
KW  - Fuzzy logic system
KW  - Fuzzy-Logic
KW  - Hardware realization
KW  - Membership function generators
KW  - Neural-networks
KW  - Reconfigurable
KW  - Van der Waal
KW  - Image segmentation
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - CONF
AU  - Sterbentz, M.
AU  - Barrie, C.
AU  - Shahi, S.
AU  - Dutta, A.
AU  - Hooshmand, D.
AU  - Pack, H.
AU  - Hammond, K.J.
TI  - SATYRN: A Platform for Analytics Augmented Generation
PY  - 2024
T2  - EMNLP 2024 - 2024 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference
SP  - 6360
EP  - 6385
DO  - 10.18653/v1/2024.emnlp-main.365
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217789863&doi=10.18653%2fv1%2f2024.emnlp-main.365&partnerID=40&md5=cf1151c191c6b1578cef0085b4629ea4
AB  - Large language models (LLMs) are capable of producing documents, and retrieval augmented generation (RAG) has shown itself to be a powerful method for improving accuracy without sacrificing fluency. However, not all information can be retrieved from text. We propose an approach that uses the analysis of structured data to generate fact sets that are used to guide generation in much the same way that retrieved documents are used in RAG. This analytics augmented generation (AAG) approach supports the ability to utilize standard analytic techniques to generate facts that are then converted to text and passed to an LLM. We present a neurosymbolic platform, SATYRN, that leverages AAG to produce accurate, fluent, and coherent reports grounded in large scale databases. In our experiments, we find that SATYRN generates reports in which over 86% of claims are accurate while maintaining high levels of fluency and coherence, even when using smaller language models such as Mistral-7B, as compared to GPT-4 Code Interpreter in which just 57% of claims are accurate. © 2024 Association for Computational Linguistics.
KW  - High level languages
KW  - Modeling languages
KW  - Program interpreters
KW  - Analytic technique
KW  - Code interpreter
KW  - Facts-set
KW  - Fluents
KW  - Language model
KW  - Large-scale database
KW  - Retrieved documents
KW  - Structured data
KW  - Computational linguistics
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Feng, C.
AU  - Sathasivam, S.
AU  - Roslan, N.
AU  - Velavan, M.
TI  - 2-SAT discrete Hopfield neural networks optimization via Crow search and fuzzy dynamical clustering approach
PY  - 2024
T2  - AIMS Mathematics
VL  - 9
IS  - 4
SP  - 9232
EP  - 9266
DO  - 10.3934/math.2024450
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186870625&doi=10.3934%2fmath.2024450&partnerID=40&md5=aa5056dbac62ebd6c8bc324a2319885c
AB  - Within the swiftly evolving domain of neural networks, the discrete Hopfield-SAT model, endowed with logical rules and the ability to achieve global minima of SAT problems, has emerged as a novel prototype for SAT solvers, capturing significant scientific interest. However, this model shows substantial sensitivity to network size and logical complexity. As the number of neurons and logical complexity increase, the solution space rapidly contracts, leading to a marked decline in the model's problem-solving performance. This paper introduces a novel discrete Hopfield-SAT model, enhanced by Crow search-guided fuzzy clustering hybrid optimization, effectively addressing this challenge and significantly boosting solving speed. The proposed model unveils a significant insight: its uniquely designed cost function for initial assignments introduces a quantification mechanism that measures the degree of inconsistency within its logical rules. Utilizing this for clustering, the model utilizes a Crow search-guided fuzzy clustering hybrid optimization to filter potential solutions from initial assignments, substantially narrowing the search space and enhancing retrieval efficiency. Experiments were conducted with both simulated and real datasets for 2SAT problems. The results indicate that the proposed model significantly surpasses traditional discrete Hopfield-SAT models and those enhanced by genetic-guided fuzzy clustering optimization across key performance metrics: Global minima ratio, Hamming distance, CPU time, retrieval rate of stable state, and retrieval rate of global minima, particularly showing statistically significant improvements in solving speed. These advantages play a pivotal role in advancing the discrete Hopfield-SAT model towards becoming an exemplary SAT solver. Additionally, the model features exceptional parallel computing capabilities and possesses the potential to integrate with other logical rules. In the future, this optimized model holds promise as an effective tool for solving more complex SAT problems. © 2024 the Author(s), licensee AIMS Press.
KW  - 2-SAT
KW  - Crow search algorithm
KW  - fuzzy clustering
KW  - Hopfield neural networks
KW  - logic programming
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Luo, P.
AU  - Parn, E.
AU  - Brilakis, I.
TI  - CHATTWIN: ENABLING NATURAL LANGUAGE INTERACTIONS WITH INFRASTRUCTURE DIGITAL TWINS
PY  - 2024
T2  - Proceedings of the European Conference on Computing in Construction
VL  - 2024
SP  - 876
EP  - 886
DO  - 10.35490/EC3.2024.259
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203422773&doi=10.35490%2fEC3.2024.259&partnerID=40&md5=aa83b43d3310bca59910a3b04d90e51d
AB  - Infrastructure lifecycle management requires interactions with dynamic datasets. Traditional interfaces often hinder users’ ability to rapidly locate lifecycle-specific information they need. Our work proposes ChatTwin, a system that employs Large Language Models (LLMs) to enable natural language queries related to various lifecycle stages of infrastructure, with a focus on operations and maintenance. Simulated scenarios were constructed to test the system. The results demonstrate that the system can effectively categorise interactions, fetch relevant information, and produce human-friendly outputs. With this LLM-based approach, we present an improvement in user-centricity in infrastructure lifecycle management, streamlining interactions and decision-making throughout the entire infrastructure lifecycle. © 2024 European Council on Computing in Construction.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Mallioris, P.
AU  - Aivazidou, E.
AU  - Bechtsis, D.
TI  - Predictive maintenance in Industry 4.0: A systematic multi-sector mapping
PY  - 2024
T2  - CIRP Journal of Manufacturing Science and Technology
VL  - 50
SP  - 80
EP  - 103
DO  - 10.1016/j.cirpj.2024.02.003
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187717210&doi=10.1016%2fj.cirpj.2024.02.003&partnerID=40&md5=c6d6deddffd7087fbc11b9a8607d12b2
AB  - Industry 4.0 is strongly intertwined with big data streaming flows from intelligent sensors and machinery installed in industrial facilities. Failures can disrupt production and lead the supply chain ecosystem to malfunction. Maintenance strategies are necessary to safeguard the continuous operation of production lines, minimize supply chain disruptions, and improve sustainability indicators. Within the context of smart manufacturing, predictive maintenance (PdM) approaches could decrease downtimes, reduce operational costs, and increase productivity, improving system performance and decision-making. The overarching aim of this research is to systematically review state-of-the-art predictive maintenance applications across diverse manufacturing sectors to provide customized insights from academic and operational perspectives, summarized into a comparative decision support map. The study classifies predictive maintenance solutions based on prevailing methodologies, input features, predicted variables, applied algorithms, evaluation metrics, and state-of-the-art software tools per industry sector. The outcomes highlight that data-driven predictive maintenance constitutes a cutting-edge solution with a growing interest in modern manufacturing. Moreover, this research provides insights into the technology readiness of each industrial sector, covering modern areas for PdM implementation, while raising the extant challenges. The proposed multi-sector framework is expected to act as a guiding light for researchers and practitioners towards the development of PdM driven applications in data driven industries. © 2024 Elsevier Ltd
KW  - Data-driven
KW  - Industry 4.0
KW  - Predictive maintenance
KW  - Smart manufacturing
KW  - Systematic review
KW  - Decision support systems
KW  - Flow control
KW  - Industrial research
KW  - Industry 4.0
KW  - Maintenance
KW  - Supply chains
KW  - Data driven
KW  - Data streaming
KW  - Industrial facilities
KW  - Intelligent sensors
KW  - Predictive maintenance
KW  - Sector mappings
KW  - Smart manufacturing
KW  - State of the art
KW  - Streaming flow
KW  - Systematic Review
KW  - Decision making
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 24
ER  -

TY  - CHAP
AU  - Raha, A.
AU  - Sung, R.
AU  - Ghosh, S.
AU  - Gupta, P.K.
AU  - Mathaikutty, D.A.
AU  - Cheema, U.I.
AU  - Hyland, K.
AU  - Brick, C.
AU  - Raghunathan, V.
TI  - Efficient Hardware Acceleration of Emerging Neural Networks for Embedded Machine Learning: An Industry Perspective
PY  - 2023
T2  - Embedded Machine Learning for Cyber-Physical, IoT, and Edge Computing: Hardware Architectures
SP  - 121
EP  - 172
DO  - 10.1007/978-3-031-19568-6_5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184760467&doi=10.1007%2f978-3-031-19568-6_5&partnerID=40&md5=b6ef4ede5df58b623076e5675c3a0892
AB  - As neural networks become more complex, the energy required for doing training and inference has resulted in a noticeable shift towards adopting specialized accelerators to meet strict latency and energy constraints that are prevalent in both edge and cloud deployments. These accelerators achieve high performance through parallelism over hundreds of processing elements, and energy efficiency is achieved by reducing data movement and maximizing resource utilization through data reuse. After providing a brief summary of the problems that neural networks have been solving in the domains of Computer Vision, Natural Language Processing, Recommendation Systems and Graph Processing we will discuss how individual layers from each of these different neural networks can be accelerated in an energy-efficient manner. In particular, we focus on design considerations and trade-offs for mapping CNNs, Transformers, and GNNs on AI accelerators that attempt to maximize compute efficiency and minimize energy consumption by reducing the number of access to memory through efficient data reuse. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Zhao, S.
AU  - Shah, N.
AU  - Meert, W.
AU  - Verhelst, M.
TI  - AIA: A Customized Multi-Core RISC-V SoC for Discrete Sampling Workloads in 16 nm
PY  - 2025
T2  - IEEE Journal of Solid-State Circuits
DO  - 10.1109/JSSC.2025.3561880
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004032225&doi=10.1109%2fJSSC.2025.3561880&partnerID=40&md5=c5486a758547daf1c6a29238655e549d
AB  - Probabilistic models (PMs) are essential in advancing machine learning capabilities, particularly in safety-critical applications involving reasoning and decision-making. Among the methods employed for inference in these models, sampling-based Markov chain Monte Carlo (MCMC) techniques are widely used. However, MCMC methods come with significant computational costs and are inherently challenging to parallelize, resulting in inefficient execution on conventional CPU/GPU platforms. To overcome these challenges, this article presents an approximate inference accelerator (AIA), a multi-core RISC-V system-on-chip (SoC) design fabricated using Intel’s 16 nm process technology. Our AIA is specifically designed to empower edge devices with robust decision-making and reasoning abilities. The AIA architecture incorporates an RISC-V host processor to manage chip-to-chip data communication and a 2-D mesh of 16 custom versatile RISC-V cores optimized for high-efficiency approximate inference. Each core features: 1) custom instructions and datapath blocks for non-normalized Knuth–Yao (KY) sampling, as well as for the interpolation of non-linear functions (e.g., logarithmic and exponential), and 2) direct data-access to the register file (RF) of each neighboring core, to reduce the data movement costs of frequent data exchanges between nearby cores. To further capitalize on the parallelism potential in MCMC algorithms, we developed a specialized compile chain that enables efficient spatial mapping and scheduling across the cores. As a result, AIA attains a peak sampling rate of 1277 MSamples/s at 0.9 V and achieves an energy efficiency of 20 GSamples/s/W at 0.7 V, surpassing the previous state-of-the-art (SotA) ASIC accelerator for probabilistic inference by up to 6× in speed and 5× in energy efficiency. Furthermore, the AIA’s versatility is demonstrated through the successful mapping of different types of PM workloads onto the chip. © 1966-2012 IEEE.
KW  - Approximate inference
KW  - customized RISC-V
KW  - graph coloring
KW  - Knuth–Yao (KY) sampler
KW  - parallel Markov chain Monte Carlo (MCMC)
KW  - probabilistic model (PM)
KW  - Fault tolerant computer systems
KW  - Integrated circuit design
KW  - Photomapping
KW  - Reduced instruction set computing
KW  - System-on-chip
KW  - Approximate inference
KW  - Customized RISC-V
KW  - Graph colorings
KW  - Knuth–yao  sampler
KW  - Markov chain Monte Carlo
KW  - Markov Chain Monte-Carlo
KW  - Multi-cores
KW  - Parallel markov chain monte carlo
KW  - Probabilistic model
KW  - Probabilistic models
KW  - Markov processes
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Agarwal, T.
AU  - Kavitha, R.
AU  - Verma, S.
AU  - Sasi, A.
TI  - Utilizing Machine Vision for Steerable Robotic Control
PY  - 2025
T2  - Lecture Notes in Electrical Engineering
VL  - 1274 LNEE
SP  - 233
EP  - 239
DO  - 10.1007/978-981-97-8043-3_37
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208185326&doi=10.1007%2f978-981-97-8043-3_37&partnerID=40&md5=4974d3af6ca06ddc7d5f917d25d10e83
AB  - This paper describes the design and implementation of a steerable robot control device making use of machine imaginative and prescient. The machine consists of a robot car ready with a 3-d digital camera, a show and a manipulate panel. The camera captures 3-d intensity pix of the surroundings and the manage panel lets in the consumer to output instructions that manipulate the motion of the auto. The vision module of the system uses a Convolutional Neural community (CNN) to discover objects inside the environment and small variations in elevation and assign distinct that means to them. This facts is then utilized by the control module to formulate the commands in step with the person’s commands, which then get sent to the car’s pressure device. The system additionally uses an optimization set of rules to help become aware of most beneficial paths thru the environment and avoid limitations. Eventually, the gadget can be used to monitor the automobiles positioning within the surroundings permitting the user to benefit information which include the place, orientation and pace of the automobile. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.
KW  - control
KW  - Convolutional
KW  - information
KW  - Automobiles
KW  - Convolutional neural networks
KW  - Industrial robots
KW  - Intelligent robots
KW  - Machine design
KW  - Machine vision
KW  - Nanorobotics
KW  - Robot vision
KW  - Control device
KW  - Convolutional
KW  - Design and implementations
KW  - Information
KW  - Machine-vision
KW  - Robot cars
KW  - Robotic controls
KW  - Robots control
KW  - System use
KW  - Vision modules
KW  - Digital cameras
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Yuan, X.
AU  - Chen, J.
AU  - Wang, Y.
AU  - Chen, A.
AU  - Huang, Y.
AU  - Zhao, W.
AU  - Yu, S.
TI  - Semantic-Enhanced Knowledge Graph Completion
PY  - 2024
T2  - Mathematics
VL  - 12
IS  - 3
C7  - 450
DO  - 10.3390/math12030450
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184478271&doi=10.3390%2fmath12030450&partnerID=40&md5=789bc8b5ba131715c97e1505930c2d75
AB  - Knowledge graphs (KGs) serve as structured representations of knowledge, comprising entities and relations. KGs are inherently incomplete, sparse, and have a strong need for completion. Although many knowledge graph embedding models have been designed for knowledge graph completion, they predominantly focus on capturing observable correlations between entities. Due to the sparsity of KGs, potential semantic correlations are challenging to capture. To tackle this problem, we propose a model entitled semantic-enhanced knowledge graph completion (SE-KGC). SE-KGC effectively addresses the issue by incorporating predefined semantic patterns, enabling the capture of semantic correlations between entities and enhancing features for representation learning. To implement this approach, we employ a multi-relational graph convolution network encoder, which effectively encodes the KG. Subsequently, we utilize a scoring decoder to evaluate triplets. Experimental results demonstrate that our SE-KGC model outperforms other state-of-the-art methods in link-prediction tasks across three datasets. Specifically, compared to the baselines, SE-KGC achieved improvements of 11.7%, 1.05%, and 2.30% in terms of MRR on these three datasets. Furthermore, we present a comprehensive analysis of the contributions of different semantic patterns, and find that entities with higher connectivity play a pivotal role in effectively capturing and characterizing semantic information. © 2024 by the authors.
KW  - higher-order semantic pattern
KW  - knowledge graph completion
KW  - relational graph convolutional network
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Xu, D.
AU  - Fekri, F.
TI  - Generalization of temporal logic tasks via future dependent options
PY  - 2024
T2  - Machine Learning
VL  - 113
IS  - 10
SP  - 7509
EP  - 7540
DO  - 10.1007/s10994-024-06614-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202046882&doi=10.1007%2fs10994-024-06614-y&partnerID=40&md5=0154a3ae3187017696405a39e0a924a5
AB  - Temporal logic (TL) tasks consist of complex and temporally extended subgoals and they are common for many real-world applications, such as service and navigation robots. However, it is often inefficient or even infeasible to train reinforcement learning (RL) agents to solve multiple TL tasks, since rewards are sparse and non-Markovian in these tasks. A promising solution to this problem is to learn task-conditioned policies which can zero-shot generalize to new TL tasks without further training. However, influenced by some practical issues, such as issues of lossy symbolic observation and long time-horizon of completing TL task, previous works suffer from sample inefficiency in training and sub-optimality (or even infeasibility) in task execution. In order to tackle these issues, this paper proposes an option-based framework to generalize TL tasks, consisting of option training and task execution parts. We have innovations in both parts. In option training, we propose to learn options dependent on the future subgoals via a novel approach. Additionally, we propose to train a multi-step value function which can propagate the rewards of satisfying future subgoals more efficiently in long-horizon tasks. In task execution, in order to ensure the optimality and safety, we propose a model-free MPC planner for option selection, circumventing the learning of a transition model which is required by previous MPC planners. In experiments on three different domains, we evaluate the generalization capability of the agent trained by the proposed method, showing its significant advantage over previous methods. © The Author(s), under exclusive licence to Springer Science+Business Media LLC, part of Springer Nature 2024.
KW  - Neuro-symbolic
KW  - Option learning
KW  - Reinforcement learning
KW  - Temporal logic task
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Markov processes
KW  - Temporal logic
KW  - Zero-shot learning
KW  - Generalisation
KW  - Learn+
KW  - Neuro-symbolic
KW  - Optimality
KW  - Option learning
KW  - Real-world
KW  - Reinforcement learnings
KW  - Subgoals
KW  - Task executions
KW  - Temporal logic task
KW  - Reinforcement learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Sandeep Telkar, R.
AU  - Ananya, R.
AU  - Akanksha, S.
AU  - Bhat, D.M.
AU  - Nireeksha, B.
TI  - Navigating Interfaces: Gaze and Gesture as Multimodal Inputs
PY  - 2025
T2  - Proceedings of 2025 International Conference on Computing for Sustainability and Intelligent Future, COMP-SIF 2025
DO  - 10.1109/COMP-SIF65618.2025.10969887
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004983372&doi=10.1109%2fCOMP-SIF65618.2025.10969887&partnerID=40&md5=9274123b1a617c8858eff1a1515880f1
AB  - The project Multimodal Maestro believes in a groundbreaking system of human-computer interaction (HCI) for the benefit of common users and people with disabilities. It provides two visual input methods which includes eye movement and hand gesture, the choice is made by the users based on their convenience and accessibility needs. For general users, Multimodal Maestro opens up a new realm of interaction allowing for a more intuitive and immersive connection with technology. To achieve this we have used the advanced embedded machine learning algorithms such as CNN, Douglas-Peucker, EAR(Eye Aspect Ratio)- based LDA(Landmark Detection Algorithm) and LSTM(Long Short Term Memory) which decodes gestures and very subtle eye movements, including blinks and shifts in gaze into commands including cursor movement, click, and screen element selection [3]-[28]. In tandem, hand gestures provide a natural and expressive alternative way to communicate with technology, thus enhancing the user experience, offering seamless handsfree control. For a person with disabilities, Multimodal Maestro is a game-changer, this will provide a very accessible tool for people with limited mobility to have a way to interact with technology without relying on any traditional input devices[10]. Gaze-based control gives a powerful and inclusive option for mobility-impaired users, while hand gestures provide an additional channel of communication with maximum freedom and independence offering flexibility and personalization, from these two complementary input methods, which is also a suite of adaptive, personalized, and accessible interface. For the first time, this system aims to make technology accessible to all users irrespective of their capabilities and preferences, directing a new challenging path where users can interact with computers in a way that is more natural, empowering and efficient. © 2025 IEEE.
KW  - CNN
KW  - Douglas-Peucker
KW  - EAR
KW  - HCI
KW  - LDA
KW  - LSTM
KW  - User interfaces
KW  - Aspect-ratio
KW  - Computer interaction
KW  - Detection algorithm
KW  - Douglas-Peucker
KW  - Eye aspect ratio
KW  - Hand gesture
KW  - Landmark detection
KW  - Landmark detection algorithm
KW  - Multi-modal
KW  - Short term memory
KW  - Embedded systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Nimmani, P.
AU  - Vodithala, S.
AU  - Polepally, V.
TI  - Neural network based integrated model for information retrieval
PY  - 2021
T2  - Proceedings - 5th International Conference on Intelligent Computing and Control Systems, ICICCS 2021
C7  - 9432241
SP  - 1286
EP  - 1289
DO  - 10.1109/ICICCS51141.2021.9432241
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107543848&doi=10.1109%2fICICCS51141.2021.9432241&partnerID=40&md5=eb66f4d04e16264aaa6589aff384803d
AB  - The paper introduces an advance to connect various current information retrieval (IR) techniques with change impact analysis (CIA) and Bag of Words, trying to recognize the possible results of a replacement or manage the required changes for affecting the necessary change. In this paper a neural network-based LSTM-RNN Algorithm is proposed to find the similarity document. Also, RMSprop Optimization model is used to reduce the vibrations in the upward path and it can improve our learning rate and precision rate. The experimental result shows that the proposed method performs better accuracy compared to the current methods.  © 2021 IEEE.
KW  - Change Impact Analysis
KW  - Information Retrieval
KW  - LSTM-RNN
KW  - RMSprop Optimization Model
KW  - Software Engineering
KW  - Control systems
KW  - Information retrieval
KW  - Intelligent computing
KW  - Bag of words
KW  - Change impact analysis
KW  - Integrated modeling
KW  - Learning rates
KW  - Optimization modeling
KW  - Precision rates
KW  - Long short-term memory
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 15
ER  -

TY  - CONF
AU  - Potteiger, N.
AU  - Koutsoukos, X.
TI  - Safe Explainable Agents for Autonomous Navigation using Evolving Behavior Trees
PY  - 2023
T2  - Proceedings - 2023 IEEE International Conference on Assured Autonomy, ICAA 2023
SP  - 44
EP  - 52
DO  - 10.1109/ICAA58325.2023.00014
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169573729&doi=10.1109%2fICAA58325.2023.00014&partnerID=40&md5=589baba9c9fd35f167edc14db2758580
AB  - Machine learning and reinforcement learning are increasingly used to solve complex tasks in autonomous systems. However, autonomous agents represented by large neural networks are not transparent leading to their assurability and trustworthiness becoming critical challenges. Large models also result in a lack of interpretability which causes severe obstacles related to trust in autonomous agents and human-machine teaming. In this paper, we leverage the hierarchical structure of behavior trees and hierarchical reinforcement learning to develop a neurosymbolic model architecture for autonomous agents. The proposed model, referred to as Evolving Behavior Trees (EBTs), integrates the required components to represent the learning tasks as well as the switching between tasks to achieve complex long-term goals. We design an agent for autonomous navigation and we evaluate the approach against a state-of-the-art hierarchical reinforcement learning method using a Maze Simulation Environment. The results show autonomous agents represented by EBTs can be trained efficiently. The approach incorporates explicit safety constraints into the model and incurs significantly fewer safety violations during training and execution. Further, the model provides explanations for the behavior of the autonomous agent by associating the state of the executing EBT with agent actions.  © 2023 IEEE.
KW  - autonomous navigation
KW  - behavior trees
KW  - explainable AI
KW  - hierarchical reinforcement learning
KW  - Air navigation
KW  - Complex networks
KW  - Learning systems
KW  - Reinforcement learning
KW  - Autonomous navigation
KW  - Behaviour Trees
KW  - Complex task
KW  - Critical challenges
KW  - Explainable AI
KW  - Hierarchical reinforcement learning
KW  - Large models
KW  - Machine-learning
KW  - Neural-networks
KW  - Reinforcement learnings
KW  - Autonomous agents
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Corrado, M.
AU  - Giliberti, V.
AU  - Gozzi, M.
AU  - Lanzolla, V.
AU  - Vetere, G.
AU  - Zurlo, D.
TI  - Assisting the Assistant: obot for Voice Customer Support
PY  - 2023
T2  - Frontiers in Artificial Intelligence and Applications
VL  - 368
SP  - 330
EP  - 339
DO  - 10.3233/FAIA230096
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171471256&doi=10.3233%2fFAIA230096&partnerID=40&md5=66974f1548cd6fcd1112724d7c8b70c7
AB  - Despite recent advances in automation, customer support still requires a substantial amount of human intervention through voice channels. With the aim of improving the work of human assistants, we developed a collaborative bot (cobot) to help them in the process of handling customer voice interactions. The cobot is a reasoning agent that starts from loading background customer data into a dynamic knowledge graph. Then it captures the audio stream of the conversation, converts it to text in real time, analyzes the blocks of conversation with neural technologies and 'thinks' about the results. Assistants can also supply data to the cobot, based on the information they gather from the ongoing conversation. The reasoning agent provides information and action suggestions to the human assistant by applying heuristics on data collected from both automatic and human sources, based on a task and domain-specific conceptual models (ontologies). While designing a prototypical solution for utility services in Italy, we are faced with many problems, including spontaneous speech understanding, factual and linguistic knowledge representation, and efficient heuristic reasoning. We adopted a standards-based approach and experimented with open source reasoners and publicly available language models. The paper presents preliminary findings and outlines the system design, with focus on the interplay of neural language processing and logic reasoning. © 2023 The Authors.
KW  - collaborative bots
KW  - knowledge graph
KW  - natural language understanding
KW  - ontologies
KW  - virtual assistants
KW  - Atoms
KW  - Botnet
KW  - Knowledge graph
KW  - Sales
KW  - Collaborative bot
KW  - Customer data
KW  - Customer support
KW  - Human intervention
KW  - Knowledge graphs
KW  - Natural language understanding
KW  - Ontology's
KW  - Virtual assistants
KW  - Voice channels
KW  - Voice interaction
KW  - Ontology
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Nan, Z.
AU  - Dave, M.
AU  - Shen, X.
AU  - Liao, C.
AU  - Vanderbruggen, T.
AU  - Lin, P.-H.
AU  - Emani, M.
TI  - Interactive NLU-Powered Ontology-Based Workflow Synthesis for FAIR Support of HPC
PY  - 2022
T2  - Proceedings of HUST 2022: 9th International Workshop on HPC User Support Tools, Held in conjunction with SC 2022: The International Conference for High Performance Computing, Networking, Storage and Analysis
SP  - 29
EP  - 40
DO  - 10.1109/HUST56722.2022.00009
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147900717&doi=10.1109%2fHUST56722.2022.00009&partnerID=40&md5=9a4246adce8e9a457bf1e3096e0ead79
AB  - Workflow synthesis is important for automatically creating the data processing workflow in a FAIR data management system for HPC. Previous methods are table-based, rigid and not scalable. This paper addresses these limitations by developing a new approach to workflow synthesis, interactive NLU-powered ontology-based workflow synthesis (INPOWS). IN-POWS allows the use of Natural Language for queries, maximizes the robustness in handling concepts and language ambiguities through an interactive ontology-based design, and achieves superior extensibility by adopting a synthesis algorithm powered by Natural Language Understanding. In our experiments, INPOWS shows the efficacy in enabling flexible, robust, and extensible workflow synthesis.  © 2022 IEEE.
KW  - FAIR
KW  - HPC
KW  - NLP
KW  - Ontology
KW  - Synthesis
KW  - Workflow
KW  - Data handling
KW  - Information management
KW  - Natural language processing systems
KW  - Data management system
KW  - FAIR
KW  - HPC
KW  - Natural language understanding
KW  - Natural languages
KW  - New approaches
KW  - Ontology's
KW  - Ontology-based
KW  - Synthesis algorithms
KW  - Work-flows
KW  - Ontology
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Ramosaj, L.
AU  - Bytyçi, A.
AU  - Shala, B.
AU  - Bytyçi, E.
TI  - Graph and Structured Data Algorithms in Electronic Health Records: A Scoping Review
PY  - 2024
T2  - Communications in Computer and Information Science
VL  - 2048 CCIS
SP  - 61
EP  - 73
DO  - 10.1007/978-3-031-65990-4_6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201022354&doi=10.1007%2f978-3-031-65990-4_6&partnerID=40&md5=c1723182cfae77ffd3afedc58adb6ed4
AB  - The provision of some of the most fundamental services related to health and wellbeing makes healthcare an essential part of society. Patient information management and accessibility are only one of many facets of healthcare that have changed as a result of technological improvements over time. Electronic health records (EHRs) being differentiated as an emerging integral component of contemporary healthcare systems, provide digital methods for patient data storage and organization. As the volume of EHRs continues to increase exponentially, it is becoming increasingly important to optimize the reasoning process in this enormous amount of data. This scoping review aims to provide a comprehensive and systematic comparison between graph and non-graph structured data in regards to their efficiency in reasoning regarding EHRs. Research Articles from prominent research paper repositories such as Science Direct, IEEExplore, SpringerLink, and ACM are analyzed in detail. Their corresponding techniques and algorithms are gathered, analyzed and concluded that neural networks are mostly used in both graph and structured data, providing a comparison of the best reasoning techniques between aforementioned data structures. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - Electronic health records
KW  - Graph data
KW  - Machine learning
KW  - Structured data
KW  - Digital storage
KW  - E-learning
KW  - Graphic methods
KW  - Health care
KW  - Hospital data processing
KW  - Machine learning
KW  - Medical computing
KW  - Records management
KW  - Data algorithm
KW  - Electronic health
KW  - Electronic health record
KW  - Graph data
KW  - Health records
KW  - Machine-learning
KW  - Patient information
KW  - Scoping review
KW  - Structured data
KW  - Wellbeing
KW  - Information management
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Slimani, K.
AU  - Khoulji, S.
AU  - Mortreau, A.
AU  - Kerkeb, M.L.
TI  - From tradition to innovation: The telecommunications metamorphosis with AI and advanced technologies
PY  - 2024
T2  - Journal of Autonomous Intelligence
VL  - 7
IS  - 1
C7  - 1099
DO  - 10.32629/jai.v7i1.1099
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175460721&doi=10.32629%2fjai.v7i1.1099&partnerID=40&md5=5733d75d98d97fc253b3a9378ad81d58
AB  - Businesses in the telecommunications industry provide global communication using a variety of channels, including but not limited to mobile phones, landlines, satellites, the Internet, and other electronic media. These businesses built the networks that enable the global transfer of text, audio, speech, and video. Companies in the telecommunications industry include those that provide landline and cellular telephone service, as well as those that provide cable television, satellite television, and online access. Once upon a time, the telecommunications industry was dominated by a small group of extremely large multinational and regional conglomerates. The industry has been caught up in a wave of liberalization and innovation since the early 2000s. Government monopolies have been privatized in several nations, exposing them to an explosion of new rivals. As mobile services continue to grow at a faster rate than fixed-line ones, and as Internet traffic begins to surpass voice traffic as the dominant form of commerce, established marketplaces have been turned on their heads. The undertaken paper endeavors to highlight the vulnerabilities that the telecommunication networking sector could be facing in the present as well as the future in light of the usage of artificial intelligence as assistive and advanced tech. © 2023 by author(s).
KW  - AI
KW  - cloud
KW  - industry
KW  - network
KW  - NGN
KW  - telecommunication
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 18
ER  -

TY  - JOUR
AU  - Ahmetoglu, A.
AU  - Seker, M.Y.
AU  - Piater, J.
AU  - Oztop, E.
AU  - Ugur, E.
TI  - DeepSym: Deep Symbol Generation and Rule Learning for Planning from Unsupervised Robot Interaction
PY  - 2022
T2  - Journal of Artificial Intelligence Research
VL  - 75
SP  - 709
EP  - 745
DO  - 10.1613/JAIR.1.13754
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147540666&doi=10.1613%2fJAIR.1.13754&partnerID=40&md5=963af0167802a7208a6e1f755e3f95a4
AB  - Symbolic planning and reasoning are powerful tools for robots tackling complex tasks. However, the need to manually design the symbols restrict their applicability, especially for robots that are expected to act in open-ended environments. Therefore symbol formation and rule extraction should be considered part of robot learning, which, when done properly, will offer scalability, flexibility, and robustness. Towards this goal, we propose a novel general method that finds action-grounded, discrete object and effect categories and builds probabilistic rules over them for non-trivial action planning. Our robot interacts with objects using an initial action repertoire that is assumed to be acquired earlier and observes the effects it can create in the environment. To form action-grounded object, effect, and relational categories, we employ a binary bottleneck layer in a predictive, deep encoder-decoder network that takes the image of the scene and the action applied as input, and generates the resulting effects in the scene in pixel coordinates. After learning, the binary latent vector represents action-driven object categories based on the interaction experience of the robot. To distill the knowledge represented by the neural network into rules useful for symbolic reasoning, a decision tree is trained to reproduce its decoder function. Probabilistic rules are extracted from the decision paths of the tree and are represented in the Probabilistic Planning Domain Definition Language (PPDDL), allowing off-the-shelf planners to operate on the knowledge extracted from the sensorimotor experience of the robot. The deployment of the proposed approach for a simulated robotic manipulator enabled the discovery of discrete representations of object properties such as 'rollable' and 'insertable'. In turn, the use of these representations as symbols allowed the generation of effective plans for achieving goals, such as building towers of the desired height, demonstrating the effectiveness of the approach for multi-step object manipulation. Finally, we demonstrate that the system is not only restricted to the robotics domain by assessing its applicability to the MNIST 8-puzzle domain in which learned symbols allow for the generation of plans that move the empty tile into any given position. © 2022 AI Access Foundation. All rights reserved.
KW  - Data mining
KW  - Decoding
KW  - Deep learning
KW  - Machine design
KW  - Manipulators
KW  - Robot programming
KW  - Action planning
KW  - Complex task
KW  - Discrete objects
KW  - General method
KW  - Non-trivial
KW  - Probabilistic rules
KW  - Robot interactions
KW  - Rule learning
KW  - Rules extraction
KW  - Symbol formation
KW  - Decision trees
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 16
ER  -

TY  - CONF
AU  - Li, X.
AU  - Tong, D.
AU  - Feng, Q.
AU  - Lei, Z.
TI  - Applying Neural Network Regression Analysis to Predict Material Price Fluctuations in Marketing Projects
PY  - 2024
T2  - ACM International Conference Proceeding Series
SP  - 292
EP  - 299
DO  - 10.1145/3662739.3663381
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201256380&doi=10.1145%2f3662739.3663381&partnerID=40&md5=e8382ac3f0d8d66e8931ee63529f530b
AB  - Accurately predicting changes in material prices is crucial in power grid marketing project activities. This article uses the method of neural network regression analysis, combined with historical data and market factors, to predict price fluctuations. This article obtains historical information on raw materials and processing costs from market reports, transaction records, and other sources, which can be obtained from market reports, transaction records, and other sources. This article collects market factors such as economy, supply and demand, and competition related to material prices from industrial reports, and uses neural network regression analysis methods to predict raw material prices for a certain period. Neural networks can extract patterns and trends from historical data, accurately grasp the patterns and trends of stock price changes, dynamically monitor market dynamics, and make corresponding adjustments to procurement strategies and capital allocation in a timely manner. The material price for Q1 2020 (Q is Quarter) is 120 yuan, with an inflation rate of 2.5%, and a GDP of 500 billion yuan. The neural network regression analysis model established by using neural network regression analysis can more accurately reflect the changes in raw material prices, thereby providing a basis for business decision-making. © 2024 ACM.
KW  - Inflation Rate
KW  - Marketing Projects
KW  - Material Price Fluctuations
KW  - Neural Network Regression Analysis
KW  - Price Prediction
KW  - Historical data
KW  - Inflation rates
KW  - Market-factors
KW  - Marketing project
KW  - Material price fluctuation
KW  - Neural network regression analyze
KW  - Neural-networks
KW  - Price fluctuation
KW  - Price prediction
KW  - Transaction records
KW  - Regression analysis
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Haghighatshoar, S.
AU  - Muir, D.R.
TI  - Low-power Spiking Neural Network audio source localisation using a Hilbert Transform audio event encoding scheme
PY  - 2025
T2  - Communications Engineering
VL  - 4
IS  - 1
C7  - 18
DO  - 10.1038/s44172-025-00359-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219704781&doi=10.1038%2fs44172-025-00359-9&partnerID=40&md5=eb5fff8401481f7053e5a823a2b850ee
AB  - Sound source localisation is used in many consumer devices, to isolate audio from individual speakers and reject noise. Localization is frequently accomplished by “beamforming”, which combines phase-shifted audio streams to increase power from chosen source directions, under a known microphone array geometry. Dense band-pass filters are often needed to obtain narrowband signal components from wideband audio. These approaches achieve high accuracy, but narrowband beamforming is computationally demanding, and not ideal for low-power IoT devices. We introduce a method for sound source localisation on arbitrary microphone arrays, designed for efficient implementation in ultra-low-power spiking neural networks (SNNs). We use a Hilbert transform to avoid dense band-pass filters, and introduce an event-based encoding method that captures the phase of the complex analytic signal. Our approach achieves high accuracy for SNN methods, comparable with traditional non-SNN super-resolution beamforming. We deploy our method to low-power SNN inference hardware, with much lower power consumption than super-resolution methods. We demonstrate that signal processing approaches co-designed with spiking neural network implementations can achieve much improved power efficiency. Our Hilbert-transform-based method for beamforming can also improve the efficiency of traditional digital signal processing. © The Author(s) 2025.
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Adhikary, A.
AU  - Deb Raha, A.
AU  - Qiao, Y.
AU  - Saad, W.
AU  - Han, Z.
AU  - Seon Hong, C.
TI  - Holographic MIMO with Integrated Sensing and Communication for Energy-Efficient Cell-Free 6G Networks
PY  - 2024
T2  - IEEE Internet of Things Journal
VL  - 11
IS  - 19
SP  - 30617
EP  - 30635
DO  - 10.1109/JIOT.2024.3411695
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196076210&doi=10.1109%2fJIOT.2024.3411695&partnerID=40&md5=9770feb59a8dd8779afd9c781a21147e
AB  - Sixth-generation wireless networks are required to satisfy the ever-increasing demands of diverse applications to guarantee power savings, energy efficiency (EE), and mass connectivity. To accomplish these goals, in this article, an artificial intelligence (AI)-based holographic MIMO (HMIMO)-empowered cell-free (CF) network is proposed while leveraging integrated sensing and communication (ISAC). The proposed AI-based framework allocates the desired power for beamforming by activating the required number of grids from the serving HMIMO base stations (BSs) in the CF network to serve the users. An optimization problem is formulated that maximizes the sensing utility function, which in turn maximizes the signal-to-interference-plus-noise ratio (SINR) of the received signal, the sensing SINR of the reflected echo signal, and EE, ensuring efficient power allocation. To solve the optimization problem, an AI-based framework is proposed to enable a decomposition of the NP-hard problem into two subproblems: 1) a sensing subproblem and 2) a power allocation subproblem. Initially, a variational autoencoder (VAE)-based scheme is utilized to solve the sensing subproblem that identifies the current location of the users with the sensing information. Then, a transformer-based mechanism is devised to allocate the desired power to users by activating the required grids from the serving HMIMO BSs in the CF network based on the sensing information achieved with the VAE-based scheme. Simulation results demonstrate that the proposed AI-based framework outperforms the long short-term memory and gated recurrent unit-based mechanisms, with cumulative power savings of 8.64% and 16.02%, and cumulative EE of 14.49% and 16.61%, accordingly, considering the ground truth values. © 2014 IEEE.
KW  - Cell-free (CF) network
KW  - energy efficiency (EE)
KW  - holographic MIMO (HMIMO)
KW  - integrated sensing and communication (ISAC)
KW  - sensing utility function (SUF)
KW  - Array processing
KW  - Beamforming
KW  - Chemical activation
KW  - Computational complexity
KW  - Holography
KW  - Internet of things
KW  - MIMO systems
KW  - Optimization
KW  - Signal interference
KW  - Signal to noise ratio
KW  - Array signal processing
KW  - Cell-free
KW  - Cell-free network
KW  - Holographic MIMO
KW  - Integrated sensing
KW  - Integrated sensing and communication
KW  - Interference
KW  - MIMO communication
KW  - Resource management
KW  - Sensing utility function
KW  - Utility functions
KW  - Energy efficiency
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 9
ER  -

TY  - JOUR
AU  - Wang, H.
TI  - Automatic question-answering modeling in English by integrating TF-IDF and segmentation algorithms
PY  - 2024
T2  - Systems and Soft Computing
VL  - 6
C7  - 200087
DO  - 10.1016/j.sasc.2024.200087
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187202923&doi=10.1016%2fj.sasc.2024.200087&partnerID=40&md5=86a48e8a5087b3442b9df3f184416918
AB  - Online network education offers convenience, however, the inefficiency and time-consuming nature of question-answering models negatively impact the demand for online learning. To address this issue, the study puts forward the development of an automatic English question-answering model. The improved model leverages a term frequence-inverse document frequency approach and an unsupervised participle algorithm based on deep learning. The precision and promptness of the question-answering model were enhanced by refining the weighted allocation of the term frequence-inverse document frequency algorithm and the unsupervised word-splitting algorithm. The validation shows that the improved precision rate is 68.14%, which is 34.37% and 50.45% more than the other two methods, respectively. The precision rate, recall rate, and F1 value for semantic similarity calculation improved by 9.23%, 9.22%, and 9.71%, respectively, compared to the traditional method. The validation experiments of the automatic English question-answering model indicate that its average accuracy was 94.68%, surpassing other models by 4.77%. The average answer time for the four types of questions was 30.52 ms, and the average answer time for the cause questions was 11.45 ms. The results show that the proposed English automatic question-answering model has better accuracy and timeliness of answering questions, and the improved accuracy for weight calculation is better. The English automatic question-answering model integrating word frequency-inverse document frequency and participle algorithm can satisfy the basic needs of teachers and students in online teaching, course question-answering, etc., which is of positive significance for the development of online education in the context of the Internet. © 2024
KW  - Automatic question-answering system
KW  - English question-answering
KW  - Semantic similarity
KW  - Term frequence-inverse document frequency
KW  - Unsupervised participle algorithm
KW  - Deep learning
KW  - E-learning
KW  - Education computing
KW  - Learning algorithms
KW  - Learning systems
KW  - Semantics
KW  - Teaching
KW  - Text processing
KW  - Automatic question answering
KW  - Automatic question-answering system
KW  - English question-answering
KW  - Inverse Document Frequency
KW  - Participle algorithms
KW  - Question Answering
KW  - Question answering systems
KW  - Semantic similarity
KW  - Term frequence-inverse document frequency
KW  - Unsupervised participle algorithm
KW  - Inverse problems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 9
ER  -

TY  - CONF
AU  - Cunnington, D.
AU  - Law, M.
AU  - Russo, A.
AU  - Lobo, J.
AU  - Kaplan, L.
TI  - Towards Neural-Symbolic Learning to support Human-Agent Operations
PY  - 2021
T2  - Proceedings of 2021 IEEE 24th International Conference on Information Fusion, FUSION 2021
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123410038&partnerID=40&md5=54fe9ef6f2c527405d3b88a0ed3c4d3a
AB  - This paper investigates neural-symbolic policy learning for information fusion in distributed human-agent operations. The architecture integrates a pre-trained neural network for feature extraction, with a state-of-the-art symbolic Inductive Logic Programming (ILP) system to learn policies, expressed as a set of logical rules. We firstly outline the challenge of policy learning within a military environment, by investigating the accuracy and confidence of neural network predictions given data outside the training distribution. Secondly, we introduce a neural-symbolic integration for policy learning and demonstrate that the symbolic ILP component, when considering the length of the learned policy rules, can generalise and learn a robust policy despite unstructured data observed at policy learning time originating from a different distribution than observed during training.  © 2021 International Society of Information Fusion (ISIF).
KW  - Human-agent
KW  - Information fusion
KW  - Policy
KW  - Rule learning
KW  - Sensors
KW  - Inductive logic programming (ILP)
KW  - Learning systems
KW  - Features extraction
KW  - Human agent
KW  - Learn+
KW  - Logic programming systems
KW  - Logical rules
KW  - Policy learning
KW  - Rule learning
KW  - State of the art
KW  - Symbolic learning
KW  - Trained neural networks
KW  - Information fusion
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Casadei, R.
AU  - Aguzzi, G.
AU  - Audrito, G.
AU  - Damiani, F.
AU  - Pianini, D.
AU  - Scarso, G.
AU  - Torta, G.
AU  - Viroli, M.
TI  - Software Engineering for Collective Cyber-Physical Ecosystems
PY  - 2025
T2  - ACM Transactions on Software Engineering and Methodology
VL  - 34
IS  - 5
C7  - 153
DO  - 10.1145/3712004
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007511221&doi=10.1145%2f3712004&partnerID=40&md5=ab691c84d5325f8031ece7eea3b1c6c0
AB  - Today’s distributed and pervasive computing addresses large-scale cyber-physical ecosystems, characterised by dense and large networks of devices capable of computation, communication and interaction with the environment and people. While most research focuses on treating these systems as ‘composites’ (i.e., heterogeneous functional complexes), recent developments in fields such as self-organising systems and swarm robotics have opened up a complementary perspective: treating systems as ‘collectives’ (i.e., uniform, collaborative and self-organising groups of entities). This article explores the motivations, state of the art and implications of this ‘collective computing paradigm’ in software engineering. In particular, it discusses its peculiar challenges, implied by characteristics like distribution, situatedness, large scale and cooperative nature. These challenges outline significant directions for future research in software engineering, touching on aspects such as macro-programming, collective intelligence, self-adaptive middleware, learning/synthesis of collective behaviour, human involvement, safety and security in collective cyber-physical ecosystems. © 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.
KW  - collective adaptive systems
KW  - cyber-physical ecosystems
KW  - distributed artificial intelligence
KW  - edge-cloud continuum
KW  - macro-programming
KW  - multi-agent systems
KW  - swarm intelligence
KW  - Application programs
KW  - Aspect oriented programming
KW  - Cloud computing
KW  - Computer operating systems
KW  - Computer software maintenance
KW  - Embedded software
KW  - Groupware
KW  - Middleware
KW  - Robot programming
KW  - Search engines
KW  - Software agents
KW  - Software design
KW  - Software packages
KW  - Software prototyping
KW  - Software quality
KW  - Software testing
KW  - Verification
KW  - Collective adaptive system
KW  - Cyber-physical ecosystems
KW  - Dense network
KW  - Distributed Artificial Intelligence
KW  - Edge clouds
KW  - Edge-cloud continuum
KW  - Large-scales
KW  - Larger networks
KW  - Macro-programming
KW  - Multiagent systems (MASs)
KW  - Swarm intelligence
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Zhou, Q.
AU  - Zhang, H.
AU  - Wang, S.
TI  - Artificial intelligence, big data, and blockchain in food safety
PY  - 2022
T2  - International Journal of Food Engineering
VL  - 18
IS  - 1
SP  - 1
EP  - 14
DO  - 10.1515/ijfe-2021-0299
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119993369&doi=10.1515%2fijfe-2021-0299&partnerID=40&md5=1960857a30fc4dcaec5f3d1a74c47f18
AB  - Food safety plays an essential role in our daily lives, and it becomes serious with the development of worldwide trade. To tackle the food safety issues, many advanced technologies have been developed to monitor the process of the food industry (FI) to ensure food safety, including the process of food production, processing, transporting, storage, and retailing. These technologies are often referred to as artificial intelligence (AI), big data, and blockchain, which have been widely applied in many research areas. In this review, we introduce these technologies and their applications in the food safety domain. Firstly, basic concepts of these technologies are presented. Then, applications for food safety from a data perspective based on these technologies are analyzed. Finally, future challenges of the applications of AI, big data, and blockchain are discussed.  © 2021 Walter de Gruyter GmbH, Berlin/Boston.
KW  - artificial intelligence (AI)
KW  - big data
KW  - blockchain
KW  - food safety
KW  - systemic view
KW  - Accident prevention
KW  - Artificial intelligence
KW  - Big data
KW  - Digital storage
KW  - Food safety
KW  - Advanced technology
KW  - Artificial intelligence
KW  - Block-chain
KW  - Daily lives
KW  - Food industries
KW  - Food production
KW  - Food retailing
KW  - Food-safety
KW  - Safety issues
KW  - Systemic views
KW  - Blockchain
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 57
ER  -

TY  - CONF
AU  - Boyer, A.
AU  - Dogdu, E.
AU  - Choupani, R.
AU  - Watson, J.S.
AU  - Sanchez, D.
AU  - Ametu, A.
TI  - Toward a Unified Cybersecurity Knowledge Graph: Leveraging Ontologies and Open Data Sources
PY  - 2024
T2  - Communications in Computer and Information Science
VL  - 2158 CCIS
SP  - 17
EP  - 33
DO  - 10.1007/978-3-031-67871-4_2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202643390&doi=10.1007%2f978-3-031-67871-4_2&partnerID=40&md5=58e06edc71641344673af4929ae01318
AB  - The cybersecurity field is very heterogeneous with the ever-growing digital cyberspace and the increasing volume of big data produced in the field. It is therefore difficult to overcome many of the security challenges with manual solutions. Automation and intelligent cybersecurity solutions are both promising tools to overcome common security challenges, however, they require robust data and knowledge management. Today, Knowledge graphs (KG) are widely used in many intelligent system solutions, including the cybersecurity field. However, the efforts to build KGs in many cybersecurity areas are narrowly focused, and therefore it is difficult to unify and integrate these otherwise very useful solutions. Earlier efforts in unifying the cybersecurity knowledge using common ontologies have not generalized their approach to provide a unified solution for cybersecurity challenges. Here, we attempt provide a renewed approach to building a Unified Cybersecurity Knowledge Graph (UCKG), using the Unified Cybersecurity Ontology (UCO), that integrates structured and unstructured open data sources in an automated fashion. With this paper, we hope to pave the way toward a Unified Cybersecurity Knowledge Graph (UCKG) and its utilization in intelligent cybersecurity solutions. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - cybersecurity knowledge graph
KW  - Cybersecurity ontology
KW  - intelligent cybersecurity
KW  - Unified Cybersecurity Knowledge Graph
KW  - Unified Cybersecurity Ontology
KW  - Knowledge graph
KW  - Cyber security
KW  - Cybersecurity knowledge graph
KW  - Cybersecurity ontology
KW  - Intelligent cybersecurity
KW  - Knowledge graphs
KW  - Ontology's
KW  - Unified cybersecurity knowledge graph
KW  - Unified cybersecurity ontology
KW  - Cybersecurity
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Kumar Jha, S.
AU  - Jha, S.
AU  - Haq Rashed, M.R.
AU  - Ewetz, R.
AU  - Velasquez, A.
TI  - Automated Synthesis of Hardware Designs using Symbolic Feedback and Grammar-Constrained Decoding in Large Language Models
PY  - 2024
T2  - Proceedings of the IEEE National Aerospace Electronics Conference, NAECON
SP  - 95
EP  - 100
DO  - 10.1109/NAECON61878.2024.10670630
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205008784&doi=10.1109%2fNAECON61878.2024.10670630&partnerID=40&md5=82124412a0ec49bb9c8c29f80e33b344
AB  - Large language models (LLMs) are capable of creating small programs including those in hardware description languages. However, there are no guarantees on the correctness of such generated programs. Our approach seeks to create correct-by-construction hardware designs using LLMs by employing formal verification to verify the designs and by using counterex-amples to guide the synthesis of such hardware designs in a counterexample-guided refinement loop. Grammar-constrained decoding is used to ensure that the generated code always satisfies the grammar of the hardware description language. We demonstrate the capability of our automated synthesis approach by generating a multiplier using LLMs and their assurance artifacts using model checking. Our approach provides a step in the direction of high-assurance synthesis of hardware artifacts using LLMs and formal methods.  © 2024 IEEE.
KW  - automated synthesis
KW  - circuits
KW  - grammar-constrained decoding
KW  - hardware description language
KW  - LLM
KW  - Verilog
KW  - Computer hardware description languages
KW  - Context free grammars
KW  - Context sensitive grammars
KW  - Decoding
KW  - Model checking
KW  - Problem oriented languages
KW  - Program debugging
KW  - Automated synthesis
KW  - Constrained decoding
KW  - Correct-by-construction
KW  - Description languages
KW  - Grammar-constrained decoding
KW  - Hardware descriptions
KW  - Hardware design
KW  - Language model
KW  - Large language model
KW  - Models checking
KW  - Formal verification
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Kurisummoottil Thomas, C.
AU  - Saad, W.
AU  - Xiao, Y.
TI  - Causal Semantic Communication for Digital Twins: A Generalizable Imitation Learning Approach
PY  - 2023
T2  - IEEE Journal on Selected Areas in Information Theory
VL  - 4
SP  - 698
EP  - 717
DO  - 10.1109/JSAIT.2023.3336538
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186498882&doi=10.1109%2fJSAIT.2023.3336538&partnerID=40&md5=30e3255c3767581434be84deb9f0b472
AB  - A digital twin (DT) leverages a virtual representation of the physical world, along with communication (e.g., 6G), computing (e.g., edge computing), and artificial intelligence (AI) technologies to enable many connected intelligence services. In order to handle the large amounts of network data based on digital twins (DTs), wireless systems can exploit the paradigm of semantic communication (SC) for facilitating informed decision-making under strict communication constraints by utilizing AI techniques such as causal reasoning. In this paper, a novel framework called causal semantic communication (CSC) is proposed for DT-based wireless systems. The CSC system is posed as an imitation learning (IL) problem, where the transmitter, with access to optimal network control policies using a DT, teaches the receiver using SC over a bandwidth-limited wireless channel how to improve its knowledge to perform optimal control actions. The causal structure in the transmitter's data is extracted using novel approaches from the framework of deep end-to-end causal inference, thereby enabling the creation of a semantic representation that is causally invariant, which in turn helps generalize the learned knowledge of the system to new and unseen situations. The CSC decoder at the receiver is designed to extract and estimate semantic information while ensuring high semantic reliability. The receiver control policies, semantic decoder, and causal inference are formulated as a bi-level optimization problem within a variational inference framework. This problem is solved using a novel concept called network state models, inspired from world models in generative AI, that faithfully represents the environment dynamics leading to data generation. Furthermore, the proposed framework includes an analytical characterization of the performance gap that results from employing a suboptimal policy learned by the receiver that uses the transmitted semantic information to construct a model of the physical environment. The CSC system utilizes two concepts, namely the integrated information theory principle in the theory of consciousness and the abstract cell complex concept in topology, to precisely express the information content conveyed by the causal states and their relationships. Through this analysis, novel formulations of semantic information, semantic reliability, distortion, and similarity metrics are proposed, which extend beyond Shannon's concept of uncertainty. Simulation results demonstrate that the proposed CSC system outperforms conventional wireless and state-of-the-art SC systems by achieving better semantic reliability with reduced bits and enabling better control policies over time thanks to the generative AI architecture.  © 2020 IEEE.
KW  - and causal inference
KW  - imitation learning
KW  - integrated information theory
KW  - model-based reinforcement learning
KW  - Semantic communication
KW  - Access control
KW  - Computation theory
KW  - Data mining
KW  - Decision making
KW  - Decoding
KW  - E-learning
KW  - Learning systems
KW  - Reliability analysis
KW  - Semantics
KW  - Transmitters
KW  - And causal inference
KW  - Causal inferences
KW  - Causal semantics
KW  - Communications systems
KW  - Control policy
KW  - Imitation learning
KW  - Integrated information theory
KW  - Integrated informations
KW  - Model-based reinforcement learning
KW  - Semantic communication
KW  - Uncertainty analysis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 15
ER  -

TY  - JOUR
AU  - Xia, Q.
AU  - Chen, J.
AU  - Yue, J.
AU  - Lyu, F.
AU  - Cui, Z.
TI  - Health condition determination of DC/DC converters based on abductive learning
PY  - 2025
T2  - Measurement: Journal of the International Measurement Confederation
VL  - 248
C7  - 116910
DO  - 10.1016/j.measurement.2025.116910
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217428982&doi=10.1016%2fj.measurement.2025.116910&partnerID=40&md5=0dc09f978e1e5e0fca90d2a69d1f8212
AB  - This paper proposes a health condition classification method based on the abductive learning concept for monitoring the health condition of power electronic converters. Specifically, the method proposes a collaborative classification of knowledge and data streams, modifying data classification with knowledge in an iterative process. However, when domain knowledge is difficult to quantify fully, the semi-supervised character of the knowledge becomes weaker. Therefore, the knowledge stream classifier constructed by the cloud model is established, the Support Vector Machine (SVM) classifier is optimized, and the knowledge stream model is enriched in continuous iterative optimization. The firefly algorithm is used to optimize the critical parameters of the SVM after each correction in order to make it better suited to the distribution data. Classification accuracy is continuously improved during the iterative process, with better classification accuracy when new unlabeled data is injected. The method's effectiveness is verified in the health classification of the Superbuck converter. © 2025 Elsevier Ltd
KW  - Abductive learning
KW  - Cloud model
KW  - Health monitoring
KW  - Superbuck convertor
KW  - Abductive learning
KW  - Classification accuracy
KW  - Classification methods
KW  - Cloud modeling
KW  - DC converter
KW  - Health condition
KW  - Health monitoring
KW  - Iterative process
KW  - Superbuck
KW  - Superbuck convertor
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Yu, J.
AU  - Guo, L.
AU  - Zhang, J.
AU  - Wang, G.
TI  - A survey on graph neural network-based next POI recommendation for smart cities
PY  - 2024
T2  - Journal of Reliable Intelligent Environments
VL  - 10
IS  - 3
SP  - 299
EP  - 318
DO  - 10.1007/s40860-024-00233-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199517321&doi=10.1007%2fs40860-024-00233-z&partnerID=40&md5=d6253e2891d7c4e458c4e6b289d96b24
AB  - Amid the rise of mobile technologies and Location-Based Social Networks (LBSNs), there’s an escalating demand for personalized Point-of-Interest (POI) recommendations. Especially pivotal in smart cities, these systems aim to enhance user experiences by offering location recommendations tailored to past check-ins and visited POIs. Distinguishing itself from traditional POI recommendations, the next POI approach emphasizes predicting the immediate subsequent location, factoring in both geographical attributes and temporal patterns. This approach, while promising, faces with challenges like capturing evolving user preferences and navigating data biases. The introduction of Graph Neural Networks (GNNs) brings forth a transformative solution, particularly in their ability to capture high-order dependencies between POIs, understanding deeper relationships and patterns beyond immediate connections. This survey presents a comprehensive exploration of GNN-based next POI recommendation approaches, delving into their unique characteristics, inherent challenges, and potential avenues for future research. © The Author(s) 2024.
KW  - Graph neural networks (GNNs)
KW  - Location-based services
KW  - Next point-of-interest (POI) recommendation
KW  - Smart city
KW  - Air navigation
KW  - Graph neural networks
KW  - Location
KW  - Smart city
KW  - Social sciences computing
KW  - Telecommunication services
KW  - Graph neural network
KW  - Graph neural networks
KW  - Location-based services
KW  - Location-based social networks
KW  - Mobile location
KW  - Mobile Technology
KW  - Network-based
KW  - Next point-of-interest  recommendation
KW  - Technology-based
KW  - Users' experiences
KW  - Location based services
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - CHAP
AU  - Bickley, S.J.
AU  - Torgler, B.
TI  - Behavioural economics: What have we missed? Exploring 'classical' behavioural economics roots in AI, cognitive psychology and complexity theory
PY  - 2023
T2  - Handbook of Research Methods in Behavioural Economics
SP  - 32
EP  - 59
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161326705&partnerID=40&md5=0589067808ef3b3c0519679d545f73c8
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Bellini, P.
AU  - Collini, E.
AU  - Fanfani, M.
AU  - Palesi, L.A.I.
AU  - Nesi, P.
TI  - Smart City Digital Twin Platform Architecture for Mobility and Transport Decision Support Systems
PY  - 2024
T2  - Proceedings - 2024 IEEE International Conference on Big Data, BigData 2024
SP  - 5486
EP  - 5495
DO  - 10.1109/BigData62323.2024.10825075
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218048918&doi=10.1109%2fBigData62323.2024.10825075&partnerID=40&md5=03c6e1bcd829d3ef51fcb43400401dbf
AB  - Addressing mobility and transport problems is nowadays of paramount importance for any city due to the increasing urbanization. Traffic congestion, pollutant emissions, energy consumption are some of the problems related to urban mobility. Therefore, there is the need of tools able to support decision-makers in studying, evaluating, and planning sustainable urban evolutions. A few open-source and proprietary solutions are available requiring on-premises installations, large effort, and providing limited capabilities to actually handle real-time data (from data spaces, and standards). Moreover, they are limited in terms of analytic integration and do not offer automatic generation of suggestions. In practice they do not manage the explosion of complexity regarding computational and storage/models aspects. For these reasons, this paper presents a comprehensive architecture for a Smart City Digital Twin platform, specifically designed to support mobility and transportation decision-making through advanced what-if analysis and optimization. The platform, integrated within the Snap4City system, enables real-time data processing and complex analytics to create virtual urban environments for evaluating potential infrastructure changes. Through microservice architecture, the platform supports massive data ingestion, scenario creation, and predictive modelling, facilitating both short-term and long-term planning. The solution leverages artificial intelligence (AI), machine learning (ML), and reinforcement learning (RL) to optimize city operations and suggest actionable insights, aiding city planners in strategic and tactical decisions. This architecture has been validated through implementations in Italian cities, demonstrating scalability and flexibility to accommodate diverse urban needs and improve traffic flow, energy efficiency, and environmental impact. This work has been performed in the context of OPTIFaaS Flagship of CN MOST, the National Centre for Sustainable Mobility in Italy, and for CN HPC Big Data and Quantum Computing, ICSC. © 2024 IEEE.
KW  - Decision Support System
KW  - Digital Twin
KW  - Optimization
KW  - Traffic
KW  - Urban Scenario
KW  - Network security
KW  - Quantum electronics
KW  - Reinforcement learning
KW  - Steganography
KW  - Urban transportation
KW  - Decision supports
KW  - Emission energies
KW  - Energy-consumption
KW  - Optimisations
KW  - Platform architecture
KW  - Pollutants emissions
KW  - Support systems
KW  - Traffic
KW  - Transport problems
KW  - Urban scenarios
KW  - Traffic congestion
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Mansour, Y.
AU  - Jan, M.
AU  - Brik, B.
AU  - Ahmed, N.
TI  - Recent Applications Using Explainable Artificial Intelligence for Data Analytics
PY  - 2024
T2  - International Conference on Control and Automation, Electronics, Robotics, Internet of Things, and Artificial Intelligence, CERIA 2024
DO  - 10.1109/CERIA64726.2024.10915113
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001563788&doi=10.1109%2fCERIA64726.2024.10915113&partnerID=40&md5=2a921932770089f085a365bba8ccb8ae
AB  - This survey paper offers a comprehensive analysis of recent advancements in eXplainable Artificial Intelligence (XAI) for data analytics, drawing from a meticulous review of 31 pertinent papers. Leveraging a focused selection process, we compare and categorize papers across multiple dimensions, including application domain, architecture, implementation level, explanation level, XAI method, model dependency, applications, and dataset characteristics. Our analysis highlights the diverse applications of XAI techniques, ranging from health care informatics to education, transportation, and beyond. Through this survey, we not only highlight recent applications but also identify key dimensions for further research and development, offering valuable insights for researchers and practitioners seeking to leverage XAI in data analytics effectively. © 2024 IEEE.
KW  - Black-box Models
KW  - Data Analytics
KW  - Explainable Artificial Intelligence
KW  - Interpretable Machine Learning
KW  - Survey
KW  - Applications domains
KW  - Black box modelling
KW  - Comprehensive analysis
KW  - Data analytics
KW  - Domain architectures
KW  - Explainable artificial intelligence
KW  - Interpretable machine learning
KW  - Machine-learning
KW  - Method model
KW  - Multiple dimensions
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Akhtar, Z.B.
AU  - Rozario, V.S.
TI  - AI Perspectives Within Computational Neuroscience: EEG Integrations and the Human Brain
PY  - 2025
T2  - Artificial Intelligence and Applications
VL  - 3
IS  - 2
SP  - 145
EP  - 160
DO  - 10.47852/bonviewAIA52024174
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007651020&doi=10.47852%2fbonviewAIA52024174&partnerID=40&md5=cb80c77f19d729761a727ad4b7491204
AB  - Current advancements within the realm of computational neuroscience, combined with the transformative capabilities of artificial intelligence (AI), have opened new paths for understanding the human brain’s interconnected complexity. This research exploration integrates electroencephalography (EEG), computational neuroscience, along with AI toward the investigation of complex cognitive mechanisms and neural activations associated with the various types of mental states. As a non-invasive tool, EEG mainly captures the internal electrical activity that reveals the interconnected cognitive processes in real time. By leveraging AI techniques—such as deep learning (DL), machine learning (ML), transfer learning, and convolutional neural networks (CNN)—this investigation deciphers EEG data to identify various specific neural patterns accompanying various types of cognitive states, memory formation, and especially toward emotional responses. To further refine these results and findings, this study organizes applications chronologically, presenting a developmental perspective on the AI-driven EEG advancements and their significance in detecting nuanced brain activity. This research not only addresses how experimental methods impact cognitive state reliability but also examines the amygdala’s role in EEG during emotional stimuli, thus expanding our multimodal level for understanding of emotional and memory-related neural signatures. By merging EEG data with AI-calibrated models, this investigation proposes new perspectives on the neural basis of attention, perception, and cognitive function, potentially informing early diagnosis of neurological disorders and enhancing brain-computer interfaces. Through this multidisciplinary lens, the exploration advances clinical applications and cognitive interventions, highlighting the interplay between EEG, computational neuroscience, and AI as an essential frontier in terms of both science and neurotechnology. © The Author(s) 2025. Published by BON VIEW PUBLISHING PTE. LTD. Tlicenses/by/4.0/).
KW  - artificial intelligence
KW  - biomedical engineering
KW  - cognitive computing
KW  - computational neuroscience
KW  - deep learning
KW  - electroencephalography
KW  - machine learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Liang, Y.
AU  - Zheng, P.
AU  - Xia, L.
TI  - A Visual Reasoning-based AR-HUD Service Design Approach for Better Driving Experience
PY  - 2023
T2  - Procedia CIRP
VL  - 119
SP  - 296
EP  - 301
DO  - 10.1016/j.procir.2023.02.136
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169878634&doi=10.1016%2fj.procir.2023.02.136&partnerID=40&md5=5688eef46c1227b78307ef6c5e6c110f
AB  - Smart traffic or transportation, as a critical part of realizing the smart city, utilizes various smart product-service systems to support it. Among them, the augmented reality head-up display (AR-HUD) system is a typical smart driving solution, which projects vital information about driving situations with pre-defined AR graphics onto the windshield of vehicles. The AR-HUD service design attracts increasing concerns owing to its enhancement of drivers' situational awareness without glancing down at the instrument cluster. Nevertheless, current in-car AR-HUDs only stack some simple driving information from sensors, such as the driving speed. It's difficult to meet the demand of drivers since they ignore a higher level of drivers' situation awareness, i.e., driving situation prediction and recommendation of driving advice. To overcome the challenge, this paper proposes a visual reasoning-based service design approach for advancing AR-HUDs' digital servitization and better user experience. Additionally, drivers are involved in the service design development in a value co-creation manner through human-computer interaction design. With the combination of experiential driving knowledge and cognitive intelligence computing on the driving scene, the proposed novel service design approach enables AR-HUD to percept driving scenarios and infer good strategies accordingly. Finally, an illustrative example is carried out to validate the feasibility of the proposed AR-HUD service design approach. © 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0)
KW  - augmented reality head-up display
KW  - smart driving
KW  - Smart product-service system
KW  - value co-creation
KW  - visual reasoning
KW  - Human computer interaction
KW  - Product design
KW  - Augmented reality head-up display
KW  - Head-UpDisplay
KW  - Heads-up-display
KW  - Product-service systems
KW  - Services designs
KW  - Smart driving
KW  - Smart product-service system
KW  - Smart products
KW  - Value co creations
KW  - Visual reasoning
KW  - Augmented reality
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Zamri, N.E.
AU  - Mansor, M.A.
AU  - Mohd Kasihmuddin, M.S.
AU  - Alway, A.
AU  - Jamaludin, S.Z.M.
AU  - Alzaeemi, S.A.
TI  - Amazon employees resources access data extraction via clonal selection algorithm and logic mining approach
PY  - 2020
T2  - Entropy
VL  - 22
IS  - 6
C7  - 596
DO  - 10.3390/E22060596
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087045434&doi=10.3390%2fE22060596&partnerID=40&md5=cc524a5dbaf32f3f736c799d083a7e24
AB  - Amazon. com Inc. seeks alternative ways to improve manual transactions system of granting employees resources access in the field of data science. The work constructs a modified Artificial Neural Network (ANN) by incorporating a Discrete Hopfield Neural Network (DHNN) and Clonal Selection Algorithm (CSA) with 3-Satisfiability (3-SAT) logic to initiate an Artificial Intelligence (AI) model that executes optimization tasks for industrial data. The selection of 3-SAT logic is vital in data mining to represent entries of Amazon Employees Resources Access (AERA) via information theory. The proposed model employs CSA to improve the learning phase of DHNN by capitalizing features of CSA such as hypermutation and cloning process. This resulting the formation of the proposed model, as an alternative machine learning model to identify factors that should be prioritized in the approval of employees resources applications. Subsequently, reverse analysis method (SATRA) is integrated into our proposed model to extract the relationship of AERA entries based on logical representation. The study will be presented by implementing simulated, benchmark and AERA data sets with multiple performance evaluation metrics. Based on the findings, the proposed model outperformed the other existing methods in AERA data extraction. © 2020 by the authors.
KW  - Boolean satisfiability
KW  - Clonal selection algorithm
KW  - Data extraction
KW  - Human resources management
KW  - Logic mining
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 49
ER  -

TY  - CONF
AU  - Sinha, H.
TI  - An Early Diagnosis of Alzheimer's Disease (AD) on MRI Images Based on Deep Learning Technique
PY  - 2024
T2  - 2024 IEEE Silchar Subsection Conference, SILCON 2024
DO  - 10.1109/SILCON63976.2024.10910870
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001359259&doi=10.1109%2fSILCON63976.2024.10910870&partnerID=40&md5=ec1c7468c77f0641cfc80160578426f8
AB  - The growing population with dementia, particularly Alzheimer's disease (AD), presents a formidable obstacle to contemporary medicine. A condition that impacts millions of people worldwide, AD currently has no known treatment. While cancer has had progress in preventing the disease from progressing, early detection of AD is critical in managing its effects. This is so because AD is relatively easier to treat in its early stages hence early diagnosis is crucial for the development of drugs and therapies. AD identification is one of several medical imaging challenges that have lately been tackled using DL approaches. MRI is one of a most effective methods for diagnosing AD at the moment. This research goal to improve early diagnosis and treatment of AD, this research uses MRI scans and DL algorithms. The Kaggle Alzheimer MRI Preprocessed Dataset, including 6400 MRI scans categorised as Moderate, Mild, Non-Demented, and Very Mild Demented, was used. InceptionV3 outperformed Recurrent Neural Networks (RNNs) for classification tasks with an accuracy of 0.98%. Also, f1-score, recall, and precision of 99%, respectively. Deep learning models can effectively diagnose AD phases, underlining their importance in early intervention and patient outcomes.  © 2024 IEEE.
KW  - Alzheimer MRI Dataset
KW  - Deep Learning
KW  - Gaussian Blur
KW  - Inception V3 Model
KW  - Disease control
KW  - Neurodegenerative diseases
KW  - Alzheimer
KW  - Alzheimer MRI dataset
KW  - Alzheimers disease
KW  - Deep learning
KW  - Early diagnosis
KW  - Gaussian blur
KW  - Image-based
KW  - Inception v3 model
KW  - MRI Image
KW  - MRI scan
KW  - Recurrent neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Mekrache, A.
AU  - Ksentini, A.
AU  - Verikoukis, C.
TI  - Machine Learning in FCAPS: Toward Enhanced beyond 5G Network Management
PY  - 2024
T2  - IEEE Communications Surveys and Tutorials
VL  - 26
IS  - 4
SP  - 2769
EP  - 2797
DO  - 10.1109/COMST.2024.3395414
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192212153&doi=10.1109%2fCOMST.2024.3395414&partnerID=40&md5=d7b96c49e8961c02c6943855dae01b2d
AB  - The increasing complexity of telecommunication networks has highlighted the need for robust network management frameworks. One such framework is FCAPS, which encompasses a wide range of functionalities, including fault management, configuration management, accounting management, performance management, and security management. To effectively address the complexities of modern networks, the integration of Artificial Intelligence (AI) techniques, particularly Machine Learning (ML) and Machine Reasoning (MR), has emerged as a pivotal strategy within FCAPS. ML provides networks with data-driven algorithms to recognize patterns and make informed predictions, while MR focuses on developing understandable AI systems that draw conclusions based on explicit knowledge. In this paper, we explore the field of MR and its usage within FCAPS. First, we present an overview of the FCAPS framework, including a categorization of FCAPS levels. Then, we provide a novel taxonomy of MR approaches, presenting both traditional and advanced MR. Next, we review MR techniques to address emerging concerns within FCAPS. Finally, we discuss open issues and future directions for further study toward 6G networks. © 2024 IEEE.
KW  - 6G networks
KW  - FCAPS
KW  - machine learning
KW  - machine reasoning
KW  - network management
KW  - Telecommunications
KW  - 5G mobile communication systems
KW  - Machine learning
KW  - Network security
KW  - Queueing networks
KW  - Software defined networking
KW  - 6g network
KW  - Cognition
KW  - Configuration management
KW  - FCAPS
KW  - Machine reasoning
KW  - Machine-learning
KW  - Networks management
KW  - Security management
KW  - Software-defined networkings
KW  - Tutorial
KW  - Network management
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Popescu, D.C.
AU  - Dumitrache, I.
TI  - Knowledge representation and reasoning using interconnected uncertain rules for describing workflows in complex systems
PY  - 2023
T2  - Information Fusion
VL  - 93
SP  - 412
EP  - 428
DO  - 10.1016/j.inffus.2023.01.007
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146421572&doi=10.1016%2fj.inffus.2023.01.007&partnerID=40&md5=0e0712a980908e8d1a3ac01682fd2ccf
AB  - Knowledge representation and reasoning (KRR) in complex systems (CSs) usually require facts from multiple experts having complementary backgrounds to fuse together. Consequently, such KRR methods should provide universal modeling languages close to human reasoning, with increased expressiveness and efficient capabilities to describe uncertainties. In this context, this paper introduces a new modeling formalism entitled Hybrid Logic-Algebraic Relational Modeling which is based on combining logic, probabilities, numerical information and network representations. The behavior, facts and workflows in a CS can be described using an environment of interconnected models enclosing sets of logical rules with attached probabilistic trust factors and links regarding logical attributes and numerical parameters. The logical and probabilistic inference applied to the modeling environment gives valuable knowledge to designers and decision-makers so that they can develop procedures or take actions in managing the CS. In this article, the proposed approach is completely formalized, from concept to definition and proofs and up to implementation, while its usage is illustrated within a complex economic, logistical, economical and technical scenario. © 2023 Elsevier B.V.
KW  - Complex workflows
KW  - Knowledge reasoning
KW  - Knowledge representation
KW  - Probabilistic logic inference
KW  - Relational modeling
KW  - Trust factors
KW  - Complex networks
KW  - Computer circuits
KW  - Decision making
KW  - Large scale systems
KW  - Modeling languages
KW  - Probabilistic logics
KW  - Uncertainty analysis
KW  - Complex workflows
KW  - Knowledge reasoning
KW  - Knowledge representation and reasoning
KW  - Knowledge-representation
KW  - Logic inferences
KW  - Probabilistic logic inference
KW  - Relational modeling
KW  - Trust factor
KW  - Uncertain rules
KW  - Work-flows
KW  - Knowledge representation
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Getu, T.M.
AU  - Kaddoum, G.
AU  - Bennis, M.
TI  - A Survey on Goal-Oriented Semantic Communication: Techniques, Challenges, and Future Directions
PY  - 2024
T2  - IEEE Access
VL  - 12
SP  - 51223
EP  - 51274
DO  - 10.1109/ACCESS.2024.3381967
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189179155&doi=10.1109%2fACCESS.2024.3381967&partnerID=40&md5=e8e8b1c696698c31b70461a5c639738d
AB  - Although many proposals have been developed for the sixth-generation (6G) technology, realizing 6G is fraught with numerous fundamental interdisciplinary, multidisciplinary, and transdisciplinary challenges. To mitigate some of these challenges, goal-oriented semantic communication (SemCom) has emerged as a promising 6G technology enabler. This enabler employs only semantically-relevant information for successful task execution while minimizing power usage, bandwidth consumption, and transmission delay. On the other hand, 6G is essential for realizing major goal-oriented SemCom use cases such as autonomous transportation. These paradigms of 6G for goal-oriented SemCom and goal-oriented SemCom for 6G call for a tighter integration of 6G and goal-oriented SemCom. To facilitate this purpose, this survey paper exposes the fundamental challenges of 6G; details the notion of goal-oriented SemCom and its state-of-the-art research landscape; presents state-of-the-art trends, use cases, and frameworks of goal-oriented SemCom; exposes the fundamental and major challenges of goal-oriented SemCom; and offers promising future research directions for goal-oriented SemCom. Consequently, this survey article stimulates numerous lines of research on goal-oriented SemCom theories, algorithms, and realization.  © 2013 IEEE.
KW  - 6G
KW  - challenges of goal-oriented SemCom
KW  - future directions for goal-oriented SemCom
KW  - goal-oriented SemCom
KW  - techniques of goal-oriented SemCom
KW  - Benchmarking
KW  - Market Research
KW  - 6g
KW  - 6g mobile communication
KW  - Challenge of goal-oriented semantic communication
KW  - Channel allocation
KW  - Delay
KW  - Future direction for goal-oriented semantic communication
KW  - Goal-oriented
KW  - Goal-oriented semantic communication
KW  - Key performance indicators
KW  - Market researches
KW  - Mobile communications
KW  - Optimisations
KW  - Semantic communication
KW  - Technique of goal-oriented semantic communication
KW  - Wireless communications
KW  - Semantics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 15
ER  -

TY  - JOUR
AU  - Liang, C.
AU  - Du, H.
AU  - Sun, Y.
AU  - Niyato, D.
AU  - Kang, J.
AU  - Zhao, D.
AU  - Imran, M.A.
TI  - Generative AI-Driven Semantic Communication Networks: Architecture, Technologies, and Applications
PY  - 2025
T2  - IEEE Transactions on Cognitive Communications and Networking
VL  - 11
IS  - 1
SP  - 27
EP  - 47
DO  - 10.1109/TCCN.2024.3435524
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200237377&doi=10.1109%2fTCCN.2024.3435524&partnerID=40&md5=4615e28d199d6b86032888264fc7b4c7
AB  - Generative artificial intelligence (GAI) has emerged as a rapidly burgeoning field demonstrating significant potential in creating diverse content intelligently and automatically. To support such artificial intelligence-generated content (AIGC) services, future communication systems must fulfill stringent requirements, including high data rates, throughput, and low latency, while efficiently utilizing limited spectrum resources. Semantic communication (SemCom) has been deemed as a revolutionary communication scheme to tackle this challenge by conveying the meaning of messages instead of bit reproduction. GAI algorithms serve as the foundation for enabling intelligent and efficient SemCom systems in terms of model pre-training and fine-tuning, knowledge base construction, and resource allocation. Conversely, SemCom can provide AIGC services with low latency and high reliability due to its ability to perform semantic-aware encoding and compression of data, as well as knowledge- and context-based reasoning. In this survey, we break new ground by investigating the architecture, wireless communication schemes, and network management of GAI-driven SemCom networks. We first introduce a novel architecture for GAI-driven SemCom networks, comprising the data plane, physical infrastructure, and network control plane. In turn, we provide an in-depth analysis of the transceiver design and semantic effectiveness calculation of end-to-end GAI-driven SemCom systems. Subsequently, we present innovative generation level and knowledge management strategies in the proposed networks, including knowledge construction, update, and sharing, ensuring accurate and timely knowledge-based reasoning. Finally, we explore several promising use cases, i.e., autonomous driving, smart cities, and the Metaverse, to provide a comprehensive understanding and future direction of GAI-driven SemCom networks.  © 2024 IEEE.
KW  - AIGC
KW  - generative AI
KW  - intelligent wireless networks
KW  - knowledge management
KW  - Semantic communication
KW  - Computer architecture
KW  - Knowledge engineering
KW  - Knowledge management
KW  - Network architecture
KW  - Radio transceivers
KW  - Resource allocation
KW  - Semantic Web
KW  - Wireless networks
KW  - Artificial intelligence-generated content
KW  - Communication schemes
KW  - Communications networks
KW  - Communications systems
KW  - Content services
KW  - Generative AI
KW  - Intelligent wireless networks
KW  - Low latency
KW  - Resource management
KW  - Semantic communication
KW  - Semantics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 14
ER  -

TY  - JOUR
AU  - Nguyen, H.
AU  - Vo, M.
AU  - Hyatt, J.
AU  - Wang, Z.
TI  - AI-Powered Visual Sensors and Sensing: Where We Are and Where We Are Going
PY  - 2025
T2  - Sensors
VL  - 25
IS  - 6
C7  - 1758
DO  - 10.3390/s25061758
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002047392&doi=10.3390%2fs25061758&partnerID=40&md5=63026e8ac139ea431a23209cc220ec1c
KW  - editorial
KW  - human
KW  - sensor
M3  - Editorial
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Ndichu, S.
AU  - Ban, T.
AU  - Takahashi, T.
AU  - Inoue, D.
TI  - AI-Assisted Security Alert Data Analysis with Imbalanced Learning Methods
PY  - 2023
T2  - Applied Sciences (Switzerland)
VL  - 13
IS  - 3
C7  - 1977
DO  - 10.3390/app13031977
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147858238&doi=10.3390%2fapp13031977&partnerID=40&md5=882752cb12cce57b53ca16ab1c7aa1ef
AB  - Intrusion analysis is essential for cybersecurity, but oftentimes, the overwhelming number of false alerts issued by security appliances can prove to be a considerable hurdle. Machine learning algorithms can automate a task known as security alert data analysis to facilitate faster alert triage and incident response. This paper presents a bidirectional approach to address severe class imbalance in security alert data analysis. The proposed method utilizes an ensemble of three oversampling techniques to generate an augmented set of high-quality synthetic positive samples and employs a data subsampling algorithm to identify and remove noisy negative samples. Experimental results using an enterprise and a benchmark dataset confirm that this approach yields significantly improved recall and false positive rates compared with conventional oversampling techniques, suggesting its potential for more effective and efficient AI-assisted security operations. © 2023 by the authors.
KW  - alert fatigue
KW  - imbalanced learning
KW  - intrusion analysis
KW  - intrusion detection
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 10
ER  -

TY  - CONF
AU  - Pen, H.
AU  - Teo, N.
AU  - Wang, Z.
TI  - Comparative Analysis of Hate Speech Detection: Traditional vs. Deep Learning Approaches
PY  - 2024
T2  - Proceedings - 2024 IEEE Conference on Artificial Intelligence, CAI 2024
SP  - 332
EP  - 337
DO  - 10.1109/CAI59869.2024.00070
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201189868&doi=10.1109%2fCAI59869.2024.00070&partnerID=40&md5=0f29c271f83fd90a97157d0e4d6e4c85
AB  - Detecting hate speech on social media poses a significant challenge, especially in distinguishing it from offensive language, as learning-based models often struggle due to nuanced differences between them, which leads to frequent misclassifications of hate speech instances, with most research focusing on refining hate speech detection methods. Thus, this paper seeks to know if traditional learning-based methods should still be used, considering the perceived advantages of deep learning in this domain. This is done by investigating advancements in hate speech detection. It involves the utilization of deep learning-based models for detailed hate speech detection tasks and compares the results with those obtained from traditional learning-based baseline models through multidimensional aspect analysis. By considering various aspects to gain a comprehensive understanding, we can discern the strengths and weaknesses in current state-of-the-art techniques. Our research findings reveal the performance of traditional learning-based hate speech detection outperforms that of deep learning-based methods. While acknowledging the potential demonstrated by deep learning methodologies, this study emphasizes the significance of traditional machine learning approaches in effectively addressing hate speech detection tasks. It advocates for a balanced perspective, highlighting that dismissing the capabilities of traditional methods in favor of emerging deep learning-based techniques may not consistently yield the most effective results. © 2024 IEEE.
KW  - Deep learning
KW  - Hate speech detection
KW  - Multidimensional aspect analysis
KW  - Performance comparison
KW  - Traditional learning-based methods
KW  - Learning systems
KW  - Speech recognition
KW  - Deep learning
KW  - Detection tasks
KW  - Hate speech detection
KW  - Learning Based Models
KW  - Learning-based methods
KW  - Multidimensional aspect analyse
KW  - Performance comparison
KW  - Speech detection
KW  - Traditional learning
KW  - Traditional learning-based method
KW  - Deep learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Lee, C.
AU  - Mahmoud, A.
AU  - Kurek, M.
AU  - Campanoni, S.
AU  - Brooks, D.
AU  - Chong, S.
AU  - Wei, G.-Y.
AU  - Rush, A.M.
TI  - GUESS & SKETCH: LANGUAGE MODEL GUIDED TRANSPILATION
PY  - 2024
T2  - 12th International Conference on Learning Representations, ICLR 2024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200582265&partnerID=40&md5=199e06664edcfaf9a39b0d8d45a713b9
AB  - Maintaining legacy software requires many software and systems engineering hours. Assembly code programs, which demand low-level control over the computer machine state and have no variable names, are particularly difficult for humans to analyze. Existing conventional program translators guarantee correctness, but are hand-engineered for the source and target programming languages in question. Learned transpilation, i.e. automatic translation of code, offers an alternative to manual re-writing and engineering efforts. Automated symbolic program translation approaches guarantee correctness but struggle to scale to longer programs due to the exponentially large search space. Their rigid rule-based systems also limit their expressivity, so they can only reason about a reduced space of programs. Probabilistic neural language models (LMs) produce plausible outputs for every input, but do so at the cost of guaranteed correctness. In this work, we leverage the strengths of LMs and symbolic solvers in a neurosymbolic approach to learned transpilation for assembly code. Assembly code is an appropriate setting for a neurosymbolic approach, since assembly code can be divided into shorter non-branching basic blocks amenable to the use of symbolic methods. GUESS & SKETCH extracts alignment and confidence information from features of the LM then passes it to a symbolic solver to resolve semantic equivalence of the transpilation input and output. We test GUESS & SKETCH on three different test sets of assembly transpilation tasks, varying in difficulty, and show that it successfully transpiles 57.6% more examples than GPT-4 and 39.6% more examples than an engineered transpiler. We also share a training and evaluation dataset for this task. © 2024 12th International Conference on Learning Representations, ICLR 2024. All rights reserved.
KW  - Computational linguistics
KW  - Computer control systems
KW  - Legacy systems
KW  - Semantics
KW  - Translation (languages)
KW  - Assembly code
KW  - Automatic translation
KW  - Code programs
KW  - Language model
KW  - Legacy software
KW  - Machine state
KW  - Program translation
KW  - Sketch languages
KW  - Software and systems engineerings
KW  - Target programming language
KW  - Program translators
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Da, M.
AU  - Zhong, T.
AU  - Huang, J.
TI  - Knowledge Graph Construction to Facilitate Indoor Fire Emergency Evacuation
PY  - 2023
T2  - ISPRS International Journal of Geo-Information
VL  - 12
IS  - 10
C7  - 403
DO  - 10.3390/ijgi12100403
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175473489&doi=10.3390%2fijgi12100403&partnerID=40&md5=778a6c0f86531834a8cc8ff77102e2b1
AB  - Indoor fire is a sudden and frequent disaster that severely threatens the safety of indoor people worldwide. Indoor fire emergency evacuation is crucial to reducing losses involving various objects and complex relations. However, traditional studies only rely on numerical simulation, which cannot provide adequate support for decision-making in indoor fire scenarios. The knowledge graph is a knowledge base that can fully utilize massive heterogeneous data to form a sound knowledge system; however, it has not been effectively applied in the fire emergency domain. This study is a preliminary attempt to construct a knowledge graph for indoor fire emergency evacuation. We constructed the indoor fire domain ontology and proposed a four-tuple knowledge representation model. A knowledge graph was constructed with 1852 nodes and 2364 relations from 25 indoor fire events. The proposed method was tested for the case study of Henan Pingdingshan ‘5.25’ Fire Accident in China. Results show that the proposed knowledge representation model and the corresponding knowledge graph can represent complicated indoor fire events and support indoor fire emergency evacuation. © 2023 by the authors.
KW  - domain ontology
KW  - emergency evacuation
KW  - indoor fire
KW  - knowledge graph
KW  - knowledge representation model
KW  - spatio-temporal process
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - CONF
AU  - Sun, J.
AU  - Kousik, S.
AU  - Fridovich-Keil, D.
AU  - Schwager, M.
TI  - Connected Autonomous Vehicle Motion Planning with Video Predictions from Smart, Self-Supervised Infrastructure
PY  - 2023
T2  - IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC
SP  - 1721
EP  - 1726
DO  - 10.1109/ITSC57777.2023.10422061
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186515639&doi=10.1109%2fITSC57777.2023.10422061&partnerID=40&md5=e6c941cd581b073b52c3dec19a5cc102
AB  - Connected autonomous vehicles (CAVs) promise to enhance safety, efficiency, and sustainability in urban transportation. However, this is contingent upon a CAV correctly predicting the motion of surrounding agents and planning its own motion safely. Doing so is challenging in complex urban environments due to frequent occlusions and interactions among many agents. One solution is to leverage smart infrastructure to augment a CAV's situational awareness; the present work leverages a recently-proposed 'Self-Supervised Traffic Advisor' (SSTA) framework of smart sensors that teach themselves to generate and broadcast useful video predictions of road users. In this work, SSTA predictions are modified to predict future occupancy instead of raw video, which reduces the data footprint of broadcast predictions. The resulting predictions are used within a planning framework, demonstrating that this design can effectively aid CAV motion planning. A variety of numerical experiments study the key factors that make SSTA outputs useful for practical CAV planning in crowded urban environments. © 2023 IEEE.
KW  - Forecasting
KW  - Intelligent systems
KW  - Intelligent vehicle highway systems
KW  - Motion planning
KW  - Urban planning
KW  - Urban transportation
KW  - Autonomous Vehicles
KW  - Complex urban environments
KW  - Motion-planning
KW  - Numerical experiments
KW  - Planning framework
KW  - Road users
KW  - Situational awareness
KW  - Smart infrastructures
KW  - Vehicle motion
KW  - Video prediction
KW  - Autonomous vehicles
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Liu, J.
AU  - Zhang, C.
TI  - A Neural Network Model for Digitizing Enterprise Carbon Assets Based on Multimodal Knowledge Mapping
PY  - 2022
T2  - Computational Intelligence and Neuroscience
VL  - 2022
C7  - 4485168
DO  - 10.1155/2022/4485168
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133147568&doi=10.1155%2f2022%2f4485168&partnerID=40&md5=8cd5032ba03a260cc22da256dad69174
AB  - In this paper, a multimodal knowledge mapping approach is used to digitize enterprise carbon assets, and a corresponding neural network model is designed for use in the practical process. Rich textual entity labels associated with images are obtained using an entity annotation system. A topology-based data fusion method is also designed based on the hierarchical relationship between WordNet and DBpedia to fuse the knowledge obtained from image visualization and text description mining. Existing neural network-based entity linking methods ignore the semantic gap between the context of sequential entity denotative items and the context of graph-structured entities, thus affecting the accuracy of entity linking. It is observed that the importance of words in the context of entity denotative items is different, and the importance of content in the entity context is also different. To solve the above problems, this paper proposes an entity linking method that combines a common attention mechanism with a graph convolutional neural network. Secondly, based on the basic theory of value assessment, the characteristics of classical asset valuation methods and their inapplicability to the valuation of carbon assets are analyzed, and thus the real option valuation method and its two classical models are introduced; after demonstrating the real option characteristics of carbon assets of power enterprise projects, a real option model-based carbon asset valuation model for power enterprise projects is constructed and its applicability is verified with case studies. Through analyzing the current situation and problems of carbon asset valuation work in power enterprises, targeted practical suggestions are put forward to further strengthen and enhance the carbon asset valuation work in power enterprises in the future.  © 2022 Jiexian Liu and Chen Zhang.
KW  - Carbon
KW  - Data Collection
KW  - Data Mining
KW  - Neural Networks, Computer
KW  - Semantics
KW  - Convolution
KW  - Convolutional neural networks
KW  - Data visualization
KW  - Image fusion
KW  - Mapping
KW  - Neural network models
KW  - Semantics
KW  - carbon
KW  - Annotation systems
KW  - Asset valuation
KW  - Data fusion methods
KW  - Knowledge mapping
KW  - Multi-modal
KW  - Neural network model
KW  - Power enterprise
KW  - Practical process
KW  - Valuation methods
KW  - Wordnet
KW  - data mining
KW  - information processing
KW  - semantics
KW  - Carbon
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Hancock, K.
TI  - Geospatial Mapping and Remote Sensing Technologies, Spatial Cognition and Visual Perception Algorithms, and Virtual Navigation and Ambient Scene Detection Tools across the Blockchain-based Metaverse
PY  - 2022
T2  - Analysis and Metaphysics
VL  - 21
SP  - 227
EP  - 243
DO  - 10.22381/AM21202214
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146470918&doi=10.22381%2fAM21202214&partnerID=40&md5=333a6d62bc90a2a298d4e19b6b6f0a61
AB  - This article reviews and advances existing literature concerning movement and behavior tracking tools and consumer retail data assisting frictionless virtual shopping experiences. In this research, previous findings were cumulated showing that immersive virtual experiences develop on customer behavior and retail business analytics in the metaverse economy, and I contribute to the literature by indicating that virtual retail experiences necessitate cognitive decision-making and spatial mapping algorithms, data mining and computer vision tools, and metaverse technologies across interconnected digital realms. Throughout July 2022, a quantitative literature review of the Web of Science, Scopus, and ProQuest databases was performed, with search terms including “metaverse” + “geospatial mapping and remote sensing technologies,” “spatial cognition and visual perception algorithms,” and “virtual navigation and ambient scene detection tools.” As research published between 2021 and 2022 was inspected, only 157 articles satisfied the eligibility criteria. By taking out controversial or ambiguous findings (insufficient/irrelevant data), outcomes unsubstantiated by replication, too general material, or studies with nearly identical titles, I selected 33 mainly empirical sources. Data visualization tools: Dimensions (bibliometric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AXIS, MMAT, ROBIS, and SRDR. © 2022, Addleton Academic Publishers. All rights reserved.
KW  - geospatial mapping
KW  - metaverse
KW  - remote sensing
KW  - spatial cognition
KW  - virtual navigation
KW  - visual perception
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Li, H.
AU  - Zhang, R.
AU  - Zheng, S.
AU  - Shen, Y.
AU  - Fu, C.
AU  - Zhao, H.
TI  - Digital twin-driven intelligent operation and maintenance platform for large-scale hydro-steel structures
PY  - 2024
T2  - Advanced Engineering Informatics
VL  - 62
C7  - 102661
DO  - 10.1016/j.aei.2024.102661
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196805294&doi=10.1016%2fj.aei.2024.102661&partnerID=40&md5=da88125d3adc63e0178d570bd2a96bc6
AB  - Large-scale hydro-steel structures (LS-HSS) are pivotal in hydraulic engineering, boasting high lift, expansive apertures, and discharge capacities. Conventional methods of operation and maintenance for LS-HSS require a digital revolution to ensure safety, reliability, and durability. This study introduces a novel approach, harnessing the power of a digital twin (DT) to integrate physical and virtual elements in LS-HSS operation and maintenance seamlessly. A digital twin modeling framework of LS-HSS operation and maintenance is first presented, incorporating five levels of a physical entity, a virtual entity, DT data, services, and connections. Subsequently, a DT-driven intelligent operation and maintenance (DT-IOM) platform is constructed and applied, which features real-time mapping, closed-loop control, dynamic health assessment, and intelligent decision-making. This platform provides a pathway for digitally transforming conventional LS-HSS operation and maintenance and paves the way for a new era of intelligent infrastructure management. The proposed approach has been successfully implemented and validated with multiple engineering projects, including radial gates of reservoir spillways, plain gates of flood discharge orifices, and emergency gates of pumped storage power stations. The impressive results demonstrate a significant anomaly response and processing efficiency improvement of over 60%. Moreover, the platform has substantially reduced field inspection time and equipment failure rate by approximately 50% and 20%, respectively. These tangible benefits further highlight the platform's functional advantages, including its capability for IoT connection, modeling and integration, virtual-real interaction, 2D/3D visualization, and service expansion. The results demonstrate the unique features in the closed loop of perception, analysis, decision-making, and optimization for DT-IOM, especially for integrating data, models, knowledge, and services in LS-HSS intelligent operation and maintenance. © 2024 Elsevier Ltd
KW  - Digital twin
KW  - Health assessment
KW  - Hydro-steel structures
KW  - Intelligent operation and maintenance platform
KW  - Online monitoring system
KW  - Digital storage
KW  - Failure analysis
KW  - Fluid mechanics
KW  - Hydraulic machinery
KW  - Maintenance
KW  - Pumped storage power plants
KW  - Reservoirs (water)
KW  - Shore protection
KW  - Steel structures
KW  - Data services
KW  - Health assessments
KW  - Hydraulic engineering
KW  - Hydro-steel structure
KW  - Intelligent maintenance
KW  - Intelligent operation and maintenance platform
KW  - Intelligent operations
KW  - Large-scales
KW  - On-line monitoring system
KW  - Operations and maintenance
KW  - Decision making
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - JOUR
AU  - Dewulf, P.
AU  - Stock, M.
AU  - De Baets, B.
TI  - The Hyperdimensional Transform: A Holographic Representation of Functions
PY  - 2025
T2  - IEEE Journal on Selected Topics in Signal Processing
VL  - 19
IS  - 1
SP  - 3
EP  - 18
DO  - 10.1109/JSTSP.2024.3405850
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194835886&doi=10.1109%2fJSTSP.2024.3405850&partnerID=40&md5=3691b80c7a4497ed2dcb67f0fa6d3657
AB  - Integral transforms are invaluable mathematical tools to map functions into spaces where they are easier to characterize. We introduce the hyperdimensional transform as a new kind of integral transform. It converts square-integrable functions into noise-robust, holographic, high-dimensional representations called hyperdimensional vectors. The central idea is to approximate a function by a linear combination of random functions. We formally introduce a set of stochastic, orthogonal basis functions and define the hyperdimensional transform and its inverse. We discuss general transform-related properties such as its uniqueness, approximation properties of the inverse transform, and the representation of integrals and derivatives. The hyperdimensional transform offers a powerful, flexible framework that connects closely with other integral transforms, such as the Fourier, Laplace, and fuzzy transforms. Moreover, it provides theoretical foundations and new insights for the field of hyperdimensional computing, a computing paradigm that is rapidly gaining attention for efficient and explainable machine learning algorithms, with potential applications in statistical modelling and machine learning. In addition, we provide straightforward and easily understandable code, which can function as a tutorial and allows for the reproduction of the demonstrated examples, from computing the transform to solving differential equations.  © 2024 IEEE.
KW  - differential equations
KW  - efficient computing
KW  - hyperdimensional computing
KW  - Integral transforms
KW  - machine learning
KW  - Cell proliferation
KW  - Cosine transforms
KW  - Differential equations
KW  - Holography
KW  - Laplace transforms
KW  - Learning algorithms
KW  - Learning systems
KW  - Machine learning
KW  - Orthogonal functions
KW  - Random processes
KW  - Signal encoding
KW  - Vector spaces
KW  - Efficient computing
KW  - Encodings
KW  - Hyperdimensional computing
KW  - Integral transform
KW  - Kernel
KW  - Machine-learning
KW  - Mathematical tools
KW  - Representation of functions
KW  - Square integrable
KW  - Stochastic systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Bendany, M.
AU  - Brahim, K.A.B.
AU  - El Hamdouni, Y.
AU  - Labjar, N.
AU  - Nasrellah, H.
AU  - Bensemlali, M.
AU  - Mortadi, H.
AU  - El Hajjaji, S.
TI  - Applications of sensors in energy and industrial processes
PY  - 2025
T2  - Handbook of Carbon Sensors: Understanding and Applications
SP  - 204
EP  - 218
DO  - 10.1201/9781003500322-10
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007719545&doi=10.1201%2f9781003500322-10&partnerID=40&md5=933f5ca955220985f5b3d6b95f69a626
KW  - Energy process
KW  - Industrial processs
KW  - Cutting
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Nsvsc Ramesh, S.
AU  - Al Fardan, B.M.M.
AU  - Anupama, C.S.S.
AU  - Vijaya Kumar, K.
AU  - Cho, S.
AU  - Acharya, S.
AU  - Yoon, C.
TI  - Leveraging Cyberattack News Tweets for Advanced Threat Detection and Classification Using Ensemble of Deep Learning Models With Wolverine Optimization Algorithm
PY  - 2025
T2  - IEEE Access
VL  - 13
SP  - 48343
EP  - 48358
DO  - 10.1109/ACCESS.2025.3550378
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001079377&doi=10.1109%2fACCESS.2025.3550378&partnerID=40&md5=428b14217c29491f865358b6cb5ab127
AB  - At present, cyber-attacks have become more critical and familiar, which appeals to a novel line of security defences to defend against them. Cyber Threat Intelligence (CTI) originated as a reputation in the frequently developing cybersecurity landscape, vital in safeguarding digital models. Understanding this domain develops over a complete study of intelligence's numerous features and sources. Data sharing and analysis centres perform as alarms of collaboration, demonstrating the collective vigilance needed to oppose such developing attacks. Inspecting and gathering data about cyberattacks from tweets can effectively deliver critical perceptions of the threats, their effects, occurrence areas, and probable mitigation tactics. Existing study on cyberattack absences in establishing Artificial Intelligence (AI) based analytic solutions for delivering country-wide cyber-attack intelligence. Cyber planners at a domestic level need AI-based decision support models to determine a country's cyber attitude or vigilance. This study designs and develops an Enhanced Threat Intelligence for Cybersecurity Using an Ensemble of Deep Leaning Models with Metaheuristic Optimization Algorithm (ETIC-EDLMOA) model. The presented ETIC-EDLMOA model's main aim is to detect and mitigate network attacks in cybersecurity effectively. Initially, the ETIC-EDLMOA model undergoes a data pre-processing stage to ensure clean and structured input data for analysis. Besides, the Word2vec model is utilized for feature extraction. For the classification process, the ensemble of DL models is employed, including the recurrent neural network (RNN) method, long short-term memory (LSTM) model, and conditional variational autoencoders (CVAE) technique. Finally, the ensemble models' hyperparameter fine-tuning process is performed using the Wolverine optimization algorithm (WoOA) technique. A comprehensive range of simulation analyses is conducted to ensure the improved performance of the ETIC-EDLMOA method on the CybAttT dataset. The comparison study of the ETIC-EDLMOA method illustrated a superior accuracy value of 98.51% over existing techniques.  © 2013 IEEE.
KW  - Cyber threat intelligence
KW  - cybersecurity
KW  - deep leaning
KW  - wolverine optimization algorithm
KW  - Word2vec
KW  - Adversarial machine learning
KW  - Computer viruses
KW  - Crime
KW  - Long short-term memory
KW  - Network security
KW  - Phishing
KW  - Algorithm model
KW  - Cybe threat intelligence
KW  - Cyber security
KW  - Cyber threats
KW  - Cyber-attacks
KW  - Deep leaning
KW  - Metaheuristic optimization
KW  - Optimization algorithms
KW  - Wolverine optimization algorithm
KW  - Word2vec
KW  - Cyber attacks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Abubakar, H.
TI  - Random Satisfiability Logic-Driven Approach in the Hopfield Neural Networks with Application to COVID-19 Datasets
PY  - 2025
T2  - International Journal of Applied and Computational Mathematics
VL  - 11
IS  - 3
C7  - 117
DO  - 10.1007/s40819-025-01941-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007241283&doi=10.1007%2fs40819-025-01941-7&partnerID=40&md5=043a348eb0cee9c8dc00d2079dbc0235
AB  - This study proposes a logic-driven satisfiability approach integrated with Hopfield Neural Networks (HNNs) for classifying the COVID-19 Surveillance Data Set (CSDS). The HNN-RANkSAT model combines Boolean logic-based satisfiability with the Lyapunov energy function of HNNs to extract logical relationships and identify critical features for COVID-19 dataset classification. Evaluated against Logistic Regression (LR), Random Forest (RF), and Support Vector Machine (SVM), the model’s performance was assessed using Accuracy, Hamming Loss, Cross-Entropy Loss, CPU Time, and Bayesian Information Criterion (BIC). HNN-RANkSAT achieves the highest accuracy of 95.0% at sample size = 500, outperforming RF with 95.0%, SVM with 94.0%, and LR with 93.0% accuracy. It also exhibits the lowest Hamming Loss of 0.04 and Cross-Entropy Loss of 0.16, demonstrating superior classification performance and probabilistic calibration. The model’s logical constraints refine the search space, reducing misclassification errors and improving confidence estimation. However, this comes at the cost of higher computational complexity, with CPU Time increasing to 60 s at 1000 sample size, compared to LR with 20 s, RF with 40 s, and SVM with 50 s. The BIC values for HNN-RANkSAT at 170 sample size is 1000 reflect its greater model complexity, justified by its robustness in structured problem domains. Statistical tests, including McNemar’s test and Wilcoxon Rank test, confirm the model’s significant improvements (p-values < 0.05), with a large Cohen’s d effect size of 1.21. The hybrid architecture, integrating logic-based reasoning with neural network learning, enables HNN-RANkSAT to handle noisy, incomplete, and high-dimensional data effectively, making it ideal for medical classification tasks. While Random Forest offers a balanced alternative for large-scale problems, HNN-RANkSAT excels in high-precision tasks like pandemic surveillance. © The Author(s), under exclusive licence to Springer Nature India Private Limited 2025.
KW  - Boolean Logic Integration
KW  - COVID-19 Surveillance Data Set
KW  - Hopfield Neural Network
KW  - Logic Mining
KW  - Satisfiability
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Zavatteri, M.
AU  - Bresolin, D.
AU  - Navarin, N.
TI  - Automated Synthesis of Certified Neural Networks: Initial Results and Open Research Lines
PY  - 2025
T2  - CEUR Workshop Proceedings
VL  - 3904
SP  - 77
EP  - 82
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216639465&partnerID=40&md5=2bc2ab76a311fd13db8c7b5abcd1ce39
AB  - Certifying machine learning systems has become more and more important, especially when they are deployed in safety critical domains. In this paper, we sum up the work in [1] that combines Deep Learning with Formal Methods for the automated synthesis of certified neural networks and we discuss current open research lines. © 2024 Copyright for this paper by its authors.
KW  - CEGIS
KW  - Certified AI
KW  - hard constraints
KW  - MILP
KW  - neural network
KW  - quadratic programming
KW  - synthesis
KW  - Adversarial machine learning
KW  - Deep neural networks
KW  - Federated learning
KW  - 'current
KW  - Automated synthesis
KW  - CEGIS
KW  - Certified AI
KW  - Hard constraints
KW  - Machine learning systems
KW  - MILP
KW  - Neural-networks
KW  - Safety-critical domain
KW  - Quadratic programming
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - de Mello, R.R.P.
AU  - de Santiago, R.
AU  - Silveira, R.A.
AU  - Gelaim, T.Â.
TI  - Neural-symbolic BDI-Agent as a Multi-Context System: A case study with negotiating agent[Formula presented]
PY  - 2024
T2  - Expert Systems with Applications
VL  - 238
C7  - 121656
DO  - 10.1016/j.eswa.2023.121656
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173159427&doi=10.1016%2fj.eswa.2023.121656&partnerID=40&md5=596ffb744a5fd224f498a622025b9e54
AB  - Intelligent systems are already being deployed in several fields (e.g., medicine, education, automation, or legal), providing relevant tools to assist in our daily tasks. It is claimed that the next step of AI is the integration of connectionist and symbolic methods. Connectionist methods embody knowledge by assigning numerical conductivities or weights to the connections inside a network of nodes. Symbolic methods work by carrying on a sequence of logic-like reasoning steps over a set of symbols consisting of language-like representations. Combining the strengths of connectionist and symbolic methods can allow the development of robust intelligent systems. We propose a neural-symbolic BDI-agent based Multi-Context Systems (MCS) model to integrate these two methods. Neural-symbolic area explores the effective integration of connectionist and symbolic methods, more precisely, learning and reasoning. MCSs allow the representation of information exchange among heterogeneous sources. BDI-agents offer robust and flexible behavior, rapid and modular development, intelligibility, and verifiability. In our work, MCSs represent the symbolic method and Neural Networks the connectionist method. We present a case study of how the proposed agent can be implemented using the Sigon framework. Sigon facilitates the development of MCS agents using a programming language-like paradigm. In this case study, we employed a trained MultiLayer Perceptron (MLP) neural network, enabling us to mitigate the necessity of modeling some hand-crafted rules in symbolic systems. We performed two experiments, in which the main goal was to analyze the impact of using a neural network during the agent's decision-making. In the first experiment, we compare the proposed agent with 136 negotiating agents participating in the Automated Negotiating Agents Competition (ANAC) available on the GENIUS framework. In the second experiment, we compare our work with one similar to ours. The results show that our agent can adapt and achieve high utility functions for different situations. However, it is necessary to consider the computational cost of using the NN's output in every reasoning cycle. The contributions of this paper are: (i) - integration of connectionist methods as part of the agent's decision-making, enabling the development of agents in a modular and flexible fashion; (ii) - custom sensors to handle different data types; (iii) - practical implementation of the proposed integration method; and (iv) - experiments of the proposed integration method, focusing on mitigating the necessity of hard-coded and hand-crafted rules. © 2023 Elsevier Ltd
KW  - Agent
KW  - BDI
KW  - Connectionist
KW  - Multi-context system
KW  - Neural network
KW  - Neural-symbolic
KW  - Symbolic
KW  - Computation theory
KW  - Decision making
KW  - Integration
KW  - Multilayer neural networks
KW  - Numerical methods
KW  - BDI
KW  - BDI Agent
KW  - Case-studies
KW  - Connectionist
KW  - Multi-context systems
KW  - Negotiating agents
KW  - Neural-networks
KW  - Neural-symbolic
KW  - Symbolic
KW  - Symbolic methods
KW  - Intelligent systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Shieh, S.W.
AU  - Voas, J.
AU  - Laplante, P.
AU  - Rupe, J.
AU  - Hansen, C.
AU  - Wu, Y.-S.
AU  - Chen, Y.-T.
AU  - Li, C.-Y.
AU  - Wu, K.-C.
TI  - Reliability Engineering in a Time of Rapidly Converging Technologies
PY  - 2024
T2  - IEEE Transactions on Reliability
VL  - 73
IS  - 1
SP  - 73
EP  - 82
DO  - 10.1109/TR.2024.3355905
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187241791&doi=10.1109%2fTR.2024.3355905&partnerID=40&md5=e05b9175c6086efc0aff550f9f11f324
AB  - The convergence of technologies is happening across various aspects, such as communication, computing, medicine, and transportation. The smartphone is a perfect example of convergence, packing features, such as a camera, GPS, artificial intelligence, and Internet connectivity into one sleek device. Autonomous driving is another good example. In a time of rapidly converging technologies, reliability engineering must take into account the potential for cyber threats, the need for cyber trust, the importance of cyber security, and the criticality of cyber resilience. In this way, reliability engineers can ensure the confidentiality, integrity, and availability of computer systems and networks in the face of evolving threats and changing technologies. In this article, we introduce the challenges and current progress of reliability engineering in emerging technologies, including practices and applications of cyber trust and security, AI-empowered autonomous driving systems, modern mobile networks, blockchains and distributed ledger technologies, prognostic and health management, integrated circuit and hardware, and enterprise cybersecurity and threat hunting.  © 1963-2012 IEEE.
KW  - Artificial intelligence (AI)
KW  - autonomous driving
KW  - blockchain
KW  - cyber resilience
KW  - cyber security
KW  - cyber threats
KW  - deep learning
KW  - distributed ledger technology (DLT)
KW  - enterprise cybersecurity
KW  - prognostics and health management (PHM)
KW  - threat hunting
KW  - trusted computing
KW  - 5G mobile communication systems
KW  - Blockchain
KW  - Computer crime
KW  - Deep learning
KW  - Distributed ledger
KW  - Engineering education
KW  - Mobile security
KW  - Network security
KW  - Reliability
KW  - 5g mobile communication
KW  - Artificial intelligence
KW  - Autonomous driving
KW  - Block-chain
KW  - Cybe resilience
KW  - Cyber security
KW  - Cyber threats
KW  - Deep learning
KW  - Distributed ledg technology
KW  - Enterprise cybersecurity
KW  - Mobile communications
KW  - Prognostic and health management
KW  - Reliability (engineering)
KW  - Security
KW  - Threat hunting
KW  - Cybersecurity
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Pacheco, A.
AU  - Rivera, M.
AU  - Torres, R.
TI  - Acoustic Spectral Analysis for Emergency Vehicle Detection: Symbolic and CNN Approaches
PY  - 2024
T2  - Advances in Artificial Intelligence and Machine Learning
VL  - 4
IS  - 2
C7  - 125
SP  - 2189
EP  - 2200
DO  - 10.54364/AAIML.2024.42125
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198351175&doi=10.54364%2fAAIML.2024.42125&partnerID=40&md5=053aad67490df7ff7f2a2ab6eaa9d272
AB  - During emergencies, ambulances on city streets face delays due to traffic obstacles. This pa-per addresses two efficient emergency vehicle detection (EVD) methods for restricted hardware implementation considering noisy conditions: a symbolic processing-based algorithm and a convolutional neural network (CNN) model, both of which utilize Mel spectrogram representations of Hi-Lo siren audio records. The symbolic method employs regular expressions and acceptance criteria to process text-pattern features extracted from spectrograms, offering a self-explanatory, easily tunable, and resource-efficient solution suitable for low-cost hardware platforms. On the other hand, the CNN model directly processes spectrogram representations, leveraging spatial correlation for classification with a streamlined architecture consisting of very few layers. The experimental results demonstrate that both approaches achieve high accuracy (97-98%) in classifying Hi-Lo sirens, with the CNN model exhibiting slightly better performance. Challenges such as signal noise and harmonics are addressed through iterative algorithms and signal reconstruction considerations. Future directions in-clude identifying additional siren effects and conducting performance measurements on constrained hardware devices. Overall, this study presents viable EVD solutions suitable for real-time implementation and underscores the importance of adaptable and explainable AI methods in enhancing road safety. © 2024 A. Pacheco, et al.
KW  - Convolutional neural network
KW  - Emergency vehicle detection (EVD)
KW  - Signal symbolization
KW  - Sound classification
KW  - Spectral signal processing
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Kroshchanka, A.
AU  - Golovko, V.
AU  - Mikhno, E.
AU  - Kovalev, M.
AU  - Zahariev, V.
AU  - Zagorskij, A.
TI  - A Neural-Symbolic Approach to Computer Vision
PY  - 2022
T2  - Communications in Computer and Information Science
VL  - 1625 CCIS
SP  - 282
EP  - 309
DO  - 10.1007/978-3-031-15882-7_15
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140471454&doi=10.1007%2f978-3-031-15882-7_15&partnerID=40&md5=11067ab116c52398222e78a2dcdf89dc
AB  - The paper presents a general computer vision model based on neural-symbolic artificial intelligence capable of performing semantic analysis of a video stream. The proposed approach integrates artificial neural networks (ANN) with the knowledge base on the basis of an ontological approach. In this case, the knowledge base interacts with the neural networks as with agents and the results of their functioning are used for further semantic analysis. The problems of object detection and recognition of images, as well as emotions, are considered as tasks of computer vision. The features, advantages and prospects of using this model are described. Its implementation is considered on the example of an intelligent module that includes the FaceNet and eXnet neural network models for face identification and emotion recognition in the conversational modeling system. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Artificial neural network
KW  - Computer vision
KW  - Knowledge base
KW  - Logical inference
KW  - Neurosymbolic AI
KW  - Computer vision
KW  - Emotion Recognition
KW  - Knowledge based systems
KW  - Object detection
KW  - Semantics
KW  - Intelligent modules
KW  - Knowledge base
KW  - Logical inference
KW  - Neural network model
KW  - Neural-networks
KW  - Neurosymbolic AI
KW  - Object detection and recognition
KW  - Ontological approach
KW  - Semantic analysis
KW  - Vision model-based
KW  - Neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Yan, R.
AU  - Wen, Y.
AU  - Bhattacharjya, D.
AU  - Luss, R.
AU  - Ma, T.
AU  - Fokoue, A.
AU  - Julius, A.
TI  - WEIGHTED CLOCK LOGIC POINT PROCESS
PY  - 2023
T2  - 11th International Conference on Learning Representations, ICLR 2023
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168823614&partnerID=40&md5=2fe5bb38627902f8663d1ab76ff23c4c
AB  - Datasets involving multivariate event streams are prevalent in numerous applications. We present a novel framework for modeling temporal point processes called clock logic neural networks (CLNN) which learn weighted clock logic (wCL) formulas as interpretable temporal rules by which some events promote or inhibit other events. Specifically, CLNN models temporal relations between events using conditional intensity rates informed by a set of wCL formulas, which are more expressive than related prior work. Unlike conventional approaches of searching for generative rules through expensive combinatorial optimization, we design smooth activation functions for components of wCL formulas that enable a continuous relaxation of the discrete search space and efficient learning of wCL formulas using gradient-based methods. Experiments on synthetic datasets manifest our model's ability to recover the ground-truth rules and improve computational efficiency. In addition, experiments on real-world datasets show that our models perform competitively when compared with state-of-the-art models. © 2023 11th International Conference on Learning Representations, ICLR 2023. All rights reserved.
KW  - Combinatorial optimization
KW  - Computation theory
KW  - Computational efficiency
KW  - Computer circuits
KW  - Activation functions
KW  - Conventional approach
KW  - Event streams
KW  - Learn+
KW  - Logic formulas
KW  - Neural network model
KW  - Neural-networks
KW  - Point process
KW  - Temporal relation
KW  - Temporal rules
KW  - Clocks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Lamanna, L.
AU  - Serafini, L.
TI  - Action Model Learning from Noisy Traces: a Probabilistic Approach
PY  - 2024
T2  - Proceedings International Conference on Automated Planning and Scheduling, ICAPS
VL  - 34
SP  - 342
EP  - 350
DO  - 10.1609/icaps.v34i1.31493
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195962173&doi=10.1609%2ficaps.v34i1.31493&partnerID=40&md5=794902d07a40591dc2ebffe7b3863045
AB  - We address the problem of learning planning domains from plan traces that are obtained by observing the environment states through noisy sensors. In such situations, approaches that assume correct traces are not applicable. We tackle the problem by designing a probabilistic graphical model where preconditions and effects of every planning domain operators, and traces' observations are modeled by random variables. Probabilistic inference conditioned by the observed traces allows our approach to derive a posterior probability of an atom being a precondition and/or an effect of an operator. Planning domains are obtained either by sampling or by applying the maximum a posteriori criterion. We compare our approach with a frequentist baseline and the currently available state-of-the-art approaches. We measure the performance of each method according to two criteria: reconstruction of the original planning domain and effectiveness in solving new planning problems of the same domain. Our experimental analysis shows that our approach learns action models that are more accurate w.r.t. state-of-the-art approaches, and strongly outperforms other approaches in generating models that are effective for solving new problems. Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.
KW  - Action modeling
KW  - Environment state
KW  - Model learning
KW  - Noisy sensors
KW  - Planning domains
KW  - Probabilistic graphical models
KW  - Probabilistic inference
KW  - Probabilistics approach
KW  - State-of-the-art approach
KW  - Trace observations
KW  - Artificial intelligence
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Lu, Z.
AU  - Li, R.
AU  - Lu, K.
AU  - Chen, X.
AU  - Hossain, E.
AU  - Zhao, Z.
AU  - Zhang, H.
TI  - Semantics-Empowered Communications: A Tutorial-Cum-Survey
PY  - 2024
T2  - IEEE Communications Surveys and Tutorials
VL  - 26
IS  - 1
SP  - 41
EP  - 79
DO  - 10.1109/COMST.2023.3333342
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178040952&doi=10.1109%2fCOMST.2023.3333342&partnerID=40&md5=0ed4535428e426729fb9315252b492d7
AB  - Along with the springing up of the semantics-empowered communication (SemCom) research, it is now witnessing an unprecedentedly growing interest towards a wide range of aspects (e.g., theories, applications, metrics and implementations) in both academia and industry. In this work, we primarily aim to provide a comprehensive survey on both the background and research taxonomy, as well as a detailed technical tutorial. Specifically, we start by reviewing the literature and answering the 'what' and 'why' questions in semantic transmissions. Afterwards, we present the ecosystems of SemCom, including history, theories, metrics, datasets and toolkits, on top of which the taxonomy for research directions is presented. Furthermore, we propose to categorize the critical enabling techniques by explicit and implicit reasoning-based methods, and elaborate on how they evolve and contribute to modern content & channel semantics-empowered communications. Besides reviewing and summarizing the latest efforts in SemCom, we discuss the relations with other communication levels (e.g., conventional communications) from a holistic and unified viewpoint. Subsequently, in order to facilitate future developments and industrial applications, we also highlight advanced practical techniques for boosting semantic accuracy, robustness, and large-scale scalability, just to mention a few. Finally, we discuss the technical challenges that shed light on future research opportunities.  © 1998-2012 IEEE.
KW  - challenges and opportunities
KW  - enabling techniques
KW  - Semantic communications
KW  - semantic information theory
KW  - semantic similarity metrics
KW  - semantic transmission and reasoning
KW  - tutorial-cum survey
KW  - Information theory
KW  - Integrated circuits
KW  - Taxonomies
KW  - Timing circuits
KW  - Challenge and opportunity
KW  - Enabling techniques
KW  - Semantic communication
KW  - Semantic information theories
KW  - Semantic similarity
KW  - Semantic similarity metric
KW  - Semantic transmission and reasoning
KW  - Similarity metrics
KW  - Tutorial
KW  - Tutorial-cum survey
KW  - Semantics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 38
ER  -

TY  - JOUR
AU  - Graziani, M.
AU  - Dutkiewicz, L.
AU  - Calvaresi, D.
AU  - Amorim, J.P.
AU  - Yordanova, K.
AU  - Vered, M.
AU  - Nair, R.
AU  - Abreu, P.H.
AU  - Blanke, T.
AU  - Pulignano, V.
AU  - Prior, J.O.
AU  - Lauwaert, L.
AU  - Reijers, W.
AU  - Depeursinge, A.
AU  - Andrearczyk, V.
AU  - Müller, H.
TI  - A global taxonomy of interpretable AI: unifying the terminology for the technical and social sciences
PY  - 2023
T2  - Artificial Intelligence Review
VL  - 56
IS  - 4
SP  - 3473
EP  - 3504
DO  - 10.1007/s10462-022-10256-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137813675&doi=10.1007%2fs10462-022-10256-8&partnerID=40&md5=d173fbe53094e0bf06b5f6464a79b64e
AB  - Since its emergence in the 1960s, Artificial Intelligence (AI) has grown to conquer many technology products and their fields of application. Machine learning, as a major part of the current AI solutions, can learn from the data and through experience to reach high performance on various tasks. This growing success of AI algorithms has led to a need for interpretability to understand opaque models such as deep neural networks. Various requirements have been raised from different domains, together with numerous tools to debug, justify outcomes, and establish the safety, fairness and reliability of the models. This variety of tasks has led to inconsistencies in the terminology with, for instance, terms such as interpretable, explainable and transparent being often used interchangeably in methodology papers. These words, however, convey different meanings and are “weighted" differently across domains, for example in the technical and social sciences. In this paper, we propose an overarching terminology of interpretability of AI systems that can be referred to by the technical developers as much as by the social sciences community to pursue clarity and efficiency in the definition of regulations for ethical and reliable AI development. We show how our taxonomy and definition of interpretable AI differ from the ones in previous research and how they apply with high versatility to several domains and use cases, proposing a—highly needed—standard for the communication among interdisciplinary areas of AI. © 2022, The Author(s).
KW  - Explainable artificial intelligence
KW  - Interpretability
KW  - Machine learning
KW  - Behavioral research
KW  - Deep neural networks
KW  - Program debugging
KW  - Taxonomies
KW  - 'current
KW  - Artificial intelligence algorithms
KW  - Different domains
KW  - Explainable artificial intelligence
KW  - Global taxonomy
KW  - Interpretability
KW  - Learn+
KW  - Machine-learning
KW  - Performance
KW  - Technology products
KW  - Terminology
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 60
ER  -

TY  - CONF
AU  - Cobb, A.D.
AU  - Matejek, B.
AU  - Elenius, D.
AU  - Roy, A.
AU  - Jha, S.
TI  - Direct Amortized Likelihood Ratio Estimation
PY  - 2024
T2  - Proceedings of the AAAI Conference on Artificial Intelligence
VL  - 38
IS  - 18
SP  - 20362
EP  - 20369
DO  - 10.1609/aaai.v38i18.30018
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189542447&doi=10.1609%2faaai.v38i18.30018&partnerID=40&md5=8c38580e5b8debbbc7d763f9a77b572f
AB  - We introduce a new amortized likelihood ratio estimator for likelihood-free simulation-based inference (SBI). Our estimator is simple to train and estimates the likelihood ratio using a single forward pass of the neural estimator. Our approach directly computes the likelihood ratio between two competing parameter sets, which differs from the previous approach of comparing two neural network output values. We refer to our model as the direct neural ratio estimator (DNRE). As part of introducing the DNRE, we derive a corresponding Monte Carlo estimate of the posterior. We benchmark our new ratio estimator and compare it to ratio estimators in the current literature. We show that our new ratio estimator often outperforms these previous approaches. As a further contribution, we introduce a new derivative estimator for likelihood ratio estimators that enables us to compare likelihood-free Hamiltonian Monte Carlo (HMC) with random-walk Metropolis-Hastings (MH). We show that HMC is equally competitive, which has not been previously shown. Finally, we include a novel real-world application of SBI using our neural ratio estimator to design a quadcopter. Code is available at https://github.com/SRI-CSL/dnre. Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.
KW  - Artificial intelligence
KW  - 'current
KW  - Likelihood ratios
KW  - Monte Carlo estimates
KW  - Neural-networks
KW  - Output values
KW  - Parameter set
KW  - Random Walk
KW  - Ratio estimations
KW  - Ratio estimators
KW  - Simple++
KW  - Monte Carlo methods
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Bojiah, J.
AU  - Alfiras, M.
AU  - Ibrahim, F.M.
AU  - Mohammed, M.N.
AU  - Al-Zubaidi, S.
AU  - Surendran, K.R.
TI  - Digital Transformation Towards Sustainability in Education: Overview on Metaverse System Adoption in E-learning
PY  - 2024
T2  - 2024 Arab ICT Conference, AICTC 2024
SP  - 37
EP  - 43
DO  - 10.1109/AICTC58357.2024.10735043
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210599129&doi=10.1109%2fAICTC58357.2024.10735043&partnerID=40&md5=0b6f56e5b3d496c86ff810ef9da17c9b
AB  - The Metaverse is the innovative technological combination of artificial intelligence, augmented reality, mixed reality, and virtual reality- an advanced technological marvel that provides a virtual world which is almost an extension of the real world where the users do not find the difference between the two. The users maintain two identities and engage in interaction and collaboration to perform their tasks. Many studies have been carried out on the Metaverse but the studies on the Metaverse and its probable applications with respect to the field of education are limited. Hence, this study intends to bring into limelight the definition, origin, elements of the Metaverse, and elaborately lists the niceties it can offer in making the teaching experience effective and learning experience fruitful. In addition, it identifies the limitations of the Metaverse and provides recommendations to address the limitations. The scope of this study is to spell out the virtual learning experience establishing the Metaverse in place which will result in vivid teaching and learning experiences.  © 2024 IEEE.
KW  - Digital Transformation
KW  - E-Learning
KW  - Education Ecosystem
KW  - Metaverse
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Transfer learning
KW  - Virtual environments
KW  - Digital transformation
KW  - E - learning
KW  - Education ecosystem
KW  - Learning experiences
KW  - Metaverses
KW  - Mixed reality
KW  - System adoption
KW  - Teaching experience
KW  - Technological combination
KW  - Virtual worlds
KW  - Federated learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Gelal Soyak, E.
AU  - Ercetin, O.
TI  - Effective networking: Enabling effective communications towards 6G
PY  - 2024
T2  - Computer Communications
VL  - 215
SP  - 1
EP  - 8
DO  - 10.1016/j.comcom.2023.12.002
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180556765&doi=10.1016%2fj.comcom.2023.12.002&partnerID=40&md5=4ae46189efa105eca1b53797eaa704f1
AB  - The realization of envisioned 6G use cases involving holographic and multi-sensory communications demand terabits per second data rates and latencies in the range of microseconds for an immersive experience. Concurrently, 6G's hyper-intelligent IoT use cases require extremely low-latency and reliable communications at the network edge. To address these requirements, communications should be tailored to end-user goals. To this end, we study communication effectiveness, where a sender and receiver harness their computing capabilities and artificial intelligence, to maximize the impact of transmitted messages while sending fewer bits. On our model, the messages can get shorter as locally accumulated knowledge increases the targeted effect of the message. Hence, we describe a framework in which the accumulated knowledge can be aggregated and shared in a distributed manner. On a real-life use case, we showcase the potential reduction in the number of bits transmitted owing to the transferred accumulated knowledge. Finally, we explore future research directions in effective communications, considering technical, economical, and privacy considerations. © 2023 Elsevier B.V.
KW  - 6G
KW  - Edge intelligence
KW  - Effective communications
KW  - Future network architectures
KW  - Knowledge accumulation
KW  - Semantic communications
KW  - Task-oriented communications
KW  - Semantic Web
KW  - Semantics
KW  - 6g
KW  - Edge intelligence
KW  - Effective communication
KW  - Future network architecture
KW  - Future networks
KW  - Knowledge accumulation
KW  - Multi-Sensory
KW  - Semantic communication
KW  - Task-oriented
KW  - Task-oriented communication
KW  - Network architecture
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Guo, W.
TI  - Explainable Artificial Intelligence for 6G: Improving Trust between Human and Machine
PY  - 2020
T2  - IEEE Communications Magazine
VL  - 58
IS  - 6
C7  - 9141213
SP  - 39
EP  - 45
DO  - 10.1109/MCOM.001.2000050
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088863961&doi=10.1109%2fMCOM.001.2000050&partnerID=40&md5=e6d84499e80caa7b7af1adfb90930c21
AB  - As 5G mobile networks are bringing about global societal benefits, the design phase for 6G has started. Evolved 5G and 6G will need sophisticated AI to automate information delivery simultaneously for mass autonomy, human machine interfacing, and targeted healthcare. Trust will become increasingly critical for 6G as it manages a wide range of mission-critical services. As we migrate from traditional mathematical model-dependent optimization to data-dependent deep learning, the insight and trust we have in our optimization modules decrease. This loss of model explainability means we are vulnerable to malicious data, poor neural network design, and the loss of trust from stakeholders and the general public - all with a range of legal implications. In this review, we outline the core methods of explainable artificial intelligence (XAI) in a wireless network setting, including public and legal motivations, definitions of explainability, performance vs. explainability trade-offs, and XAI algorithms. Our review is grounded in case studies for both wireless PHY and MAC layer optimization and provide the community with an important research area to embark upon.  © 1979-2012 IEEE.
KW  - Deep learning
KW  - Economic and social effects
KW  - Wireless networks
KW  - Data dependent
KW  - General publics
KW  - Information delivery
KW  - Legal implications
KW  - Mission critical
KW  - Neural network designs
KW  - Optimization module
KW  - Societal benefits
KW  - 5G mobile communication systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 170
ER  -

TY  - JOUR
AU  - Desmet, C.
AU  - Greeley, C.
AU  - Cook, D.J.
TI  - Hydra-TS: Enhancing Human Activity Recognition With Multiobjective Synthetic Time-Series Data Generation
PY  - 2025
T2  - IEEE Sensors Journal
VL  - 25
IS  - 1
SP  - 763
EP  - 772
DO  - 10.1109/JSEN.2024.3483108
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210290719&doi=10.1109%2fJSEN.2024.3483108&partnerID=40&md5=8d20f601da8032b65338c51b8ee502fc
AB  - The advent of wearable technologies ushered in an era of abundant time-series data, offering profound insights into human health and behavior. However, the full utilization of such data was hindered by challenges such as the scarcity of labeled datasets and the need for privacy in sensitive domains like personal health tracking. To address these challenges, this article introduces Hydra-TS, a multiagent generative adversarial network (GAN). Hydra-TS uniquely excels in optimizing multiple objectives concurrently. Hydra-TS offers a spectral representation for time-series data. Here, a single generator is pitted against a variable number of discriminators to create multivariate synthetic data that are realistic, useful for classification, and privacy-preserving. Using a one-month dataset of real-world, in-the-wild smartwatch data containing 5271143 labeled activity instances for ten participants, we demonstrated that Hydra-TS yielded a superior area under the radar chart value (AuRC =0.72) in comparison with the original data and three baselines methods. We also verified that activity recognition performance was improved using Hydra-TS as a vehicle for data augmentation, improving the F1 score by as much as 130.54%. Hydra-TS's effectiveness underlines its potential to facilitate research and applications in areas where data scarcity and privacy issues are prevalent. © 2024 IEEE.
KW  - Generative adversarial network (GAN)
KW  - human activity recognition (HAR)
KW  - mobile computing
KW  - synthetic data generation
KW  - time-series analysis
KW  - Adversarial machine learning
KW  - Adversarial networks
KW  - Data generation
KW  - Human activity recognition
KW  - Human health
KW  - Mobile-computing
KW  - Multi objective
KW  - Synthetic data generations
KW  - Synthetic-time
KW  - Time-series analysis
KW  - Time-series data
KW  - Generative adversarial networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Glukhikh, D.
AU  - Shchinnikov, I.
AU  - Glukhikh, I.
TI  - Using hybrid-CBR for intelligence monitoring and decision-making systems on SMART grid
PY  - 2022
T2  - Intelligent Decision Technologies
VL  - 16
IS  - 2
SP  - 449
EP  - 456
DO  - 10.3233/IDT-210239
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133304675&doi=10.3233%2fIDT-210239&partnerID=40&md5=92f33d8c6307a1b91eca4445a2f3608a
AB  - Smart grid systems are being actively developed and implemented all over the world. However, along with developed systems for monitoring and data analysis, decision support functions are not fully implemented. Wherein decision support is necessary due to the complexity of possible emergencies. In this work, we offer the concept of an intelligent decision support system (IDSS) for the SMART grid, which is based on the hybrid Case-Based Reasoning (CBR) method. This method combines models of knowledge-based systems and models of neural networks and machine learning, which simplifies realization on complex changing objects of the SMART grid. In the first part of the research, we describe the concept of the proposed hybrid-CBR method, the principle of formalizing the situation at the objects of the SMART grid systems and present the involved neural network architecture Comparator-Adder. The second parts of the research reveal the concept of applied IDSS and also show the results of an experiment of retrieving precedent from a knowledge base with using a neural network. Experimental results show that our architecture successfully copes with the task of selecting the most similar situation. We believe that the MAPE error in this incident does not play a key role; the efficiency of the neural network is confirmed primarily by the coherence with the results of the expert choice and the absence of collisions.  © 2022 - IOS Press. All rights reserved.
KW  - adder
KW  - Case-based reasoning
KW  - comparator
KW  - control of complex systems
KW  - decision making
KW  - decision support system
KW  - neural network
KW  - neural network architecture
KW  - perceptron
KW  - SMART grid
KW  - Case based reasoning
KW  - Comparator circuits
KW  - Complex networks
KW  - Decision making
KW  - Decision support systems
KW  - Deep learning
KW  - Electric power transmission networks
KW  - Knowledge based systems
KW  - Network architecture
KW  - Neural networks
KW  - Smart power grids
KW  - Casebased reasonings (CBR)
KW  - Control of complex systems
KW  - Decision supports
KW  - Decision-making systems
KW  - Decisions makings
KW  - Intelligent decision-support systems
KW  - Neural network architecture
KW  - Neural-networks
KW  - Reasoning methods
KW  - SMART grid
KW  - Comparators (optical)
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - CONF
AU  - Barbastefano, R.G.
AU  - de Araujo Carvalho, D.M.
AU  - Lippi, M.C.
TI  - Process Mining Classification with a Weightless Neural Network
PY  - 2020
T2  - Springer Proceedings in Mathematics and Statistics
VL  - 337
SP  - 349
EP  - 356
DO  - 10.1007/978-3-030-56920-4_28
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097186563&doi=10.1007%2f978-3-030-56920-4_28&partnerID=40&md5=c8d9e9b9445a0d95048b81b7d57318e8
AB  - Using a weightless neural network architecture WiSARD we propose a straightforward graph to retina codification to represent business process graph flows avoiding kernels, and we present how WiSARD outperforms the classification performance with small training sets in the process mining context. © 2020, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Business process management
KW  - Process mining
KW  - Weightless neural network
KW  - Classification (of information)
KW  - Data mining
KW  - Flow graphs
KW  - Network architecture
KW  - Business Process
KW  - Classification performance
KW  - Process mining
KW  - Small training
KW  - Weightless neural networks
KW  - Neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Kour, R.
AU  - Karim, R.
AU  - Patwardhan, A.
AU  - Kumar, M.
AU  - Eriksson, H.
AU  - Kumar, U.
TI  - Metaverse for Intelligent Asset Management
PY  - 2022
T2  - 2022 International Conference on Maintenance and Intelligent Asset Management, ICMIAM 2022
DO  - 10.1109/ICMIAM56779.2022.10146891
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163860699&doi=10.1109%2fICMIAM56779.2022.10146891&partnerID=40&md5=544afa9280334900773e0d56ad01bc83
AB  - Industries are utilising Artificial Intelligence (AI) and digital technologies to facilitate asset management. Increased implementation of AI and digital technologies requires new concepts to facilitate and simplify the Human- System-Interaction (HSI) in industrial contexts. One of the concepts for improving the HSI is by enabling a multi-space environment that integrates the physical space and the virtual space. Such a multi-space environment, materialised as metaverse, aims to augment the interaction between liveware, software, and hardware. In industry, the concept of metaverse can be used to facilitate various industrial processes, such as asset management, operation, and maintenance. One of the main challenges when enabling a metaverse in industrial contexts is the aspect of visualisation of physical and virtual assets. Asset visualisation can be supported through various emerging technologies such as gaming technology, Virtual Reality (VR), Augmented Reality (AR), and eXtented Reality (XR). In this paper, the applicability of such advanced technologies i.e., eXtended Reality (XR) have been reviewed for the asset management within various industrial domains. To carry out this research work, literature review has been conducted related to available XR technologies and their applications within the industries. It has been found that these technologies are available, but not applied in industrial asset management. Thus, the aim of this paper is to describe the developed Metaverse for asset management to enhance the operation and maintenance processes in industrial contexts utilising AI, digitalisation, and XR technologies. The developed Metaverse has been verified using a case study in railway using railway's digital assets within eMaintenance LAB. The practical implication of the findings from this work will benefit in increased efficiency and effectiveness of the operation and maintenance processes in various industrial domains.  © 2022 IEEE.
KW  - Asset Management
KW  - Intelligent
KW  - Metaverse
KW  - railway
KW  - Asset management
KW  - Maintenance
KW  - Railroad transportation
KW  - Railroads
KW  - Virtual reality
KW  - Visualization
KW  - Artificial intelligence technologies
KW  - Assets management
KW  - Digital technologies
KW  - Human-system interaction
KW  - Industrial context
KW  - Intelligent
KW  - Metaverses
KW  - Operations and maintenance
KW  - Railway
KW  - Space environment
KW  - Augmented reality
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - JOUR
AU  - Sheng, H.
AU  - Mo, H.
AU  - Zhang, T.
TI  - A Novel Multimodal Generative Learning Model based on Basic Fuzzy Concepts
PY  - 2024
T2  - Cognitive Computation
VL  - 16
IS  - 6
SP  - 2916
EP  - 2930
DO  - 10.1007/s12559-024-10336-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202737880&doi=10.1007%2fs12559-024-10336-7&partnerID=40&md5=d25ce25acf7f2a9f16ebbeb6a387ab5a
AB  - Multimodal models are designed to process different types of data within a single generative framework. The prevalent strategy in previous methods involves learning joint representations that are shared across different modalities. These joint representations are typically obtained by concatenating the top of layers of modality-specific networks. Recently, significant advancements have been made in generating images from text and vice versa. Despite these successes, current models often overlook the role of fuzzy concepts, which are crucial given that human cognitive processes inherently involve a high degree of fuzziness. Recognizing and incorporating fuzzy concepts is therefore essential for enhancing the effectiveness of multimodal cognition models. In this paper, a novel framework, named the Fuzzy Concept Learning Model (FCLM), is proposed to process modalities based on fuzzy concepts. The high-level abstractions between different modalities in the FCLM are represented by the ‘fuzzy concept functions.’ After training, the FCLM is capable of generating images from attribute descriptions and inferring the attributes of input images. Additionally, it can formulate fuzzy concepts at various levels of abstraction. Extensive experiments were conducted on the dSprites and 3D Chairs datasets. Both qualitative and quantitative results from these experiments demonstrate the effectiveness and efficiency of the proposed framework. The FCLM integrates the fuzzy cognitive mechanism with the statistical characteristics of the environment. This innovative cognition-inspired framework offers a novel perspective for processing multimodal information. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
KW  - Fuzzy Concept Learning Model (FCLM)
KW  - Fuzzy concepts understanding
KW  - Gaussian concept functions
KW  - Multimodal generative models
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Federated learning
KW  - Generative adversarial networks
KW  - Concept learning
KW  - Fuzzy concept
KW  - Fuzzy concept learning model
KW  - Fuzzy concept understanding
KW  - Gaussian concept function
KW  - Gaussians
KW  - Generative model
KW  - Learning models
KW  - Multi-modal
KW  - Multimodal generative model
KW  - Fuzzy models
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Young, D.L.
AU  - Bigham, M.
AU  - Bradbury, M.
AU  - Larson, E.
AU  - Thornton, M.
TI  - SMU-DDI Cyber Autonomy Range
PY  - 2022
T2  - Proceedings - Applied Imagery Pattern Recognition Workshop
VL  - 2022-October
DO  - 10.1109/AIPR57179.2022.10092228
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153763976&doi=10.1109%2fAIPR57179.2022.10092228&partnerID=40&md5=e0ed5d79ee506bc25763ce9eaf98deab
AB  - The Southern Methodist University-Darwin Deason Institute for Cybersecurity (SMU-DDI) Cyber Autonomy Range (CAR) addresses the incorporation of increased resiliency, reliability, and cyber security of the autonomous systems (AS) cyberinfrastructure; an issue with widespread concern and broad impact on society. The advances of data science and Machine Learning/Artificial Intelligence (ML/AI) methods coupled with their integration into autonomous subsystems is an enabling trend that supports AS maturity. Likewise, these same aspects of ML/AI present entirely new aspects of cyber security, many of which have only been analyzed in a preliminary sense or for special cases. The ML/AI aspects of cyber security are critically important, with significant ramifications in human safety and well-being. The CAR is a collaborative facility that supports the assessment of AS when faced with cyber threats by assessing their attack surface, vulnerability, and their degree of resistance to such threats. It is instrumented to simulate and/or emulate the external environment of an AS and can subject the AS to a variety of controlled cyber-Attacks. Because the decision-making capabilities of many AS are based upon data-driven ML/AI-enabled technologies, the threat surface surrounding ML/AI subsystems is of particular concern. The CAR is especially configured to investigate and simulate (or emulate) cyber-Attacks on ML/AI-equipped subsystems; particularly ML/AI subsystems that depend upon data sources derived from sensor suites or other data sources.  © 2022 IEEE.
KW  - Adversarial Attack
KW  - Autonomy
KW  - Vulnerabilities
KW  - Artificial intelligence
KW  - Computer crime
KW  - Crime
KW  - Cyber attacks
KW  - Network security
KW  - Adversarial attack
KW  - Autonomy
KW  - Broader impacts
KW  - Cyber security
KW  - Cyber-attacks
KW  - Cyberinfrastructure
KW  - Data-source
KW  - Machine-learning
KW  - Southern methodist universities
KW  - Vulnerability
KW  - Decision making
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Sun, H.
AU  - Liu, Y.
AU  - Al-Tahmeesschi, A.
AU  - Nag, A.
AU  - Soleimanpour, M.
AU  - Canberk, B.
AU  - Arslan, H.
AU  - Ahmadi, H.
TI  - Advancing 6G: Survey for Explainable AI on Communications and Network Slicing
PY  - 2025
T2  - IEEE Open Journal of the Communications Society
VL  - 6
SP  - 1372
EP  - 1412
DO  - 10.1109/OJCOMS.2025.3534626
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216835565&doi=10.1109%2fOJCOMS.2025.3534626&partnerID=40&md5=70462c245206f2f3a64261860babdc32
AB  - The unprecedented advancement of Artificial Intelligence (AI) has positioned Explainable AI (XAI) as a critical enabler in addressing the complexities of next-generation wireless communications. With the evolution of the 6G networks, characterized by ultra-low latency, massive data rates, and intricate network structures, the need for transparency, interpretability, and fairness in AI-driven decision-making has become more urgent than ever. This survey provides a comprehensive review of the current state and future potential of XAI in communications, with a focus on network slicing, a fundamental technology for resource management in 6G. By systematically categorizing XAI methodologies-ranging from modelagnostic to model-specific approaches, and from pre-model to post-model strategies-this paper identifies their unique advantages, limitations, and applications in wireless communications. Moreover, the survey emphasizes the role of XAI in network slicing for vehicular network, highlighting its ability to enhance transparency and reliability in scenarios requiring real-time decision-making and high-stakes operational environments. Real-world use cases are examined to illustrate how XAI-driven systems can improve resource allocation, facilitate fault diagnosis, and meet regulatory requirements for ethical AI deployment. By addressing the inherent challenges of applying XAI in complex, dynamic networks, this survey offers critical insights into the convergence of XAI and 6G technologies. Future research directions, including scalability, real-time applicability, and interdisciplinary integration, are discussed, establishing a foundation for advancing transparent and trustworthy AI in 6G communications systems.  © 2025 IEEE.
KW  - Artificial Intelligent (AI)
KW  - Explainable AI (XAI)
KW  - Machine Learning (ML)
KW  - network slicing
KW  - Sixth Generation (6G)
KW  - vehicular networks
KW  - wireless communications
KW  - Adversarial machine learning
KW  - Decision making
KW  - Vehicular ad hoc networks
KW  - Artificial intelligent
KW  - Explainable artificial intelligent (XAI)
KW  - Machine learning
KW  - Machine-learning
KW  - Network slicing
KW  - Sixth generation (6g)
KW  - Vehicular networks
KW  - Wireless communications
KW  - Resource allocation
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - CONF
AU  - Blasch, E.
AU  - Schrader, P.
AU  - Chen, G.
AU  - Wei, S.
AU  - Chen, Y.
AU  - Khan, S.
AU  - Aved, A.
AU  - Munir, A.
TI  - Dynamic Digital Twins for Situation Awareness
PY  - 2024
T2  - Proceedings of the IEEE National Aerospace Electronics Conference, NAECON
SP  - 433
EP  - 440
DO  - 10.1109/NAECON61878.2024.10670654
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205020979&doi=10.1109%2fNAECON61878.2024.10670654&partnerID=40&md5=31987d1604f9861ce8cfef2f48bffba9
AB  - Digital twins (DT) are becoming popular methods to leverage auxiliary information for real-time support. Digital Twins are closely related to the Dynamic Data driven Applications Systems (DDDAS) paradigm which utilizes real-time data to update first-principle simulations, while at the same time the simulation provides augmented data to enhance run-time instrumentation support. Hence, DDDAS using concepts in data assimilation, object estimation, and scientific modeling can be considered as a 'dynamic digital twin'. Key advances in recent dynamic DT methods include techniques from artificial intelligence (AI) to provide trustworthy and explainable DTs (xDT). Among the many attributes desired for the AI-DT coordination, the DDDAS first-principle physics can enhance DT interpretability and explainability. This paper highlights opportunities to coordinate measured and augmented data from static, dynamic, and generative DTs for enhanced multi-modal systems engineered awareness.  © 2024 IEEE.
KW  - context assessment
KW  - Digital engineering
KW  - Digital Twins
KW  - information management
KW  - situation awareness
KW  - Auxiliary information
KW  - Context assessment
KW  - Data assimilation
KW  - Digital engineering
KW  - Dynamic Data Driven Application Systems
KW  - First-principles simulations
KW  - Real- time
KW  - Real-time data
KW  - Runtimes
KW  - Situation awareness
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Hamdani, R.
AU  - Chihi, I.
TI  - Adaptive human-computer interaction for industry 5.0: A novel concept, with comprehensive review and empirical validation
PY  - 2025
T2  - Computers in Industry
VL  - 168
C7  - 104268
DO  - 10.1016/j.compind.2025.104268
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218927225&doi=10.1016%2fj.compind.2025.104268&partnerID=40&md5=53dad02ff3a31e266aee9367b5b35619
AB  - This paper explores the domain of adaptive Human-Computer Interaction (HCI) within the emerging context of Industry 5.0, which marks the transition from Industry 4.0 by emphasizing human-centric approaches and collaboration between humans and intelligent systems. It focuses on enhancing user experience while maintaining high security standards. The complexity of intelligent industrial environments introduces various challenges, including vulnerabilities caused by faults that can propagate across multiple layers and heterogeneous systems. Predictive maintenance becomes more complicated due to the need for advanced monitoring across interconnected systems, and the dynamic nature of these environments demands seamless adaptation. This is essential for fostering harmony between human operators and intelligent systems in real-time. However, the increasing complexity of these environments reveals the limitations of the current HCI models, making adaptability a basic requirement. This paper carries a complete 141-paper review regarding research on HCI along with a detailed exposition of the core architecture, enabling technologies, and real-world application examples. Furthermore, it presents an innovative conceptual model for implementing an HCI system that dynamically adapts to environmental changes, user behavior, diverse user profiles, and varying accessibility needs, specifically within the context of fault detection and diagnosis systems. The proposed approach has been rigorously validated through empirical studies, demonstrating its effectiveness and practical applicability. To improve resiliency and efficiency in such a smart industrial system as is vulnerable, the interface would adapt itself to user behavior and diversity. It addresses the challenges that arise during this dynamic and complex environment that would ensure a secure and seamless interaction. © 2025 The Authors
KW  - Behavioral Insights
KW  - Cognitive Load Management
KW  - Fault Detection and Diagnosis
KW  - Human-Computer Interaction
KW  - Industry 5.0
KW  - User-Centric Design
KW  - Behavioral insight
KW  - Cognitive load management
KW  - Cognitive loads
KW  - Computer interaction
KW  - Empirical validation
KW  - Fault detection and diagnosis
KW  - Industry 5.0
KW  - Novel concept
KW  - User behaviors
KW  - User-centric designs
KW  - Predictive maintenance
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Choi, R.-Y.
AU  - Song, Y.
AU  - Jang, M.
AU  - Kim, T.
AU  - Ahn, J.
AU  - Im, D.-H.
TI  - Smart Contract Vulnerability Detection Using Large Language Models and Graph Structural Analysis
PY  - 2025
T2  - Computers, Materials and Continua
VL  - 83
IS  - 1
SP  - 785
EP  - 801
DO  - 10.32604/cmc.2025.061185
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001378249&doi=10.32604%2fcmc.2025.061185&partnerID=40&md5=aa892f92e63cabeada01063ca3638b8d
AB  - Smart contracts are self-executing programs on blockchains that manage complex business logic with transparency and integrity. However, their immutability after deployment makes programming errors particularly critical, as such errors can be exploited to compromise blockchain security. Existing vulnerability detection methods often rely on fixed rules or target specific vulnerabilities, limiting their scalability and adaptability to diverse smart contract scenarios. Furthermore, natural language processing approaches for source code analysis frequently fail to capture program flow, which is essential for identifying structural vulnerabilities. To address these limitations, we propose a novel model that integrates textual and structural information for smart contract vulnerability detection. Our approach employs the CodeBERT NLP model for textual analysis, augmented with structural insights derived from control flow graphs created using the abstract syntax tree and opcode of smart contracts. Each graph node is embedded using Sent2Vec, and centrality analysis is applied to highlight critical paths and nodes within the code. The extracted features are normalized and combined into a prompt for a large language model to detect vulnerabilities effectivel. Experimental results demonstrate the superiority of our model, achieving an accuracy of 86.70%, a recall of 84.87%, a precision of 85.24%, and an F1-score of 84.46%. These outcomes surpass existing methods, including CodeBERT alone (accuracy: 81.26%, F1-score: 79.84%) and CodeBERT combined with abstract syntax tree analysis (accuracy: 83.48%, F1-score: 79.65%). The findings underscore the effectiveness of incorporating graph structural information alongside text-based analysis, offering improved scalability and performance in detecting diverse vulnerabilities. © 2025 The Authors.
KW  - Blockchain
KW  - large language model
KW  - smart contract
KW  - vulnerability detection
KW  - Abstract Syntax Trees
KW  - Block-chain
KW  - Business logic
KW  - Detection methods
KW  - F1 scores
KW  - Language model
KW  - Large language model
KW  - Programming errors
KW  - Structural information
KW  - Vulnerability detection
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Xu, S.
AU  - Ghosh, B.
AU  - Hobbs, C.
AU  - Fraccaroli, E.
AU  - Duggirala, P.S.
AU  - Chakraborty, S.
TI  - Statistical Approach to Efficient and Deterministic Schedule Synthesis for Cyber-Physical Systems
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14215 LNCS
SP  - 312
EP  - 333
DO  - 10.1007/978-3-031-45329-8_15
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176001382&doi=10.1007%2f978-3-031-45329-8_15&partnerID=40&md5=e9b4226128caaeba8bdfb71950596fe6
AB  - Correctness of controller implementations rely on real-time guarantees that all control tasks finish execution by their prescribed deadlines. However, with increased complexity and heterogeneity in hardware, the worst-case execution time estimates are becoming very conservative. Thus, for efficient usage of hardware resources, some control tasks might have to miss their deadlines. Recent work has shown that a system can still abide by its safety requirements even after missing some of its deadlines. This paper investigates an approach to synthesize a scheduler for control tasks that miss some deadlines without compromising its safety requirements. But given that the number of possible schedules increase combinatorially with the number of tasks involved, our scheduler synthesis uses an efficient automata representation to search for the appropriate schedule. We incorporate statistical verification techniques to construct this automaton and accelerate the search process. Statistical verification is advantageous compared to deterministic verification in the synthesis process in two ways: first, it enables us to synthesize schedules that would not be possible otherwise, and second, it drastically reduces the time taken to synthesize such a schedule. We demonstrate both these advantages through a case study with five controllers having different safety specifications, but sharing the same computational resource. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Controllers
KW  - Embedded systems
KW  - Control task
KW  - Controller implementation
KW  - Cybe-physical systems
KW  - Cyber-physical systems
KW  - Deterministics
KW  - Real time guarantees
KW  - Safety requirements
KW  - Statistical approach
KW  - Statistical verification
KW  - Worst-case execution time
KW  - Cyber Physical System
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Eisele, C.
AU  - Seiffer, D.
AU  - Sucher, E.
AU  - Sjöqvist, L.
AU  - Henriksson, M.
AU  - Lavigne, C.
AU  - Domel, R.
AU  - Déliot, P.
AU  - Dijk, J.
AU  - Kuijf, H.
AU  - Boehrer, N.
TI  - DEBELA – Investigations on potential Detect before Launch technologies
PY  - 2024
T2  - Proceedings of SPIE - The International Society for Optical Engineering
VL  - 13200
C7  - 132001A
DO  - 10.1117/12.3031507
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210022534&doi=10.1117%2f12.3031507&partnerID=40&md5=f5672f3731c940bd252acbf7a13462ab
AB  - Advanced missile seeker technologies and missile propulsion systems with reduced electrooptical signatures constitute a serious threat to military platforms. Seekers using multiple spectral bands may be hard to jam using current countermeasure systems. Imaging seekers may have adaptive tracking algorithms to suppress the effect of current countermeasure strategies. Furthermore, countermeasures can only be used if a threat has been declared. Low-signature propellants in combination with the missile seen in head-on angle, where a bigger portion of the missile plume is shielded by the missile body, will make it extremely hard to detect the missile with current warning sensor systems. We report on the objectives and the status of the EDA CAT B project DEBELA (Detect Before Launch), which tries to address this threat and which looked into potential technologies for future self-protection systems. The project focusses on within visual range threats and electrooptical sensors only. Candidate-technologies have been identified and tested in a field experiment on the premises of the Bundeswehr Technical Center (WTD 52) in Oberjettenberg, Germany. © 2024 SPIE.
KW  - electrooptical sensors
KW  - event camera
KW  - hyperspectral
KW  - LIDAR
KW  - missile
KW  - self-protection
KW  - Air to surface missiles
KW  - Electrooptical devices
KW  - Missile launching systems
KW  - Radar countermeasures
KW  - Remote sensing
KW  - Surface to air missiles
KW  - Surveillance radar
KW  - 'current
KW  - Electro-optical signatures
KW  - Electrooptical sensors
KW  - Event camera
KW  - HyperSpectral
KW  - Launch technology
KW  - Missile-seeker technology
KW  - On potentials
KW  - Propulsion system
KW  - Self protection
KW  - Optical radar
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Saad, W.
AU  - Hashash, O.
AU  - Thomas, C.K.
AU  - Chaccour, C.
AU  - Debbah, M.
AU  - Mandayam, N.
AU  - Han, Z.
TI  - Artificial General Intelligence (AGI)-Native Wireless Systems: A Journey beyond 6G
PY  - 2025
T2  - Proceedings of the IEEE
DO  - 10.1109/JPROC.2025.3526887
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000542326&doi=10.1109%2fJPROC.2025.3526887&partnerID=40&md5=3ecb3d23997d96a421de022a1b232071
AB  - Building the next-generation wireless systems that could support services such as the metaverse, digital twins (DTs), and holographic teleportation is challenging to achieve exclusively through incremental advances to conventional wireless technologies like metasurfaces or holographic antennas. While the 6G concept of artificial intelligence (AI)-native networks promises to overcome some of the limitations of existing wireless technologies, current developments of AI-native wireless systems rely mostly on conventional AI tools such as auto-encoders and off-The-shelf artificial neural networks. However, those tools struggle to manage and cope with the complex, nontrivial scenarios faced in real-world wireless environments and the growing quality-of-experience (QoE) requirements of the aforementioned, emerging wireless use cases. In contrast, in this article, we propose to fundamentally revisit the concept of AI-native wireless systems, equipping them with the common sense necessary to transform them into artificial general intelligence (AGI)-native systems. Our envisioned AGI-native wireless systems acquire common sense by exploiting different cognitive abilities such as reasoning and analogy. These abilities in our proposed AGI-native wireless system are mainly founded on three fundamental components: A perception module, a world model, and an action-planning component. Collectively, these three fundamental components enable the four pillars of common sense that include dealing with unforeseen scenarios through horizontal generalizability, capturing intuitive physics, performing analogical reasoning, and filling in the blanks. Toward developing these components, we start by showing how the perception module can be built through abstracting real-world elements into generalizable representations. These representations are then used to create a world model, founded on principles of causality and hyperdimensional (HD) computing. Specifically, we propose a concrete definition of a world model, viewing it as an HD causal vector space that aligns with the intuitive physics of the real world-a cornerstone of common sense. In addition,we discuss how this proposed world model can enable analogical reasoning and manipulation of the abstract representations. Then, we show how the world model can drive an action-planning feature of the AGI-native network. In particular, we propose an intent-driven and objective-driven planning method that can maneuver the AGI-native network to plan its actions. These planning methods are based on brain-inspired frameworks such as integrated information theory and hierarchical abstractions that play a crucial role in enabling human-like decision-making. Next, we explain how an AGI-native network can be further exploited to enable three use cases related to human users and autonomous agent applications: 1) analogical reasoning for the next-generation DTs; 2) synchronized and resilient experiences for cognitive avatars; and 3) brain-level metaverse experiences exemplified by holographic teleportation. Finally, we conclude with a set of recommendations to ignite the quest for AGI-native systems. Ultimately, we envision this article as a roadmap for the next generation of wireless systems beyond 6G.  © 1963-2012 IEEE.
KW  - AGI-Augmented digital twins (DTs)
KW  - AGI-native
KW  - Artificial general intelligence (AGI)
KW  - beyond 6G
KW  - common sense
KW  - planning
KW  - reasoning
KW  - world model
KW  - 4G mobile communication systems
KW  - Broaches
KW  - Frequency allocation
KW  - Metamaterial antennas
KW  - Shear walls
KW  - Television studios
KW  - Video on demand
KW  - Window screens
KW  - Windows
KW  - Artificial general intelligence
KW  - Artificial general intelligence-augmented digital twin
KW  - Artificial general intelligence-native
KW  - Artificial general intelligences
KW  - Beyond 6g
KW  - Common sense
KW  - Reasoning
KW  - World model
KW  - 5G mobile communication systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CHAP
AU  - Sammut, C.
AU  - Farid, R.
AU  - Wicaksono, H.
AU  - Wiley, T.
TI  - Logic-based robotics
PY  - 2021
T2  - Human-Like Machine Intelligence
SP  - 465
EP  - 486
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132687777&partnerID=40&md5=47fe170db4380b1b2432404ae3d7bacd
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Yuan, W.
AU  - Paxton, C.
AU  - Desingh, K.
AU  - Fox, D.
TI  - SORNet: Spatial Object-Centric Representations for Sequential Manipulation
PY  - 2021
T2  - Proceedings of Machine Learning Research
VL  - 164
SP  - 148
EP  - 157
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171745652&partnerID=40&md5=9c9dda2e918db7e91e0676fa8aa3493e
AB  - Sequential manipulation tasks require a robot to perceive the state of an environment and plan a sequence of actions leading to a desired goal state, where the ability to reason about spatial relations among object entities from raw sensor inputs is crucial. Prior works relying on explicit state estimation or end-to-end learning struggle with novel objects or new tasks. In this work, we propose SORNet (Spatial Object-Centric Representation Network), which extracts object-centric representations from RGB images conditioned on canonical views of the objects of interest. We show that the object embeddings learned by SORNet generalize zero-shot to unseen object entities on three spatial reasoning tasks: spatial relation classification, skill precondition classification and relative direction regression, significantly outperforming baselines. Further, we present real-world robotic experiments demonstrating the usage of the learned object embeddings in task planning for sequential manipulation. © 2021 Proceedings of Machine Learning Research. All rights reserved.
KW  - Manipulation
KW  - Object-centric Representation
KW  - Spatial Reasoning
KW  - Robot programming
KW  - Zero-shot learning
KW  - Embeddings
KW  - Manipulation
KW  - Manipulation task
KW  - Object-centric representation
KW  - Raw sensor
KW  - Sensor inputs
KW  - Sequence of actions
KW  - Spatial objects
KW  - Spatial reasoning
KW  - Spatial relations
KW  - Embeddings
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 45
ER  -

TY  - CONF
AU  - Achour, M.
AU  - Boufaied, A.
TI  - Multi-objective Optimization for Sensor Networks Based Smart Parking Systems
PY  - 2023
T2  - Lecture Notes in Networks and Systems
VL  - 646 LNNS
SP  - 230
EP  - 241
DO  - 10.1007/978-3-031-27440-4_22
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163332831&doi=10.1007%2f978-3-031-27440-4_22&partnerID=40&md5=c93c8fd6c406d2d79d7392932c36c412
AB  - Smart parking systems become very important nowadays because of the growth of the number of cars in cities and the necessity to rapidly find an empty parking lot. Although there is no a hard real time need, but it is preferable to quickly serve the users entering to the park before the arrival of other users which can cause many conflicts. So we propose a soft real time smart parking management method based on a sensor network to capture the lots state. A multi-objective optimization based on time and energy constraints is proposed and solved, and many simulations with VisualSense are done to evaluate the performance of our work. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - hard/soft real time
KW  - multi-objective optimization
KW  - sensor network
KW  - smart parking system
KW  - VisualSense
KW  - Multiobjective optimization
KW  - Parks
KW  - Real time systems
KW  - Hard real-time
KW  - Hard-real-time
KW  - Hard/soft real time
KW  - Multi-objectives optimization
KW  - Network-based
KW  - Parking lots
KW  - Sensors network
KW  - Smart parking systems
KW  - Soft real time
KW  - Visualsense
KW  - Sensor networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Alimam, H.
AU  - Mazzuto, G.
AU  - Tozzi, N.
AU  - Emanuele Ciarapica, F.
AU  - Bevilacqua, M.
TI  - The resurrection of digital triplet: A cognitive pillar of human-machine integration at the dawn of industry 5.0
PY  - 2023
T2  - Journal of King Saud University - Computer and Information Sciences
VL  - 35
IS  - 10
C7  - 101846
DO  - 10.1016/j.jksuci.2023.101846
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178062783&doi=10.1016%2fj.jksuci.2023.101846&partnerID=40&md5=a55797f41d77593053b166a43ec4aefe
AB  - The integration of AI technology with digital transformation has profoundly shaped the evolution towards digital triplet architecture, grounded in human-centric methodologies. By infusing human intellectual activities into both physical and cyberspace, innovative links between humans and machines are established. Despite limitations in transitioning from tangible human presence to the digital realm in cyberspace, extensive efforts are underway to harness emotional, visual, and oral responses, thereby enhancing the reasoning and predictive capabilities of digital twins. These advancements aim to elevate real-time human interactions with physical and virtual systems by integrating intelligent AI algorithms and cognitive computing systems into digital twins. This paper meticulously analyses recent trends in digital twins, tracing their evolution from traditional concepts and applications to a nuanced digital triplet hierarchy that incorporates human intuition, knowledge, and creativity within cyberspace. we delve into the hierarchical framework of the digital triplet, resonating with maturity, domination, and volition levels, enhances cognitive and perceptual capabilities in cyberspace. The study provides a systematic overview of the development of ultra-realistic digital models, incorporating real-time data-driven artefacts that integrate intelligent activities with multidomain, multiphysics, and multiscale simulations. The research scope is focused on augmenting the perceptive and heuristic capabilities of the digital triplet framework by utilizing AI in data analytics, retrieving heterogeneous data from virtual entities using semantic artificial intelligence technologies, and amalgamating AI and machine learning with human insight and perceptual knowledge. The proposed digital triplet hierarchy aims to enhance cyberspace's capacity for learning, cognitive skills, and knowledge transfer. It can be a guideline for the researcher to promote cognitive augmentation of the human brain through brain-machine/computer interface, virtual, augmented, and extended reality, fostering a symbiotic relationship between humans and machines in the industrial metaverse and industry 5.0. The paper discusses future directions for research and the challenges involved in developing intelligent digital twins towards the digital triplet paradigm, aiming to embody intelligent activities and cognitive capabilities within the framework of human–machine symbiosis. © 2023 The Author(s)
KW  - Artificial Intelligence AI
KW  - Brain-Computer Interface BCI
KW  - Cognitive Digital Twin CDT/DT
KW  - Digital Triplet D3
KW  - Human-Machine Integration
KW  - Industry 5.0
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 38
ER  -

TY  - JOUR
AU  - Hou, Z.
AU  - Liu, Y.
AU  - Fan, Q.
TI  - Temporal Logic-Guided DQN for Object Delivery and Transportation Using Magnetic Microrobots With Local Control
PY  - 2025
T2  - IEEE Robotics and Automation Letters
VL  - 10
IS  - 6
SP  - 5441
EP  - 5448
DO  - 10.1109/LRA.2025.3560879
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003698566&doi=10.1109%2fLRA.2025.3560879&partnerID=40&md5=9f6e7f6b2164e49510afd2b85b9b6727
AB  - Microrobots driven by magnetic fields hold significant promise in medical applications, particularly in drug delivery–a key area in the biomedical field. Traditional approaches primarily rely on global magnetic fields to control single microrobots, which makes it challenging to independently control multiple microrobots. To address this limitation, this letter introduces a local magnetic field generation system that enables independent control of multiple microrobots. The proposed system employs a printed circuit board (PCB) array-based magnetic microrobot system, utilizing a microcoil array for precise and localized control. To enhance task execution, we integrate Deep Reinforcement Learning (DRL) with Linear Temporal Logic (LTL) to generate obstacle-avoiding paths for single and dual magnetic microrobots. The system is validated through magnetic droplet transport experiments. Experimental results demonstrate the effectiveness of the proposed system in achieving autonomous multi-task drug delivery and droplet fusion. This work underscores the potential of magnetic field-driven microcoil array systems in advancing transportation and drug delivery technologies in biomedical engineering. © 2016 IEEE.
KW  - deep reinforcement learning (DRL)
KW  - linear temporal logic (LTL)
KW  - Magnetic microrobots
KW  - navigation
KW  - task planning
KW  - Galvanomagnetic effects
KW  - Robots
KW  - Deep reinforcement learning
KW  - Linear temporal logic
KW  - Local control
KW  - Magnetic microrobots
KW  - Magnetic-field
KW  - Micro robots
KW  - Microcoil arrays
KW  - Reinforcement learnings
KW  - Task planning
KW  - Deep reinforcement learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Baroni, P.
AU  - Cerutti, F.
AU  - Fogli, D.
AU  - Giacomin, M.
AU  - Gringoli, F.
AU  - Guida, G.
AU  - Sullivan, P.
TI  - Self-Aware Effective Identification and Response to Viral Cyber Threats
PY  - 2021
T2  - International Conference on Cyber Conflict, CYCON
VL  - 2021-May
C7  - 9468294
SP  - 353
EP  - 370
DO  - 10.23919/CyCon51939.2021.9468294
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112297201&doi=10.23919%2fCyCon51939.2021.9468294&partnerID=40&md5=5bdfa0fe5f51c4c4f323fa272aa41b65
AB  - Artificial intelligence (AI) techniques can significantly improve cyber security operations if tasks and responsibilities are effectively shared between human and machine. AI techniques excel in some situational understanding tasks; for instance, classifying intrusions. However, existing AI systems are often overconfident in their classification: this reduces the trust of human analysts. Furthermore, sophisticated intrusions span across long time periods to reduce their footprint, and each decision to respond to a (suspected) attack can have unintended side effects. In this position paper we show how advanced AI systems handling uncertainty and encompassing expert knowledge can lessen the burden on human analysts. In detail: (1) Effective interaction with the analyst is a key issue for the success of an intelligence support system. This involves two issues: a clear and unambiguous system-analyst communication, only possible if both share the same domain ontology and conceptual framework, and effective interaction, allowing the analyst to query the system for justifications of the reasoning path followed and the results obtained. (2) Uncertainty-aware machine learning and reasoning is an effective method for anomaly detection, which can provide human operators with alternative interpretations of data with an accurate assessment of their confidence. This can contribute to reducing misunderstandings and building trust. (3) An event-processing algorithm including both a neural and a symbolic layer can help identify attacks spanning long intervals of time, that would remain undetected via a pure neural approach. (4) Such a symbolic layer is crucial for the human operator to estimate the appropriateness of possible responses to a suspected attack by considering both the probability that an attack is actually occurring and the impact (intended and unintended) of a given response.  © 2021 NATO CCDCOE.
KW  - artificial intelligence
KW  - cyber threat intelligence
KW  - machine learning
KW  - Anomaly detection
KW  - Security of data
KW  - Conceptual frameworks
KW  - Cyber security
KW  - Domain ontologies
KW  - Effective interactions
KW  - Event Processing
KW  - Expert knowledge
KW  - Intelligence-support systems
KW  - Position papers
KW  - Artificial intelligence
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 9
ER  -

TY  - CONF
AU  - Adhikary, A.
AU  - Raha, A.D.
AU  - Qiao, Y.
AU  - Kang, S.W.
AU  - Hong, C.S.
TI  - Transfer Learning Empowered Power Allocation in Holographic MIMO-enabled Wireless Network
PY  - 2024
T2  - Proceedings of IEEE/IFIP Network Operations and Management Symposium 2024, NOMS 2024
DO  - 10.1109/NOMS59830.2024.10575901
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198363280&doi=10.1109%2fNOMS59830.2024.10575901&partnerID=40&md5=b717dc0dd7a34f015e127c7722949310
AB  - The upcoming 6G wireless communication networks are anticipated to offer extensive mobile connectivity, faster data services with reduced power consumption, and seamless integration among different technologies for providing effective beamforming. To accomplish these aims, a transfer learning empowered AI framework is proposed to allocate the power for serving the users under the coverage areas of the corresponding holographic MIMOs (HMIMOs) by activating the required number of grids from the respective HMIMOs. An optimization problem is formulated with the goal of maximizing the utility function for achievable rate, which in turn maximizes the signal-to-interference-plus-noise ratio (SINR), and achievable rate of the users. The HMIMO that serves the highest number of users is considered as the parent HMIMO and the rest of the HMIMOs are regarded as the child HMIMOs. A Transformer-based AI framework is utilized for allocating the power to the users under the coverage areas of the parent HMIMO and transfers the knowledge of the trained model to the child HMIMOs which requires lower learning cost to allocate power to the corresponding users within the coverage areas of the child HMIMOs. Finally, simulation results show that the proposed AI framework empowered by transfer learning surpasses the baseline methods such as gated recurrent unit and long short-term memory, achieving power savings ranging from 28.14% to 38.92% and achievable rate enhancements from 16.58 bps/Hz to 16.84 bps/Hz. © 2024 IEEE.
KW  - achievable rate
KW  - holographic MIMO
KW  - power allocation
KW  - signal-to-interference-plus-noise ratio
KW  - Transfer learning
KW  - 5G mobile communication systems
KW  - Holography
KW  - Learning systems
KW  - Signal interference
KW  - Signal to noise ratio
KW  - Wireless networks
KW  - Achievable rate
KW  - Coverage area
KW  - Data services
KW  - Holographic MIMO
KW  - Mobile connectivity
KW  - Power
KW  - Power allocations
KW  - Signalto-interference-plus-noise ratios (SINR)
KW  - Transfer learning
KW  - Wireless communications networks
KW  - MIMO systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Pearson, S.
TI  - Artificial intelligence in horticulture
PY  - 2025
T2  - Journal of Horticultural Science and Biotechnology
DO  - 10.1080/14620316.2025.2475401
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000511818&doi=10.1080%2f14620316.2025.2475401&partnerID=40&md5=eefbf6ff389917129e69433a2d75b65a
AB  - Horticultural crop production systems are being transformed by the advent of artificial intelligence (AI). The pace of technology development is extraordinary. The well-known large language model (LLMs) CHAT-GPT was only released in November 2022, yet it and analogous systems are transforming lives, industry and education. Prior to the advent of LLMs, ‘narrower’ AI and machine learning systems transformed image recognition and natural language processing. Multiple applications of AI and machine learning are now deployed across global horticulture, whether in robots for crop harvesting, imaging technologies for crop forecasting, decision support to optimise greenhouse control, accelerated knowledge transfer or general business management. Here, we review the advent of these technologies within horticulture. Whilst the journal is now 100 years old, artificial intelligence is now starting to realise its potential, an accelerator with the power to transform next century horticulture. © 2025 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.
KW  - Agri-tech
KW  - Artificial intelligence
KW  - horticulture
KW  - robotics
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Yang, Y.
AU  - Jing, J.
AU  - Zhang, J.
AU  - Liu, Z.
AU  - Li, X.
TI  - Discriminative fault diagnosis transfer learning network under joint mechanism
PY  - 2025
T2  - Scientific Reports
VL  - 15
IS  - 1
C7  - 8888
DO  - 10.1038/s41598-025-93996-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000120721&doi=10.1038%2fs41598-025-93996-1&partnerID=40&md5=61cb7f5fb608d53580abb5bc5908b655
AB  - Unsupervised fault diagnosis methods for rotating machinery are gaining attention but face challenges such as feature extraction from vibration signals, aligning distributions between source and target domains, and managing domain shifts. This paper proposes a novel unsupervised transfer learning method that integrates the Squeeze-and-Excitation (SE) attention mechanism to enhance useful features while suppressing redundant ones. An Integrated Distribution Alignment Framework (IDAF) is introduced, which employs the Joint Adaptation Network (JAN) approach to construct a local maximum mean discrepancy in conjunction with Correlation Alignment (CORAL) to improve distribution alignment between domains. Moreover, to enhance feature learning and obtain more distinct features, the authors utilize a novel discriminative feature learning method called I-Softmax loss. This method can be optimized in a manner similar to the traditional Softmax loss while providing improved classification performance. Finally, deep adversarial training is applied between the source and target domains to adaptively optimize the target domain network parameters, reducing domain shift and improving fault classification accuracy. Experimental validation using four sets of bearing faults and six sets of gear faults demonstrates the superior performance of the proposed method in unsupervised fault diagnosis tasks. © The Author(s) 2025.
KW  - Classification loss
KW  - Conditional adversarial network
KW  - Domain adaptation
KW  - SE attention mechanism
KW  - adaptation
KW  - article
KW  - classification
KW  - diagnosis
KW  - feature extraction
KW  - human
KW  - learning
KW  - transfer of learning
KW  - vibration
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Kejriwal, M.
TI  - Designing Social Good Semantic Computing Architectures for the Long Tail: Case Studies, Evaluation, and Challenges
PY  - 2024
T2  - Proceedings - IEEE International Conference on Semantic Computing, ICSC
SP  - 253
EP  - 260
DO  - 10.1109/ICSC59802.2024.00047
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192253266&doi=10.1109%2fICSC59802.2024.00047&partnerID=40&md5=679f2d1cb19105588f4e54243248fbf4
AB  - Many real-world systems, especially systems characterized by high social activity (such as the Web), tend to obey power law distributions and thereby have a significant 'long tail'. We argue that researching, developing and designing semantic computing systems for the long tail, especially dependent on inductive AI, constitutes an important class of problems, not least because the long tail is challenging both technically and socially. By its very nature, the long tail is irregular, testing the generalization capabilities of the state-of-the-art, especially in architectures and interfaces that are built on some form of machine learning or statistical inference (including large language models). As machine learning and generative AI continues to be integrated into more front facing systems, the issue of the long tail cannot be ignored by either the systems engineering or the AI communities. We present two case studies with important social consequences (fighting human trafficking online, and managing information effectively and in real-time during humanitarian crises) where semantic computing and AI platforms specifically designed to handle long-tail challenges find critical application, and sometimes with drastically different design choices compared to designing only for the short tail (with the main goal of maximizing average accuracy).  © 2024 IEEE.
KW  - crisis response
KW  - human trafficking
KW  - Long tail
KW  - social good
KW  - Computer architecture
KW  - Crime
KW  - Interface states
KW  - Semantics
KW  - Case-studies
KW  - Computing architecture
KW  - Crisis response
KW  - Human trafficking
KW  - Long tail
KW  - Machine-learning
KW  - Real-world system
KW  - Semantic Computing
KW  - Social activities
KW  - Social good
KW  - Machine learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Ahmed, N.
AU  - Afyouni, I.
AU  - Dabool, H.
AU  - Al Aghbari, Z.
TI  - A systemic survey of the Omniverse platform and its applications in data generation, simulation and metaverse
PY  - 2024
T2  - Frontiers in Computer Science
VL  - 6
C7  - 1423129
DO  - 10.3389/fcomp.2024.1423129
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211091704&doi=10.3389%2ffcomp.2024.1423129&partnerID=40&md5=0560f2593614fe66d21247b2f9ff902b
AB  - Nvidia’s Omniverse platform represents a paradigm shift in the realm of virtual environments and simulation technologies. This paper presents a comprehensive examination of the Omniverse platform, a transformative force in virtual environments and simulation technologies. We offer a detailed systematic survey of the Omniverse’s impact across various scientific fields, underscoring its role in fostering innovation and sculpting the technological future. Our focus includes the Omniverse Replicator for generating synthetic data to address data insufficiency, and the utilization of Isaac Sim with its Issac Gym and software development kit (SDK) for robotic simulations, alongside Drive Sim for autonomous vehicle emulation. We further investigate the Extended Reality (XR) suite for augmented and virtual realities, as well as the Audio2Face application, which translates audio inputs into animated facial expressions. A critical analysis of Omniverse’s technical architecture, user-accessible applications, and extensions are provided. We contrast existing surveys on the Omniverse with those on the metaverse, delineating their focus, applications, features, and constraints. The paper identifies potential domains where the Omniverse excels and explores its real-world application capabilities by discussing how existing research papers utilize the Omniverse platform. Finally, we discuss the challenges and hurdles facing the Omniverse’s broader adoption and implementation, mitigating the lack of surveys solely focusing on the Omniverse. Copyright © 2024 Ahmed, Afyouni, Dabool and Al Aghbari.
KW  - collaboration
KW  - metaverse
KW  - Omniverse
KW  - real time simulation
KW  - synthetic data creation
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Hung, N.V.
AU  - Quan, N.A.
AU  - Van Vu, N.
AU  - Yen, P.T.
AU  - Binh, N.H.
AU  - Nga, N.T.T.
TI  - Using Ontology to Analyze Sentiment of Comments on Vietnamese Social Media
PY  - 2024
T2  - CEUR Workshop Proceedings
VL  - 3876
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214225056&partnerID=40&md5=9e01227c099f578826645838f0678f57
AB  - Recently, there has been a growing trend in studies that employ ontology-based methods to analyze sentiment in social media comments in Vietnam. Ontology, a model comprising concepts, attributes, and relationships, serves as a knowledge reference framework for expressing emotions in comments. This approach enhances understanding of how Vietnamese individuals convey emotions on platforms such as YouTube, Facebook, and others. In contrast to traditional sentiment analysis methods, ontology aims to achieve more detailed and accurate sentiment analysis by leveraging semantic connections between concepts. Therefore, this paper proposes: (1) employing ontology for sentiment analysis in Vietnamese social media, (2) collecting and preprocessing comment data from popular platforms in Vietnam, (3) utilizing ontology to assign sentiment labels (positive, negative) to comments, (4) analyzing sentiment patterns and trends in comments, and (5) evaluating the performance of ontology-based methods versus traditional sentiment analysis. The ?ndings of this study contribute to advancing social data analysis techniques and o er insights into user behaviors on Vietnamese social media platforms. Experiments also show that the proposed method achieves the best performance compared to other methods, with an accuracy of up to 0.8657 and an F1 score of up to 0.9174.  © 2024 Copyright for this paper by its authors.
KW  - Analyze Sentiment
KW  - Ontology
KW  - Opinion
KW  - Social Media
KW  - Vietnamese
KW  - Ontology's
KW  - Ontology-based methods
KW  - Opinion
KW  - Performance
KW  - Reference frameworks
KW  - Sentiment analysis
KW  - Social media
KW  - Viet Nam
KW  - Vietnamese
KW  - YouTube
KW  - Social psychology
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Chaghazardi, Z.
AU  - Fallah, S.
AU  - Tamaddoni-Nezhad, A.
TI  - Explainable and Trustworthy Traffic Sign Detection for Safe Autonomous Driving: An Inductive Logic Programming Approach
PY  - 2023
T2  - Electronic Proceedings in Theoretical Computer Science, EPTCS
VL  - 385
SP  - 201
EP  - 212
DO  - 10.4204/EPTCS.385.21
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172994519&doi=10.4204%2fEPTCS.385.21&partnerID=40&md5=764b90430b324578fe8d7ce55f16bbc3
AB  - Traffic sign detection is a critical task in the operation of Autonomous Vehicles (AV), as it ensures the safety of all road users. Current DNN-based sign classification systems rely on pixel-level features to detect traffic signs and can be susceptible to adversarial attacks. These attacks involve small, imperceptible changes to a sign that can cause traditional classifiers to misidentify the sign. We propose an Inductive Logic Programming (ILP) based approach for stop sign detection in AVs to address this issue. This method utilises high-level features of a sign, such as its shape, colour, and text, to detect categories of traffic signs. This approach is more robust against adversarial attacks, as it mimics human-like perception and is less susceptible to the limitations of current DNN classifiers. We consider two adversarial attacking methods to evaluate our approach: Robust Physical Perturbation (PR2) and Adversarial Camouflage (AdvCam). These attacks are able to deceive DNN classifiers, causing them to misidentify stop signs as other signs with high confidence. The results show that the proposed ILP-based technique is able to correctly identify all targeted stop signs, even in the presence of PR2 and ADvCam attacks. The proposed learning method is also efficient as it requires minimal training data. Moreover, it is fully explainable, making it possible to debug AVs. © Z. Chaghazardi, S. Fallah & A. Tamaddoni-Nezhad.
KW  - Autonomous vehicles
KW  - Computer circuits
KW  - Feature extraction
KW  - Inductive logic programming (ILP)
KW  - Learning systems
KW  - 'current
KW  - Autonomous driving
KW  - Autonomous Vehicles
KW  - Classification system
KW  - Critical tasks
KW  - Inductive logic
KW  - Logic-programming
KW  - Pixel level
KW  - Road users
KW  - Traffic sign detection
KW  - Traffic signs
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Persson, A.
AU  - Loutfi, A.
TI  - Embodied Affordance Grounding using Semantic Simulations and Neural-Symbolic Reasoning: An Overview of the PlayGround Project
PY  - 2022
T2  - CEUR Workshop Proceedings
VL  - 3400
SP  - 165
EP  - 171
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160852018&partnerID=40&md5=edc8b138b844d23f9ec9f480e1309321
AB  - In this paper, we present a synopsis of the PlayGround project. Through neural-symbolic learning and reasoning, the PlayGround project assumes that high-level concepts and reasoning processes can be used to advance both symbol grounding and object affordance inference. However, a prerequisite for reasoning about objects and their affordances is integrated object representations that concurrently maintain symbolic values (e.g., high-level concepts), and sub-symbolic features (e.g., spatial aspects of objects). Integrated representations that, preferably, should be based upon neural-symbolic computation such that neural-symbolic models can, subsequently, be used for high-level reasoning processes. Nevertheless, reasoning processes for symbol grounding and affordance inference often require multiple inference steps. Taking inspiration from the cognitive prospects in simulation semantics, the PlayGround project further presumes that these reasoning processes can be simulated by neural rendering complementary to high-level reasoning processes. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0)
KW  - Affordance Inference
KW  - Neural-Symbolic Reasoning
KW  - Semantic Simulation
KW  - Semantic World Modeling
KW  - Symbol Grounding
KW  - Affordance inference
KW  - Affordances
KW  - Creative Commons
KW  - High-level reasoning
KW  - Neural-symbolic reasoning
KW  - Reasoning process
KW  - Semantic simulation
KW  - Semantic world modeling
KW  - Symbol grounding
KW  - Symbolic reasoning
KW  - Semantics
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Kureychik, V.
AU  - Danilchenko, V.
AU  - Danilchenko, E.
TI  - ROUTING OF AUTONOMOUS DEVICES IN THREE-DIMENSIONAL SPACE
ST  - МАРШРУТИЗАЦИЯ АВТОНОМНЫХ УСТРОЙСТВ В ТРЁХМЕРНОМ ПРОСТРАНСТВЕ
PY  - 2025
T2  - Informatics and Automation
VL  - 24
IS  - 2
SP  - 492
EP  - 525
DO  - 10.15622/ia.24.2.5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001836892&doi=10.15622%2fia.24.2.5&partnerID=40&md5=1ee97dbd8b503a63bf7d45fbfcc0611c
AB  - The article addresses the problem of routing autonomous devices in three-dimensional space, which is a relevant task for intelligent control. The three-dimensional space is characterized by a high degree of freedom, complex topology, and dynamic environmental changes, which significantly complicate the task of effective trajectory planning. The development of routing methods that ensure safety, energy efficiency, and computational efficiency is crucial for improving the performance of autonomous systems. The paper presents a comprehensive routing system based on a hybrid approach that combines high-level modeling of the working space with metaheuristic optimization methods. Hierarchical data structures, such as octrees, are used to represent the three-dimensional environment, providing compactness and flexibility for spatial models. These models are transformed into graph structures, allowing the routing problem to be described as an optimization problem on graphs. A modified metaheuristic ant colony optimization algorithm, belonging to the class of swarm optimization methods, is proposed. The algorithm is designed to build safe and energy-efficient routes, as well as to solve problems related to finding the shortest Hamiltonian cycles and dynamically reconfiguring routes in a changing external environment. The paper presents the results of computational experiments, including algorithm testing in three-dimensional space and a comparative analysis with other routing algorithms. The computational experiment confirmed the effectiveness of the developed routing algorithm, including reduced computation time and improved energy efficiency of autonomous devices. The prospects for further research include integrating the proposed system into a wide range of applications for autonomous devices aimed at optimizing control processes and enhancing performance in a dynamically changing external environment. It is worth noting that the developed algorithm can be adapted to solve complex tasks where routing and wind generator placement on a plane are interrelated. The placement problem is directly connected to route construction for servicing these objects, which requires a comprehensive approach for an efficient solution. This will be part of a decision support system designed for the planning and servicing of wind power complexes, ensuring their effective operation and resource management. © 2025 St. Petersburg Federal Research Center of the Russian Academy of Sciences. All rights reserved.
KW  - ant colony optimization
KW  - energy systems
KW  - graph-based mathematical models
KW  - metaheuristic algorithm
KW  - routing
KW  - three-dimensional space modeling
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Buu, S.-J.
AU  - Cho, S.-B.
TI  - A Transformer network calibrated with fuzzy logic for phishing URL detection
PY  - 2025
T2  - Fuzzy Sets and Systems
VL  - 517
C7  - 109474
DO  - 10.1016/j.fss.2025.109474
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007010718&doi=10.1016%2fj.fss.2025.109474&partnerID=40&md5=a12b338f246e3a2da55060ac5d742cb9
AB  - In the field of cybersecurity, phishing attacks by leveraging deceptive URLs continue to be a formidable challenge. These attacks evolve continuously, often rendering traditional detection methods inadequate. Even powerful deep learning models lack the adaptability required to keep pace with rapidly shifting phishing tactics. In this paper, we propose a novel fuzzy-calibrated transformer network for phishing URL detection. This model integrates a transformer network with the expert knowledge offered by fuzzy logic, enhancing its ability to interpret and adapt to the complex patterns of phishing URLs. This integration addresses the limitations of previous models, particularly their dependence on historical data, which is often outdated as phishing strategies evolve. Empirical evaluations of the proposed model on real-world datasets, which include over a million URLs, demonstrate its superior accuracy and adaptability in detecting phishing URLs, particularly in identifying novel and emerging phishing tactics. In experiments simulating real-world phishing detection scenarios, our model achieves an accuracy of 98.93 %, with a precision of 98.54 %, recall of 97.84 %, and F1-score of 98.03 %, outperforming baseline models by 5 %p in accuracy, highlighing adaptability to evolving phishing strategies. © 2025 Elsevier B.V.
KW  - Cybersecurity
KW  - Deep learning
KW  - Fuzzy logic
KW  - Phishing URL detection
KW  - Transformer network
KW  - Digital arithmetic
KW  - Cyber security
KW  - Deep learning
KW  - Detection methods
KW  - Expert knowledge
KW  - Fuzzy-Logic
KW  - Learning models
KW  - Phishing
KW  - Phishing attacks
KW  - Phishing URL detection
KW  - Transformer network
KW  - Phishing
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Wang, Q.
AU  - Wang, L.
AU  - Xu, S.
AU  - Zhang, S.
AU  - Shao, W.
AU  - Mihaljevic, M.J.
TI  - Single-Layer Trainable Neural Network for Secure Inference
PY  - 2025
T2  - IEEE Internet of Things Journal
VL  - 12
IS  - 3
SP  - 2968
EP  - 2978
DO  - 10.1109/JIOT.2024.3480195
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207735290&doi=10.1109%2fJIOT.2024.3480195&partnerID=40&md5=99ad05e3e752080a43f034105e8f16ce
AB  - Secure neural network inference provides privacy guarantees for both the client and the server, and is an integral approach in Machine Learning as a Service Setting (MLaaS). However, the multilayer structure in the neural network introduces frequent activation function calculations, which causes large overhead. Most of the prior secure inference systems focused on designing cryptographic protocols to improve computational efficiency, but high computing and communication overhead are still bottlenecks in practicality. In this work, we refocus on the potential of shallow neural networks and propose a model with only one trainable layer to reduce the required computation. Our main contributions are in three-fold: 1) introduce training-free weights and formally prove their contribution in the model expressivity; 2) design the Self Enhanced Module that is more suitable for shallow models as an alternative for the activation function; and 3) propose a linear layer with multiscale and normalization property, named Nested & Norm Conv. We conduct extensive experiments on visual datasets and the results demonstrate the proposed single-layer trainable model holds promise as a viable platform for secure inference in practical applications.  © 2014 IEEE.
KW  - Activation component
KW  - convolution layer
KW  - neural networks
KW  - secure inference
KW  - Convolutional neural networks
KW  - Differential privacy
KW  - Network layers
KW  - Privacy by design
KW  - Activation component
KW  - Activation functions
KW  - Convolution layer
KW  - Integral approach
KW  - Machine-learning
KW  - Multilayer structures
KW  - Network inference
KW  - Neural-networks
KW  - Secure inference
KW  - Single layer
KW  - Multilayer neural networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Gui, F.
AU  - Yang, J.
AU  - Tang, Y.
AU  - Chen, H.
AU  - An, N.
TI  - Structured Life Narratives: Building Life Story Hierarchies with Graph-Enhanced Event Feature Refinement
PY  - 2024
T2  - Applied Sciences (Switzerland)
VL  - 14
IS  - 2
C7  - 918
DO  - 10.3390/app14020918
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192474286&doi=10.3390%2fapp14020918&partnerID=40&md5=8f6f065b65288f1df11a25246e8b807c
AB  - The life stories of older adults encapsulate an array of personal experiences that reflect their care needs. However, due to inherent fuzzy features, fragmented natures, repetition, and redundancies, the practical application of the life story approach poses challenges for caregivers in acquiring and comprehending these narratives. Addressing this challenge, our study introduces a novel approach called Life Story Hierarchies with Graph-Enhanced Event Feature Refinement (LSH-GEFR). LSH-GEFR constructs a bilayer graph. Firstly, the event element map leverages intricate relationships between event elements to extract environmental features, providing a detailed context for understanding each event element. Secondly, the event map explores the complex web of relationships between the events themselves, allowing LSH-GEFR to generate a comprehensive understanding of each event and enhance its representation. Subsequently, we conducted experiments on different datasets and found that, in comparison with four advanced event tree generation methods, the proposed LSH-GEFR method outperformed them in terms of path coherence, branch reasonableness, and overall readability when generating life story hierarchies. Over 84.91% of the structured life narratives achieved readability, marking a 5.96% increase over the best-performing approach at the baseline. © 2024 by the authors.
KW  - eldercare
KW  - event clustering
KW  - event fusion
KW  - Graph-Enhanced Event Feature Refinement
KW  - machine learning
KW  - structured life narratives
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Nambiar, S.
AU  - Jonsson, M.
AU  - Tarkian, M.
TI  - Automation in Unstructured Production Environments Using Isaac Sim: A Flexible Framework for Dynamic Robot Adaptability
PY  - 2024
T2  - Procedia CIRP
VL  - 130
SP  - 837
EP  - 846
DO  - 10.1016/j.procir.2024.10.173
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215000911&doi=10.1016%2fj.procir.2024.10.173&partnerID=40&md5=77fd99db027c938fbe26e21cd4363013
AB  - In response to the growing complexity of industrial automation requirements, this paper introduces a comprehensive framework tailored for the automation of industrial robots within unstructured production environments. The framework, emphasizing on adaptability and flexibility, seamlessly merges cutting-edge GPU-based physics engine, the Isaac Sim from Omniverse NVIDIA, with industrial robots, thereby laying the foundation for the development of a robust and versatile digital twin. This digital shadow serves as a main step towards the realization of digital twin technologies in dynamically evolving production environments, facilitating dynamic decision-making processes powered by real-time virtual environmental data. Furthermore, this paper show a compelling application scenario to underscore the practical relevance of the proposed framework. Specifically, the application case centers around a hospital test lab, an onsite facility charged with the preparation of tissue samples for subsequent evaluation by medical professionals. Presently, many of the lab's tasks are performed manually, underscoring the urgent need for increased automation to enhance efficiency and the working environment. The specific task targeted by this paper involves the re-stacking of microscope slides from a slider fixture to a holder in preparation for subsequent operations. The motivation behind the integration of more dynamic behavior into the robotic system stems from the unstructured nature of incoming samples, coupled with deficiencies in the digital information chain, all within the constraints of a cost-sensitive, non-expert setting. Proving the applicability of this framework in the current test case, it not only enhances efficiency in the hospital test lab scenario but also demonstrates its potential in more advanced applications within the manufacturing field, especially in environments with similar levels of complexity. By removing technical barriers and streamlining the exploration of digital twin applications, this paper contributes to the advancement of automation technologies and sets the stage for future developments in dynamic production environments. © 2024 The Authors. Published by Elsevier B.V.
KW  - Digital Twin
KW  - Dynamic Production
KW  - Industrial Robot
KW  - Financial markets
KW  - Fixtures (tooling)
KW  - Quality control
KW  - Toy manufacture
KW  - Cutting edges
KW  - Decision-making process
KW  - Dynamic decision making
KW  - Dynamic production
KW  - Environmental data
KW  - Flexible framework
KW  - Industrial automation
KW  - Physics engine
KW  - Production environments
KW  - Real- time
KW  - Robots
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Ge, Y.
AU  - Zhang, S.
AU  - Cai, Y.
AU  - Lu, T.
AU  - Wang, H.
AU  - Hui, X.
AU  - Wang, S.
TI  - Ontology based autonomous robot task processing framework
PY  - 2024
T2  - Frontiers in Neurorobotics
VL  - 18
C7  - 1401075
DO  - 10.3389/fnbot.2024.1401075
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193472861&doi=10.3389%2ffnbot.2024.1401075&partnerID=40&md5=f050b9631b4760102c128a5e5749a518
AB  - Introduction: In recent years, the perceptual capabilities of robots have been significantly enhanced. However, the task execution of the robots still lacks adaptive capabilities in unstructured and dynamic environments. Methods: In this paper, we propose an ontology based autonomous robot task processing framework (ARTProF), to improve the robot's adaptability within unstructured and dynamic environments. ARTProF unifies ontological knowledge representation, reasoning, and autonomous task planning and execution into a single framework. The interface between the knowledge base and neural network-based object detection is first introduced in ARTProF to improve the robot's perception capabilities. A knowledge-driven manipulation operator based on Robot Operating System (ROS) is then designed to facilitate the interaction between the knowledge base and the robot's primitive actions. Additionally, an operation similarity model is proposed to endow the robot with the ability to generalize to novel objects. Finally, a dynamic task planning algorithm, leveraging ontological knowledge, equips the robot with adaptability to execute tasks in unstructured and dynamic environments. Results: Experimental results on real-world scenarios and simulations demonstrate the effectiveness and efficiency of the proposed ARTProF framework. Discussion: In future work, we will focus on refining the ARTProF framework by integrating neurosymbolic inference. Copyright © 2024 Ge, Zhang, Cai, Lu, Wang, Hui and Wang.
KW  - knowledge representation
KW  - knowledge-enabled robot
KW  - ontology
KW  - service robot
KW  - task planning
KW  - Knowledge management
KW  - Object detection
KW  - Ontology
KW  - Robot Operating System
KW  - Robot programming
KW  - Dynamic environments
KW  - Knowledge-enabled robot
KW  - Knowledge-representation
KW  - Ontology's
KW  - Ontology-based
KW  - Robot tasks
KW  - Service robots
KW  - Task planning
KW  - Task-processing
KW  - Unstructured environments
KW  - algorithm
KW  - Article
KW  - automation
KW  - cognition
KW  - conceptual framework
KW  - convolution algorithm
KW  - convolutional neural network
KW  - data processing
KW  - deep learning
KW  - dynamic task planning
KW  - dynamics
KW  - human
KW  - information processing
KW  - knowledge
KW  - knowledge base
KW  - learning
KW  - manipulation operator
KW  - nerve cell network
KW  - object operation similarity model
KW  - ontology
KW  - perception
KW  - recognition
KW  - robotic process automation
KW  - task execution
KW  - task knowledge representation
KW  - visual information
KW  - Knowledge representation
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Hussain, S.A.
AU  - Williams, M.J.
AU  - Izquierdo, M.F.V.
AU  - Dumrongthai, P.
AU  - Wilasari, N.M.
AU  - Pramita, M.D.
AU  - Riedel, K.L.
AU  - Shah, S.
AU  - Anindita, F.
TI  - Revolutionizing Drilling Through Natural Fractures: Leveraging Causal Artificial Intelligence (AI) and Real-Time Feed Zone Monitoring
PY  - 2024
T2  - Society of Petroleum Engineers - ADIPEC 2024
DO  - 10.2118/222117-MS
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215107822&doi=10.2118%2f222117-MS&partnerID=40&md5=958cd33f89425216bdd13b2062f1a9aa
AB  - Geothermal operations face drilling challenges like stuck-pipe incidents, posing significant project risks. In this paper, we introduce a real-time monitoring system for early detection of natural fractures that correspond to permeable feed - subsurface areas where geothermal fluids enter the wellbore from surrounding rock formations. This system is integrated with the Stuck-Pipe Risk Advisor (SPRA), a novel tool we created that enhances drilling efficiency through causal artificial intelligence (AI) and semantic web technologies, aimed at revolutionizing geothermal drilling practices. Our approach integrates the real-time feed zone monitoring system with SPRA, to identify key risk factors for stuck-pipe incidents. The time-series analysis of drilling parameters like rate of penetration (ROP) and standpipe pressure (SPP) predicts the occurrence of feed zones, which triggers the mechanism to run the explainable decision support model and understand the causal relationships among the different formation and well properties in the proximity of feed zones. The system's use of semantic web technologies enhances transparency and aids in the comprehension of the predictive outputs, while a flow-diagram interface provides real-time visualizations of risk factors and potential interventions. Field application of this integrated workflow between the real-time monitoring system and SPRA, has demonstrated accurate prediction on the onset of feed zones, a key component in decreasing stuck pipe incidents. Observations confirm that proactive time series analysis of ROP and SPP across seven wells in three fields showed a 97% accuracy in early detection of feed zones that triggered the mechanism to predict risks of stuck pipe from the SPRA. Actionable insights based on a root-cause analysis diagram for drilling operators, provide real-time visualizations of risk factors, potential mitigations, and interactive explanations, empowering the wellsite team to reduce the frequency of stuck-pipe incidents, enhancing drilling efficiency, and contributing to the overall safety and success of geothermal drilling projects. The semantic annotations add further details to the causal links and risk factors involved, enhancing operational decision-making, and enabling continuous improvement for safe drilling practices. This integrated approach has been validated and endorsed by domain experts (drilling engineers and geologists), showing significant advancements in risk management and drilling efficiency. We present a pioneering neurosymbolic integration of causal AI with time-series analysis (neural) and semantic web technologies (symbolic) in geothermal drilling operations, marking a first in the industry. The SPRA's capability to predictively assess feed zones and preempt stuck pipe using real-time data analytics offers significant advancements in operational safety and efficiency. This innovative methodology not only improves hazard prevention but also provides engineers with actionable and understandable insights that enhance both immediate and long-term drilling operations success. Copyright 2024, Society of Petroleum Engineers.
KW  - Crack tips
KW  - Enhanced recovery
KW  - Exploratory oil well drilling
KW  - Gasoline
KW  - Geothermal fields
KW  - Geothermal wells
KW  - Mineral oils
KW  - Pipelines
KW  - Risk analysis
KW  - Risk assessment
KW  - Risk perception
KW  - Drilling efficiency
KW  - Drilling practices
KW  - Geothermal drilling
KW  - Natural fracture
KW  - Real time monitoring system
KW  - Real- time
KW  - Risk factors
KW  - Semantic Web technology
KW  - Stuck pipe
KW  - Time-series analysis
KW  - Risk management
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Adebayo, S.A.
AU  - Sathasiva, S.
AU  - Ali, M.K.M.
TI  - HornSAT Solver Using Agent-Based Modelling in Hopfield Network
PY  - 2022
T2  - Studies in Systems, Decision and Control
VL  - 444
SP  - 251
EP  - 263
DO  - 10.1007/978-3-031-04028-3_17
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140244390&doi=10.1007%2f978-3-031-04028-3_17&partnerID=40&md5=aac159b4301383ea846cfcb7c26c047a
AB  - Horn Satisfiability (HornSAT) problem has been undoubtedly used as a relevant logical rule in much research works of recent, this is not only because it has a special formation in logic programming but also poses interesting interpretations in artificial intelligence. So many attempts have been employed to solve HornSAT and the results are amazingly good, one area that has not seen intense exploration is solving HornSAt using the Agent-based modelling approach, an area we consider very important because of massively parallel computation leverage offered by the ABM. In this research, we implement HornSAT in an Agent-based model using NETLOGO as our platform and embedded horn clause as a logical rule in Hopfield neural network. We investigated the performance of the integration by global minima, local minima, hamming distance, and CPU time. The summary of our findings showed high proficiency in the performance of HornSAT in the Agent-based model, our model provided an additional option to the number of available algorithms that solve HornSAT with an additional user-friendly environment and interface that reduces the bulkiness of the program. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - ABM
KW  - Hopfield
KW  - HornSAT
KW  - Netlogo
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Chaccour, C.
AU  - Saad, W.
AU  - Debbah, M.
AU  - Han, Z.
AU  - Vincent Poor, H.
TI  - Less Data, More Knowledge: Building Next-Generation Semantic Communication Networks
PY  - 2025
T2  - IEEE Communications Surveys and Tutorials
VL  - 27
IS  - 1
SP  - 37
EP  - 76
DO  - 10.1109/COMST.2024.3412852
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196109771&doi=10.1109%2fCOMST.2024.3412852&partnerID=40&md5=ba14a8830dce61029d77c86c0034eff3
AB  - Semantic communication is viewed as a revolutionary paradigm that can potentially transform how we design and operate wireless communication systems. However, despite a recent surge of research activities in this area, remarkably, the research landscape is still limited in at least three ways. First and foremost, the definition of a "semantic communication system"is ambiguous and varies widely between different studies. This lack of consensus makes it challenging to develop rigorous and scalable frameworks for building semantic communication networks. Secondly, current approaches to building semantic communication networks are limited by their reliance on data-driven and information-driven AI-augmented networks. These networks remain "tied"to the data, which limits their ability to perform versatile logic. In contrast, knowledge-driven and reasoning-driven AI-native networks would allow for more flexible and powerful communication capabilities. However, there is currently a lack of technical foundations to support such networks. Thirdly, the concept of "semantic representation"is not well understood yet, and its role in embedding meaning and structure in data transferred across wireless network is still a subject of active research. The development of semantic representations that are minimalist, generalizable, and efficient is critical to enabling the transmitter and receiver to generate content via a minimally semantic representation. To address these limitations, in this tutorial, we propose the first rigorous and holistic vision of an end-to-end semantic communication network that is founded on novel concepts from artificial intelligence (AI), causal reasoning, transfer learning, and minimum description length theory. We first discuss how the design of semantic communication networks requires a move from data-driven AI-augmented networks, in which wireless networks remain "tied"to data, towards reasoning-driven AI-native networks which can perform versatile logic and generalizable intelligence. We then distinguish the concept of semantic communications from several other approaches that have been conflated with it. We opine that building effective and efficient semantic communication systems necessitates surpassing the creation of new encoder and decoder types at the transmitter/receiver side, or developing an "AI for wireless"framework that only extracts application features or fine-tunes wireless protocols/algorithms. Then, we identify the main tenets that are needed to build an end-to-end semantic communication network. Among those building blocks of a semantic communication network, we highlight the necessity of creating semantic representations of data that satisfy the key properties of minimalism, generalizability, and efficiency so as to faithfully represent the data and enable the transmitter and receiver to do more with less. We then explain how those representations can form the basis of a so-called semantic language that will allow a transmitter and receiver to communicate at a semantic level. We then concretely define the concept of reasoning by investigating the fundamentals of causal representation learning and their role in designing reasoning-driven semantic communication networks. For such reasoning-driven networks, we propose novel and essential semantic communication key performance indicators (KPIs) and metrics, including new "reasoning capacity"measures that could surpass Shannon's bound to capture the imminent convergence of computing and communication resources. Finally, we explain how semantic communications can be scaled to large-scale networks such as 6G and beyond cellular networks. In a nutshell, we expect this tutorial to provide a unified and self-contained reference on how to properly build, design, analyze, and deploy next-generation semantic communication networks. © 1998-2012 IEEE.
KW  - 6G
KW  - AI-native
KW  - beyond 6G
KW  - causality
KW  - knowledge
KW  - machine learning
KW  - reasoning
KW  - Semantic communications
KW  - semantic language
KW  - Artificial intelligence
KW  - Buildings
KW  - Computer circuits
KW  - Data communication systems
KW  - Learning systems
KW  - Telecommunication networks
KW  - Transmitters
KW  - Wireless networks
KW  - 6g
KW  - Artificial intelligence-native
KW  - Beyond 6g
KW  - Causality
KW  - Cognition
KW  - Knowledge
KW  - Machine-learning
KW  - Reasoning
KW  - Receiver
KW  - Semantic communication
KW  - Semantic language
KW  - Semantics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 25
ER  -

TY  - CHAP
AU  - Kirboga, K.K.
TI  - XAI in drug discovery
PY  - 2024
T2  - Explainable Artificial Intelligence (XAI) in Healthcare
SP  - 55
EP  - 64
DO  - 10.1201/9781003426073-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192533744&doi=10.1201%2f9781003426073-4&partnerID=40&md5=732ca6cc447c0a9a1b5b1fe534ec54c1
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Fabre, R.
AU  - Bellot, P.
AU  - Egret, D.
TI  - Challenging Scientific Categorizations Through Dispute Learning
PY  - 2025
T2  - Applied Sciences (Switzerland)
VL  - 15
IS  - 4
C7  - 2241
DO  - 10.3390/app15042241
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218639325&doi=10.3390%2fapp15042241&partnerID=40&md5=da888eead9d6f9f0b44c860fb52dbb23
AB  - Scientific dispute and scholarly debate have traditionally served as mechanisms for arbitrating between competing scientific categorizations. However, current AI technologies lack both the ethical framework and technical capabilities to handle the adversarial reasoning inherent in scientific discourse effectively. This creates a ‘categorization conundrum’ where new knowledge emerges from opaque black-box systems while simultaneously introducing unresolved vulnerabilities to errors and adversarial attacks. Our research addresses this challenge by examining how to preserve and enhance human dispute’s vital role in the creation, development, and resolution of knowledge categorization, supported by traceable AI assistance. Building on our previous work, which introduced GRAPHYP—a multiverse hypergraph representation of adversarial opinion profiles derived from multimodal web-based documentary traces—we present three key findings. First, we demonstrate that standardizing concepts and methods through ‘Dispute Learning’ not only expands the range of adversarial pathways in scientific categorization but also enables the identification of GRAPHYP model extensions. These extensions accommodate additional forms of human reasoning in adversarial contexts, guided by novel philosophical and methodological frameworks. Second, GRAPHYP’s support for human reasoning through graph-based visualization provides access to a broad spectrum of practical applications in decidable challenging categorizations, which we illustrate through selected case studies. Third, we introduce a hybrid analytical approach combining probabilistic and possibilistic methods, applicable to diverse classical research data types. We identify analytical by-products of GRAPHYP and examine their epistemological implications. Our discussion of standardized representations of documented adversarial uses highlights the enhanced value that structured dispute brings to elicit differential categorizations in the scientific discourse. © 2025 by the authors.
KW  - category assignment
KW  - diagrams of graphs
KW  - dialogical reasoning
KW  - dispute learning
KW  - human centric systems
KW  - hypernetwork
KW  - knowledge structure
KW  - possibilistic reasoning
KW  - Contrastive Learning
KW  - Generative adversarial networks
KW  - Knowledge graph
KW  - Category assignment
KW  - Diagram of graph
KW  - Dialogical reasoning
KW  - Dispute learning
KW  - Human centric system
KW  - Human-centric
KW  - Hypernetwork
KW  - Knowledge structures
KW  - Possibilistic reasoning
KW  - Scientific discourse
KW  - Adversarial machine learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Soltoggio, A.
AU  - Ben-Iwhiwhu, E.
AU  - Braverman, V.
AU  - Eaton, E.
AU  - Epstein, B.
AU  - Ge, Y.
AU  - Halperin, L.
AU  - How, J.
AU  - Itti, L.
AU  - Jacobs, M.A.
AU  - Kantharaju, P.
AU  - Le, L.
AU  - Lee, S.
AU  - Liu, X.
AU  - Monteiro, S.T.
AU  - Musliner, D.
AU  - Nath, S.
AU  - Panda, P.
AU  - Peridis, C.
AU  - Pirsiavash, H.
AU  - Parekh, V.
AU  - Roy, K.
AU  - Shperberg, S.
AU  - Siegelmann, H.T.
AU  - Stone, P.
AU  - Vedder, K.
AU  - Wu, J.
AU  - Yang, L.
AU  - Zheng, G.
AU  - Kolouri, S.
TI  - A collective AI via lifelong learning and sharing at the edge
PY  - 2024
T2  - Nature Machine Intelligence
VL  - 6
IS  - 3
SP  - 251
EP  - 264
DO  - 10.1038/s42256-024-00800-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188545268&doi=10.1038%2fs42256-024-00800-2&partnerID=40&md5=81d2e69477ad84fd02292fc15ab56e38
AB  - One vision of a future artificial intelligence (AI) is where many separate units can learn independently over a lifetime and share their knowledge with each other. The synergy between lifelong learning and sharing has the potential to create a society of AI systems, as each individual unit can contribute to and benefit from the collective knowledge. Essential to this vision are the abilities to learn multiple skills incrementally during a lifetime, to exchange knowledge among units via a common language, to use both local data and communication to learn, and to rely on edge devices to host the necessary decentralized computation and data. The result is a network of agents that can quickly respond to and learn new tasks, that collectively hold more knowledge than a single agent and that can extend current knowledge in more diverse ways than a single agent. Open research questions include when and what knowledge should be shared to maximize both the rate of learning and the long-term learning performance. Here we review recent machine learning advances converging towards creating a collective machine-learned intelligence. We propose that the convergence of such scientific and technological advances will lead to the emergence of new types of scalable, resilient and sustainable AI systems. © Springer Nature Limited 2024.
KW  - Artificial intelligence
KW  - Learning systems
KW  - Artificial intelligence systems
KW  - Common languages
KW  - Decentralised
KW  - Learn+
KW  - Life long learning
KW  - Local communications
KW  - Local data
KW  - One visions
KW  - Separate unit
KW  - Single-agent
KW  - Knowledge management
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 19
ER  -

TY  - CONF
AU  - Chen, B.
AU  - Marussy, K.
AU  - Pilarski, S.
AU  - Semeráth, O.
AU  - Varro, D.
TI  - Consistent Scene Graph Generation by Constraint Optimization
PY  - 2022
T2  - ACM International Conference Proceeding Series
C7  - 25
DO  - 10.1145/3551349.3560433
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146966522&doi=10.1145%2f3551349.3560433&partnerID=40&md5=a6b7fa1a9413ad5c0b94f65fa25c089c
AB  - Scene graph generation takes an image and derives a graph representation of key objects in the image and their relations. This core computer vision task is often used in autonomous driving, where traditional software and machine learning (ML) components are used in tandem. However, in such a safety-critical context, valid scene graphs can be further restricted by consistency constraints captured by domain or safety experts. Existing ML approaches for scene graph generation focus exclusively on relation-level accuracy but provide little to no guarantee that consistency constraints are satisfied in the generated scene graphs. In this paper, we aim to complement existing ML-based approaches by a post-processing step using constraint optimization over probabilistic scene graphs that can (1) guarantee that no consistency constraints are violated and (2) improve the overall accuracy of scene graph generation by fixing constraint violations. We evaluate the effectiveness of our approach using well-known, and novel metrics in the context of two popular ML datasets augmented with consistency constraints and two ML-based scene graph generation approaches as baselines.  © 2022 Owner/Author.
KW  - consistency constraints
KW  - constraint optimization
KW  - machine learning
KW  - probabilistic logic programming
KW  - scene graph generation
KW  - Computer vision
KW  - Graphic methods
KW  - Machine components
KW  - Machine learning
KW  - Probabilistic logics
KW  - Safety engineering
KW  - Autonomous driving
KW  - Consistency constraints
KW  - Constraint optimizations
KW  - Graph generation
KW  - Graph representation
KW  - Key object
KW  - Machine-learning
KW  - Probabilistic logic programming
KW  - Scene graph generation
KW  - Scene-graphs
KW  - Constrained optimization
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Rawas, S.
TI  - AI: the future of humanity
PY  - 2024
T2  - Discover Artificial Intelligence
VL  - 4
IS  - 1
C7  - 25
DO  - 10.1007/s44163-024-00118-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190671728&doi=10.1007%2fs44163-024-00118-3&partnerID=40&md5=7ed8096bb686ecbde5961577cfc64a04
AB  - Artificial intelligence (AI) is reshaping humanity's future, and this manuscript provides a comprehensive exploration of its implications, applications, challenges, and opportunities. The revolutionary potential of AI is investigated across numerous sectors, with a focus on addressing global concerns. The influence of AI on areas such as healthcare, transportation, banking, and education is revealed through historical insights and conversations on different AI systems. Ethical considerations and the significance of responsible AI development are addressed. Furthermore, this study investigates AI's involvement in addressing global issues such as climate change, public health, and social justice. This paper serves as a resource for policymakers, researchers, and practitioners understanding the complex link between AI and humans. © The Author(s) 2024.
KW  - Applications of AI
KW  - Artificial Intelligence
KW  - Challenges and risks
KW  - Ethical implications
KW  - Future of humanity
KW  - Global challenges
KW  - Climate change
KW  - Ethical technology
KW  - Application of artificial intelligence
KW  - Artificial intelligence systems
KW  - Challenge and risk
KW  - Ethical considerations
KW  - Ethical implications
KW  - Future of humanity
KW  - Global challenges
KW  - Global issues
KW  - Policy makers
KW  - Social justice
KW  - Artificial intelligence
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 23
ER  -

TY  - CHAP
AU  - Izzo, D.
AU  - Hadjiivanov, A.
AU  - Dold, D.
AU  - Meoni, G.
AU  - Blazquez, E.
TI  - Neuromorphic Computing and Sensing in Space
PY  - 2023
T2  - Artificial Intelligence for Space: AI4SPACE: Trends, Applications, and Perspectives
SP  - 107
EP  - 159
DO  - 10.1201/9781003366386-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180043973&doi=10.1201%2f9781003366386-4&partnerID=40&md5=ebfabfe0dac61c9c90dd939aac76016e
AB  - The recent success of AI comes at the price of high data and power demands. However, this success also rekindled a lot of interest in revisiting biology to explore and develop novel bio-inspired sensor and computing architectures, promising to not only reduce the power and data footprints of current technologies, but also uncover novel paradigms and technologies altogether. In this chapter, we review the potential opportunities of emerging neuromorphic technologies for edge computing and learning in space, focusing on preliminary results in the areas of event-based sensing, spiking neural networks and neuromorphic hardware for onboard applications. © 2024 selection and editorial matter, Matteo Madi and Olga Sokolova; individual chapters, the contributors.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Bao, Y.
AU  - Xing, T.
AU  - Chen, X.
TI  - Confidence-based interactable neural-symbolic visual question answering
PY  - 2024
T2  - Neurocomputing
VL  - 564
C7  - 126991
DO  - 10.1016/j.neucom.2023.126991
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176375617&doi=10.1016%2fj.neucom.2023.126991&partnerID=40&md5=59458c173fda77c3716554e6c9d493e2
AB  - Visual question answering (VQA) task demands proficiency in processing multi-modal information, and the ability to reason effectively using the information. One promising method for this task is neural-symbolic (NS) learning, which leverages the strengths of both neural network (NN) learning and symbolic reasoning to achieve efficient VQA. However, current NS approaches do not account for the uncertain nature of NN learning and can only provide a single answer to a question without any indication of its confidence, thereby limiting their ability to handle incorrect reasoning. To address this limitation, we propose a confidence-based neural-symbolic (CBNS) approach, which evaluates the confidence of the NN inferences based on uncertainty quantification and makes confidence-based reasoning. The proposed approach comprises three main components: (1) a probabilistic question parser that generates multiple program candidates, each with a corresponding confidence evaluation; (2) a probabilistic scene perception module that provides object-based scene representation and confidence evaluations for each attribute of objects in an image; and (3) a confidence-based program executor that provides answers with confidence evaluations throughout the inference process by leveraging the confidence evaluations of the scene representation and programs. Additionally, we present a data augmentation method to improve the training efficiency of NS learning. The proposed approach allows user interactions and feedback on the weak links based on confidence evaluations. Experiments on CLEVR and GQA datasets demonstrate that the proposed approach was effective in identifying the correctness of predictions and led to a promising performance improvement with a significantly reduced computation cost. © 2023 Elsevier B.V.
KW  - Confidence-based neural-symbolic methods
KW  - Interactable neural-symbolic methods
KW  - Visual question answering
KW  - Confidence-based neural-symbolic method
KW  - Interactable neural-symbolic method
KW  - Neural network learning
KW  - Probabilistics
KW  - Question Answering
KW  - Scene representation
KW  - Symbolic learning
KW  - Symbolic methods
KW  - Visual question answering
KW  - article
KW  - learning
KW  - perception
KW  - prediction
KW  - reasoning
KW  - uncertainty
KW  - Neural networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 11
ER  -

TY  - JOUR
AU  - De Felice, F.
AU  - Petrillo, A.
AU  - Iovine, G.
AU  - Salzano, C.
AU  - Baffo, I.
TI  - How Does the Metaverse Shape Education? A Systematic Literature Review
PY  - 2023
T2  - Applied Sciences (Switzerland)
VL  - 13
IS  - 9
C7  - 5682
DO  - 10.3390/app13095682
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159380761&doi=10.3390%2fapp13095682&partnerID=40&md5=af2fb57063d2b66ec2652d498fb69fde
AB  - In recent years, the potential of the metaverse as a tool to connect people has been increasingly recognized. The opportunities offered by the metaverse seem enormous in many sectors and fields of application. However, on the academic side, although a growing number of papers have been found to address the adoption of the metaverse, a clear overview of the solutions in place and their impact on education has been largely neglected so far. In the context of increasing challenges found with the metaverse, this review aims to investigate the role of the metaverse as tool in education. This contribution aims to address this research gap by offering a state-of-the-art analysis of the role the metaverse plays in education in relation to the future of work. The study is based on a systematic review approach performed by means of the Preferred Reporting Items for Systematic Review and Meta-Analyses (PRISMA) protocol. The findings of this research help us to better understand the benefits, potential and risks of the metaverse as a tool for immersive and innovative learning experiences. Implications are discussed and streams for future investigation are identified. © 2023 by the authors.
KW  - artificial intelligence
KW  - blockchain
KW  - e-learning
KW  - education
KW  - horizon workrooms
KW  - metaverse
KW  - virtual reality
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 43
ER  -

TY  - JOUR
AU  - Matejek, B.
AU  - Gehani, A.
AU  - Bastian, N.D.
AU  - Clouse, D.J.
AU  - Kline, B.
AU  - Jha, S.
TI  - SAFE-NID: Self-Attention with Normalizing-Flow Encodings for Network Intrusion Detection
PY  - 2025
T2  - Transactions on Machine Learning Research
VL  - 2025-March
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001574882&partnerID=40&md5=1576e72b4c6ce7b20e042bacd3f5761b
AB  - Machine learning models are increasingly adopted to monitor network traffic and detect intrusions. In this work, we introduce SAFE-NID, a novel machine learning approach for real-time packet-level traffic monitoring and intrusion detection that includes a safeguard to detect zero day attacks as out-of-distribution inputs. Unlike traditional models, which falter against zero-day attacks and concept drift, SAFE-NID leverages a lightweight encoder-only transformer architecture combined with a novel normalizing flows-based safeguard. This safeguard not only quantifies uncertainty but also identifies out-of-distribution (OOD) in-puts, enabling robust performance in dynamic threat landscapes. Our generative model learns class-conditional representations of the internal features of the deep neural network. We demonstrate the effectiveness of our approach by converting publicly available network flow-level intrusion datasets into packet-level ones. We release the labeled packet-level ver-sions of these datasets with over 50 million packets each and describe the challenges in creating these datasets. We withhold from the training data certain attack categories to simulate zero-day attacks. Existing deep learning models, which achieve an accuracy of over 99% when detecting known attacks, only correctly classify 1% of the novel attacks. Our proposed transformer architecture with normalizing flows model safeguard achieves an area under the receiver operating characteristic curve of over 0.97 in detecting these novel inputs, outperforming existing combinations of neural architectures and model safeguards. The additional latency in processing each packet by the safeguard is a small fraction of the overall inference task. This dramatic improvement in detecting zero-day attacks and distribution shifts emphasizes SAFE-NID’s novelty and utility as a reliable and efficient safety monitoring tool for real-world network intrusion detection. © 2025, Transactions on Machine Learning Research. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Yılmaz, C.
AU  - Ozgun, A.
AU  - Erol, B.A.
AU  - Gumus, A.
TI  - Open-Source Visual Target-Tracking System Both on Simulation Environment and Real Unmanned Aerial Vehicles
PY  - 2024
T2  - EAI/Springer Innovations in Communication and Computing
SP  - 147
EP  - 159
DO  - 10.1007/978-3-031-52760-9_11
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189545876&doi=10.1007%2f978-3-031-52760-9_11&partnerID=40&md5=7043f3e42e792475229ef48354abaa75
AB  - This work presents an investigation into the domain of dynamic target tracking through object detection, particularly emphasizing the context of open-source applications like PX4, ROS, and YOLO. Over the years, achieving real-time object tracking on UAVs in dynamic environments has been a formidable challenge, necessitating offline computations or substantial onboard processing resources. However, contemporary UAVs are now equipped with advanced edge embedded devices, sensors, and cameras, enabling the integration of deep learning-based vision applications. This advancement offers the prospect of directly deploying cutting-edge applications onto UAVs, thereby expanding their utility in areas such as surveillance, search and rescue, and videography. To fully harness the potential of these vision applications, a communication infrastructure interfacing with the UAV’s underneath closed controllers becomes imperative. We’ve developed an integrated visual target-tracking system that connects a flight controller unit with a graphical unit by leveraging ROS tools and open-source deep learning packages. The overall integrated system based on ROS, deep learning applications, and custom PID controllers is shared on GitHub as open-source software package in a way that benefits everyone interested: https://github.com/miralab-ai/vision-ROS. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - Computer Vision
KW  - ROS
KW  - Sim2Real
KW  - UAV
KW  - Visual Target Tracking
KW  - YOLOv7-Tiny
KW  - Aircraft detection
KW  - Antennas
KW  - Application programs
KW  - Clutter (information theory)
KW  - Computer vision
KW  - Controllers
KW  - Deep learning
KW  - Object detection
KW  - Open source software
KW  - Open systems
KW  - Security systems
KW  - Three term control systems
KW  - Video recording
KW  - Aerial vehicle
KW  - Dynamic target
KW  - Open-source
KW  - ROS
KW  - Sim2real
KW  - Simulation environment
KW  - Target tracking systems
KW  - Vision applications
KW  - Visual target tracking
KW  - YOLOv7-tiny
KW  - Unmanned aerial vehicles (UAV)
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Wein, S.
AU  - Opitz, J.
TI  - A Survey of AMR Applications
PY  - 2024
T2  - EMNLP 2024 - 2024 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference
SP  - 6856
EP  - 6875
DO  - 10.18653/v1/2024.emnlp-main.390
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212535888&doi=10.18653%2fv1%2f2024.emnlp-main.390&partnerID=40&md5=460bead496f7c7299a3da792cd785bb9
AB  - In the ten years since the development of the Abstract Meaning Representation (AMR) formalism, substantial progress has been made on AMR-related tasks such as parsing and alignment. Still, the engineering applications of AMR are not fully understood. In this survey, we categorize and characterize more than 100 papers which use AMR for downstream tasks-the first survey of this kind for AMR. Specifically, we highlight (1) the range of applications for which AMR has been harnessed, and (2) the techniques for incorporating AMR into those applications. We also detect broader AMR engineering patterns and outline areas of future work that seem ripe for AMR incorporation. We hope that this survey will be useful to those interested in using AMR and that it sparks discussion on the role of symbolic representations in the age of neural-focused NLP research. © 2024 Association for Computational Linguistics.
KW  - Down-stream
KW  - Engineering applications
KW  - Engineering patterns
KW  - Representation formalisms
KW  - Symbolic representation
KW  - Computational linguistics
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Zhang, Y.
AU  - Yu, H.
TI  - LR-XFL: Logical Reasoning-Based Explainable Federated Learning
PY  - 2024
T2  - Proceedings of the AAAI Conference on Artificial Intelligence
VL  - 38
IS  - 19
SP  - 21788
EP  - 21796
DO  - 10.1609/aaai.v38i19.30179
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189630560&doi=10.1609%2faaai.v38i19.30179&partnerID=40&md5=e1143e054bcf6c2997bafa3abded4dc8
AB  - Federated learning (FL) is an emerging approach for training machine learning models collaboratively while preserving data privacy. The need for privacy protection makes it difficult for FL models to achieve global transparency and explainability. To address this limitation, we incorporate logic-based explanations into FL by proposing the Logical Reasoning-based eXplainable Federated Learning (LR-XFL) approach. Under LR-XFL, FL clients create local logic rules based on their local data and send them, along with model updates, to the FL server. The FL server connects the local logic rules through a proper logical connector that is derived based on properties of client data, without requiring access to the raw data. In addition, the server also aggregates the local model updates with weight values determined by the quality of the clients' local data as reflected by their uploaded logic rules. The results show that LR-XFL outperforms the most relevant baseline by 1.19%, 5.81% and 5.41% in terms of classification accuracy, rule accuracy and rule fidelity, respectively. The explicit rule evaluation and expression under LR-XFL enable human experts to validate and correct the rules on the server side, hence improving the global FL model's robustness to errors. It has the potential to enhance the transparency of FL models for areas like healthcare and finance where both data privacy and explainability are important. Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.
KW  - Computer circuits
KW  - Learning systems
KW  - Privacy-preserving techniques
KW  - Learning approach
KW  - Learning models
KW  - Local data
KW  - Logic rules
KW  - Logical reasoning
KW  - Machine learning models
KW  - Model updates
KW  - Privacy protection
KW  - Rule based
KW  - Training machines
KW  - Transparency
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Chkroun, M.
AU  - Azaria, A.
TI  - A safe collaborative chatbot for smart home assistants
PY  - 2021
T2  - Sensors
VL  - 21
IS  - 19
C7  - 6641
DO  - 10.3390/s21196641
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116374007&doi=10.3390%2fs21196641&partnerID=40&md5=e753c092ad51f3d89f7c5634788a13b1
AB  - Smart home assistants, which enable users to control home appliances and can be used for holding entertaining conversations, have become an inseparable part of many people’s homes. Recently, there have been many attempts to allow end-users to teach a home assistant new commands, responses, and rules, which can then be shared with a larger community. However, allowing end-users to teach an agent new responses, which are shared with a large community, opens the gate to malicious users, who can teach the agent inappropriate responses in order to promote their own business, products, or political views. In this paper, we present a platform that enables users to collaboratively teach a smart home assistant (or chatbot) responses using natural language. We present a method of collectively detecting malicious users and using the commands taught by the malicious users to further mitigate activity of future malicious users. We ran an experiment with 192 subjects and show the effectiveness of our platform. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.
KW  - Collaborative smart home assistants
KW  - Human–agent interaction
KW  - Mitigating offensive behavior
KW  - Smart environments
KW  - Domestic appliances
KW  - Intelligent buildings
KW  - Business products
KW  - Chatbots
KW  - Collaborative smart home assistant
KW  - End-users
KW  - Human-agent interaction
KW  - Mitigating offensive behavior
KW  - Natural languages
KW  - Political views
KW  - Smart environment
KW  - Smart homes
KW  - adult
KW  - article
KW  - female
KW  - human
KW  - human experiment
KW  - language
KW  - major clinical study
KW  - male
KW  - Automation
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - JOUR
AU  - Ciatto, G.
AU  - Calegari, R.
AU  - Omicini, A.
TI  - 2P-KT: A logic-based ecosystem for symbolic AI
PY  - 2021
T2  - SoftwareX
VL  - 16
C7  - 100817
DO  - 10.1016/j.softx.2021.100817
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122782224&doi=10.1016%2fj.softx.2021.100817&partnerID=40&md5=b40139d49e689952ad9946228524f261
AB  - To date, logic-based technologies are either built on top or as extensions of the Prolog language, mostly working as monolithic solutions tailored upon specific inference procedures, unification mechanisms, or knowledge representation techniques. Instead, to maximise their impact, logic-based technologies should support and enable the general-purpose exploitation of all the manifold contributions from logic programming. Accordingly, we present 2P-KT, a reboot of the tuProlog project offering a general, extensible, and interoperable ecosystem for logic programming and symbolic AI. © 2021 The Authors
KW  - Artificial intelligence
KW  - Kotlin
KW  - Logic programming
KW  - Prolog
KW  - tuProlog
KW  - Computer circuits
KW  - Ecosystems
KW  - Knowledge representation
KW  - PROLOG (programming language)
KW  - Knowledge-representation
KW  - Kotlin
KW  - Logic based technology
KW  - Logic-programming
KW  - Monolithic solutions
KW  - Prolog
KW  - Representation techniques
KW  - Tuprolog
KW  - Logic programming
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 11
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Liu, Y.
AU  - Bai, R.
AU  - Chen, H.
AU  - Li, J.
AU  - Chen, X.
AU  - Yao, L.
AU  - Zhao, J.
AU  - Chu, F.
TI  - Multi-modal multi-scale multi-level fusion quadrant entropy for mechanical fault diagnosis
PY  - 2025
T2  - Expert Systems with Applications
VL  - 281
C7  - 127715
DO  - 10.1016/j.eswa.2025.127715
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002858490&doi=10.1016%2fj.eswa.2025.127715&partnerID=40&md5=5a69271bfbe1d99639c098d7877d0147
AB  - Compared to single-sensor fault diagnosis models, multi-sensor information fusion models utilize potential fault information from various sensors for more precise fault diagnosis. However, most fusion models require many training samples to construct accurate models. Collecting these data is costly and challenging, increasing the time needed to build the training model. These models typically fuse information from multiple vibration sensors, with limited research on multi-modal information fusion, such as combining vibration and acoustic data. Additionally, the generality of existing models is weak, often requiring structural and parameter adjustments for different diagnostic tasks. To address these challenges, this paper proposes a high-accuracy and high-efficiency mechanical fault diagnosis model based on the multi-modal multi-scale multi-level fusion quadrant entropy (MMMFQE) using limited training samples. The proposed MMMFQE theory effectively constructs multi-modal information fusion feature maps across multiple scales and levels. The fusion quadrant entropy is then proposed to accurately characterize the mechanical states by analyzing the complexities of fusion feature maps. Analysis of two industrial datasets shows that the proposed model achieves 100% and 99.46% accuracy with only five training samples per state. Moreover, the accuracy, efficiency, and few-shot ability of the proposed model surpass those of several advanced models. © 2025 Elsevier Ltd
KW  - Fusion quadrant entropy
KW  - Information fusion
KW  - Mechanical fault diagnosis
KW  - Support vector machine
KW  - Sensor data fusion
KW  - Fault diagnosis model
KW  - Fusion features
KW  - Fusion quadrant entropy
KW  - Mechanical faults diagnosis
KW  - Multi level fusion
KW  - Multi-modal
KW  - Multi-scales
KW  - Multimodal information fusion
KW  - Support vectors machine
KW  - Training sample
KW  - Information fusion
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Manjarres, J.C.
AU  - Cardoso, D.O.
AU  - Klautau, A.
AU  - de Rezende, J.F.
TI  - A WiSARD Network Approach for 5G MIMO Beam Selection
PY  - 2024
T2  - Lecture Notes in Networks and Systems
VL  - 1174 LNNS
SP  - 360
EP  - 373
DO  - 10.1007/978-3-031-74003-9_29
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215960084&doi=10.1007%2f978-3-031-74003-9_29&partnerID=40&md5=3c9539aafd3b4d72286bfec4ce247bdb
AB  - The integration of context information and machine learning techniques can enhance the capabilities of 5G/6G networks when dealing with the beam selection problem. This paper proposes the use of a Weightless Neural Network (WiSARD) with multimodal data as input to address this problem. The performance of the WiSARD is compared to classic machine learning algorithms (KNN, Decision Tree, SVC, Random Forest) based on the top-k accuracy in a vehicular network. The simulation results indicate that the WiSARD is a competitive method for this scenario and can be a valuable asset for future cellular networks. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - 5G
KW  - AI
KW  - Beam selection
KW  - machine learning
KW  - Mm-wave
KW  - WiSARD network
KW  - Adaptive boosting
KW  - Carrier sense multiple access
KW  - Cellular neural networks
KW  - Decision trees
KW  - Random forests
KW  - Vehicular ad hoc networks
KW  - 5g
KW  - Beam selection
KW  - Context information
KW  - Machine learning techniques
KW  - Machine-learning
KW  - Mm waves
KW  - Multi-modal
KW  - Selection problems
KW  - Weightless neural networks
KW  - WiSARD network
KW  - 5G mobile communication systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Wortmann, T.
AU  - Herschel, M.
AU  - Staab, S.
AU  - Tarín, C.
TI  - AI for AEC
ST  - AI for AEC: KI für Bauplanung und Bau
PY  - 2022
T2  - Bautechnik
VL  - 99
IS  - 10
SP  - 711
EP  - 719
DO  - 10.1002/bate.202200070
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139080725&doi=10.1002%2fbate.202200070&partnerID=40&md5=3c1ec81998baca8812a1b05a833e913b
AB  - AI for AEC. The article surveys current methods of data integration, artificial intelligence (AI), optimization, and control and their (potential) applications in architecture, engineering and construction. The survey includes symbolic AI-methods as well as subsymbolic AI methods, i. e., machine learning. The article presents these methods in the context of applications that provide insight into current research projects at the Cluster of Excellence “Integrative Computational Design and Construction for Architecture” (IntCDC) at the University of Stuttgart: (1) Data integration to link data silos in design and construction processes, (2) knowledge graphs to represent knowledge in multidisciplinary design processes, (3) automated planning for scheduling and distribution of construction tasks, (4) supervised learning to estimate the results of expensive building simulations such as operational energy or of the behavior of natural materials such as wood, (5) unsupervised learning to visualize optimization results, (6) reinforcement learning for building with fibers and bamboo, and (8) control for construction robotics. The article concludes that integrative computational design and construction requires the cooperation of humans, material, and machines, and that AI – instead of merely automating design and construction processes – can moderate this cooperation. © 2022, Ernst und Sohn. All rights reserved.
KW  - AI for AEC
KW  - automated planning
KW  - Building, Information Modelling
KW  - co-design
KW  - control systems
KW  - data integration
KW  - Digital design/Optimization
KW  - IT/Automatical/CAD
KW  - knowledge graphs
KW  - optimization
KW  - reinforcement learning
KW  - supervised learning
KW  - unsupervised learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Borghoff, U.M.
AU  - Bottoni, P.
AU  - Pareschi, R.
TI  - Human-artificial interaction in the age of agentic AI: a system-theoretical approach
PY  - 2025
T2  - Frontiers in Human Dynamics
VL  - 7
C7  - 1579166
DO  - 10.3389/fhumd.2025.1579166
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006445358&doi=10.3389%2ffhumd.2025.1579166&partnerID=40&md5=680b6c440eece9e8f1c813be9d024a5c
AB  - This paper presents a novel perspective on human-computer interaction (HCI), framing it as a dynamic interplay between human and computational agents within a networked system. Going beyond traditional interface-based approaches, we emphasize the importance of coordination and communication among heterogeneous agents with different capabilities, roles, and goals. The paper distinguishes between Multi-Agent Systems (MAS)—where agents maintain autonomy through structured cooperation—and Centaurian systems, which integrate human and AI capabilities for unified decision making. To formalize these interactions, we introduce a framework for communication spaces, structured into surface, observation, and computation layers, ensuring seamless integration between MAS and Centaurian architectures, where colored Petri nets effectively represent structured Centaurian systems and high-level reconfigurable networks address the dynamic nature of MAS. We recognize that elements such as task recommendation, feedback loops, and natural language interfaces are common in contemporary adaptive HCI. What distinguishes our framework is not the introduction of these elements per se, but the synthesis of architectural principles that systematically accommodate both autonomy-preserving and integration-seeking configurations within a shared formal foundation. Our research has practical applications in autonomous robotics, human-in-the-loop decision making, and AI-driven cognitive architectures, and provides a foundation for next-generation hybrid intelligence systems that balance structured coordination with emergent behavior. Copyright © 2025 Borghoff, Bottoni and Pareschi.
KW  - Centaurian systems
KW  - communication spaces
KW  - large action models (LAMs)
KW  - multi-agent systems
KW  - satellite and swarm robots
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Atzmueller, M.
AU  - Fürnkranz, J.
AU  - Kliegr, T.
AU  - Schmid, U.
TI  - Explainable and interpretable machine learning and data mining
PY  - 2024
T2  - Data Mining and Knowledge Discovery
VL  - 38
IS  - 5
SP  - 2571
EP  - 2595
DO  - 10.1007/s10618-024-01041-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200029394&doi=10.1007%2fs10618-024-01041-y&partnerID=40&md5=81653944b2f4521108a24291712834c5
AB  - The growing number of applications of machine learning and data mining in many domains—from agriculture to business, education, industrial manufacturing, and medicine—gave rise to new requirements for how to inspect and control the learned models. The research domain of explainable artificial intelligence (XAI) has been newly established with a strong focus on methods being applied post-hoc on black-box models. As an alternative, the use of interpretable machine learning methods has been considered—where the learned models are white-box ones. Black-box models can be characterized as representing implicit knowledge—typically resulting from statistical and neural approaches of machine learning, while white-box models are explicit representations of knowledge—typically resulting from rule-learning approaches. In this introduction to the special issue on ‘Explainable and Interpretable Machine Learning and Data Mining’ we propose to bring together both perspectives, pointing out commonalities and discussing possibilities to integrate them. © The Author(s) 2024.
KW  - Explainable AI
KW  - Explainable and interpretable data mining
KW  - Explainable and interpretable machine learning
KW  - Hybrid artificial intelligence
M3  - Editorial
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 8
ER  -

TY  - JOUR
AU  - Wirawan, I.M.
AU  - Wibawa, A.P.
AU  - Widiyanintyas, T.
TI  - Photovoltaic Energy Anomaly Detection using Transformer Based Machine Learning
PY  - 2024
T2  - International Journal of Robotics and Control Systems
VL  - 4
IS  - 3
SP  - 1337
EP  - 1352
DO  - 10.31763/ijrcs.v4i3.1260
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203704451&doi=10.31763%2fijrcs.v4i3.1260&partnerID=40&md5=c3d75e524623af5ae4d7e5d0f455e4e8
AB  - This study uses the Anomaly Transformer model to find anomalies in photovoltaic energy generation in Malang, Indonesia. The main background of this study is the lack of satellite monitoring in this region and the importance of annual data for electricity generation forecasting. Temperature scattered direct solar radiation, and hourly electricity production are all part of the dataset used which is only available since 2019. Anomalies were detected at 05.00 and 16.00 WIB, indicating instability in the energy supply due to high temperatures in the morning and heavy rain in the afternoon. Detection of these anomalies is important to improve the efficiency and reliability of photovoltaic systems, reduce operational costs, and reduce the risk of system failure. Indonesia has many challenges for photovoltaic energy generation due to its unique location, with many islands located close to the equator. The use of the Anomaly Transformer algorithm improves the accuracy of anomaly detection over conventional methods. This algorithm helps to find complex patterns in very large time series. The results show that the anomaly transformer model can effectively detect anomalous patterns. It offers ideas to improve the stability and efficiency of photovoltaic systems in Malang and other areas with comparable environmental conditions. Improved energy efficiency and environmental sustainability are the results of anomaly pattern detection. © 2024, Association for Scientific Computing Electronics and Engineering (ASCEE). All rights reserved.
KW  - Anomaly Detection
KW  - Photovoltaic Energy
KW  - Time Series
KW  - Transformers Anomaly
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Loia, F.
AU  - Capolupo, N.
AU  - Adinolfi, P.
TI  - Training me softly. Metaverse-based immersive and gamified learning through a knowledge management perspective
PY  - 2025
T2  - Journal of Knowledge Management
VL  - 29
IS  - 5
SP  - 1465
EP  - 1489
DO  - 10.1108/JKM-08-2024-0929
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003762317&doi=10.1108%2fJKM-08-2024-0929&partnerID=40&md5=64e6fb64a871f6f1042bbbf12a11a30d
AB  - Purpose: The digital revolution, the growing demand for organizational agility, the holistic capabilities of human resources and the pandemic crisis are driving revolutionary changes within and outside organizational boundaries. This paper aims to explore the potential of the metaverse to advance organizational learning and knowledge sharing in the evolving digital landscape. Moreover, it investigates the potential and challenges related to the adoption of the metaverse for organizational learning and knowledge management. Design/methodology/approach: Multiple case studies were carried out using a structured approach to collect data, including interviews, analysis of publicly available information and participant observation. Findings: The findings shed light on the metaverse’s potential to enhance organizational learning and knowledge in the new digital era through immersive training, developing soft and hard skills and team-building activities. They also show the impact of knowledge management processes in organizations through gamified logic. Challenges for companies are also critically highlighted. Practical implications: Implications are drawn for both scholars and managers in terms of experiential learning and knowledge management, stemming from the potential of the metaverse that, beyond “hard” skills, could act as a strategic mover for developing “soft” skills, such as relational and social ones. Originality/value: In a period of growing hype about metaverse technology, literature has a gap regarding the potential and challenges for companies that adopt the metaverse from a knowledge-based perspective. Drawing from a case study, this paper explores the metaverse and its applications for enhancing organizational learning and knowledge management, highlighting the connection between the immersive learning approaches in the metaverse and the T-shaped knowledge. © 2025, Emerald Publishing Limited.
KW  - Gamification
KW  - Immersive learning
KW  - Knowledge management
KW  - Metaverse
KW  - Organizational learning
KW  - Soft skills
KW  - T-shaped knowledge
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Prikler, L.M.
AU  - Wotawa, F.
TI  - 9 in 10 cameras agree: Pedestrians in front possibly endangered
PY  - 2024
T2  - Proceedings - 2024 IEEE/ACM International Conference on Automation of Software Test, AST 2024
SP  - 219
EP  - 223
DO  - 10.1145/3644032.3644468
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196400451&doi=10.1145%2f3644032.3644468&partnerID=40&md5=0951ce019591a82bf09430cd24982908
AB  - Modern cyber-physical systems integrate data from many sensors as a regular part of their operations. Over the years, researchers have proposed methods ranging from statistical approaches to neural networks to achieve this sensor fusion, along with high-level paradigms such as early and late fusion. However, quality assurance of sensor fusion algorithms typically focuses on highlighting their accuracy or ability to reduce uncertainty under given conditions. This paper aims to establish a qualitative approach to testing sensor fusion. We formulate an answer set program based on desirable properties for sensor fusion and show how to apply it to test fusion algorithms. Our results indicate that our approach is effective at finding faults, but does not easily find minimal models for large inputs.  © 2024 Copyright held by the owner/author(s).
KW  - passive testing
KW  - qualitative testing
KW  - sensor fusion
KW  - Embedded systems
KW  - Logic programming
KW  - Software testing
KW  - Cybe-physical systems
KW  - Cyber-physical systems
KW  - Early fusion
KW  - Late fusion
KW  - Neural-networks
KW  - Passive testing
KW  - Qualitative Testing
KW  - Sensor fusion
KW  - Sensor fusion algorithms
KW  - Statistical approach
KW  - Quality assurance
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Liang, P.P.
AU  - Lyu, Y.
AU  - Chhablani, G.
AU  - Jain, N.
AU  - Deng, Z.
AU  - Wang, X.
AU  - Morency, L.-P.
AU  - Salakhutdinov, R.
TI  - MultiViz: Towards User-Centric Visualizations and Interpretations of Multimodal Models
PY  - 2023
T2  - Conference on Human Factors in Computing Systems - Proceedings
C7  - 214
DO  - 10.1145/3544549.3585604
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158076483&doi=10.1145%2f3544549.3585604&partnerID=40&md5=55392ca22e88f5084b899e0779c0b185
AB  - The nature of human and computer interactions are inherently multimodal, which has led to substantial interest in building interpretable, interactive, and reliable multimodal interfaces. However, modern multimodal models and interfaces are typically black-box neural networks, which makes it challenging to understand their internal mechanics. How can we visualize their internal workings in order to empower stakeholders to visualize model behavior, perform model debugging, and promote trust in these models? Our paper proposes MultiViz, a method for analyzing the behavior of multimodal models via 4 stages: (1) unimodal importance, (2) cross-modal interactions, (3) multimodal representations and (4) multimodal prediction. MultiViz includes modular visualization tools for each stage before combining outputs from all stages through an interactive and human-in-the-loop API. Through user studies with 21 participants on 8 trained models across 6 real-world tasks, we show that the complementary stages in MultiViz together enable users to (1) simulate model predictions, (2) assign interpretable concepts to features, (3) perform error analysis on model misclassifications, and (4) use insights from error analysis to debug models. MultiViz is publicly available at https://github.com/pliang279/MultiViz, will be regularly updated with new visualization tools and metrics, and welcomes input from the community1. © 2023 Owner/Author.
KW  - explainable AI
KW  - human-in-the-loop
KW  - interpretability
KW  - model analysis and debugging
KW  - multimodal machine learning
KW  - visualization
KW  - Error analysis
KW  - Learning systems
KW  - Machine learning
KW  - Neural networks
KW  - Program debugging
KW  - User interfaces
KW  - Explainable AI
KW  - Human-in-the-loop
KW  - Interpretability
KW  - Machine-learning
KW  - Model analyse and debugging
KW  - Modeling analyzes
KW  - Multi-modal
KW  - Multi-modal interfaces
KW  - Multimodal machine learning
KW  - Multimodal models
KW  - Visualization
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - LinLin, H.
AU  - Sangheang, L.
AU  - GuanTing, S.
TI  - CAM-Vtrans: real-time sports training utilizing multi-modal robot data
PY  - 2024
T2  - Frontiers in Neurorobotics
VL  - 18
C7  - 1453571
DO  - 10.3389/fnbot.2024.1453571
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207187076&doi=10.3389%2ffnbot.2024.1453571&partnerID=40&md5=07a3528dd826c230f3a890fd2d07e1e2
AB  - Introduction: Assistive robots and human-robot interaction have become integral parts of sports training. However, existing methods often fail to provide real-time and accurate feedback, and they often lack integration of comprehensive multi-modal data. Methods: To address these issues, we propose a groundbreaking and innovative approach: CAM-Vtrans—Cross-Attention Multi-modal Visual Transformer. By leveraging the strengths of state-of-the-art techniques such as Visual Transformers (ViT) and models like CLIP, along with cross-attention mechanisms, CAM-Vtrans harnesses the power of visual and textual information to provide athletes with highly accurate and timely feedback. Through the utilization of multi-modal robot data, CAM-Vtrans offers valuable assistance, enabling athletes to optimize their performance while minimizing potential injury risks. This novel approach represents a significant advancement in the field, offering an innovative solution to overcome the limitations of existing methods and enhance the precision and efficiency of sports training programs. Copyright © 2024 LinLin, Sangheang and GuanTing.
KW  - assistive robotics
KW  - balance control
KW  - CLIP
KW  - cross-attention
KW  - human-machine interaction
KW  - movement recovery
KW  - vision-transformer
KW  - Human robot interaction
KW  - Industrial robots
KW  - Intelligent robots
KW  - Modal analysis
KW  - Multipurpose robots
KW  - Assistive robotics
KW  - Balance control
KW  - CLIP
KW  - Cross-attention
KW  - Human machine interaction
KW  - Movement recovery
KW  - Multi-modal
KW  - Real- time
KW  - Sports trainings
KW  - Vision-transformer
KW  - Article
KW  - artificial neural network
KW  - convolutional neural network
KW  - decision tree
KW  - human
KW  - image segmentation
KW  - long short term memory network
KW  - machine learning
KW  - multimodal imaging
KW  - natural language processing
KW  - personalized medicine
KW  - random forest
KW  - sport
KW  - support vector machine
KW  - training
KW  - visual information
KW  - Cams
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Jebathangam, J.
AU  - Shanthi, C.
AU  - Sharmila, K.
AU  - Devi, R.
TI  - Implementation of fuzzy logic in identification of calcification in mammogram image
PY  - 2021
T2  - Proceedings - 5th International Conference on Intelligent Computing and Control Systems, ICICCS 2021
C7  - 9432381
SP  - 806
EP  - 810
DO  - 10.1109/ICICCS51141.2021.9432381
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107543532&doi=10.1109%2fICICCS51141.2021.9432381&partnerID=40&md5=a5dca3f2c868ac1c60c518a0abacaf3e
AB  - Mammogram is a specialized medical imaging tool used for finding the presence of Microcalcification in the women's breast. Microcalcification generally refers to an initial form of breast cancer. A mammogram image helps the doctor to understand the approximate number of calcifications identified in the breast. Many analytical methods have been proposed to identify the extent of MC in the mammogram image. Those analytical methods can help in Computer Aided Detection (CAD) of MC. To encircle the Microcalcification locations, many commercial software have been developed. The proposed system uses Fuzzy logic for segmentation and Gray Level Co-Occurrence Matrix to extract features based on texture for identifying MC from the mammogram images. Comparison of ground truth image with the extracted features is done to find the segmentation accuracy. The accuracy of the algorithm is analyzed by PSNR metric in identifying the calcification in mammogram.  © 2021 IEEE.
KW  - Fuzzy logic
KW  - Gray level co-occurrence matrix
KW  - Mammography
KW  - Segmentation accuracy
KW  - Biomineralization
KW  - Bone
KW  - Computer aided diagnosis
KW  - Computer circuits
KW  - Control systems
KW  - Fuzzy logic
KW  - Image segmentation
KW  - Intelligent computing
KW  - Mammography
KW  - Textures
KW  - X ray screens
KW  - Analytical method
KW  - Breast Cancer
KW  - Commercial software
KW  - Computer-aided detection
KW  - Gray level co-occurrence matrix
KW  - Mammogram images
KW  - Microcalcifications
KW  - Segmentation accuracy
KW  - Medical imaging
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Lin, Y.-C.
AU  - Chen, W.-D.
TI  - Automatic aircraft detection in very-high-resolution satellite imagery using a YOLOv3-based process
PY  - 2021
T2  - Journal of Applied Remote Sensing
VL  - 15
IS  - 1
C7  - 018502
DO  - 10.1117/1.JRS.15.018502
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103692028&doi=10.1117%2f1.JRS.15.018502&partnerID=40&md5=37a7f0dd6e1b5d48f805b6cef16c5eec
AB  - Aircraft detection in remote-sensing images is a fundamental task in civil and military applications. Deep learning techniques to achieve end-To-end object detection have attracted the attention of the Earth observation community. One of the primary factors behind the success of deep learning techniques is the utilized data. Several previous studies focused on designing the network infrastructure. Instead, this study pays more attention to the data. With the increasing number of available public datasets, whether directly employing a large number of instances with great variation will lead to a good performance has become a research topic. The ways in which these object instances are collected differ greatly. For example, the image sizes, object sizes in the training images, and geospatial resolution are varied. Therefore, herein, the factors influencing the detection performance, such as the object size, ground sampling distance, and Google zoom view, are investigated. A you-only-look-once-v3-based detection process is proposed for automatic aircraft detection. A nonmaximum suppression algorithm strategy is applied to filter unreliable and redundant bounding boxes detected in the overlapping image blocks. The model generalization ability under different training data combinations is evaluated in several challenging cases. The results prove that more variety of training instances from a greater variety of zoom levels will result in more false alarms. Instead, more variety in the object sizes under a constant zoom level is welcome. A large range of aircraft sizes (i.e., 7 to 77 m in length in this study) can be detected, with a promising F1 score of 0.98. © 2021 Society of Photo-Optical Instrumentation Engineers (SPIE).
KW  - Aircraft detection
KW  - Nonmaximum suppression
KW  - Very-high-resolution
KW  - You-only-look-once-v3
KW  - Deep learning
KW  - Large dataset
KW  - Learning systems
KW  - Military applications
KW  - Military photography
KW  - Object detection
KW  - Remote sensing
KW  - Satellite imagery
KW  - Training aircraft
KW  - Detection performance
KW  - Ground sampling distances
KW  - Learning techniques
KW  - Model generalization
KW  - Network infrastructure
KW  - Non-maximum suppression
KW  - Remote sensing images
KW  - Very high resolution satellite imagery
KW  - Aircraft detection
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 13
ER  -

TY  - JOUR
AU  - Jevinger, Å.
AU  - Zhao, C.
AU  - Persson, J.A.
AU  - Davidsson, P.
TI  - Artificial intelligence for improving public transport: a mapping study
PY  - 2024
T2  - Public Transport
VL  - 16
IS  - 1
SP  - 99
EP  - 158
DO  - 10.1007/s12469-023-00334-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177171423&doi=10.1007%2fs12469-023-00334-7&partnerID=40&md5=76f8239a04097714198fb03a2273512a
AB  - The objective of this study is to provide a better understanding of the potential of using Artificial Intelligence (AI) to improve Public Transport (PT), by reviewing research literature. The selection process resulted in 87 scientific publications constituting a sample of how AI has been applied to improve PT. The review shows that the primary aims of using AI are to improve the service quality or to better understand traveller behaviour. Train and bus are the dominant modes of transport investigated. Furthermore, AI is mainly used for three tasks; the most frequent one is prediction, followed by an estimation of the current state, and resource allocation, including planning and scheduling. Only two studies concern automation; all the others provide different kinds of decision support for travellers, PT operators, PT planners, or municipalities. Most of the reviewed AI solutions require significant amounts of data related to the travellers and the PT system. Machine learning is the most frequently used AI technology, with some studies applying reasoning or heuristic search techniques. We conclude that there still remains a great potential of using AI to improve PT waiting to be explored, but that there are also some challenges that need to be considered. They are often related to data, e.g., that large datasets of high quality are needed, that substantial resources and time are needed to pre-process the data, or that the data compromise personal privacy. Further research is needed about how to handle these issues efficiently. © The Author(s) 2023.
KW  - Artificial intelligence
KW  - Literature review
KW  - Machine learning
KW  - Mass transit
KW  - Public transit
KW  - Public transport
KW  - Decision support systems
KW  - Heuristic algorithms
KW  - Large dataset
KW  - Dominant mode
KW  - Literature reviews
KW  - Machine-learning
KW  - Mapping studies
KW  - Mass transit
KW  - Public transit
KW  - Public transport
KW  - Scientific publications
KW  - Service Quality
KW  - Traveler behaviors
KW  - Machine learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 15
ER  -

TY  - CONF
AU  - Žikelić, Ð.
AU  - Lechner, M.
AU  - Verma, A.
AU  - Chatterjee, K.
AU  - Henzinger, T.A.
TI  - Compositional Policy Learning in Stochastic Control Systems with Formal Guarantees
PY  - 2023
T2  - Advances in Neural Information Processing Systems
VL  - 36
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194319540&partnerID=40&md5=c6569daeb4963943a202af0dc1875366
AB  - Reinforcement learning has shown promising results in learning neural network policies for complicated control tasks. However, the lack of formal guarantees about the behavior of such policies remains an impediment to their deployment. We propose a novel method for learning a composition of neural network policies in stochastic environments, along with a formal certificate which guarantees that a specification over the policy's behavior is satisfied with the desired probability. Unlike prior work on verifiable RL, our approach leverages the compositional nature of logical specifications provided in SPECTRL, to learn over graphs of probabilistic reach-avoid specifications. The formal guarantees are provided by learning neural network policies together with reach-avoid supermartingales (RASM) for the graph's sub-tasks and then composing them into a global policy. We also derive a tighter lower bound compared to previous work on the probability of reach-avoidance implied by a RASM, which is required to find a compositional policy with an acceptable probabilistic threshold for complex tasks with multiple edge policies. We implement a prototype of our approach and evaluate it on a Stochastic Nine Rooms environment. © 2023 Neural information processing systems foundation. All rights reserved.
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Federated learning
KW  - Stochastic control systems
KW  - Stochastic systems
KW  - Control task
KW  - Learning neural networks
KW  - Network policy
KW  - Neural-networks
KW  - Novel methods
KW  - Policy learning
KW  - Probabilistics
KW  - Reinforcement learnings
KW  - Stochastic control
KW  - Supermartingales
KW  - Reinforcement learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Belmecheri, N.
AU  - Gotlieb, A.
AU  - Lazaar, N.
AU  - Spieker, H.
TI  - Toward Trustworthy Automated Driving through Qualitative Scene Understanding and Explanations
PY  - 2024
T2  - SAE International Journal of Connected and Automated Vehicles
VL  - 8
IS  - 1
DO  - 10.4271/12-08-01-0003
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199410798&doi=10.4271%2f12-08-01-0003&partnerID=40&md5=d3316a85afe13fa74ef183f2189ff59f
AB  - Understanding driving scenes and communicating automated vehicle decisions are key requirements for trustworthy automated driving. In this article, we introduce the qualitative explainable graph (QXG), which is a unified symbolic and qualitative representation for scene understanding in urban mobility. The QXG enables interpreting an automated vehicle's environment using sensor data and machine learning models. It utilizes spatiotemporal graphs and qualitative constraints to extract scene semantics from raw sensor inputs, such as LiDAR and camera data, offering an interpretable scene model. A QXG can be incrementally constructed in real-time, making it a versatile tool for in-vehicle explanations across various sensor types. Our research showcases the potential of QXG, particularly in the context of automated driving, where it can rationalize decisions by linking the graph with observed actions. These explanations can serve diverse purposes, from informing passengers and alerting vulnerable road users to enabling post hoc analysis of prior behaviors.  © 2025 SAE International.
KW  - Automated Driving
KW  - Connected Mobility
KW  - Explainable AI
KW  - Qualitative Reasoning
KW  - Scene Understanding
KW  - Symbolic AI
KW  - Artificial intelligence
KW  - Automation
KW  - Vehicles
KW  - Automated driving
KW  - Automated vehicles
KW  - Connected mobility
KW  - Explainable AI
KW  - Qualitative reasoning
KW  - Qualitative representation
KW  - Scene understanding
KW  - Symbolic AI
KW  - Symbolic representation
KW  - Urban mobility
KW  - Semantics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Xiao, X.
AU  - Li, C.
AU  - Huang, J.
AU  - Yu, T.
TI  - Fault Diagnosis of Rolling Bearing Based on Knowledge Graph With Data Accumulation Strategy
PY  - 2022
T2  - IEEE Sensors Journal
VL  - 22
IS  - 19
SP  - 18831
EP  - 18840
DO  - 10.1109/JSEN.2022.3201839
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137917195&doi=10.1109%2fJSEN.2022.3201839&partnerID=40&md5=953618b5d0a11b765531eebdeabb8d60
AB  - The fault diagnosis of rolling bearing plays an important role in ensuring the safe and stable operation and maintenance of rotating machinery. Traditional bearing fault diagnosis methods fail to consider the correlation between faults and characteristics and do not take full advantage of the ever-increasing monitoring data. Thus, a bearing fault diagnosis framework based on knowledge graph (KG) and data accumulation strategy is proposed. First, the entities of the KG are defined based on multiple features extracted from the time domain, frequency domain, and time-frequency domain of bearing vibration data collected by the vibration sensors. Then, the feature-fault correlation as the edges is designed and calculated to establish a KG framework together with the entities. In addition, a weighted random forest algorithm is proposed as a reasoning algorithm for the KG, making full use of the feature-fault correlation to improve the accuracy of bearing fault classification. Finally, a data accumulation strategy is designed to continuously increase the size of the training dataset of KG. Relevant parameters are updated in the process to make the results produced by the inference algorithm more accurate. The advantage of the proposed method was demonstrated by a comparison with several models for the same circumstance. The test results showed that the proposed method was promising and it had good prediction accuracy and robustness for different working conditions.  © 2001-2012 IEEE.
KW  - Data accumulation strategy
KW  - fault diagnosis
KW  - feature-fault correlation
KW  - knowledge graph (KG)
KW  - weighted random forest (WRF)
KW  - Data mining
KW  - Decision trees
KW  - Fault detection
KW  - Frequency domain analysis
KW  - Inference engines
KW  - Roller bearings
KW  - Time domain analysis
KW  - Accumulation strategy
KW  - Cognition
KW  - Correlation
KW  - Data accumulation
KW  - Data accumulation strategy
KW  - Fault correlation
KW  - Faults diagnosis
KW  - Feature-fault correlation
KW  - Features extraction
KW  - Knowledge graphs
KW  - Random forests
KW  - Rolling bearings
KW  - Vibration
KW  - Weighted random forest
KW  - Failure analysis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 18
ER  -

TY  - JOUR
AU  - Li, W.
AU  - Fu, M.
AU  - Liu, S.
AU  - Yu, H.
TI  - Revolutionizing Neurosurgery with GPT-4: A Leap Forward or Ethical Conundrum?
PY  - 2023
T2  - Annals of Biomedical Engineering
VL  - 51
IS  - 10
SP  - 2105
EP  - 2112
DO  - 10.1007/s10439-023-03240-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159726317&doi=10.1007%2fs10439-023-03240-y&partnerID=40&md5=05e93700951d9966904bdbdb57a5dfec
AB  - Neurosurgery, a highly specialized and sophisticated branch of medicine, is devoted to the surgical intervention of maladies impacting both the central and peripheral nervous systems. The intricate nature and meticulous precision demanded by neurosurgery has piqued the interest of artificial intelligence experts. In our comprehensive analysis, we encapsulate the prospective applications of the revolutionary GPT-4 technology within the sphere of neurosurgery, encompassing areas such as preoperative evaluation and preparation, tailored surgical simulations, postoperative care and rehabilitation, enriched patient communication, fostering collaboration and knowledge dissemination, as well as training and education. Furthermore, we plunge into the complex and intellectually stimulating conundrums that arise when integrating the cutting-edge GPT-4 technology into neurosurgery, taking into account the moral considerations and substantial hurdles intrinsic to its adoption. Our stance is that GPT-4 will not supplant neurosurgeons; on the contrary, it possesses the potential to serve as an invaluable instrument in augmenting the precision and effectiveness of neurosurgical procedures, ultimately enhancing patient outcomes and propelling the field forward. © 2023, The Author(s) under exclusive licence to Biomedical Engineering Society.
KW  - Artificial intelligence
KW  - Chatbot
KW  - GPT-4
KW  - Neurosurgery
KW  - Artificial Intelligence
KW  - Humans
KW  - Neurosurgeons
KW  - Neurosurgery
KW  - Neurosurgical Procedures
KW  - Artificial intelligence
KW  - Patient rehabilitation
KW  - Petroleum reservoir evaluation
KW  - Central nervous systems
KW  - Chatbots
KW  - Comprehensive analysis
KW  - GPT-4
KW  - Peripheral nervous system
KW  - Postoperative care
KW  - Postoperative rehabilitations
KW  - Prospective applications
KW  - Surgical interventions
KW  - Surgical simulation
KW  - artificial intelligence
KW  - artificial intelligence chatbot
KW  - clinical effectiveness
KW  - GPT 4
KW  - human
KW  - intraoperative period
KW  - Letter
KW  - neurorehabilitation
KW  - neurosurgery
KW  - patient care
KW  - postoperative period
KW  - preoperative period
KW  - professional knowledge
KW  - neurosurgeon
KW  - Neurosurgery
M3  - Letter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 9
ER  -

TY  - CONF
AU  - Nambiar, S.
AU  - Jonsson, M.
AU  - Tarkian, M.
TI  - Automation in Unstructured Production Environments Using Isaac Sim: A Flexible Framework for Dynamic Robot Adaptability
PY  - 2024
T2  - IFAC-PapersOnLine
VL  - 58
IS  - 27
SP  - 837
EP  - 846
DO  - 10.1016/j.procir.2024.10.173
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213028871&doi=10.1016%2fj.procir.2024.10.173&partnerID=40&md5=e58922eebd0ad2c98543efa631e1a071
AB  - In response to the growing complexity of industrial automation requirements, this paper introduces a comprehensive framework tailored for the automation of industrial robots within unstructured production environments. The framework, emphasizing on adaptability and flexibility, seamlessly merges cutting-edge GPU-based physics engine, the Isaac Sim from Omniverse NVIDIA, with industrial robots, thereby laying the foundation for the development of a robust and versatile digital twin. This digital shadow serves as a main step towards the realization of digital twin technologies in dynamically evolving production environments, facilitating dynamic decision-making processes powered by real-time virtual environmental data. Furthermore, this paper show a compelling application scenario to underscore the practical relevance of the proposed framework. Specifically, the application case centers around a hospital test lab, an onsite facility charged with the preparation of tissue samples for subsequent evaluation by medical professionals. Presently, many of the lab's tasks are performed manually, underscoring the urgent need for increased automation to enhance efficiency and the working environment. The specific task targeted by this paper involves the re-stacking of microscope slides from a slider fixture to a holder in preparation for subsequent operations. The motivation behind the integration of more dynamic behavior into the robotic system stems from the unstructured nature of incoming samples, coupled with deficiencies in the digital information chain, all within the constraints of a cost-sensitive, non-expert setting. Proving the applicability of this framework in the current test case, it not only enhances efficiency in the hospital test lab scenario but also demonstrates its potential in more advanced applications within the manufacturing field, especially in environments with similar levels of complexity. By removing technical barriers and streamlining the exploration of digital twin applications, this paper contributes to the advancement of automation technologies and sets the stage for future developments in dynamic production environments. © 2024 The Authors.
KW  - Digital Twin
KW  - Dynamic Production
KW  - Industrial Robot
KW  - Intelligent robots
KW  - Robot applications
KW  - Slideways
KW  - Toy manufacture
KW  - Cutting edges
KW  - Decision-making process
KW  - Dynamic decision making
KW  - Dynamic production
KW  - Environmental data
KW  - Flexible framework
KW  - Industrial automation
KW  - Physics engine
KW  - Production environments
KW  - Real- time
KW  - Industrial robots
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Zhuo, S.D.
AU  - Wu, D.
AU  - Hu, X.
AU  - Wang, Y.
TI  - ARDST: An Adversarial-Resilient Deep Symbolic Tree for Adversarial Learning
PY  - 2024
T2  - International Journal of Intelligent Systems
VL  - 2024
C7  - 2767008
DO  - 10.1155/2024/2767008
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196884420&doi=10.1155%2f2024%2f2767008&partnerID=40&md5=b5ec4e920e83459a271dc633aef20f32
AB  - The advancement of intelligent systems, particularly in domains such as natural language processing and autonomous driving, has been primarily driven by deep neural networks (DNNs). However, these systems exhibit vulnerability to adversarial attacks that can be both subtle and imperceptible to humans, resulting in arbitrary and erroneous decisions. This susceptibility arises from the hierarchical layer-by-layer learning structure of DNNs, where small distortions can be exponentially amplified. While several defense methods have been proposed, they often necessitate prior knowledge of adversarial attacks to design specific defense strategies. This requirement is often unfeasible in real-world attack scenarios. In this paper, we introduce a novel learning model, termed "immune"learning, known as adversarial-resilient deep symbolic tree (ARDST), from a neurosymbolic perspective. The ARDST model is semiparametric and takes the form of a tree, with logic operators serving as nodes and learned parameters as weights of edges. This model provides a transparent reasoning path for decision-making, offering fine granularity, and has the capacity to withstand various types of adversarial attacks, all while maintaining a significantly smaller parameter space compared to DNNs. Our extensive experiments, conducted on three benchmark datasets, reveal that ARDST exhibits a representation learning capability similar to DNNs in perceptual tasks and demonstrates resilience against state-of-the-art adversarial attacks.  © 2024 Sheng Da Zhuo et al.
KW  - Decision making
KW  - Intelligent systems
KW  - Learning algorithms
KW  - Learning systems
KW  - Natural language processing systems
KW  - Network security
KW  - Adversarial learning
KW  - Attacks scenarios
KW  - Autonomous driving
KW  - Defense strategy
KW  - Language processing
KW  - Layer by layer
KW  - Learning structure
KW  - Natural languages
KW  - Prior-knowledge
KW  - Real-world attack
KW  - Deep neural networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Rajabi, E.
AU  - Kafaie, S.
TI  - Knowledge Graphs and Explainable AI in Healthcare
PY  - 2022
T2  - Information (Switzerland)
VL  - 13
IS  - 10
C7  - 459
DO  - 10.3390/info13100459
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140638079&doi=10.3390%2finfo13100459&partnerID=40&md5=22c15a56cc7280cfaaf83d448ab77d5a
AB  - Building trust and transparency in healthcare can be achieved using eXplainable Artificial Intelligence (XAI), as it facilitates the decision-making process for healthcare professionals. Knowledge graphs can be used in XAI for explainability by structuring information, extracting features and relations, and performing reasoning. This paper highlights the role of knowledge graphs in XAI models in healthcare, considering a state-of-the-art review. Based on our review, knowledge graphs have been used for explainability to detect healthcare misinformation, adverse drug reactions, drug-drug interactions and to reduce the knowledge gap between healthcare experts and AI-based models. We also discuss how to leverage knowledge graphs in pre-model, in-model, and post-model XAI models in healthcare to make them more explainable. © 2022 by the authors.
KW  - explainability
KW  - eXplainable AI
KW  - healthcare
KW  - knowledge graph
KW  - Decision making
KW  - Drug interactions
KW  - Graphic methods
KW  - Health care
KW  - Knowledge management
KW  - Adverse drug reactions
KW  - Decision-making process
KW  - Explainability
KW  - Explainable AI
KW  - Extracting features
KW  - Health care professionals
KW  - Healthcare
KW  - Information extracting
KW  - Knowledge graphs
KW  - State-of-the art reviews
KW  - Knowledge graph
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 29
ER  -

TY  - JOUR
AU  - Zarkasi, A.
AU  - Satria, H.
AU  - Primanita, A.
AU  - Afifah, N.
TI  - A new system for underwater vehicle balancing control based on weightless neural network and fuzzy logic methods
PY  - 2024
T2  - IAES International Journal of Artificial Intelligence
VL  - 13
IS  - 3
SP  - 2870
EP  - 2882
DO  - 10.11591/ijai.v13.i3.pp2870-2882
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200052717&doi=10.11591%2fijai.v13.i3.pp2870-2882&partnerID=40&md5=1894f91b618cb9acb27b43ff007b00cf
AB  - The utilization of humans to be in the water for short time, resulting in limited area underwater that can be explored, so the information obtained is very limited, plus the influence of irregular water movements, changes in waves, and changes in water pressure, indirectly also constitutes obstacle to this problem. One of the best solutions is to develop underwater vessel that can travel either autonomously or by giving control of movement and navigation systems. New system for underwater vehicle balance control through weightless neural network (WNN) and fuzzy logic methods was proposed in this study. The aim was to simplify complicated data source on stability system using WNN algorithm and determine depth level of autonomous underwater vehicle (AUV) through fuzzy logic method. Moreover, speed control of underwater vehicle was determined using fuzzy rule-based design and inference. The tests were conducted by showing convergence performance of system in the form of AUV simulator. The results showed that proposed system could produce real-time motion balance performance, faster execution time, and good level of accuracy. This study was expected to produce real-time motion balance system with better performance, faster execution time, and good level of accuracy which could be subsequently used to design simple, cheap, and efficient hardware prototype. © 2024, Institute of Advanced Engineering and Science. All rights reserved.
KW  - Balance control system
KW  - Fuzzy logic
KW  - Underwater vehicle
KW  - Unmanned aerial vehicles
KW  - Weightless neural network
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Yao, J.
AU  - Tran, S.N.
AU  - Garg, S.
AU  - Sawyer, S.
TI  - Deep Learning for Plant Identification and Disease Classification from Leaf Images: Multi-prediction Approaches
PY  - 2024
T2  - ACM Computing Surveys
VL  - 56
IS  - 6
C7  - 153
DO  - 10.1145/3639816
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188820725&doi=10.1145%2f3639816&partnerID=40&md5=c89bc4be0569c03249e7fc653c594bb9
AB  - Deep learning (DL) plays an important role in modern agriculture, especially in plant pathology using leaf images where convolutional neural networks (CNN) are attracting a lot of attention. While numerous reviews have explored the applications of DL within this research domain, there remains a notable absence of an empirical study to offer insightful comparisons due to the employment of varied datasets in the evaluation. Furthermore, a majority of these approaches tend to address the problem as a singular prediction task, overlooking the multifaceted nature of predicting various aspects of plant species and disease types. Lastly, there is an evident need for a more profound consideration of the semantic relationships that underlie plant species and disease types. In this article, we start our study by surveying current DL approaches for plant identification and disease classification. We categorise the approaches into multi-model, multi-label, multi-output, and multi-task, in which different backbone CNNs can be employed. Furthermore, based on the survey of existing approaches in plant pathology and the study of available approaches in machine learning, we propose a new model named Generalised Stacking Multi-output CNN (GSMo-CNN). To investigate the effectiveness of different backbone CNNs and learning approaches, we conduct an intensive experiment on three benchmark datasets Plant Village, Plant Leaves, and PlantDoc. The experimental results demonstrate that InceptionV3 can be a good choice for a backbone CNN as its performance is better than AlexNet, VGG16, ResNet101, EfficientNet, MobileNet, and a custom CNN developed by us. Interestingly, there is empirical evidence to support the hypothesis that using a single model for both tasks can be comparable or better than using two models, one for each task. Finally, we show that the proposed GSMo-CNN achieves state-of-the-art performance on three benchmark datasets. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
KW  - Additional Key Words and PhrasesDeep learning
KW  - convolutional neural networks
KW  - leaf disease classification
KW  - multi-prediction
KW  - plant identification
KW  - plant pathology
KW  - Convolution
KW  - Convolutional neural networks
KW  - Deep learning
KW  - Image classification
KW  - Learning systems
KW  - Pathology
KW  - Plants (botany)
KW  - Semantics
KW  - Additional key word and phrasesdeep learning
KW  - Convolutional neural network
KW  - Disease classification
KW  - Key words
KW  - Leaf disease
KW  - Leaf disease classification
KW  - Multi-prediction
KW  - Plant disease
KW  - Plant identification
KW  - Plant pathology
KW  - Forecasting
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 22
ER  -

TY  - JOUR
AU  - Zhao, H.
AU  - Yang, B.
AU  - Cui, J.
AU  - Xing, Q.
AU  - Shen, J.
AU  - Zhu, F.
AU  - Cao, J.
TI  - Effective Fault Scenario Identification for Communication Networks via Knowledge-Enhanced Graph Neural Networks
PY  - 2024
T2  - IEEE Transactions on Mobile Computing
VL  - 23
IS  - 4
SP  - 3243
EP  - 3258
DO  - 10.1109/TMC.2023.3271715
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159828278&doi=10.1109%2fTMC.2023.3271715&partnerID=40&md5=d9b4a2e25da04bf175d95adfc1458890
AB  - Fault Scenario Identification (FSI) is a challenging task that aims to automatically identify the fault types in communication networks from massive alarms to guarantee effective fault recoveries. Existing methods are developed based on rules, which are not accurate enough due to the mismatching issue. In this paper, we propose an effective method named Knowledge-Enhanced Graph Neural Network (KE-GNN), the main idea of which is to integrate the advantages of both the rules and GNN. This work is the first work that employs GNN and rules to tackle the FSI task. Specifically, we encode knowledge using propositional logic and map them into a knowledge space. Then, we elaborately design a teacher-student scheme to minimize the distance between the knowledge embedding and the prediction of GNN, integrating knowledge and enhancing the GNN. To validate the performance of the proposed method, we collected and labeled three real-world 5G fault scenario datasets. Extensive evaluation conducted on these datasets indicates that our method achieves the best performance compared with other representative methods, improving the accuracy by up to 8.10%. Furthermore, the proposed method achieves the best performance against a small dataset setting and can be effectively applied to a new carrier site with a different topology structure.  © 2002-2012 IEEE.
KW  - Communication networks
KW  - fault scenario identification
KW  - graph neural network
KW  - knowledge
KW  - propositional logic
KW  - Computer circuits
KW  - Fault detection
KW  - Formal logic
KW  - Graph neural networks
KW  - Job analysis
KW  - Communications networks
KW  - Fault scenario identification
KW  - Fault scenarios
KW  - Faults diagnosis
KW  - Graph neural networks
KW  - Knowledge
KW  - Network topology
KW  - Propositional logic
KW  - Scenario identifications
KW  - Task analysis
KW  - Topology
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - CONF
AU  - Casciani, A.
AU  - Bernardi, M.L.
AU  - Cimitile, M.
AU  - Marrella, A.
TI  - Conversational Systems for AI-Augmented Business Process Management
PY  - 2024
T2  - Lecture Notes in Business Information Processing
VL  - 513
SP  - 183
EP  - 200
DO  - 10.1007/978-3-031-59465-6_12
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193617258&doi=10.1007%2f978-3-031-59465-6_12&partnerID=40&md5=6b45a49da74a138ad1bda1b815e25056
AB  - AI-augmented Business Process Management Systems (ABPMSs) are an emerging class of process-aware information systems empowered by AI technology for autonomously unfolding and adapting the execution flow of business processes (BPs). A central characteristic of an ABPMS is the ability to be conversationally actionable, i.e., to proactively interact with human users about BP-related actions, goals, and intentions. While today’s trend is to support BP automation using reactive conversational agents, an ABPMS is required to create dynamic conversations that not only respond to user queries but even initiate conversations with users to inform them of the BP progression and make recommendations to improve BP performance. In this paper, we explore the extent to which state-of-the-art conversational systems (CSs) can be used to develop such proactive conversation features, and we discuss the research challenges and opportunities within this area. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - AI-augmented Business Process Management
KW  - Conversational Systems
KW  - Large Language Models
KW  - Process Mining
KW  - Enterprise resource management
KW  - AI Technologies
KW  - AI-augmented business process management
KW  - Business Process
KW  - Business process management systems
KW  - Conversational systems
KW  - Language model
KW  - Large language model
KW  - Process management
KW  - Process mining
KW  - Process-aware information systems
KW  - Information management
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 10
ER  -

TY  - CONF
AU  - Jokinen, K.
AU  - Deryagina, K.
AU  - Napolitano, G.
AU  - Hyder, A.
TI  - Large Language Models and RAG Approach for Conversational Coaching - Experiments for Enhancing e-VITA Virtual Coach
PY  - 2024
T2  - CEUR Workshop Proceedings
VL  - 3906
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217155028&partnerID=40&md5=444d650f44541c7fd629eb4f5564eae3
AB  - We give an overview of the dialogue modelling research conducted for the e-VITA Virtual Coach, developed in the EU-Japan collaboration project e-VITA with the aim of supporting personalised interaction with older adults, on topics related to active healthy living. The system integrates Rasa Conversational AI and RAG-based LLMs and addresses two main requirements for AI-based applications: how to provide reliable information, and how to maintain smooth personalised conversation. We focus on motivational coaching dialogues and qualitative user evaluation of the prototype system, which tailors dialogue interaction to develop user interest and to support their daily activities. © 2022 Copyright for this paper by its authors.
KW  - Dialogue system
KW  - e-VITA Virtual Coach
KW  - LangChain
KW  - Large Language Models
KW  - RAG
KW  - reliable interaction
KW  - Computer simulation languages
KW  - Virtual addresses
KW  - Collaboration projects
KW  - Dialogue models
KW  - Dialogue systems
KW  - E-VITA virtual coach
KW  - Langchain
KW  - Language model
KW  - Large language model
KW  - Older adults
KW  - RAG
KW  - Reliable interaction
KW  - Virtual environments
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Sinha, H.
TI  - An Evaluation of Medical Image Analysis using Image Segmentation and Deep Learning Techniques for Brain-Tumour
PY  - 2024
T2  - 2024 2nd International Conference on Advances in Computation, Communication and Information Technology, ICAICCIT 2024
SP  - 200
EP  - 206
DO  - 10.1109/ICAICCIT64383.2024.10912292
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001317779&doi=10.1109%2fICAICCIT64383.2024.10912292&partnerID=40&md5=494e52eb71cf9aa6ef0197d9d565a381
AB  - An aberrant mass of rapidly proliferating brain cells, known as a brain tumour, may develop into various forms of cancer. The segmentation of brain tumours by MRI scans is a challenging but crucial process with several medical analytic applications. Radiologists or clinical specialists are responsible for performing a tedious and time-consuming process that involves identifying, segmenting, and extracting contaminated tumour regions from MRI images. The different anatomical structures of human organs may be imagined via image-processing ideas. The human brain is notoriously difficult for basic imaging techniques to identify abnormal structures. A large number of researchers looked at several rapid and accurate algorithms for brain tumour (BT) detection and classification. Recent advances in DL-based automated systems have allowed for faster and more accurate segmentation of DT. This research makes use of a DenseNet50 model for medical picture classification of brain malignancies that is built on a pre-trained CNN model made possible by DL. The model is available on Kaggle. An optimiser like Adam and a categorical cross-entropy loss function were utilised to train a model. A suggested DenseNet50 model outperformed other comparative advanced DL models and attained an experimental accuracy of 95%. The visual results also highlight the impressive outcomes of the MRI brain tumour segmentation system, which will help doctors automatically detect and treat brain tumours. The results acquired demonstrate the effective identification of tumorous images, which is extremely beneficial for the diagnosis process and future applications. © 2024 IEEE.
KW  - Brain tumour
KW  - cancer prediction
KW  - CNN model
KW  - deep learning
KW  - DenseNet50
KW  - image segmentation
KW  - Image analysis
KW  - Image segmentation
KW  - Medical image processing
KW  - Brain cells
KW  - Brain tumors
KW  - Cancer prediction
KW  - CNN models
KW  - Deep learning
KW  - Densenet50
KW  - Images segmentations
KW  - Learning techniques
KW  - Medical image analysis
KW  - MRI scan
KW  - Magnetic resonance imaging
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Gjoreski, M.
AU  - Hassan, T.
AU  - Vered, M.
AU  - Houben, S.
AU  - Kopp, S.
TI  - XAI for U: Explainable AI for Ubiquitous, Pervasive and Wearable Computing
PY  - 2024
T2  - UbiComp Companion 2024 - Companion of the 2024 ACM International Joint Conference on Pervasive and Ubiquitous Computing
SP  - 992
EP  - 995
DO  - 10.1145/3675094.3677571
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206131103&doi=10.1145%2f3675094.3677571&partnerID=40&md5=590931c3c073810283fce2890db26555
AB  - The workshop XAI for U aims to address the critical need for transparency in Artificial Intelligence (AI) systems that integrate into our daily lives through mobile systems, wearables, and smart environments. Despite advances in AI, many of these systems remain opaque, making it difficult for users, developers, and stakeholders to verify their reliability and correctness. This workshop addresses the pressing need for enabling Explainable AI (XAI) tools within Ubiquitous and Wearable Computing and highlights the unique challenges that come with it, such as XAI that deals with time-series and multimodal data, XAI that explains interconnected machine learning (ML) components, and XAI that provides user-centered explanations. The workshop aims to foster collaboration among researchers in related domains, share recent advancements, address open challenges, and propose future research directions to improve the applicability and development of XAI in Ubiquitous Pervasive and Wearable Computing - and with that seeks to enhance user trust, understanding, interaction, and adoption, ensuring that AI-driven solutions are not only more explainable but also more aligned with ethical standards and user expectations. © 2024 Copyright held by the owner/author(s).
KW  - explainable AI
KW  - Ubiquitous Wearable Computing
KW  - User Studies
KW  - Wearable Computing
KW  - XAI
KW  - Artificial intelligence systems
KW  - Daily lives
KW  - Explainable artificial intelligence
KW  - Mobile systems
KW  - Ubiquitous wearable computing
KW  - Ubiquitous/pervasive computing
KW  - User study
KW  - Wearable computing
KW  - XAI
KW  - Ubiquitous computing
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Schneider, H.
TI  - The emergence of compositionality in a brain-inspired cognitive architecture
PY  - 2024
T2  - Cognitive Systems Research
VL  - 86
C7  - 101215
DO  - 10.1016/j.cogsys.2024.101215
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187542061&doi=10.1016%2fj.cogsys.2024.101215&partnerID=40&md5=f98df268d6bfde4d982efc48ec0bd0ca
AB  - Compositionality can be considered as finding (or creating) the correct meaning of the constituents of a non-simple language expression or visual image. The Causal Cognitive Architecture is a brain-inspired cognitive architecture (BICA). It is not a traditional artificial neural network architecture, nor a traditional symbolic AI system but instead uses spatial navigation maps as its fundamental circuits. In previously described versions of the architecture, sensory inputs are compared in each existing sensory system against previous stored navigation maps for that sensory system, and the best navigation map is chosen and then updated with the new sensory inputs and a best multisensory navigation map is similarly created and used as the working navigation map. Instinctive and learned small procedures are triggered by input sensory inputs as well as matched navigation maps, and in the Navigation Module operate on the working navigation map and produce an output signal. By feeding back intermediate results in the Navigation Module it has been shown previously how causal and analogical behaviors emerge from the architecture. In new work, the Navigation Module is duplicated in a biologically plausible manner. It becomes possible to compositionally process information in the duplicated Navigation Module, and as a result compositional language comprehension and behavior readily emerge. A formalization and simulation of the architecture is presented. A demonstration example, and its negation, are explored of solving a compositional problem requiring the placement of an object in a specific location with regard to other objects. Future work is discussed using large language models to create navigation maps. Given the mammalian brain inspiration of the architecture, it suggests that it is indeed feasible for modest genetic changes to have allowed the emergence of compositional language in humans. © 2024 Elsevier B.V.
KW  - Artificial Intelligence (AI)
KW  - Brain-Inspired Cognitive Architecture (BICA)
KW  - Compositionality
KW  - Language evolution
KW  - Large Language Model (LLM)
KW  - Neurosymbolic computing
KW  - Brain
KW  - Computer architecture
KW  - Mammals
KW  - Navigation
KW  - Neural networks
KW  - Visual languages
KW  - Artificial intelligence
KW  - Brain-inspired
KW  - Brain-inspired cognitive architecture
KW  - Cognitive architectures
KW  - Compositionality
KW  - Language evolution
KW  - Language model
KW  - Large language model
KW  - Navigation map
KW  - Neurosymbolic computing
KW  - Article
KW  - artificial intelligence
KW  - behavior
KW  - comprehension
KW  - information processing
KW  - language
KW  - large language model
KW  - nervous system parameters
KW  - problem solving
KW  - simulation
KW  - spatial orientation
KW  - Network architecture
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Benfenati, D.
AU  - De Filippis, G.M.
AU  - Rinaldi, A.M.
AU  - Russo, C.
AU  - Tommasino, C.
TI  - A Retrieval-augmented Generation application for Question-Answering in Nutrigenetics Domain
PY  - 2024
T2  - Procedia Computer Science
VL  - 246
IS  - C
SP  - 586
EP  - 595
DO  - 10.1016/j.procs.2024.09.467
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213332448&doi=10.1016%2fj.procs.2024.09.467&partnerID=40&md5=e2a288ec8c35f8c92be4a7da3d1e4fc9
AB  - The domain of nutrigenetics investigates the complex relationship between genetic variations and individual dietary responses, encompassing a wide array of disciplines, including genomics, nutrition science, bioinformatics, and personalized medicine. This field is marked by its intricate data landscape, necessitating innovative approaches to effectively manage and interpret the vast volumes of information involved. Given nutrigenetic data sheer volume and complexity, traditional AI models often struggle to maintain comprehensive and up-to-date knowledge. In this paper, we propose an implementation of the Retrieval-Augmented Generation (RAG) strategy to address the question-answering task in nutrigenetic domain. This framework enhances the accuracy and relevancy of outputs produced by an advanced Large Language Model, circumventing the exhaustive model fine-tuning process. As a result, our RAG approach not only alleviates the computational demand but also fortifies against data leakage concerns, particularly critical in the sensitive area of nutrigenetics. The implementation of RAG in the nutrigenetic domain not only addresses the existing challenges but also paves the way for more advanced and efficient exploration of nutrigenetic data. Our proposed workflow could advance the understanding of nutrigenetic interactions and personalized nutrition. © 2024 The Authors.
KW  - AI-generated content
KW  - Information Retrieval
KW  - Large language models
KW  - Nutrigenetics
KW  - Personalized nutrition
KW  - Retrieval-augmented generation
KW  - Information leakage
KW  - Information retrieval
KW  - Personalized medicine
KW  - AI-generated content
KW  - Complex relationships
KW  - Genetic variation
KW  - Genomics
KW  - Language model
KW  - Large language model
KW  - Nutrigenetic
KW  - Personalized nutrition
KW  - Question Answering
KW  - Retrieval-augmented generation
KW  - Question answering
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Zavatteri, M.
AU  - Bresolin, D.
AU  - Navarin, N.
TI  - Automated Synthesis of Certified Neural Networks
PY  - 2024
T2  - Frontiers in Artificial Intelligence and Applications
VL  - 392
SP  - 1341
EP  - 1348
DO  - 10.3233/FAIA240633
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213314472&doi=10.3233%2fFAIA240633&partnerID=40&md5=702c3b79a1d755e2b093805af6a45a96
AB  - Neural networks find applications in many safety-critical systems that raise concerns about their deployment: Are we sure the network will never advise doing anything violating a set of safety constraints? Formal verification has been recently applied to prove whether an existing neural network is certified for some property (i.e., if it satisfies the property for all possible inputs) or not. Formal verification can prove that a network respects the property, but cannot fix a network that does not respect it. In this paper we focus on the automated synthesis of certified neural networks, that is, on how to automatically build a network that is guaranteed to respect some required properties. We exploit a Counter Example Guided Inductive Synthesis (CEGIS) loop that alternates Deep Learning, Formal Verification, and a novel data generation technique that augments the training data to synthesize certified networks in a fully automatic way. An application of a proof-of-concept implementation of the framework shows the feasibility of the approach. © 2024 The Authors.
KW  - Neural networks
KW  - Safety engineering
KW  - Automated synthesis
KW  - Counter examples
KW  - Data generation
KW  - Generation techniques
KW  - Neural-networks
KW  - Proof of concept
KW  - Property
KW  - Safety constraint
KW  - Safety critical systems
KW  - Training data
KW  - Formal verification
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Zhu, P.
AU  - Pan, Z.
AU  - Liu, Y.
AU  - Tian, J.
AU  - Tang, K.
AU  - Wang, Z.
TI  - A General Black-box Adversarial Attack on Graph-based Fake News Detectors
PY  - 2024
T2  - IJCAI International Joint Conference on Artificial Intelligence
SP  - 568
EP  - 576
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204286133&partnerID=40&md5=80995d0aa8ac2c9109c3466b624b3f80
AB  - Graph Neural Network (GNN)-based fake news detectors apply various methods to construct graphs, aiming to learn distinctive news embeddings for classification. Since the construction details are unknown for attackers in a black-box scenario, it is unrealistic to conduct the classical adversarial attacks that require a specific adjacency matrix. In this paper, we propose the first general black-box adversarial attack framework, i.e., General Attack via Fake Social Interaction (GAFSI), against detectors based on different graph structures. Specifically, as sharing is an important social interaction for GNN-based fake news detectors to construct the graph, we simulate sharing behaviors to fool the detectors. Firstly, we propose a fraudster selection module to select engaged users leveraging local and global information. In addition, a post injection module guides the selected users to create shared relations by sending posts. The sharing records will be added to the social context, leading to a general attack against different detectors. Experimental results on empirical datasets demonstrate the effectiveness of GAFSI. © 2024 International Joint Conferences on Artificial Intelligence. All rights reserved.
KW  - Generative adversarial networks
KW  - Graph embeddings
KW  - Graph neural networks
KW  - Adjacency matrix
KW  - Black boxes
KW  - Embeddings
KW  - Fraudsters
KW  - Graph neural networks
KW  - Graph structures
KW  - Graph-based
KW  - Learn+
KW  - Network-based
KW  - Social interactions
KW  - Adversarial machine learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 10
ER  -

TY  - CONF
AU  - Sterbini, A.
AU  - Temperini, M.
TI  - Automated Analysis of Algorithm Descriptions Quality, Through Large Language Models
PY  - 2024
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14798 LNCS
SP  - 258
EP  - 271
DO  - 10.1007/978-3-031-63028-6_20
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195877099&doi=10.1007%2f978-3-031-63028-6_20&partnerID=40&md5=8b087ac8dbfa92caa1f276fa30bcc234
AB  - In this paper we propose a method to classify the students’ textual descriptions of algorithms. This work is based on a wealth of data (programming tasks, related algorithm descriptions, and Peer Assessment data), coming from 6 years of use of the system Q2A, in a “Fundamentals of Computer Programming” course, given at first year in our university’s Computer Science curriculum. The descriptions are submitted, as part of the answer to a computer programming task, through Q2A, and are subject to (formative) Peer Assessment. The proposed classification method aims to support the teacher on the analysis of the quite numerous students’ descriptions, in ours as well as in other similar systems. We 1) process the students’ submissions, by topic automated extraction (BERTopic) and by separate Large Language Models, 2) compute their degree of suitability as “algorithm description”, in a scale from BAD to GOOD, and 3) compare the obtained classification with those coming from the teacher’s direct assessment (expert: one of the authors), and from the Peer Assessment. The automated classification does correlate with both the expert classification and the grades given by the peers to the “clarity” of the descriptions. This result is encouraging in view of the production of a Q2A subsystem allowing the teacher to analyse the students’ submissions guided by an automated classification, and ultimately support fully automated grading. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - Automated Assessment
KW  - Large Language Models
KW  - LLM-based Text Similarity
KW  - Peer Assessment
KW  - Automation
KW  - Computational linguistics
KW  - Curricula
KW  - Grading
KW  - Quality control
KW  - Teaching
KW  - Algorithm description
KW  - Automated assessment
KW  - Automated classification
KW  - Language model
KW  - Large language model
KW  - LLM-based text similarity
KW  - Peer assessment
KW  - Programming tasks
KW  - Teachers'
KW  - Text similarity
KW  - Students
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Thota, S.R.
AU  - Arora, S.
AU  - Gupta, S.
TI  - Quantum-Inspired Data Processing for Big Data Analytics
PY  - 2024
T2  - 2024 4th International Conference on Advancement in Electronics and Communication Engineering, AECE 2024
SP  - 502
EP  - 508
DO  - 10.1109/AECE62803.2024.10911758
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001661087&doi=10.1109%2fAECE62803.2024.10911758&partnerID=40&md5=048a0a3a7d6e7d68403b5037f9f7db80
AB  - Technological advancements in the 21st century have led to the rise of "big data,"characterized by datasets so vast and complex that traditional database systems struggle to manage them. This term denotes datasets that are too vast and complex to be processed by traditional database systems. As big data continues to evolve, it introduces significant challenges related to data processing, storage, and analysis. In response, quantum-inspired algorithms have emerged as a promising solution to these challenges. Quantum-inspired algorithms, which draw on principles from quantum computing, present a promising solution to the challenges of big data processing, storage, and analysis. Techniques such as Quantum Annealing, Quantum Circuits and Gates, and Quantum Parallelism leverage quantum principles like superposition and entanglement to enhance data processing efficiency and speed. These methods offer significant improvements over traditional tools like Hadoop, MapReduce, RapidMiner, and R Programming, which are used for distributed storage, processing, and analytics of large datasets. By integrating quantum-inspired algorithms with existing data processing techniques, this study aims to address the limitations of classical methods and advance the field of big data analytics.  © 2024 IEEE.
KW  - Big Data Processing
KW  - Data Analytics
KW  - Quantum Computing
KW  - Data Analytics
KW  - Data assimilation
KW  - Database systems
KW  - Large datasets
KW  - Quantum efficiency
KW  - Quantum electronics
KW  - Big data processing
KW  - Data analytics
KW  - Hadoop MapReduce
KW  - Quantum annealing
KW  - Quantum circuit
KW  - Quantum Computing
KW  - Quantum gates
KW  - Quantum parallelism
KW  - R programming
KW  - Technological advancement
KW  - Quantum entanglement
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Zamri, N.E.
AU  - Alway, A.
AU  - Mansor, M.A.
AU  - Kasihmuddin, M.S.M.
AU  - Sathasivam, S.
TI  - Modified imperialistic competitive algorithm in hopfield neural network for boolean three satisfiability logic mining
PY  - 2020
T2  - Pertanika Journal of Science and Technology
VL  - 28
IS  - 3
SP  - 983
EP  - 1008
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087934490&partnerID=40&md5=1853b08c89340e0038dd058b703d99e1
AB  - Artificial neural networks (ANNs) are actively utilized by researchers due to their extensive capability during the training process of the networks. The intricate training stages of many ANNs provide a powerful mechanism in solving various optimization or classification tasks. The integration of an ANN with a robust training algorithm is the supreme model to outperform the existing framework. Therefore, this work presented the inclusion of three satisfiability Boolean logic in the Hopfield neural network (HNN) with a sturdy evolutionary algorithm inspired by the Imperialist Competitive Algorithm (ICA). In general, ICA stands out from other metaheuristics as it is inspired by the policy of extending the power and rule of a government/country beyond its own borders. Existing models that incorporate standalone HNN are projected as non-versatile frameworks as it fundamentally employs random search in its training stage. The main purpose of this work was to conduct a comprehensive comparison of the proposed model by using two real data sets with an elementary HNN with exhaustive search (ES) versus a HNN with a standard evolutionary algorithm, namely-the genetic algorithm (GA). The performance evaluation of the proposed model was analyzed by computing plausible errors, such as root mean square error (RMSE), mean absolute error (MAE), global minima ratio (Rm), computational time (CT) and accuracy (Q). The computational simulations were carried out by operating the different numbers of neurons in order to validate the efficiency of the proposed model in the training stage. Based on the simulations, the proposed model was found to execute the best performance in terms of attaining small errors and efficient computational time compared to other existing models. © Universiti Putra Malaysia Press.
KW  - 3-satisfiability
KW  - Hopfield neural network
KW  - Imperialist competitive algorithm
KW  - Logic mining
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 14
ER  -

TY  - CONF
AU  - Neider, D.
AU  - Johnson, T.T.
TI  - Track C1: Safety Verification of Deep Neural Networks (DNNs)
PY  - 2024
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14380 LNCS
SP  - 217
EP  - 224
DO  - 10.1007/978-3-031-46002-9_12
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180620043&doi=10.1007%2f978-3-031-46002-9_12&partnerID=40&md5=366771c5a9bdd8d46cb8623c8084ef32
AB  - Formal verification of neural networks and broader machine learning models is an emerging field that has gained significant attention due to the growing use and impact of these data-driven methods. This track explores techniques for formally verifying neural networks and other machine learning models across various application domains. It includes papers and presentations discussing new methodologies, software frameworks, technical approaches, and case studies. Benchmarks play a crucial role in evaluating the effectiveness and scalability of these methods. Currently, available benchmarks mainly focus on computer vision problems, such as local robustness to adversarial perturbations of image classifiers. To address this limitation, this track compiles and publishes benchmarks comprising machine learning models and their specifications across domains such as computer vision, finance, security, and others. These benchmarks will help assess the suitability and applicability of formal verification methods in diverse domains. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Formal Methods
KW  - Formal Verification
KW  - Neural Networks
KW  - Safety of Autonomy
KW  - Computer vision
KW  - Deep neural networks
KW  - Learning systems
KW  - Applications domains
KW  - Case-studies
KW  - Computer vision problems
KW  - Data-driven methods
KW  - Image Classifiers
KW  - Machine learning models
KW  - Neural-networks
KW  - Safety of autonomy
KW  - Safety verification
KW  - Software frameworks
KW  - Formal verification
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Getu, T.M.
AU  - Kaddoum, G.
AU  - Bennis, M.
TI  - Making Sense of Meaning: A Survey on Metrics for Semantic and Goal-Oriented Communication
PY  - 2023
T2  - IEEE Access
VL  - 11
SP  - 45456
EP  - 45492
DO  - 10.1109/ACCESS.2023.3269848
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159671858&doi=10.1109%2fACCESS.2023.3269848&partnerID=40&md5=c3d40bf08dcfb92426e9652fb1116c7d
AB  - Semantic communication (SemCom) aims to convey the meaning behind a transmitted message by transmitting only semantically-relevant information. This semantic-centric design helps to minimize power usage, bandwidth consumption, and transmission delay. SemCom and goal-oriented SemCom (or effectiveness-level SemCom) are therefore promising enablers of 6G and developing rapidly. Despite the surge in their swift development, the design, analysis, optimization, and realization of robust and intelligent SemCom as well as goal-oriented SemCom are fraught with many fundamental challenges. One of the challenges is that the lack of unified/universal metrics of SemCom and goal-oriented SemCom can stifle research progress on their respective algorithmic, theoretical, and implementation frontiers. Consequently, this survey paper documents the existing metrics- scattered in many references- of wireless SemCom, optical SemCom, quantum SemCom, and goal-oriented wireless SemCom. By doing so, this paper aims to inspire the design, analysis, and optimization of a wide variety of SemCom and goal-oriented SemCom systems. This article also stimulates the development of unified/universal performance assessment metrics of SemCom and goal-oriented SemCom, as the existing metrics are purely statistical and hardly applicable to reasoning-type tasks that constitute the heart of 6G and beyond.  © 2013 IEEE.
KW  - 6G
KW  - goal-oriented wireless SemCom
KW  - metrics of SemCom and goal-oriented SemCom
KW  - optical SemCom
KW  - quantum SemCom
KW  - wireless SemCom
KW  - Job analysis
KW  - Semantics
KW  - 6g
KW  - 6g mobile communication
KW  - Goal-oriented
KW  - Goal-oriented wireless semantic communication
KW  - Metric of semantic communication and goal-oriented semantic communication
KW  - Mobile communications
KW  - NIST
KW  - Optical semantic communication
KW  - Optical-
KW  - Quantum semantic communication
KW  - Quantum semantics
KW  - Semantic communication
KW  - Task analysis
KW  - Wireless communications
KW  - Wireless semantic communication
KW  - Wireless sensor networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 33
ER  -

TY  - CONF
AU  - Themistocleous, M.
AU  - Christodoulou, K.
AU  - Katelaris, L.
TI  - An Educational Metaverse Experiment: The First On-Chain and In-Metaverse Academic Course
PY  - 2023
T2  - Lecture Notes in Business Information Processing
VL  - 464 LNBIP
SP  - 678
EP  - 690
DO  - 10.1007/978-3-031-30694-5_47
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161469750&doi=10.1007%2f978-3-031-30694-5_47&partnerID=40&md5=e3ada29fb6a1aaba35ce895b03e13a20
AB  - The Metaverse is not a new concept; nor its use for educational purpose. Despite its considerable attention and recent popularity, largely due to Facebook’s strategic bet, educators have been experimenting with such an environment for a while. Still though, educational activities that are delivered over a Metaverse environment require further exploration to fully understand their full potential, opportunities, and challenges, since such activities differ from traditional on-campus or e-learning education. Nowadays, the area of on-chain education in the Metaverse remains unexplored. In this paper, we are presenting the findings from our attempt to deliver the first of its kind on-chain and in the Metaverse course delivered by the University of Nicosia (UNIC). The course was offered in Fall 2022 as a Massive Open Online Course (MOOC) and was attended by 22,500 students. The paper reports interesting observations from this experiment highlighting lessons learned and open issues for further research. The findings reveal that a Metaverse-like environment that is structured for offering educational experiences to potential learners is likely to disrupt existing educational paradigms and academic practices. We are at a stage where significant amount of research and development is required to further understand and explore the opportunities for the application of a “meta” environment for education. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - education
KW  - experiment
KW  - Metaverse
KW  - MOOC
KW  - on-chain
KW  - E-learning
KW  - Academic course
KW  - E - learning
KW  - Educational activities
KW  - Educational experiences
KW  - Facebook
KW  - Massive open online course
KW  - Meta-environment
KW  - Metaverses
KW  - On-chain
KW  - Research and development
KW  - Curricula
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - CONF
AU  - de Raedt, L.
AU  - Dumancic, S.
AU  - Manhaeve, R.
AU  - Marra, G.
TI  - From statistical relational to neural-symbolic artificial intelligence
PY  - 2020
T2  - IJCAI International Joint Conference on Artificial Intelligence
VL  - 2021-January
SP  - 4943
EP  - 4950
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097352958&partnerID=40&md5=d6402df5d7fc42d2b4af299e71464731
AB  - Neural-symbolic and statistical relational artificial intelligence both integrate frameworks for learning with logical reasoning. This survey identifies several parallels across seven different dimensions between these two fields. These cannot only be used to characterize and position neural-symbolic artificial intelligence approaches but also to identify a number of directions for further research. © 2020 Inst. Sci. inf., Univ. Defence in Belgrade. All rights reserved.
KW  - Logical reasoning
KW  - Artificial intelligence
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 97
ER  -

TY  - CONF
AU  - Cobb, A.
AU  - Roy, A.
AU  - Elenius, D.
AU  - Jha, S.
TI  - Trinity AI Co-Designer for Hierarchical Oracle-guided Design of Cyber-Physical Systems
PY  - 2022
T2  - Proceedings - 4th Workshop on Design Automation for CPS and IoT, DESTION 2022
SP  - 42
EP  - 44
DO  - 10.1109/DESTION56136.2022.00013
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134345404&doi=10.1109%2fDESTION56136.2022.00013&partnerID=40&md5=93aafc74439a0febcbba1446700a99eb
AB  - The design of complex cyber-physical systems entails satisfying several competing performance objectives. In practice, some design requirements are often implicit in the intuition and knowledge of designers who have many years of experience working with similar designs. Designers use this experience to sample a few promising candidates in the design space and evaluate or simulate them using detailed, typically slow scientific models. The goal in design is usually to generate a diverse set of high-performing design configurations that allow trade-offs across different objectives and avoid early concretization. In this paper, we present a demonstration of Trinity AI co-designer that implements a machine learning approach to automate some aspects of system design. Trinity implements an extension of oracle-guided inductive synthesis, where the learning approaches interact with a hierarchy of oracles that range from detailed slow-to-evaluate scientific models to fast but low fidelity deep neural network surrogate models and symbolic rules. The goal is to enable fast design iterations for earlier phases of design. Trinity uses deep generative models to learn a manifold of the valid design space, followed by a joint exploration and optimization of designs over the learned manifold, producing a diverse set of optimal designs with respect to given design objectives. In our demonstration, we will use several case studies including the design of propellers, a ground vehicle, air vehicle and underwater vehicle. Across these case studies, we successfully show how our method generates high-performing and diverse designs.  © 2022 IEEE.
KW  - Design
KW  - Generative Modeling
KW  - Machine Learning
KW  - Neurosymbolic Artificial Intelligence
KW  - Synthesis
KW  - Uncertainty Quantification
KW  - Deep neural networks
KW  - Economic and social effects
KW  - Embedded systems
KW  - Ground vehicles
KW  - Hierarchical systems
KW  - Learning systems
KW  - Uncertainty analysis
KW  - Case-studies
KW  - Cybe-physical systems
KW  - Cyber-physical systems
KW  - Design spaces
KW  - Generative model
KW  - Machine-learning
KW  - Neurosymbolic artificial intelligence
KW  - Performance objective
KW  - Scientific modeling
KW  - Uncertainty quantifications
KW  - Cyber Physical System
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Narayan, A.
AU  - Chami, I.
AU  - Orr, L.
AU  - Ré, C.
TI  - Can Foundation Models Wrangle Your Data?
PY  - 2022
T2  - Proceedings of the VLDB Endowment
VL  - 16
IS  - 4
SP  - 738
EP  - 746
DO  - 10.14778/3574245.3574258
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146264691&doi=10.14778%2f3574245.3574258&partnerID=40&md5=253200e3115dc6f374facd1874afef4a
AB  - Foundation Models (FMs) are models trained on large corpora of data that, at very large scale, can generalize to new tasks without any task-specific finetuning. As these models continue to grow in size, innovations continue to push the boundaries of what these models can do on language and image tasks. This paper aims to understand an underexplored area of FMs: classical data tasks like cleaning and integration. As a proof-of-concept, we cast five data cleaning and integration tasks as prompting tasks and evaluate the performance of FMs on these tasks. We find that large FMs generalize and achieve SoTA performance on data cleaning and integration tasks, even though they are not trained for these data tasks. We iden-tify specific research challenges and opportunities that these models present, including challenges with private and domain specific data, and opportunities to make data management systems more accessible to non-experts. We make our code and experiments publicly available at: https://github.com/HazyResearch/fm_data_tasks. © 2022, VLDB Endowment. All rights reserved.
KW  - Data integration
KW  - Information management
KW  - Integration
KW  - Data cleaning
KW  - Data management system
KW  - Domain specific
KW  - Foundation models
KW  - Large corpora
KW  - Large-scales
KW  - Performance
KW  - Proof of concept
KW  - Research challenges
KW  - Research opportunities
KW  - Cleaning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 60
ER  -

TY  - CONF
AU  - Cominelli, M.
AU  - Gringoli, F.
AU  - Kaplan, L.M.
AU  - Srivastava, M.B.
AU  - Cerutti, F.
TI  - Accurate Passive Radar via an Uncertainty-Aware Fusion of Wi-Fi Sensing Data
PY  - 2023
T2  - 2023 26th International Conference on Information Fusion, FUSION 2023
DO  - 10.23919/FUSION52260.2023.10224098
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171598132&doi=10.23919%2fFUSION52260.2023.10224098&partnerID=40&md5=e71bfef8b60b2e9b1982013d30b80cf7
AB  - Wi-Fi devices can effectively be used as passive radar systems that sense what happens in the surroundings and can even discern human activity. We propose, for the first time, a principled architecture which employs Variational Auto-Encoders for estimating a latent distribution responsible for generating the data, and Evidential Deep Learning for its ability to sense out-of-distribution activities. We verify that the fused data processed by different antennas of the same Wi-Fi receiver results in increased accuracy of human activity recognition compared with the most recent benchmarks, while still being informative when facing out-of-distribution samples and enabling semantic interpretation of latent variables in terms of physical phenomena. The results of this paper are a first contribution toward the ultimate goal of providing a flexible, semantic characterisation of black-swan events, i.e., events for which we have limited to no training data.  © 2023 International Society of Information Fusion.
KW  - Machine learning
KW  - Sensor fusion
KW  - Wireless communications
KW  - Deep learning
KW  - Learning systems
KW  - Semantics
KW  - Sensor data fusion
KW  - Wireless local area networks (WLAN)
KW  - Auto encoders
KW  - Human activities
KW  - Human activity recognition
KW  - Machine-learning
KW  - Passive radars
KW  - Semantic interpretation
KW  - Sensing data
KW  - Sensor fusion
KW  - Uncertainty
KW  - Wireless communications
KW  - Wi-Fi
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Hu, Y.
AU  - Song, Y.
AU  - He, X.
AU  - Zhao, X.
AU  - Yang, X.
AU  - Yao, J.
AU  - Wang, Z.
AU  - Pei, H.
AU  - Hu, C.
TI  - MAACCN: An Intelligent Decoupling Diagnosis Method for Compound Faults in Electrohydrostatic Actuators
PY  - 2025
T2  - IEEE Transactions on Instrumentation and Measurement
VL  - 74
C7  - 3532611
DO  - 10.1109/TIM.2025.3563047
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003371448&doi=10.1109%2fTIM.2025.3563047&partnerID=40&md5=e7a26a48472b56196042e8aaf54e2d95
AB  - Electrohydrostatic actuators (EHAs), as complex integrated systems of mechanical, electrical, and hydraulic components, play a crucial role in aerospace and other fields. However, due to the complexity of their internal structure and harsh working environments, the compound faults are the most common fault types. Considering the high cost of data collection for uncertainties and complex compound faults in EHA, an intelligent decoupling diagnosis method for compound faults in EHAs based on maximized aggregation attention convolutional capsule network (MAACCN) can be proposed. First, the multidimensional sensor information from the EHA can be collected, the feature-level data are fused through a 1-D convolutional layer combined with an efficient channel attention (ECA) mechanism. Second, it utilizes the capsule network to extract features deeply and introduces a maximized aggregation routing algorithm between capsule layers. Finally, a decoupling classification layer can be added, and its model is optimized by minimizing the margin loss function, enabling the network to more accurately identify and decouple compound faults. Validation on the EHA fault dataset demonstrates that the proposed method achieves higher subset accuracy under different working conditions, which can diagnose compound faults by learning data from single faults.  © 1963-2012 IEEE.
KW  - Attention convolutional capsule network
KW  - decoupling classification
KW  - electrohydrostatic actuator (EHA)
KW  - maximized aggregation
KW  - Building materials
KW  - Concrete buildings
KW  - Religious buildings
KW  - Solar buildings
KW  - Steganography
KW  - Attention convolutional capsule network
KW  - Compound faults
KW  - Decoupling classification
KW  - Decouplings
KW  - Diagnosis methods
KW  - Electrical components
KW  - Electro-hydrostatic-actuators
KW  - Integrated systems
KW  - Maximized aggregation
KW  - Mechanical components
KW  - Electrostatic actuators
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Jain, R.C.
TI  - Multimodal Agents: From Vision to Reality
PY  - 2024
T2  - IEEE Multimedia
VL  - 31
IS  - 4
SP  - 4
EP  - 16
DO  - 10.1109/MMUL.2024.3485253
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212970084&doi=10.1109%2fMMUL.2024.3485253&partnerID=40&md5=c276d1ebda9735f83fbcdfd5975d501a
AB  - The rise of multimodal agents marks a significant advancement in both the science and technology of artificial intelligence. By integrating diverse sensory inputs-ranging from vision and speech to contextual sensor data-these agents are poised to redefine applications of intelligent systems as well as human-computer interaction. This article explores the evolution of multimodal agents, highlighting their ability to transcend the limitations of single-modality systems and deliver results based on a comprehensive, context-aware understanding of their environment. We outline the technical requirements for building robust multimodal agents, discuss the ethical challenges of their deployment, and emphasize the critical role that the multimedia community must play in advancing this field. As multimodal agents become increasingly embedded in real-world applications like health care, autonomous driving, and personalized services, we call upon researchers and practitioners to pioneer the future of multimodal intelligence. © 1994-2012 IEEE.
KW  - Autonomous driving
KW  - Computer interaction
KW  - Context-Aware
KW  - Multi-modal agent
KW  - Multimedia community
KW  - Real-world
KW  - Science and Technology
KW  - Sensors data
KW  - Sensory input
KW  - Technical requirement
KW  - Multimedia systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Dong, Z.
AU  - Omidshafiei, S.
AU  - Everett, M.
TI  - Collision Avoidance Verification of Multiagent Systems With Learned Policies
PY  - 2024
T2  - IEEE Control Systems Letters
VL  - 8
SP  - 652
EP  - 657
DO  - 10.1109/LCSYS.2024.3400190
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192726197&doi=10.1109%2fLCSYS.2024.3400190&partnerID=40&md5=a77f91399dffd9031d1186867d1f3bb9
AB  - For many multiagent control problems, neural networks (NNs) have enabled promising new capabilities. However, many of these systems lack formal guarantees (e.g., collision avoidance, robustness), which prevents leveraging these advances in safety-critical settings. While there is recent work on formal verification of NN-controlled systems, most existing techniques cannot handle scenarios with more than one agent. To address this research gap, this letter presents a backward reachability-based approach for verifying the collision avoidance properties of Multi-Agent Neural Feedback Loops (MA-NFLs). Given the dynamics models and trained control policies of each agent, the proposed algorithm computes relative backprojection sets by (simultaneously) solving a series of Mixed Integer Linear Programs (MILPs) offline for each pair of agents. We account for state measurement uncertainties, making it well aligned with real-world scenarios. Using those results, the agents can quickly check for collision avoidance online by solving low-dimensional Linear Programs (LPs). We demonstrate the proposed algorithm can verify collision-free properties of a MA-NFL with agents trained to imitate a collision avoidance algorithm (Reciprocal Velocity Obstacles). We further demonstrate the computational scalability of the approach on systems with up to 10 agents. © 2017 IEEE.
KW  - multi-agent systems
KW  - Neural networks
KW  - reachability analysis
KW  - safety verification
KW  - Collision avoidance
KW  - Formal verification
KW  - Integer programming
KW  - Safety engineering
KW  - Software agents
KW  - Uncertainty analysis
KW  - Collisions avoidance
KW  - Control problems
KW  - Feedback loops
KW  - Multi agent
KW  - Multiagent control
KW  - Network-controlled
KW  - Neural feedback
KW  - Neural-networks
KW  - Reachability analysis
KW  - Safety verification
KW  - Multi agent systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Yuen, K.K.F.
TI  - Fuzzy cognitive network process for software reliability and quality measurement: comparisons with fuzzy analytic hierarchy process
PY  - 2024
T2  - Journal of Reliable Intelligent Environments
VL  - 10
IS  - 3
SP  - 319
EP  - 336
DO  - 10.1007/s40860-024-00230-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199555810&doi=10.1007%2fs40860-024-00230-2&partnerID=40&md5=f317153f31e946e506882301f3dddca2
AB  - Software reliability and quality measurement has a long-lasting impact on the final products and user experiences. The analytic hierarchy process (AHP) and its various hybrid models, including fuzzy AHP, have been applied to software reliability and quality measurement in various aspects. Related studies indicate that limitations in the paired ratio scales of AHP may lead to misapplications, which most AHP users might not be aware of. To address this issue, the fuzzy cognitive network process (FCNP) is proposed as a promising alternative applied for software reliability and quality measurement. One application based Fuzzy AHP is revisited to demonstrate the feasibility and usability of the FCNP. The paper discusses conversion from the FAHP to the FCNP, examining their reproducibility, comparability, merits, and limitations. The proposed fuzzy CNP method can a valuable tool for software customers, designers, developers, testers, and purchasers, to evaluate the level of software reliability and quality in general applications within intelligent environment. © The Author(s) 2024.
KW  - Measurement
KW  - Operations research
KW  - Pairwise comparisons
KW  - Software quality
KW  - Software reliability
KW  - Application programs
KW  - Computer software selection and evaluation
KW  - Fuzzy logic
KW  - Hierarchical systems
KW  - Operations research
KW  - Software reliability
KW  - Cognitive network process
KW  - Fuzzy analytic hierarchy
KW  - Long lasting
KW  - Measurement comparison
KW  - Operation research
KW  - Pair-wise comparison
KW  - Quality measurements
KW  - Software Quality
KW  - Software reliability measurements
KW  - Software-Reliability
KW  - Analytic hierarchy process
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Sinha, H.
TI  - A Robust Machine Learning System for Classification and Prediction of Customer Churn in Telecom Sector
PY  - 2024
T2  - 2024 IEEE 4th International Conference on ICT in Business Industry and Government, ICTBIG 2024
DO  - 10.1109/ICTBIG64922.2024.10911484
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001586820&doi=10.1109%2fICTBIG64922.2024.10911484&partnerID=40&md5=dd41475614ad009cb0392b226980d371
AB  - Customer desertion detection is one of the most critical research topics that the telecommunications industry must address in order to retain existing customers. Churn is the term utilised to describe a loss of consumers as a result of the existing offers of competitors or, in some cases, network issues. Customers may prefer to terminate their subscriptions to services in these circumstances. Customer churn prediction is crucial for retaining long-term customers and ensuring profitability. The main goal of this system is to analyse various ML algorithms that are required to build models that can anticipate customer attrition and, once retention tactics and plans have been implemented, to identify the reasons behind churn. This study focuses on developing an effective churn prediction model using the Telco customer churn dataset by Kaggle, encompassing 7043 customer records. Through comprehensive data preprocessing, feature selection, and employing ML models - ETC, Decision Tree, and Stacking Classifier - the study evaluates and compares their performance in predicting customer churn according to F1-score, recall, accuracy, and precision. The outcomes demonstrate that a Stacking Classifier achieves the highest accuracy of 91%, highlighting its potential for practical implementation in the telecom sector to reduce churn rates and enhance customer retention strategies. © 2024 IEEE.
KW  - Churn prediction
KW  - Customer turnover
KW  - machine learning
KW  - Telco customer data
KW  - Telecommunication
KW  - Prediction models
KW  - Churn predictions
KW  - Critical researches
KW  - Customer churns
KW  - Customer data
KW  - Customer turnover
KW  - Machine learning systems
KW  - Machine-learning
KW  - Stackings
KW  - Telco customer data
KW  - Telecom sector
KW  - Telecommunication industry
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Zi, Y.
AU  - Henson, C.
AU  - Sheth, A.
TI  - Empowering Causal Machine Learning for Large-scale Manufacturing Pipelines with Knowledge Graphs
PY  - 2024
T2  - CEUR Workshop Proceedings
VL  - 3828
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210254219&partnerID=40&md5=d53809f1dd26ecb6076e4ffbcad3df97
AB  - Understanding causal relations within manufacturing pipelines is crucial for key manufacturing tasks such as anomaly detection and root cause analysis. However, existing causal machine learning (causal ML) approaches struggle to scale effectively to the vast number of variables present in manufacturing settings. We advocate for incorporating domain knowledge within the manufacturing pipelines, represented as knowledge graphs (KGs), for designing causal ML methods for large-scale manufacturing problems. Knowledge graphs can encode rich contextual information about the interactions and dependencies between different components and stages of the manufacturing pipeline, providing a structured framework to guide the discovery of causal relationships. By incorporating KGs, causal ML models can leverage both data-driven approaches and domain knowledge, enhancing scalability and improving the accuracy of causal learning in large scale manufacturing settings. © 2024 Copyright for this paper by its authors.
KW  - Computer aided manufacturing
KW  - Smart manufacturing
KW  - Anomaly detection
KW  - Causal relations
KW  - Domain knowledge
KW  - Knowledge graphs
KW  - Large-scale manufacturing
KW  - Machine learning approaches
KW  - Machine learning methods
KW  - Machine-learning
KW  - Manufacturing tasks
KW  - Root cause analysis
KW  - Knowledge graph
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Bouhadra, K.
AU  - Forest, F.
TI  - Knowledge-based and Expert Systems in Prognostics and Health Management: a Survey
PY  - 2024
T2  - International Journal of Prognostics and Health Management
VL  - 15
IS  - 2
DO  - 10.36001/ijphm.2024.v15i2.3986
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208198946&doi=10.36001%2fijphm.2024.v15i2.3986&partnerID=40&md5=dca070917ae43948610296a50a687b5d
AB  - Prognostics and Health Management (PHM) has become increasingly popular in recent years, and data-driven methods and artificial intelligence have emerged as dominant tools within the PHM field. This trend is mainly due to the increasing use of sensors and the ability of machine learning techniques to leverage condition monitoring data. However, despite their utility and effectiveness, these techniques are not without draw-backs. One major issue is that data-driven methods often lack transparency in their reasoning, which is crucial for understanding fault occurrences and diagnostics. Additionally, the availability of data can be a challenge. In some cases, data are scarce or hard to obtain, either due to the cost of installing necessary sensors or the rarity of the required in-formation. Lastly, the insights derived from data can some-times diverge from those obtained through expert analysis and established norms. This contrasts with knowledge-based approaches such as expert systems, which formally organize the knowledge acquired from norms and experts, and then de-duce the desired conclusion. While research is increasingly exploring data-driven techniques, industry tends to still fre-quently employ knowledge-based methods. To fill this gap, this paper offers a detailed survey of knowledge-based and expert systems in PHM, examining methodologies such as propositional logic, fuzzy logic, Dempster-Shafer theory and Bayesian networks. It assesses the integration and impact of these techniques in PHM for fault detection, diagnosis and prognosis, highlighting their strengths, limitations, and potential future developments. The study provides a thorough evaluation of current developments and contributes signifi-cant insights into the current capabilities and future directions of knowledge-based techniques in enhancing decision-making processes in PHM. © 2024, Prognostics and Health Management Society. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Yu, Z.
AU  - Du, H.
AU  - Lei, Y.
AU  - Shan, M.
TI  - Short-term Load Forecasting of Power System Based on Weighted Improved Adaptive Neuro-Fuzzy Inference System and Random Forest
PY  - 2024
T2  - 2024 IEEE 2nd International Conference on Power Science and Technology, ICPST 2024
SP  - 2024
EP  - 2029
DO  - 10.1109/ICPST61417.2024.10601995
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200709531&doi=10.1109%2fICPST61417.2024.10601995&partnerID=40&md5=e139f7d7225d81204fbf645dfd4a5b40
AB  - Load forecasting of power system has become one of the important symbols to measure the modernization of power system operation and management, and it is very important for the safe and stable operation and economic dispatching of power system. Aiming at the problem that the accuracy of short term load forecasting of power system is reduced due to external interference, this paper first introduces the basic principle of related algorithms. Then, a short-term load forecasting method based on weighted adaptive neuro-fuzzy inference system (ANFIS) and random forest (RF) is proposed. A whale optimization algorithm (WOA) is employed to fine-tune the parameters within the membership function of the adaptive neuro-fuzzy inference system, while a random forest algorithm is utilized to identify the most important features. In conclusion, a comparison is made on the load data predictions using different algorithms. The adaptive neuro-fuzzy inference system is employed for short-term load forecasting in the power system, yielding experimental results with a maximum relative error of 1.6659%, a minimum relative error of 0.00768%, and an average absolute error of 64.352MW. By optimizing the membership function parameters of the adaptive neuro-fuzzy inference system using the whale optimization algorithm and weighting the results with random forest predictions, the experimental results showed a maximum relative error of 0.991%, a minimum relative error of 0.00008%, and an average absolute error of 24.84MW, further enhancing the accuracy of the predictions. Compared with the relevant algorithms, the proposed WOA-ANFIS-RF algorithm can further increase the nonlinear processing ability, reduce the error of load prediction and improve the accuracy of load prediction. In addition, the load prediction results obtained by the proposed algorithm meet the practical application requirements and have certain reference value.  © 2024 IEEE.
KW  - load forecasting
KW  - neuro-fuzzy
KW  - random forest
KW  - whale optimization algorithm
KW  - Electric load dispatching
KW  - Electric power plant loads
KW  - Errors
KW  - Fuzzy inference
KW  - Fuzzy neural networks
KW  - Fuzzy systems
KW  - Membership functions
KW  - Optimization
KW  - Parameter estimation
KW  - Adaptive neuro-fuzzy inference
KW  - Load forecasting
KW  - Load predictions
KW  - Neuro-Fuzzy
KW  - Neuro-fuzzy inference systems
KW  - Optimization algorithms
KW  - Power
KW  - Random forests
KW  - Short term load forecasting
KW  - Whale optimization algorithm
KW  - Forecasting
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Schneider, P.
AU  - Alvarez-Coello, D.
AU  - Le-Tuan, A.
AU  - Nguyen-Duc, M.
AU  - Le-Phuoc, D.
TI  - Stream Reasoning Playground
PY  - 2022
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 
VL  - 13261 LNCS
SP  - 406
EP  - 424
DO  - 10.1007/978-3-031-06981-9_24
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131942560&doi=10.1007%2f978-3-031-06981-9_24&partnerID=40&md5=c746675e777828402e3e72a87218a5f1
AB  - Stream Reasoning is a well established field not only in the Semantic Web, but is also adapted in the knowledge representation and reasoning and AI community in general. In the Semantic Web area, there have been valuable efforts in building data generators and benchmarks, however they are not well suited for evaluating more expressive stream reasoning approaches, since the focus is on a graph-based data model and more limited reasoning features, such as query answering. This paper aims at filling the gap, so the different communities can compare, discuss, and benchmark the various approaches for stream reasoning based on a common playground. We will present the stream reasoning playground that targets streaming reasoning as the first-class modelling and processing feature. Our playground includes an easy-to-extend platform for data stream generation with pluggable data formatters, whereby different data stream sources, and modelling problems for two interesting application scenarios, i.e., intelligent traffic management and vehicle stream data analytics, are provided. Furthermore, we present a more generic scenario for time-series data, where a workflow for streaming time-series data from various datasets is facilitated by using mapping functions. To illustrate a first application of the playground, we report on the usage experience of well-known stream reasoner developers in the “model and solve” Hackathon event of the annual Stream Reasoning workshop. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Data Analytics
KW  - Graphic methods
KW  - Knowledge representation
KW  - Time series
KW  - Class models
KW  - Data stream
KW  - Graph-based
KW  - In-buildings
KW  - Knowledge representation and reasoning
KW  - Query answering
KW  - Reasoning approach
KW  - Semantic-Web
KW  - Stream reasonings
KW  - Time-series data
KW  - Semantic Web
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - JOUR
AU  - Li, D.
AU  - Liu, B.
AU  - Yang, C.
AU  - Shi, F.
AU  - Peng, Y.
AU  - Lin, W.
TI  - K-Core Structure Feature Encoding-Based Enhanced Federated Graph Learning Framework
PY  - 2025
T2  - IEEE Transactions on Emerging Topics in Computational Intelligence
DO  - 10.1109/TETCI.2025.3526278
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216674972&doi=10.1109%2fTETCI.2025.3526278&partnerID=40&md5=90897bdded3c654a16edbe2ec332271c
AB  - Federated Graph Learning (FGL) demonstrates tremendous potential in distributed graph data analysis and modeling. The rapid growth of graph data and the increasing awareness of privacy protection make FGL research highly valuable. However, its development faces two critical challenges: the non-IID problem in heterogeneous graphs and low communication efficiency. This study proposes an Enhanced FGL framework based on K-core Structure Feature Encoding (FedKcore) to utilize various heterogeneous graphs efficiently. The nested chain structure containing rich information and linear encoding time make K-core structural attributes highly suitable for graph enhancement and aggregate sharing on edge devices. Client personalization capabilities are enhanced by combining original features with K-core attributes for local training. To improve convergence speed and overcome the non-IID challenge, we aggregate and share only the learnable parameters related to K-core attributes. Upon this, the introduced Circle Loss function optimizes feature space and boundaries, enhancing the performance of K-core attributes. Extensive experiments on heterogeneous graphs show that, compared to the state-of-the-art FedStar, FedKcore improves accuracy by over 1.3% and speeds up convergence by 1.3 times.  © 2017 IEEE.
KW  - federated graph learning (FGL)
KW  - Federated learning
KW  - graph neural networks
KW  - non-IID
KW  - Encoding (symbols)
KW  - Graph neural networks
KW  - Core structure
KW  - Encodings
KW  - Federated graph learning
KW  - Graph data
KW  - Graph neural networks
KW  - Heterogeneous graph
KW  - K-cores
KW  - Learning frameworks
KW  - Non-IID
KW  - Structure features
KW  - Federated learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Yongyin, L.
AU  - Caixia, Y.
TI  - Cross-attention swin-transformer for detailed segmentation of ancient architectural color patterns
PY  - 2024
T2  - Frontiers in Neurorobotics
VL  - 18
C7  - 1513488
DO  - 10.3389/fnbot.2024.1513488
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213345679&doi=10.3389%2ffnbot.2024.1513488&partnerID=40&md5=5b982df4da583a3a60c2b3c6c6512bc4
AB  - Introduction: Segmentation tasks in computer vision play a crucial role in various applications, ranging from object detection to medical imaging and cultural heritage preservation. Traditional approaches, including convolutional neural networks (CNNs) and standard transformer-based models, have achieved significant success; however, they often face challenges in capturing fine-grained details and maintaining efficiency across diverse datasets. These methods struggle with balancing precision and computational efficiency, especially when dealing with complex patterns and high-resolution images. Methods: To address these limitations, we propose a novel segmentation model that integrates a hierarchical vision transformer backbone with multi-scale self-attention, cascaded attention decoding, and diffusion-based robustness enhancement. Our approach aims to capture both local details and global contexts effectively while maintaining lower computational overhead. Results and discussion: Experiments conducted on four diverse datasets, including Ancient Architecture, MS COCO, Cityscapes, and ScanNet, demonstrate that our model outperforms state-of-the-art methods in accuracy, recall, and computational efficiency. The results highlight the model's ability to generalize well across different tasks and provide robust segmentation, even in challenging scenarios. Our work paves the way for more efficient and precise segmentation techniques, making it valuable for applications where both detail and speed are critical. Copyright © 2024 Yongyin and Caixia.
KW  - computational efficiency
KW  - multi-scale attention
KW  - robustness enhancement
KW  - segmentation
KW  - vision transformer
KW  - Image segmentation
KW  - Medical imaging
KW  - Color pattern
KW  - Cultural heritage preservation
KW  - Multi-scale attention
KW  - Multi-scales
KW  - Objects detection
KW  - Robustness enhancement
KW  - Segmentation
KW  - Traditional approaches
KW  - Traditional approachs
KW  - Vision transformer
KW  - article
KW  - color
KW  - computer vision
KW  - convolutional neural network
KW  - diagnosis
KW  - diagnostic imaging
KW  - diffusion
KW  - human
KW  - inheritance
KW  - velocity
KW  - vision
KW  - Convolutional neural networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Nguyen, L.X.
AU  - Tun, Y.L.
AU  - Tun, Y.K.
AU  - Nguyen, M.N.H.
AU  - Zhang, C.
AU  - Han, Z.
AU  - Seon Hong, C.
TI  - Swin Transformer-Based Dynamic Semantic Communication for Multi-User with Different Computing Capacity
PY  - 2024
T2  - IEEE Transactions on Vehicular Technology
VL  - 73
IS  - 6
SP  - 8957
EP  - 8972
DO  - 10.1109/TVT.2024.3362328
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184798470&doi=10.1109%2fTVT.2024.3362328&partnerID=40&md5=e2409cbdc0ab11a1d04c7cc052536c45
AB  - Semantic communication has gained significant attention from researchers as a promising technique to replace conventional communication in the next generation of communication systems, primarily due to its ability to reduce communication costs. However, little literature has studied its effectiveness in multi-user scenarios, particularly when there are variations in the model architectures used by users and their computing capacities. To address this issue, we explore a semantic communication system that caters to multiple users with different model architectures by using a multi-purpose transmitter at the base station (BS). Specifically, the BS in the proposed framework employs semantic and channel encoders to encode the image for transmission, while the receiver utilizes its local channel and semantic decoder to reconstruct the original image. Our joint source-channel encoder at the BS can effectively extract and compress semantic features for specific users by considering the signal-To-noise ratio (SNR) and computing capacity of the user. Based on the network status, the joint source-channel encoder at the BS can adaptively adjust the length of the transmitted signal. A longer signal ensures more information for high-quality image reconstruction for the user, while a shorter signal helps avoid network congestion. In addition, we propose a hybrid loss function for training, which enhances the perceptual details of reconstructed images. Finally, we conduct a series of extensive evaluations and ablation studies to validate the effectiveness of the proposed system. © 1967-2012 IEEE.
KW  - dynamic compression rate
KW  - image reconstruction
KW  - image transmission
KW  - multi-user
KW  - Semantic communication
KW  - swin transformer
KW  - Channel coding
KW  - Image coding
KW  - Image enhancement
KW  - Image reconstruction
KW  - Memory architecture
KW  - Network architecture
KW  - Semantics
KW  - Signal encoding
KW  - Signal to noise ratio
KW  - Communications systems
KW  - Compression rates
KW  - Dynamic compression
KW  - Dynamic compression rate
KW  - Images reconstruction
KW  - Multiusers
KW  - Receiver
KW  - Semantic communication
KW  - Swin transformer
KW  - Task analysis
KW  - Transformer
KW  - Transmitters
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 16
ER  -

TY  - CONF
AU  - Monaldini, A.
AU  - Vozna, A.
AU  - Costantini, S.
TI  - Blueprint Personas in Digital Health Transformation
PY  - 2024
T2  - CEUR Workshop Proceedings
VL  - 3880
SP  - 40
EP  - 49
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214205066&partnerID=40&md5=5884f302cfe0a74da6b517f4a5f493e3
AB  - This paper presents a work in progress on the application of Blueprint Personas as a foundational tool for advancing the digital transformation of health and care services in an aging society. The paper presents how artificial intelligence (AI) and intelligent agents can support patients, caregivers, and healthcare professionals through customized, patient-centered care. By synthesizing detailed patient profiles, including medical, social, and personal factors, the aim is to enhance the interaction between healthcare technologies and users. Additionally, the work introduces the use of ontologies to structure knowledge in e-health systems, emphasizing the integration of a Reference Ontology of Trust to ensure the reliability and transparency of AI-driven care solutions. This ongoing research aims to contribute to a more empathetic and effective digital health ecosystem. © 2024 CEUR-WS. All rights reserved.
KW  - Blueprint Personas
KW  - Healthcare
KW  - Intelligent agent
KW  - Ontology
KW  - Trust
KW  - Electronic health record
KW  - Ontology
KW  - Aging societies
KW  - Blueprint persona
KW  - Digital transformation
KW  - e-Health systems
KW  - Health care professionals
KW  - Healthcare
KW  - Healthcare technology
KW  - Ontology's
KW  - Patient-centered care
KW  - Trust
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Insawan, H.
AU  - Alwahidin, A.
AU  - Kira, H.
AU  - Putri, A.I.
TI  - Implementation of the Eco-Metaverse in Indonesia: Sharia Economic Perspective
PY  - 2025
T2  - Samarah
VL  - 9
IS  - 1
SP  - 107
EP  - 129
DO  - 10.22373/sjhk.v9i1.26262
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217483009&doi=10.22373%2fsjhk.v9i1.26262&partnerID=40&md5=2892ee3d709d5538a47e0b6b61ac7dc9
AB  - This article discusses the implementation of the eco-metaverse in Indonesia, with a focus on the economic aspects of the metaverse. This article begins by providing an overview of the metaverse concept and its potential impact on various sectors, including education, commerce, and entertainment. Then, this article examines the principles of metaverse economics, such as the concepts of values, principles and norms, and how these concepts can be applied in the context of the metaverse. This research uses a qualitative research paradigm with a sharia economic approach. Data and information were collected through interviews, literature studies and focus group discussions (FGD). The condition of the ecometaverse in Indonesia has begun to develop, although it is not yet running optimally. Several ways of using the Metaverse that can be considered in the context of sharia economics are Education and Knowledge, Communication and Empowerment, Economics and Business, and Socio-Cultural Life. Eco-metaverse development can be carried out through the waqf and syirkah application model on the sharia banking platform in the metaverse. Apart from that, another model being developed is a platform for selling MSME products through metverse where sellers and buyers can interact directly virtually. Based on the results and discussion in this research, it is highly recommended to; Explaining sharia-based eco-metaverse applications. There is a need for sharia-based eco-metaverse education, so that more and more people build or join the eco-metaverse. In implementing a sharia-based eco-metaverse, institutions are needed that oversee the consistent application of sharia principles in a transparent and interconnected eco-metaverse. © 2025 Universitas Islam Negeri Ar-Raniry. All rights reserved.
KW  - digital economy
KW  - Eco-metaverse
KW  - sharia economics
KW  - virtual world
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Singh, U.
AU  - Saraswat, A.
AU  - Azad, H.K.
AU  - Abhishek, K.
AU  - Shitharth, S.
TI  - Towards improving e-commerce customer review analysis for sentiment detection
PY  - 2022
T2  - Scientific Reports
VL  - 12
IS  - 1
C7  - 21983
DO  - 10.1038/s41598-022-26432-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144261868&doi=10.1038%2fs41598-022-26432-3&partnerID=40&md5=9fc8b6ec06464fe776ed4813202173ac
AB  - According to a report published by Business Wire, the market value of e-commerce reached US$ 13 trillion and is expected to reach US$ 55.6 trillion by 2027. In this rapidly growing market, product and service reviews can influence our purchasing decisions. It is challenging to manually evaluate reviews to make decisions and examine business models. However, users can examine and automate this process with Natural Language Processing (NLP). NLP is a well-known technique for evaluating and extracting information from written or audible texts. NLP research investigates the social architecture of societies. This article analyses the Amazon dataset using various combinations of voice components and deep learning. The suggested module focuses on identifying sentences as ‘Positive‘, ‘Neutral‘, ‘Negative‘, or ‘Indifferent‘. It analyses the data and labels the ‘better’ and ‘worse’ assumptions as positive and negative, respectively. With the expansion of the internet and e-commerce websites over the past decade, consumers now have a vast selection of products within the same domain, and NLP plays a vital part in classifying products based on evaluations. It is possible to predict sponsored and unpaid reviews using NLP with Machine Learning. This article examined various Machine Learning algorithms for predicting the sentiment of e-commerce website reviews. The automation achieves a maximum validation accuracy of 79.83% when using Fast Text as word embedding and the Multi-channel Convolution Neural Network. © 2022, The Author(s).
KW  - Algorithms
KW  - Attitude
KW  - Commerce
KW  - Language
KW  - Natural Language Processing
KW  - Neural Networks, Computer
KW  - article
KW  - automation
KW  - consumer
KW  - convolutional neural network
KW  - deep learning
KW  - electronic commerce
KW  - embedding
KW  - human
KW  - Internet
KW  - machine learning
KW  - natural language processing
KW  - organization
KW  - purchasing
KW  - voice
KW  - algorithm
KW  - attitude
KW  - commercial phenomena
KW  - language
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 25
ER  -

TY  - CONF
AU  - Evans, R.
AU  - Bošnjak, M.
AU  - Buesing, L.
AU  - Ellis, K.
AU  - Pfau, D.
AU  - Kohli, P.
AU  - Sergot, M.
TI  - Making Sense of Raw Input (Extended Abstract)
PY  - 2022
T2  - IJCAI International Joint Conference on Artificial Intelligence
SP  - 5727
EP  - 5731
DO  - 10.24963/ijcai.2022/799
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137848841&doi=10.24963%2fijcai.2022%2f799&partnerID=40&md5=65a209ef617c9e8bceff2aea1528f53c
AB  - How should a machine intelligence perform unsupervised structure discovery over streams of sensory input? One approach to this problem is to cast it as an apperception task. Here, the task is to construct an explicit interpretable theory that both explains the sensory sequence and also satisfies a set of unity conditions, designed to ensure that the constituents of the theory are connected in a relational structure. However, the original formulation of the apperception task had one fundamental limitation: it assumed the raw sensory input had already been parsed using a set of discrete categories, so that all the system had to do was receive this already-digested symbolic input, and make sense of it. But what if we don't have access to pre-parsed input? What if our sensory sequence is raw unprocessed information? The central contribution of this paper is a neurosymbolic framework for distilling interpretable theories out of streams of raw, unprocessed sensory experience. First, we extend the definition of the apperception task to include ambiguous (but still symbolic) input: sequences of sets of disjunctions. Next, we use a neural network to map raw sensory input to disjunctive input. Our binary neural network is encoded as a logic program, so the weights of the network and the rules of the theory can be solved jointly as a single SAT problem. This way, we are able to jointly learn how to perceive (mapping raw sensory information to concepts) and apperceive (combining concepts into declarative rules). © 2022 International Joint Conferences on Artificial Intelligence. All rights reserved.
KW  - Logic programming
KW  - Binary neural networks
KW  - Condition
KW  - Extended abstracts
KW  - Fundamental limitations
KW  - Input sequence
KW  - Machine intelligence
KW  - Neural-networks
KW  - Relational structures
KW  - Sensory experiences
KW  - Sensory input
KW  - Artificial intelligence
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Szymański, J.
AU  - Dobrosolski, J.
AU  - Mora, H.
AU  - Draszawka, K.
TI  - Neural network agents trained by declarative programming tutors
PY  - 2024
T2  - 2024 IEEE Congress on Evolutionary Computation, CEC 2024 - Proceedings
DO  - 10.1109/CEC60901.2024.10611953
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201733815&doi=10.1109%2fCEC60901.2024.10611953&partnerID=40&md5=75a7384fcc0add9cb1679b359d4741e3
AB  - This paper presents an experimental study on the development of a neural network-based agent, trained using data generated using declarative programming. The focus of the study is the application of various agents to solve the classic logic task - The Wumpus World. The paper evaluates the effectiveness of neural-based agents across different map configurations, offering a comparative analysis to underline the strengths and limitations of these approaches. We discuss the quantitative and qualitative aspects of these agents in scenarios that require generalization. For a concise comparison, we present the performance and resource utilization of different agents as follows: The Prolog-based agent showed a base task win rate of 61 %, which dropped to 5 % in a modified task setting, requiring 13KB of memory. The Q- Learning agent achieved a 2 % win rate in the base task, with the modified task performance not applicable, and a memory requirement of 67KB. An agent based on a Convolutional Neural Network (CNN) recorded a 44% win rate on the base task and 32% on the modified task, consuming 134KB of memory. The Deep Q-Network (DQN) agent displayed a 56% win rate in the base task and 46 % in the modified task, necessitating a substantial amount of memory, 284MB.  © 2024 IEEE.
KW  - DQN
KW  - Logic Games
KW  - Prolog
KW  - Reinforcement Learning
KW  - Wumpus World
KW  - Contrastive Learning
KW  - Convolutional neural networks
KW  - Logic programming
KW  - PROLOG (programming language)
KW  - Reinforcement learning
KW  - Software agents
KW  - Declarative Programming
KW  - Deep Q-network
KW  - Logic game
KW  - Network-based
KW  - Neural network agents
KW  - Neural-networks
KW  - Programming tutors
KW  - Prolog
KW  - Reinforcement learnings
KW  - Wumpus world
KW  - Computer circuits
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Jia, F.
AU  - Jia, F.
AU  - Li, H.
AU  - Qi, S.
AU  - Zhu, H.
TI  - Breaking data barriers in medical diagnosis with MSDGD framework based on Gaussian Diffusion Generation
PY  - 2025
T2  - Information Processing and Management
VL  - 62
IS  - 4
C7  - 104130
DO  - 10.1016/j.ipm.2025.104130
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000296136&doi=10.1016%2fj.ipm.2025.104130&partnerID=40&md5=5701cd3a4cdd3c0cee7f312b35d1897c
AB  - Domain knowledge gaps and scarcity of data on rare medical conditions pose significant challenges to leveraging Medical Service Data (MSD) effectively, resulting in compromised research quality and uninformed medical decision-making. To address these limitations, we propose a novel Gaussian diffusion-based MSD generation framework, MSDGD. This framework includes embedding modules such as the Parents-Children Numerical encoding scheme (ParentChild), which encodes column pair interactions, the Random Column Rearrangement algorithm (RamCol), which uncovers hidden multi-column relationships, and a Spatial Dimensional Transformation strategy (DimTrans) for optimal multi-row feature extraction. Additionally, we develop a new UNet model (MSDUNet) and a column relationship predictive process to enhance MSDGD optimization. We perform three sub-experiments to evaluate the effectiveness of MSDGD in generating MSD, and to assess the framework across five metrics, we use (1) a Simulation Table without Column Relationship, (2) a Simulation Table with Column Relationship, and even (3) a complex relationship table derived from real-world U.S. Chronic Disease Indicators datasets. This table contains more than 40 columns and 8x4 categories. The experimental results indicate that MSDGD has a high potential for improving medical service quality, achieving a 97.97% reduction in errors rate, thus promoting research by generating dependable and diversified generation of medical services data. © 2025 Elsevier Ltd
KW  - Categorical data modeling
KW  - Data generation
KW  - Decision support systems
KW  - Diffusion framework
KW  - Medical Service Data
KW  - Categorical data model
KW  - Data generation
KW  - Decision supports
KW  - Diffusion framework
KW  - Gaussian diffusion
KW  - Medical service data
KW  - Medical services
KW  - Service data
KW  - Simulation table
KW  - Support systems
KW  - Data consistency
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CHAP
AU  - Bastian, N.D.
AU  - Jha, S.
AU  - Tabuada, P.
AU  - Veeravalli, V.
AU  - Verma, G.
TI  - Principles of Robust Learning and Inference for IoBTs
PY  - 2022
T2  - IoT for Defense and National Security
SP  - 119
EP  - 131
DO  - 10.1002/9781119892199.ch8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159474892&doi=10.1002%2f9781119892199.ch8&partnerID=40&md5=51bfcf6af1146f2727901cb7f1966a64
AB  - The Internet of Battlefield Things (IoBTs) operate in an adversarial rapidly-evolving environment, necessitating fast, robust and resilient decision-making. The success of machine learning, in particular deep learning methods, can improve the performance and effectiveness of IoBTs, but these models are known to be brittle, untrustworthy, and vulnerable. In this chapter, we discuss the principles and methodologies to make machine learning models robust, resilient to adversarial attacks, and more interpretable for human-on-the-loop decision-making. We also identify the key challenges in developing trustworthy machine learning for IoBTs. © 2023 The Institute of Electrical and Electronics Engineers, Inc.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CHAP
AU  - Pachauri, Y.
AU  - Kumar, R.
AU  - Dalrymple, J.R.
TI  - Introduction to the Metaverse
PY  - 2025
T2  - Applying Metaverse Technologies to Human-Computer Interaction for Healthcare
SP  - 1
EP  - 19
DO  - 10.1201/9781003491668-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218374269&doi=10.1201%2f9781003491668-1&partnerID=40&md5=0a67c1fa2ee0c2d20e84abc81eb27a9e
AB  - The term metaverse, coined almost two decades ago, now describes a virtual realm in which individuals experience complete cognitive immersion using advanced augmented virtual reality technology. Initially, the metaverse was mostly utilized in the form of computer games that featured virtual worlds. Game developers were competing to provide increasingly distinctive experiences to their players. The concept of the metaverse, hailed by social media platforms and tech companies as the frontier of the Internet, is starting to pique the curiosity of everyday people. Scholars, from fields such as literature, art, music, and education, have delved deeply into the potential of the metaverse. Under these conditions, when employing metaverse applications, there are no transportation fees and no limitations on the number of individuals, users, participants, learners, or trainees who can participate. Because of this characteristic, the metaverse has garnered the attention of scholars from other disciplines who have utilized it to make valuable contributions to their respective subjects and areas of study. While developing the metaverse, interested researchers must consider many factors despite its advantages. An issue that arises is the matter of privacy in the metaverse, specifically in relation to the players who are portrayed as avatars within the metaverse environment. Another concern arises from the fact that the metaverse is now in its nascent phase, necessitating numerous efforts from enthusiastic academics who are actively involved in its development and improvement. This chapter tries to systematically study and analyze concepts pertaining to the metaverse and its growth. It provides a comprehensive overview of the chronological stages in the history of metaverse development. Additionally, the challenges encountered by researchers and other pertinent problems pertaining to the metaverse have been thoroughly examined and emphasized. Furthermore, the conclusion has been elucidated. © 2025 selection and editorial matter, B. Sundaravadivazhagan, Balasubramaniam S, Pethuru Raj, and K. Shantha Kumari.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Villalonga-Gomez, C.
AU  - Ortega-Fernandez, E.
AU  - Borau-Boira, E.
TI  - Fifteen Years of Metaverse in Higher Education: A Systematic Literature Review
PY  - 2023
T2  - IEEE Transactions on Learning Technologies
VL  - 16
IS  - 6
SP  - 1057
EP  - 1070
DO  - 10.1109/TLT.2023.3302382
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167833746&doi=10.1109%2fTLT.2023.3302382&partnerID=40&md5=944b67f05aa0f54bf6420e563a29fe41
AB  - The application of the metaverse poses important challenges for the field of education. The aim of this article is to analyze the evolution of the development of the metaverse experiences in Higher Education and thus identify the key aspects of its application as a virtual environment for teaching and learning. To this end, a systematic literature review of articles published in Web of Science and Scopus since 2007 was carried out. In the selection process, 115 articles were identified, of which 34 deal with the metaverse in the field of Higher Education. The analysis shows that the educational metaverse follows a growing trend, since 23.5% of the publications are concentrated in the last year of the analysis and, furthermore, how the metaverse can be analyzed as a virtual learning environment from its three dimensions: technological, pedagogical, and content. Educational practices are identified in multiple areas of knowledge, with the educational metaverse being used in the learning of second languages and the simulation of professional environments, both of which are key to HE teaching. The experiences have had mostly positive results, especially due to the immersive potential of the metaverse and the active role of the learner, who becomes the protagonist of the action. Another key element identified in the development of educational strategies in the metaverse is interaction, not only within the techno-educational context, but also with the learning community itself and the communicative and interactive options that arise in this space.  © 2008-2011 IEEE.
KW  - Augmented reality (AR)
KW  - educational innovation
KW  - higher education
KW  - learning environments
KW  - metaverse
KW  - systematic literature review
KW  - virtual reality (VR)
KW  - Computer aided instruction
KW  - Computer simulation languages
KW  - E-learning
KW  - Engineering education
KW  - Teaching
KW  - Three dimensional displays
KW  - Virtual reality
KW  - Educational innovations
KW  - High educations
KW  - ITS applications
KW  - Learning environments
KW  - Metaverses
KW  - Systematic
KW  - Systematic literature review
KW  - Technological innovation
KW  - Three-dimensional display
KW  - Augmented reality
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 10
ER  -

TY  - CONF
AU  - van der Sluis, D.
TI  - NUTS, NARS, and Speech
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 13921 LNCS
SP  - 307
EP  - 316
DO  - 10.1007/978-3-031-33469-6_31
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163308484&doi=10.1007%2f978-3-031-33469-6_31&partnerID=40&md5=47ca35deb242857d7f7a463c2f4a62d8
AB  - To investigate whether “Intelligence is the capacity of an information-processing system to adapt to its environment while operating with insufficient knowledge and resources" [29], we look at utilising the non axiomatic reasoning system (NARS) for speech recognition. This article presents NUTS: raNdom dimensionality redUction non axiomaTic reasoning few Shot learner for perception. NUTS consists of naive dimensionaility reduction, some pre-processing, and then non axiomatic reasoning (NARS). With only 2 training examples NUTS performs similarly to the Whisper Tiny model for discrete word identification. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Few shot learning
KW  - Non Axiomatic Reasoning
KW  - Perception
KW  - Artificial intelligence
KW  - % reductions
KW  - Axiomatics
KW  - Dimensionality reduction
KW  - Few shot learning
KW  - Information processing systems
KW  - Insufficient knowledge and resources
KW  - Non axiomatic reasoning
KW  - Pre-processing
KW  - Reasoning system
KW  - Training example
KW  - Speech recognition
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Kumar, P.
AU  - Misra, S.
AU  - Shao, Z.
AU  - Zhu, B.
AU  - Raman, B.
AU  - Li, X.
TI  - Multimodal Interpretable Depression Analysis Using Visual, Physiological, Audio and Textual Data
PY  - 2025
T2  - Proceedings - 2025 IEEE Winter Conference on Applications of Computer Vision, WACV 2025
SP  - 5305
EP  - 5315
DO  - 10.1109/WACV61041.2025.00518
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003626655&doi=10.1109%2fWACV61041.2025.00518&partnerID=40&md5=362f46773091c9e100fe33dec0eda3ab
AB  - Motivated by depression's significant impact on global health, this work proposes MultiDepNet, a novel multi-modal interpretable depression detection system integrating visual, physiological, audio, and textual data. Through ded-icated feature extraction methods (MTCNN for video, TS-CAN for physiological, ResNet-18 for audio, and RoBERTa for text modalities) and a strategic fusion of modality-specific networks including CNN-RNN, Transformer, MLP, and ResNet-18, it achieves significant advancements in depression detection. Its performance, evaluated across four benchmark datasets (AVEC 2013, AVEC 2014, DAIC, and E-DAIC), demonstrates average MAE of 5.64, RMSE of 7.15, accuracy of 74.19%, precision of 0.7373, re-call of 0.7378, and F1 of 0.7376. It also implements a Multiviz-based interpretability mechanism that computes each modality's contribution to the model's performance. The results reveal the visual modality to be the most signifi-cant, contributing 37.88% towards depression detection. © 2025 IEEE.
KW  - affective computing
KW  - interpretable ai
KW  - mental health
KW  - multimodal fusion
KW  - social signal analysis
KW  - Affective Computing
KW  - Interpretable ai
KW  - Mental health
KW  - Multi-modal
KW  - Multi-modal fusion
KW  - Physiological data
KW  - Signals analysis
KW  - Social signal analyze
KW  - Social signals
KW  - Visual data
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Mansouri, N.
AU  - Cina, M.
AU  - Ben Jemaa, Y.
AU  - Watelain, E.
TI  - Bayesian model for pedestrian's behavior analysis based on image and video processing
PY  - 2021
T2  - Journal of Electronic Imaging
VL  - 30
IS  - 1
C7  - 013019
DO  - 10.1117/1.JEI.30.1.013019
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101956461&doi=10.1117%2f1.JEI.30.1.013019&partnerID=40&md5=ab59626ef2f29c56b857f70b1f895e6b
AB  - Road accidents continue to increase and cause intense fatalities. Studies based on manual and/or semiautomatic methods remain unable to reliably track the random behavior of pedestrians. Hence, we fill this gap by developing an automatic Bayesian and cognitive model (ABC model) for pedestrian behavior analysis. We propose a full and complete computer vision process composed of two images processing levels: (i) low-level for pedestrian and traffic features extraction to characterize crossing the street scenarios. (ii) High-level for data correlation and behavior recognition based on Bayesian model. Since computer vision sensors are usually unsure, we propose an innovative metric to introduce the detection uncertainty as Bayesian evidence in the Bayesian network decision level. Results highlight computer vision techniques' potential to collect random and reliable road user's data at a degree of automation and accuracy that cannot be feasibly achieved by manual or semiautomated techniques during the first time. During the second time, the Bayesian network structure provides very reliable decisions that can more completely characterize a person's random behavior. In addition to that, quantifying the uncertainty of computer vision's sensors as Bayesian evidence is an important contribution. In fact, the proposed tool will be an important contribution to deal with pedestrian behavior. Hence, the proposed process reliably addresses a person's Bayes behavior and illustrates the pedestrian/environment causal relationship. The proposed ABC model is validated based on cross-street sequences integrating different scenarios and pedestrians' behaviors every 1/10 time slice.  © 2021 SPIE and IS&T.
KW  - Bayesian network
KW  - confidence degree
KW  - evidence generation
KW  - pedestrian behavior
KW  - vision-based data collection
KW  - Automation
KW  - Bayesian networks
KW  - Computer vision
KW  - Motor transportation
KW  - Roads and streets
KW  - Video signal processing
KW  - Bayesian network structure
KW  - Causal relationships
KW  - Computer vision process
KW  - Computer vision sensors
KW  - Computer vision techniques
KW  - Degree of automation
KW  - Image and video processing
KW  - Semiautomatic methods
KW  - Behavioral research
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Holzinger, A.
AU  - Saranti, A.
AU  - Angerschmid, A.
AU  - Finzel, B.
AU  - Schmid, U.
AU  - Mueller, H.
TI  - Toward human-level concept learning: Pattern benchmarking for AI algorithms
PY  - 2023
T2  - Patterns
VL  - 4
IS  - 8
C7  - 100788
DO  - 10.1016/j.patter.2023.100788
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167997340&doi=10.1016%2fj.patter.2023.100788&partnerID=40&md5=89db2402b108e9b5eb7485860172ecc1
AB  - Artificial intelligence (AI) today is very successful at standard pattern-recognition tasks due to the availability of large amounts of data and advances in statistical data-driven machine learning. However, there is still a large gap between AI pattern recognition and human-level concept learning. Humans can learn amazingly well even under uncertainty from just a few examples and are capable of generalizing these concepts to solve new conceptual problems. The growing interest in explainable machine intelligence requires experimental environments and diagnostic/benchmark datasets to analyze existing approaches and drive progress in pattern analysis and machine intelligence. In this paper, we provide an overview of current AI solutions for benchmarking concept learning, reasoning, and generalization; discuss the state-of-the-art of existing diagnostic/benchmark datasets (such as CLEVR, CLEVRER, CLOSURE, CURI, Bongard-LOGO, V-PROM, RAVEN, Kandinsky Patterns, CLEVR-Humans, CLEVRER-Humans, and their extension containing human language); and provide an outlook of some future research directions in this exciting research domain. © 2023 The Authors
KW  - artificial intelligence
KW  - benchmarks
KW  - concept learning
KW  - diagnostic datasets
KW  - pattern analysis
KW  - Artificial intelligence
KW  - Digital storage
KW  - Learning systems
KW  - Pattern recognition
KW  - Artificial intelligence algorithms
KW  - Benchmark
KW  - Benchmark datasets
KW  - Concept learning
KW  - Diagnostic dataset
KW  - Human levels
KW  - Learning patterns
KW  - Machine intelligence
KW  - Pattern analysis
KW  - Standard pattern
KW  - Benchmarking
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 25
ER  -

TY  - CONF
AU  - Dumrongthai, P.
AU  - Riedel, K.L.
AU  - Williams, M.J.
AU  - Izquierdo, M.F.V.
AU  - Hussain, S.A.
AU  - Wilasari, N.M.
AU  - Pramita, M.D.
AU  - Anindita, F.
TI  - Enhancing Geothermal Drilling Performance: A Stuck-Pipe Risk Advisor Leveraging Causal-AI and Semantic Web for Explainable Decision Support
PY  - 2024
T2  - Transactions - Geothermal Resources Council
VL  - 48
SP  - 550
EP  - 567
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214209020&partnerID=40&md5=8614649c158404f542958a336e35777f
AB  - Geothermal drilling operations face inherent challenges, with stuck-pipe incidents posing significant risks to both safety and project success. In this paper, we introduce a groundbreaking stuck-pipe risk advisor (SPRA) that integrates causal artificial intelligence (AI) and semantic web technologies to provide explainable real-time decision support and enhance drilling performance. Our causal-AI model uses advanced machine-learning algorithms to analyze historical drilling data, identifying complex relationships and potential risk factors which may lead to stuck-pipe incidents. By leveraging causal relationships, the SPRA can proactively assess the likelihood of a stuck-pipe occurrence based on current drilling conditions. To enhance transparency and trust in the decision-making process, our system incorporates semantic web technologies to generate explainable outputs. The SPRA generates detailed explanations of its predictions, using semantic annotations to link specific risk factors through causal relationships. This not only aids drilling operators in understanding the basis of the system's reported risk levels but also facilitates continuous learning and improvement of drilling practices. In addition, the SPRA has a flow-diagram-based interface for drilling operators that shows risk factors, possible solutions, and interactive explanations in real time. By empowering operators with actionable insights, the SPRA aims to support the wellsite team in reducing the frequency of stuck-pipe incidents, enhancing drilling efficiency, and ultimately contributing to the overall safety and success of geothermal drilling projects. We present the development, validation, and practical application of the SPRA, demonstrating its potential to revolutionize geothermal drilling performance through causal AI and semantic web technologies. © 2024 Geothermal Resources Council. All rights reserved.
KW  - Causal AI
KW  - Drilling
KW  - Geothermal
KW  - Machine Learning
KW  - Semantic Web
KW  - Stuck Pipe Risk Advisor
KW  - Adversarial machine learning
KW  - Geothermal fields
KW  - Geothermal wells
KW  - Risk assessment
KW  - Causal artificial intelligence
KW  - Drilling performance
KW  - Geothermal
KW  - Geothermal drilling
KW  - Machine-learning
KW  - Risk factors
KW  - Semantic Web technology
KW  - Semantic-Web
KW  - Stick pipe risk advisor
KW  - Stuck pipe
KW  - Decision making
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Raghavendra, R.
AU  - Pandeya, M.
AU  - Kumar, D.
TI  - The Smart Intuitive Natural Language Understanding with Recurrent Neural Networks
PY  - 2024
T2  - 2024 International Conference on Optimization Computing and Wireless Communication, ICOCWC 2024
DO  - 10.1109/ICOCWC60930.2024.10470796
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190246521&doi=10.1109%2fICOCWC60930.2024.10470796&partnerID=40&md5=8cdaea5ef4d52c3abfd942ca8efac303
AB  - Recurrent neural networks (RNNs) are becoming increasingly popular in addressing natural language knowledge duties. It is because of their ability to capture lengthy-time period dependencies and collection shapes by leveraging the temporal houses of lengthy-time period reminiscence. Mainly, RNNs can process facts with unique sequences of inputs, continuously running the same functions over various series steps. By using expertise-primarily based techniques in the shape of knowledge graphs, ontologies, and semantic triples, RNNs may be used to explain the semantic relationships between domain entities and their related attributes. The innovative Intuitive natural Language information (INLU) with RNNs combines knowledge-based tactics with the strength of collecting and gaining knowledge of RNNs. It allows for understanding natural language by modulating the understanding of graph semantic models to seize and interact with the distributed representations of language. This method allows RNNs to research languages and identifiers that may be used to interpret personal queries. Moreover, INLU permits efficient inference over the semantic graph to provide correct information on herbal language queries. INLU can obtain superior semantic accuracy and extra-accurate question matching by offering semantic relationships among user questions and related domains. © 2024 IEEE.
KW  - modulating
KW  - neural networks
KW  - Recurrent
KW  - reminiscence
KW  - understanding
KW  - Knowledge graph
KW  - Semantics
KW  - Language informations
KW  - Modulating
KW  - Natural language understanding
KW  - Natural languages
KW  - Neural-networks
KW  - Recurrent
KW  - Reminiscence
KW  - Semantic relationships
KW  - Time-periods
KW  - Understanding
KW  - Recurrent neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Roy, R.
AU  - Babakerkhell, M.D.
AU  - Mukherjee, S.
AU  - Pal, D.
AU  - Funilkul, S.
TI  - Development of a Framework for Metaverse in Education: A Systematic Literature Review Approach
PY  - 2023
T2  - IEEE Access
VL  - 11
SP  - 57717
EP  - 57734
DO  - 10.1109/ACCESS.2023.3283273
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161503839&doi=10.1109%2fACCESS.2023.3283273&partnerID=40&md5=f0704fad3db8f1e60c24725ef6315bed
AB  - A more interactive learning environment is made possible by the metaverse, a made-up world with vastly expanding digital spaces. The metaverse is a development in synchronous communication that enables many users to share different experiences. This study proposes a research framework for adopting metaverse in education. A systematic literature review using the PRISMA methodology identified seventy-three research papers on metaverse and education. Also, this research provided various applications, challenges, dominant themes of research, and future perspectives of a metaverse in education. The proposed framework discusses multiple drivers for adopting a metaverse in education. There are few papers in the metaverse for education, so this research tries to fill the gap. This research also proposed twenty-seven future research questions which can addressed by future researchers. This research will benefit students and teachers across universities/ colleges and schools.  © 2013 IEEE.
KW  - education
KW  - Metaverse
KW  - PRISMA
KW  - students
KW  - teachers
KW  - universities/colleges
KW  - Computer aided instruction
KW  - Market Research
KW  - Personnel training
KW  - Teaching
KW  - Interactive learning environment
KW  - Market researches
KW  - Medical services
KW  - Metaverses
KW  - PRISMA
KW  - Systematic
KW  - Systematic literature review
KW  - Teachers'
KW  - University/college
KW  - Students
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 29
ER  -

TY  - JOUR
AU  - Ramos, I.F.
AU  - Gianini, G.
AU  - Leva, M.C.
AU  - Damiani, E.
TI  - Collaborative Intelligence for Safety-Critical Industries: A Literature Review
PY  - 2024
T2  - Information (Switzerland)
VL  - 15
IS  - 11
C7  - 728
DO  - 10.3390/info15110728
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210224295&doi=10.3390%2finfo15110728&partnerID=40&md5=f2e44973010e4dea0b2b97173c52a073
AB  - While AI-driven automation can increase the performance and safety of systems, humans should not be replaced in safety-critical systems but should be integrated to collaborate and mitigate each other’s limitations. The current trend in Industry 5.0 is towards human-centric collaborative paradigms, with an emphasis on collaborative intelligence (CI) or Hybrid Intelligent Systems. In this survey, we search and review recent work that employs AI methods for collaborative intelligence applications, specifically those that focus on safety and safety-critical industries. We aim to contribute to the research landscape and industry by compiling and analyzing a range of scenarios where AI can be used to achieve more efficient human–machine interactions, improved collaboration, coordination, and safety. We define a domain-focused taxonomy to categorize the diverse CI solutions, based on the type of collaborative interaction between intelligent systems and humans, the AI paradigm used and the domain of the AI problem, while highlighting safety issues. We investigate 91 articles on CI research published between 2014 and 2023, providing insights into the trends, gaps, and techniques used, to guide recommendations for future research opportunities in the fast developing collaborative intelligence field. © 2024 by the authors.
KW  - AI
KW  - collaborative intelligence
KW  - safety-critical industries
KW  - 'current
KW  - Collaborative intelligence
KW  - Collaborative interaction
KW  - Human machine interaction
KW  - Human-centric
KW  - Hybrid intelligent system
KW  - Literature reviews
KW  - Performance
KW  - Safety critical systems
KW  - Safety-critical industry
KW  - Intelligent systems
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Lui, A.K.-F.
AU  - Lui, T.-T.
AU  - Leung, T.C.-H.
AU  - Chan, H.-Y.
TI  - Recognition of roles of variables based on deep learning technologies
PY  - 2020
T2  - Communications in Computer and Information Science
VL  - 1302
SP  - 362
EP  - 374
DO  - 10.1007/978-981-33-4594-2_30
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098240427&doi=10.1007%2f978-981-33-4594-2_30&partnerID=40&md5=77a5d37200451ab25d71a663fe2ed008
AB  - Using variables in regulating computing procedures is a key competence of structured programming. This tacit knowledge, which is highly repetitive and transferrable between programming tasks, may be succinctly described as the roles of variables. The role of a variable defines the pattern of the uses and changes of variable for computing procedures. This notion is an effective pedagogical tool for providing feedback on how to fix faulty computing procedures linked to misuse of variables. This paper proposes the automation of variable role recognition and describes an evaluation study for a variable role classifier based on deep neural network architectures. The classifier is designed to learn the variable roles from execution-time traces of variables. Experimental results showed the classification accuracy reached over 0.95. Other findings indicated that the variable roles revealed diverse temporal characteristics in their execution-time traces, and specifically designed deep learning architectures would be needed for some individual roles. Automated variable role recognition will find applications in intelligent tutoring systems and the feedback to programs will significantly improve learning effectiveness. © 2020, Springer Nature Singapore Pte Ltd.
KW  - Deep learning
KW  - Machine learning
KW  - Novice programmers
KW  - Programming
KW  - Roles of variables
KW  - Application programs
KW  - Computer aided instruction
KW  - Deep neural networks
KW  - Educational technology
KW  - Network architecture
KW  - Structured programming
KW  - Classification accuracy
KW  - Intelligent tutoring system
KW  - Learning architectures
KW  - Learning effectiveness
KW  - Learning technology
KW  - Pedagogical tools
KW  - Programming tasks
KW  - Temporal characteristics
KW  - Deep learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Wang, Y.
AU  - Liu, H.
TI  - Comparative Study of Algorithms Used in Water Pollution Prevention and Control
PY  - 2023
T2  - Frontiers in Artificial Intelligence and Applications
VL  - 373
SP  - 1142
EP  - 1150
DO  - 10.3233/FAIA230931
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181404875&doi=10.3233%2fFAIA230931&partnerID=40&md5=6c3e2922fb243ba531b8439ca2613ca9
AB  - Water pollution prevention and control is crucial to ensure the safety of water environment and human health, and various types of algorithms play an important role in it. We introduce the history and algorithm overview of various algorithms in water pollution prevention and control, analyze the current research status and recent research results in this field, compare and evaluate the advantages and disadvantages of various algorithms, and focus on the following algorithms: neural network, convolutional neural network, decision tree, random forest, naive Bayes, SVM, K-Means, and AdaBoost. Through the comparative analysis of these algorithms, we hope to provide a more effective method for water pollution prevention and control.  © 2023 The Authors.
KW  - algorithms
KW  - comparative study
KW  - prevention and control
KW  - water pollution
KW  - Adaptive boosting
KW  - Convolutional neural networks
KW  - Decision trees
KW  - K-means clustering
KW  - Comparatives studies
KW  - Control analysis
KW  - Current research status
KW  - Human health
KW  - Neural-networks
KW  - Prevention and controls
KW  - Recent researches
KW  - Research results
KW  - Water environments
KW  - Water pollution prevention and controls
KW  - Water pollution
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Wang, X.
AU  - Wang, X.
AU  - Park, S.
AU  - Yao, Y.
TI  - Mental Models of Generative AI Chatbot Ecosystems
PY  - 2025
T2  - International Conference on Intelligent User Interfaces, Proceedings IUI
SP  - 1016
EP  - 1031
DO  - 10.1145/3708359.3712125
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001923216&doi=10.1145%2f3708359.3712125&partnerID=40&md5=a9e9de6147d4f51400958649c6812d00
AB  - The capability of GenAI-based chatbots, such as ChatGPT and Gemini, has expanded quickly in recent years, turning them into GenAI Chatbot Ecosystems. Yet, users' understanding of how such ecosystems work remains unknown. In this paper, we investigate users' mental models of how GenAI Chatbot Ecosystems work. This is an important question because users' mental models guide their behaviors, including making decisions that impact their privacy. Through 21 semi-structured interviews, we uncovered users' four mental models towards first-party (e.g., Google Gemini) and third-party (e.g., ChatGPT) GenAI Chatbot Ecosystems. These mental models centered around the role of the chatbot in the entire ecosystem. We further found that participants held a more consistent and simpler mental model towards third-party ecosystems than the first-party ones, resulting in higher trust and fewer concerns towards the third-party ecosystems. We discuss the design and policy implications based on our results.  © 2025 Copyright held by the owner/author(s).
KW  - Generative AI Chatbots
KW  - Human Computer Interaction
KW  - Mental Models
KW  - Privacy and Security
KW  - Chatbots
KW  - Computer interaction
KW  - Generative AI chatbot
KW  - Google+
KW  - Making decision
KW  - Mental model
KW  - Privacy and security
KW  - Semi structured interviews
KW  - Simple++
KW  - Third parties
KW  - Generative adversarial networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Sun, B.
AU  - Li, H.
AU  - Wang, J.
TI  - Two-stage dynamic time warping for intelligent fault detection of rotating machinery under variable speed
PY  - 2025
T2  - Measurement Science and Technology
VL  - 36
IS  - 5
C7  - 056124
DO  - 10.1088/1361-6501/add0cf
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005147928&doi=10.1088%2f1361-6501%2fadd0cf&partnerID=40&md5=fb1e6e1d12baa0cf6aeeaee6c67ce965
AB  - Effective fault detection in rotating machinery operating at variable speeds often necessitates numerous fault samples for deep learning model training. In practice, acquiring sufficient fault samples is frequently challenging due to cost limitations. To address this issue, this paper introduces a two-stage dynamic time warping (DTW) method for intelligent fault detection in rotating machinery at variable speeds. In the first stage, the original fault signal is filtered based on the collected speed data to create a vibration signal for the shaft under variable speeds. A reference signal for fixed speed is then estimated, allowing the DTW algorithm to determine optimal paths for regularization. This process transforms the non-stationary signal, mitigating the effects of speed variations, and normalizes it to produce a consistent signal. The normalized signal undergoes spectral analysis to generate a normalized order spectrum. In the second stage, distances to each standard sample in the order domain are calculated using the DTW algorithm, with the shortest distance indicating the corresponding fault type. Finally, experimental data from bearings and gears is utilized, comparing this method with others to demonstrate its effectiveness and advantages. © 2025 IOP Publishing Ltd. All rights, including for text and data mining, AI training, and similar technologies, are reserved.
KW  - dynamic time warping
KW  - intelligent fault detection
KW  - rotating machinery
KW  - two-stage
KW  - variable speed
KW  - Dynamic time warping
KW  - Dynamic time warping algorithms
KW  - Fault sample
KW  - Faults detection
KW  - Intelligent fault detection
KW  - Learning models
KW  - Model training
KW  - Time warping methods
KW  - Two-stage
KW  - Variable speed
KW  - Rotating machinery
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Yahya, M.
AU  - Zhou, B.
AU  - Breslin, J.G.
AU  - Ali, M.I.
AU  - Kharlamov, E.
TI  - Semantic Modeling, Development and Evaluation for the Resistance Spot Welding Industry
PY  - 2023
T2  - IEEE Access
VL  - 11
SP  - 37360
EP  - 37377
DO  - 10.1109/ACCESS.2023.3267000
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153380122&doi=10.1109%2fACCESS.2023.3267000&partnerID=40&md5=a0adaf5fa17fa78a983bea1a127c1b59
AB  - The ongoing industrial revolution termed Industry 4.0 (I4.0) has borne witness to a series of profound changes towards increasing smart automation, particularly in the industrial sectors of automotive, aerospace, manufacturing, etc. Automatic welding, a widely applied manufacturing process in these domains, is not an exception to these changes. One type of automatic welding, Resistance Spot Welding (RSW), lies at the center of this work. Large volumes and varieties of RSW data are being generated, thanks to the technologies behind I4.0. To address the associated data challenges, ontologies are essential in various aspects: integrating data sources, enhancing interoperability, and unifying knowledge etc. However, there have been limited studies around the semantic modelling of Resistance Spot Welding: Existing ontologies have overlooked some crucial concepts, such as an operation-centric view, welding software, and welding electrodes, which are essential for the monitoring of sensor measurements as well as the status of machine components (e.g., electrode wear). Additionally, current ontologies are not publicly available (to the best of our knowledge), and therefore cannot be accessed by other users. Such a lack of availability often requires that users build their ontologies from scratch. In this paper, we propose our RSW ontology (RSWO) (RSWO is publicly available at https://w3id.org/def/mo-rswo) to formalize knowledge in the RSW domain. It combines three sources of knowledge: extensive discussions with Bosch welding experts; reusing terminologies following ISO-14327 and ISO-14373 standards; and existing established ontologies. We have evaluated RSWO on real-world data from monitoring welding quality at Bosch in Germany, using Competency Questions, FAIR principles, OOPS!, and OntoMetrics. © 2013 IEEE.
KW  - knowledge representation
KW  - ontology
KW  - Resistance spot welding
KW  - semantic modeling
KW  - smart manufacturing
KW  - Flow control
KW  - Knowledge representation
KW  - Quality control
KW  - Semantics
KW  - Spot welding
KW  - Automatic welding
KW  - Knowledge represenation
KW  - Knowledge-representation
KW  - Ontology's
KW  - Resistance
KW  - Resistance spot welding
KW  - Semantic modelling
KW  - Smart manufacturing
KW  - Ontology
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 10
ER  -

TY  - CONF
AU  - Arabshahi, F.
AU  - Lee, J.
AU  - Bosselut, A.
AU  - Choi, Y.
AU  - Mitchell, T.
TI  - Conversational Multi-Hop Reasoning with Neural Commonsense Knowledge and Symbolic Logic Rules
PY  - 2021
T2  - EMNLP 2021 - 2021 Conference on Empirical Methods in Natural Language Processing, Proceedings
SP  - 7404
EP  - 7418
DO  - 10.18653/v1/2021.emnlp-main.588
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127456748&doi=10.18653%2fv1%2f2021.emnlp-main.588&partnerID=40&md5=f5d472f2d23771143ffc8c7dee25db7a
AB  - One of the challenges faced by conversational agents is their inability to identify unstated presumptions of their users' commands, a task trivial for humans due to their common sense. In this paper, we propose a zero-shot commonsense reasoning system for conversational agents in an attempt to achieve this. Our reasoner uncovers unstated presumptions from user commands satisfying a general template of if-(state ), then-(action ), because-(goal ). Our reasoner uses a state-of-the-art transformer-based generative commonsense knowledge base (KB) as its source of background knowledge for reasoning. We propose a novel and iterative knowledge query mechanism to extract multi-hop reasoning chains from the neural KB which uses symbolic logic rules to significantly reduce the search space. Similar to any KBs gathered to date, our commonsense KB is prone to missing knowledge. Therefore, we propose to conversationally elicit the missing knowledge from human users with our novel dynamic question generation strategy, which generates and presents contextualized queries to human users. We evaluate the model with a user study with human users that achieves a 35% higher success rate compared to SOTA. © 2021 Association for Computational Linguistics
KW  - Computational linguistics
KW  - Computer circuits
KW  - Natural language processing systems
KW  - Zero-shot learning
KW  - Common sense
KW  - Commonsense knowledge
KW  - Commonsense knowledge basis
KW  - Conversational agents
KW  - Human users
KW  - Logic rules
KW  - Multi-hops
KW  - Reasoners
KW  - Symbolic logic
KW  - User commands
KW  - Knowledge based systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 13
ER  -

TY  - JOUR
AU  - Xia, T.
AU  - Dai, Z.
AU  - Zhang, Y.
AU  - Wang, F.
AU  - Zhang, W.
AU  - Xu, L.
AU  - Zhou, D.
AU  - Zhou, J.
TI  - Construction Method and Practical Application of Oil and Gas Field Surface Engineering Case Database Based on Knowledge Graph
PY  - 2024
T2  - Processes
VL  - 12
IS  - 6
C7  - 1088
DO  - 10.3390/pr12061088
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197244075&doi=10.3390%2fpr12061088&partnerID=40&md5=3837871d3fffa5e3a574c1d2cc43dbbb
AB  - To address the challenge of quickly and efficiently accessing relevant management experience for a wide range of ground engineering construction projects, supporting project management with information technology is crucial. This includes the establishment of a case database and an application platform for intelligent search and recommendations. The article leverages Optical Character Recognition (OCR) technology, knowledge graph technology, and Natural Language Processing (NLP) technology. It explores the mechanisms for classifying construction cases, methods for constructing a case database, structuring case data, intelligently retrieving and matching cases, and intelligent recommendation methods. This research forms a complete, feasible, and scalable method for deconstructing, storing, intelligently retrieving, and recommending construction cases, providing a theoretical basis for the establishment of a construction case database. It aims to meet the needs of digital project management and intelligent decision-making support in the oil and gas sector, thereby enhancing the efficiency and accuracy of project construction. This work offers a theoretical foundation for the development of an intelligent management platform for ground engineering projects in the oil and gas industry, supporting the sector’s digital transformation and intelligent development. © 2024 by the authors.
KW  - decision-making assistance
KW  - engineering construction cases
KW  - intelligent push
KW  - intelligent retrieval
KW  - knowledge graph technology
KW  - Classification (of information)
KW  - Database systems
KW  - Gas industry
KW  - Knowledge graph
KW  - Natural language processing systems
KW  - Optical character recognition
KW  - Project management
KW  - Case database
KW  - Construction case
KW  - Decision-making assistance
KW  - Decisions makings
KW  - Engineering construction case
KW  - Engineering constructions
KW  - Intelligent push
KW  - Intelligent retrieval
KW  - Knowledge graph technology
KW  - Knowledge graphs
KW  - Decision making
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CHAP
AU  - Kotal, A.
AU  - Chukkapalli, S.S.L.
AU  - Joshi, A.
TI  - Synthetic Data for Privacy Preservation in Distributed Data Analysis Systems
PY  - 2025
T2  - Springer Optimization and Its Applications
VL  - 213
SP  - 393
EP  - 407
DO  - 10.1007/978-3-031-58923-2_13
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203269576&doi=10.1007%2f978-3-031-58923-2_13&partnerID=40&md5=5a333aa9b934e847a9a7232bfa771c6c
AB  - Over the years, data anonymization and federated learning have been proposed to address the challenges of data privacy in distributed systems. Unfortunately, data anonymization techniques are not fool proof and can be broken with new information that an adversary may obtain or through weaknesses in the anonymization process. Federated learning techniques are costly to maintain and require consensus and centralization of models. This limits the ability to share data across organizations of diverse administrative and judiciary needs. One approach to address these challenges is the generation of synthetic data. Generating synthetic data provides a practical way to make data available while preserving privacy. Generative models produce data indistinguishable from real-world data while safeguarding privacy. Synthetic data offers cost-effective, scalable datasets that encourages data sharing. It reduces data privacy costs, fosters experimentation, enables collaboration, and expedites projects, seamlessly aligning with digital transformation goals. In this chapter, we review the work in this space and describe some of our own recent efforts. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Meli, D.
AU  - Fiorini, P.
TI  - Inductive learning of robot task knowledge from raw data and online expert feedback
PY  - 2025
T2  - Machine Learning
VL  - 114
IS  - 4
C7  - 91
DO  - 10.1007/s10994-024-06636-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218415349&doi=10.1007%2fs10994-024-06636-6&partnerID=40&md5=548b1abd48789db696469279abda75aa
AB  - The increasing level of autonomy of robots poses challenges of trust and social acceptance, especially in human-robot interaction scenarios. This requires an interpretable implementation of robotic cognitive capabilities, possibly based on formal methods as logics for the definition of task specifications. However, prior knowledge is often unavailable in complex realistic scenarios. In this paper, we propose an offline algorithm based on inductive logic programming from noisy examples to extract task specifications (i.e., action preconditions, constraints and effects) directly from raw data of few heterogeneous (i.e., not repetitive) robotic executions. Our algorithm leverages on the output of any unsupervised action identification algorithm from video-kinematic recordings. Combining it with the definition of very basic, almost task-agnostic, commonsense concepts about the environment, which contribute to the interpretability of our methodology, we are able to learn logical axioms encoding preconditions of actions, as well as their effects in the event calculus paradigm. Since the quality of learned specifications depends mainly on the accuracy of the action identification algorithm, we also propose an online framework for incremental refinement of task knowledge from user’s feedback, guaranteeing safe execution. Results in a standard manipulation task and benchmark for user training in the safety-critical surgical robotic scenario, show the robustness, data- and time-efficiency of our methodology, with promising results towards the scalability in more complex domains. © The Author(s), under exclusive licence to Springer Science+Business Media LLC, part of Springer Nature 2025.
KW  - Answer set programming
KW  - Explainable AI
KW  - Human-robot interaction
KW  - Inductive logic programming
KW  - Learning under uncertainty
KW  - Online learning
KW  - Adversarial machine learning
KW  - Benchmarking
KW  - Contrastive Learning
KW  - Inductive logic programming (ILP)
KW  - Robot learning
KW  - Robotic surgery
KW  - Social robots
KW  - Answer set programming
KW  - Explainable AI
KW  - Humans-robot interactions
KW  - Inductive logic
KW  - Inductive logic programming
KW  - Learning under uncertainty
KW  - Logic-programming
KW  - Online learning
KW  - Task knowledge
KW  - Uncertainty
KW  - Robot programming
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Driess, D.
AU  - Xia, F.
AU  - Sajjadi, M.S.M.
AU  - Lynch, C.
AU  - Chowdhery, A.
AU  - Ichter, B.
AU  - Wahid, A.
AU  - Tompson, J.
AU  - Vuong, Q.
AU  - Yu, T.
AU  - Huang, W.
AU  - Chebotar, Y.
AU  - Sermanet, P.
AU  - Duckworth, D.
AU  - Levine, S.
AU  - Vanhoucke, V.
AU  - Hausman, K.
AU  - Toussaint, M.
AU  - Greff, K.
AU  - Zeng, A.
AU  - Mordatch, I.
AU  - Florence, P.
TI  - PaLM-E: An Embodied Multimodal Language Model
PY  - 2023
T2  - Proceedings of Machine Learning Research
VL  - 202
SP  - 8469
EP  - 8488
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170634258&partnerID=40&md5=69865ee6ac0e743ba265560bdd027eae
AB  - Large language models excel at a wide range of complex tasks. However, enabling general inference in the real world, e.g. for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multimodal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pre-trained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning. Our evaluations show that PaLM-E, a single large embodied multimodal model, can address a variety of embodied reasoning tasks, from a variety of observation modalities, on multiple embodiments, and further, exhibits positive transfer: the model benefits from diverse joint training across internet-scale language, vision, and visual-language domains. Our largest model with 562B parameters, in addition to being trained on robotics tasks, is a visual-language generalist with state-of-the-art performance on OK-VQA, and retains generalist language capabilities with increasing scale. © 2023 Proceedings of Machine Learning Research. All rights reserved.
KW  - Computational linguistics
KW  - Encoding (symbols)
KW  - Machine learning
KW  - Natural language processing systems
KW  - Robot programming
KW  - Complex task
KW  - Continuous state
KW  - Encodings
KW  - Excel
KW  - Input encoding
KW  - Language model
KW  - Multi-modal
KW  - Real-world
KW  - Robotic problems
KW  - Sensor modality
KW  - Visual languages
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 168
ER  -

TY  - JOUR
AU  - Mansor, M.A.
AU  - Jamaludin, S.Z.M.
AU  - Kasihmuddin, M.S.M.
AU  - Alzaeemi, S.A.
AU  - Basir, M.F.M.
AU  - Sathasivam, S.
TI  - Systematic boolean satisfiability programming in radial basis function neural network
PY  - 2020
T2  - Processes
VL  - 8
IS  - 2
C7  - 214
DO  - 10.3390/pr8020214
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080907719&doi=10.3390%2fpr8020214&partnerID=40&md5=2e73f44f9341ea8f64ca94810d243ae5
AB  - Radial Basis Function Neural Network (RBFNN) is a class of Artificial Neural Network (ANN) that contains hidden layer processing units (neurons) with nonlinear, radially symmetric activation functions. Consequently, RBFNN has extensively suffered from significant computational error and difficulties in approximating the optimal hidden neuron, especially when dealing with Boolean Satisfiability logical rule. In this paper, we present a comprehensive investigation of the potential effect of systematic Satisfiability programming as a logical rule, namely 2 Satisfiability (2SAT) to optimize the output weights and parameters in RBFNN. The 2SAT logical rule has extensively applied in various disciplines, ranging from industrial automation to the complex management system. The core impetus of this study is to investigate the effectiveness of 2SAT logical rule in reducing the computational burden for RBFNN by obtaining the parameters in RBFNN. The comparison is made between RBFNN and the existing method, based on the Hopfield Neural Network (HNN) in searching for the optimal neuron state by utilizing different numbers of neurons. The comparison was made with the HNN as a benchmark to validate the final output of our proposed RBFNN with 2SAT logical rule. Note that the final output in HNN is represented in terms of the quality of the final states produced at the end of the simulation. The simulation dynamic was carried out by using the simulated data, randomly generated by the program. In terms of 2SAT logical rule, simulation revealed that RBFNN has two advantages over HNN model: RBFNN can obtain the correct final neuron state with the lowest error and does not require any approximation for the number of hidden layers. Furthermore, this study provides a new paradigm in the field feed-forward neural network by implementing a more systematic propositional logic rule. © 2020 by the authors.
KW  - Hopfield neural network
KW  - Logic programming
KW  - Optimization
KW  - Radial basis function neural network
KW  - Satisfiability
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 18
ER  -

TY  - JOUR
AU  - Chen, W.
AU  - Zhang, J.
AU  - Yu, Z.
TI  - A Bibliometric Analysis of the Use of the Metaverse in Education over Three Decades
PY  - 2023
T2  - International Journal of Information and Communication Technology Education
VL  - 19
IS  - 1
DO  - 10.4018/IJICTE.322101
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159211685&doi=10.4018%2fIJICTE.322101&partnerID=40&md5=56a5955ab34ec0eae23c752bb82ec5af
AB  - Since Facebook announced itself as Meta, the metaverse has been popular with educationalists. However, scanty studies have bibliographically analyzed the use of the metaverse in education. This study complements the missing link in the literature by bibliometrically analyzing the research into the use of the metaverse in education using both VOSviewer and CitNetExplorer. The study identified the top authors, organizations, countries, keywords, documents, sources, the research trends, and challenges of the metaverse used in education, together with the effects of the metaverse on learning environments, interactions, educational outcomes, and learning attitudes. This study paves a solid ground and provides a meaningful reference for future research in the use of the metaverse in education. Implications for future research were also provided. © 2023 IGI Global. All rights reserved.
KW  - Bibliometric Analysis
KW  - CitNetExplorer
KW  - Education
KW  - Metaverse
KW  - VOSviewer
KW  - Bibliometrics analysis
KW  - Citnetexplorer
KW  - Facebook
KW  - Learning attitudes
KW  - Learning environments
KW  - Metaverses
KW  - Research challenges
KW  - Research trends
KW  - Vosviewer
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 11
ER  -

TY  - CONF
AU  - Xiong, Z.
AU  - Eappen, J.
AU  - Zhu, H.
AU  - Jagannathan, S.
TI  - Robustness to Adversarial Attacks in Learning-Enabled Controllers
PY  - 2021
T2  - ALA 2021 - Adaptive and Learning Agents Workshop at AAMAS 2021
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173574380&partnerID=40&md5=214746020cbb1df3577ae531dde02b19
AB  - Learning-enabled controllers used in cyber-physical systems (CPS) are known to be susceptible to adversarial attacks. Such attacks manifest as perturbations to the states generated by the controller's environment in response to its actions. We consider state perturbations that encompass a wide variety of adversarial attacks and describe an attack scheme for discovering adversarial states. To be useful, these attacks need to be natural, yielding states in which the controller can be reasonably expected to generate a meaningful response. We consider shield-based defenses as a means to improve controller robustness in the face of such perturbations. Our defense strategy allows us to treat the controller and environment as blackboxes with unknown dynamics. We provide a two-stage approach to construct this defense and show its effectiveness through a range of experiments on realistic continuous control domains such as the navigation control-loop of an F16 aircraft and the motion control system of humanoid robots. © 2021 Association for Computing Machinery.
KW  - Adversarial Attack
KW  - Adversarial Defense
KW  - Safe Reinforcement Learning
KW  - Shield
KW  - Air navigation
KW  - Aircraft control
KW  - Anthropomorphic robots
KW  - Embedded systems
KW  - Flight control systems
KW  - Learning systems
KW  - Motion control
KW  - Network security
KW  - Reinforcement learning
KW  - Robustness (control systems)
KW  - Adversarial attack
KW  - Adversarial defense
KW  - Black boxes
KW  - Controller robustness
KW  - Cybe-physical systems
KW  - Cyber-physical systems
KW  - Defense strategy
KW  - Reinforcement learnings
KW  - Safe reinforcement learning
KW  - Shield
KW  - Controllers
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Wang, X.
AU  - Wang, Y.
AU  - He, D.
AU  - Yu, Z.
AU  - Li, Y.
AU  - Wang, L.
AU  - Dang, J.
AU  - Jin, D.
TI  - Elevating Knowledge-Enhanced Entity and Relationship Understanding for Sarcasm Detection
PY  - 2025
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 37
IS  - 6
SP  - 3356
EP  - 3371
DO  - 10.1109/TKDE.2025.3547055
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000115495&doi=10.1109%2fTKDE.2025.3547055&partnerID=40&md5=adf8e4f779ceb6f5b2990b39a53dd5d1
AB  - Sarcasm thrives on popular social media platforms such as Twitter and Reddit, where users frequently employ it to convey emotions in an ironic or satirical manner. The ability to detect sarcasm plays a pivotal role in comprehending individuals' true sentiments. To achieve a comprehensive grasp of sentence semantics, it is crucial to integrate external knowledge that can aid in deciphering entities and their intricate relationships within a sentence. Although some efforts have been made in this regard, their use of external knowledge is still relatively superficial. Specifically, Knowledge-enhanced entity and relationship understanding still face significant challenges. In this paper, we propose the Knowledge Enhanced Sentiment Dependency Graph Convolutional Network (KSDGCN) framework, which constructs a commonsense-augmented sentiment graph and a commonsense-replaced dependency graph for each text to explicitly capture the role of external knowledge for sarcasm detection. Furthermore, we validate the irrational relationships between co-occurring entity pairs within sentences and background knowledge by a signed attention mechanism. We conduct experiments on four benchmark datasets, and the results show that KSDGCN outperforms existing state-of-the-art methods and is highly interpretable. © 1989-2012 IEEE.
KW  - commonsense knowledge
KW  - external knowledge
KW  - graph convolutional networks
KW  - knowledge graph
KW  - Sarcasm detection
KW  - Semantics
KW  - Social networking (online)
KW  - Tweets
KW  - Background knowledge
KW  - Commonsense knowledge
KW  - Convolutional networks
KW  - Dependency graphs
KW  - External knowledge
KW  - Graph convolutional network
KW  - Knowledge graphs
KW  - Network frameworks
KW  - Sarcasm detection
KW  - Social media platforms
KW  - Knowledge graph
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Alharasees, O.
AU  - Abdalla, M.S.M.
AU  - Kale, U.
TI  - Digitalization in Aviation MRO Training
PY  - 2023
T2  - NTAD 2023 - New Trends in Aviation Development 2023: 18th International Scientific Conference - Proceedings
SP  - 10
EP  - 14
DO  - 10.1109/NTAD61230.2023.10380173
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183466859&doi=10.1109%2fNTAD61230.2023.10380173&partnerID=40&md5=d8310c9d10fcb9f874e186043186fd42
AB  - In the realm of aviation Maintenance, Repair, and Operations (MRO) training, the integration of digital technologies offers a transformative response to industry dynamics. This research delves into this paradigm shift, anchored in the Analytical Hierarchy Process (AHP) methodology. Through meticulous examination of diverse aviation experts representing various job roles and expertise contexts, this study unveils insightful revelations. User satisfaction emerges as a focal point, aligning with the need for enhanced contentment. The analysis accentuates the technical feasibility of digital integration, emphasizing compatibility, reliability, and seamless assimilation within established systems. Expert-derived weights and rankings enhance findings, serving as a foundation for informed decision-making in MRO training digitalization. This synthesis emphasizes aviation's imperative to leverage digitalization, fostering adept professionals capable of navigating contemporary aircraft systems while accommodating diverse job roles and experience levels.  © 2023 IEEE.
KW  - Analytic Hierarchy Process
KW  - Aviation MRO Training
KW  - Digitalization
KW  - Technical Feasibility
KW  - User Satisfaction
KW  - Air navigation
KW  - Analytic hierarchy process
KW  - Personnel training
KW  - Reliability analysis
KW  - Repair
KW  - Training aircraft
KW  - Aviation maintenance
KW  - Aviation maintenance, repair, and operation training
KW  - Aviation operations
KW  - Digital technologies
KW  - Digitalization
KW  - Industry dynamics
KW  - Maintenance repair and operations
KW  - Paradigm shifts
KW  - Technical feasibility
KW  - Users' satisfactions
KW  - Decision making
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Meroño-Peñuela, A.
AU  - Simperl, E.
AU  - Kurteva, A.
AU  - Reklos, I.
TI  - KG.GOV: Knowledge graphs as the backbone of data governance in AI
PY  - 2025
T2  - Journal of Web Semantics
VL  - 85
C7  - 100847
DO  - 10.1016/j.websem.2024.100847
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214472848&doi=10.1016%2fj.websem.2024.100847&partnerID=40&md5=e53cd6f24bb5f26ab9ca3b0c836f42ca
AB  - As (generative) Artificial Intelligence continues to evolve, so do the challenges associated with governing the data that powers it. Ensuring data quality, privacy, security, and ethical use become more and more challenging due to the increasing volume and variety of the data, the complexity of AI models, and the rapid pace of technological advancement. Knowledge graphs have the potential to play a significant role in enabling data governance in AI, as we move beyond their traditional use as data organisational systems. To address this, we present KG.GOV, a framework that positions KGs at a higher abstraction level within AI workflows, and enables them as a backbone of AI data governance. We illustrate the three dimensions of KG.GOV: modelling data, alternative representations, and describing behaviour; and describe the insights and challenges of three use cases implementing them: Croissant, a vocabulary to model and document ML datasets; WikiPrompts, a collaborative KG of prompts and prompt workflows to study their behaviour at scale; and Multimodal transformations, an approach for multimodal KGs harmonisation and completion aiming at broadening access to knowledge. © 2025 The Authors
KW  - AI
KW  - Governance
KW  - Knowledge graphs
KW  - Abstraction level
KW  - Data governances
KW  - Data quality
KW  - Governance
KW  - Knowledge graphs
KW  - Multi-modal
KW  - Organizational system
KW  - Power
KW  - Technological advancement
KW  - Work-flows
KW  - Knowledge graph
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Ichou, S.
AU  - Veress, Á.
TI  - Hierarchy of Roadmap Items: Prioritization Strategy Development in Aircraft MRO Industry to Enhance Profit and Sustainability
PY  - 2024
T2  - Acta Polytechnica Hungarica
VL  - 21
IS  - 6
SP  - 187
EP  - 201
DO  - 10.12700/APH.21.6.2024.6.10
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196496426&doi=10.12700%2fAPH.21.6.2024.6.10&partnerID=40&md5=3dfb1841a6bef45ead909a3092f2cc42
AB  - Aviation’s global aftermarket is expected to grow 22% in 2023, topping $94 billion, and will reach $125 billion by 2033 with a 2.9% compound annual growth rate. Besides that, the aircraft maintenance industry operates in a highly dynamic and competitive environment where ceaseless development is a requirement to ensure continuity, profitability, and sustainability. Hence, and based on the actual technological level and so striving for higher level advancement and introduction of new technologies and processes in this area, a significant number of research and development projects are under way or in the pipeline. With so many new ideas and innovations, it is hard for the upper management to make informed decisions and be sure that those decisions are what the company needs. Usually, these decisions are mainly made from one or a set of managers’ points of view. However, the decision might not be suitable from a scientific point of view due to the numerous factors, data, and concerns that are very hard to spot without a numerical perspective. Hence, it is important to create a scientific strategy to prioritize these new ideas or items based on accurate factors and indications to give a vision of what is the most needed idea to adopt by the company. This is what the present paper is focused on. A case study investigation was made herein, where after collecting all the proposed ideas and development areas from the assigned managers and decision-makers, a prioritization was made. The ideas were ranked based on a novel hierarchy model which was developed to govern the development process of the maintenance repair and overhaul activity in the optimum and effective way to reach the set expectations. It means that the companies can have a scientific tool to point at the development direction that they should follow, and their focus will be shed on the most essential activities at hand and aim to get the most value towards the fulfilment of the upper management goals and stakeholders’ vision. The proposed framework has assessed three different groups of aircraft maintenance development concepts based on a set of picked criteria and concludes which out of the three should be pursued next for more development. The results taken from the created framework showed that the "Development and Digitalization of the Operational Process for MRO Applications" topic is the most interesting one with 34 scores, which is higher than the second one by 21%. The proposed solution not only showed the reliability of this framework to give good decision support but also showed that it could build a suitable, unified structure and procedure to follow while determining the company’s future development direction. © 2024, Budapest Tech Polytechnical Institution. All rights reserved.
KW  - Aircraft maintenance repair and overhaul
KW  - Decision Making
KW  - Management strategy
KW  - Roadmap Item Prioritization
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Gupta, S.
AU  - Kaloo, G.
AU  - Sharma, P.
AU  - Wali, A.
AU  - Bali, A.
AU  - Aslam, M.
TI  - Machine Learning-Based Approach for Diabetes Detection and Prediction
PY  - 2025
T2  - Proceedings - 3rd International Conference on Advancement in Computation and Computer Technologies, InCACCT 2025
SP  - 671
EP  - 676
DO  - 10.1109/InCACCT65424.2025.11011335
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007656414&doi=10.1109%2fInCACCT65424.2025.11011335&partnerID=40&md5=bb1587ddadbe7c5097dbe7860e2e0708
AB  - Diabetes, is a group of metabolic disorders in which there are high blood sugar levels over a prolonged period. If it was possible to predict the chance of the development of the disease then more timely intervention might help reduce the extent to which the disease effects its victims and health care services. This study focuses on the use of Machine Learning (ML) algorithms in analyzing patient data for the purpose of predicting diabetes risk. The Logistic Regression, Decision Tree, K-Nearest neighbors, Random Forest, Gradient Boost, Naive Bayes and XGBoost algorithms were employed to classify diabetes status, leveraging demographic and clinical features from a dataset of patient records. Each model’s effectiveness was assessed through preprocessing steps such as encoding categorical variables (e.g., gender and smoking history) and scaling numerical attributes (e.g., age, BMI, blood glucose levels). These classifiers have been evaluated using metrics which included accuracy, precision, recall and F1-score to gain the predictive performance and generalizability. Among all the models, Gradient Boost and XGBoost classifiers demonstrated the highest accuracy having 86% and 0.85 and robustness which makes them highly suitable for clinical decision-making applications in diabetes diagnosis and management. © 2025 IEEE.
KW  - Decision tree
KW  - Gradient boost
KW  - Logistic regression
KW  - Machine learning
KW  - Model prediction
KW  - Blood sugar levels
KW  - Diabetes detection
KW  - Gradient boost
KW  - Healthcare services
KW  - Learning-based approach
KW  - Logistics regressions
KW  - Machine learning algorithms
KW  - Machine-learning
KW  - Metabolic disorders
KW  - Model prediction
KW  - Logistic regression
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Li, X.
AU  - Peng, H.
AU  - Wang, H.
AU  - Huang, Q.
AU  - Xu, Z.
TI  - PCA and Binary K -Means Clustering Based Collaborative Filtering Recommendation
PY  - 2023
T2  - Journal of Sensors
VL  - 2023
C7  - 2724418
DO  - 10.1155/2023/2724418
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154547904&doi=10.1155%2f2023%2f2724418&partnerID=40&md5=f4d535face27e90d85b90cc7b6f2d1d5
AB  - Aiming at the problem of similarity calculation error caused by the extremely sparse data in collaborative filtering recommendation algorithm, a collaborative filtering recommendation algorithm based on slope one matrix prefilling model, principal component dimension reduction, and binary K-means clustering is proposed in this paper. Firstly, the algorithm uses the slope one model based on item similarity to prefill the original scoring matrix. Secondly, principal component analysis is used to reduce the dimension of the filled matrix, retain the most representative dimension of user characteristics, and remove the dimension with less information. Finally, in order to solve the time-consuming problem of similarity calculation of collaborative filtering algorithm in the case of large-scale system, binary K-means clustering is carried out in the reduced dimension vector space to reduce the search range of the nearest neighbour of the target user. The algorithm ensures the efficiency and accuracy of recommendation while the scale of users is expanded. The experimental results on movielens dataset show that the algorithm proposed in this paper is superior to the traditional collaborative filtering algorithm and the collaborative filtering recommendation algorithm based on PCA (principal component analysis) and binary K-means clustering in recall rate, accuracy rate, average error, and running time. © 2023 Xiao Li et al.
KW  - Cluster analysis
KW  - Collaborative filtering
KW  - Large scale systems
KW  - Matrix algebra
KW  - Nearest neighbor search
KW  - Principal component analysis
KW  - Signal filtering and prediction
KW  - Vector spaces
KW  - Calculation error
KW  - Collaborative filtering algorithms
KW  - Collaborative filtering recommendations
KW  - K-means++ clustering
KW  - matrix
KW  - Principal-component analysis
KW  - Recommendation algorithms
KW  - Similarity calculation
KW  - Slope ones
KW  - Sparse data
KW  - K-means clustering
M3  - Retracted
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Lai, Y.
AU  - Li, X.
AU  - Long, Y.
AU  - Su, L.
AU  - Qi, K.
AU  - Gan, L.
TI  - A novel intelligent evacuation system under complex fire scenarios for multi-storey buildings based on computer vision
PY  - 2025
T2  - International Journal of Management Science and Engineering Management
DO  - 10.1080/17509653.2025.2475759
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000527154&doi=10.1080%2f17509653.2025.2475759&partnerID=40&md5=eb49b6eec4522a7c1c20ec048652935c
AB  - Due to their complex structures and high occupancy, multi-storey buildings face significant fire risks. Effective evacuation must consider crowd dynamics and changing environments. Therefore, it is particularly urgent to develop intelligent evacuation systems that can assist in identifying complex environments and provide real-time and effective guidance. To address this need, the study proposes a novel bootstrap program that integrates various technical knowledge, uses CFD fluid dynamics simulation technology and LK pyramid optical flow method to realize the dynamic behavior analysis of people in this complex scene, combines DFS path planning algorithm and multi-threading concurrency technology. The intelligent evacuation system proposed in this project is based on computer vision technology. It comprehensively considers the complex environmental factors of fire scenarios, significantly enhancing evacuation efficiency, reducing casualties and property losses, and contributing to urban safety and social stability. © 2025 International Society of Management Science and Engineering Management.
KW  - Computer vision
KW  - fires
KW  - intelligent evacuation system
KW  - multi-storey buildings
KW  - optimal path
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Narin, N.G.
TI  - A Content Analysis of the Metaverse Articles
PY  - 2021
T2  - Journal of Metaverse
VL  - 1
IS  - 1
SP  - 17
EP  - 24
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162128473&partnerID=40&md5=2dfb6ab1010813139a5cd0ad101a1506
AB  - Metaverse, which was first defined as fictional about 20 years ago, refers to a virtual universe where people feel entirely mentally with engaged augmented virtual reality devices today. The first applications of metaverse were computer games consisting of virtual worlds. Gaming companies were racing to offer more unique experiences to their users. With social media giants and big technology companies announcing the metaverse as the future of the internet, it started to attract the attention of the wider masses. The concept of metaverse has been the subject of academic studies in many different fields, from literature to art, from music to education over the years. In this review article, a total of 40 journal articles containing the "metaverse" keyword in all fields in the Web of Science database were examined in terms of content and method. The outputs of this study provide a piece of brief information about the research area to both researchers and technology developers. © 2021, Izmir Academy Association. All rights reserved.
KW  - content analysis
KW  - metaverse
KW  - second life
KW  - virtual worlds
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 173
ER  -

TY  - CONF
AU  - Shen, Y.-T.
AU  - Li, J.-T.
TI  - Application and Prospect of Knowledge Graph in Unmanned Vehicle Field
PY  - 2024
T2  - Communications in Computer and Information Science
VL  - 2062 CCIS
SP  - 227
EP  - 241
DO  - 10.1007/978-981-97-2275-4_18
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192164277&doi=10.1007%2f978-981-97-2275-4_18&partnerID=40&md5=cfa8bc5e4e798588adcfcdb9cb1b0eb3
AB  - With the rapid development of unmanned vehicle technology, unmanned vehicle plays an increasingly important role in related fields, which is of great significance to the future development of intelligent transportation. In order to break through the bottleneck of the intelligent degree of existing unmanned vehicles, unmanned vehicle driving technology based on knowledge graph has become one of the development trends. Firstly, this paper gives a brief overview of the decision-making process of unmanned vehicles, and introduces the basic principles and related concepts of unmanned vehicle technology based on knowledge graph. Then the application of knowledge graph in intelligent decision-making of unmanned vehicle is introduced, including target recognition, semantic segmentation, target trajectory prediction and scene understanding. Then an automatic driving decision system based on knowledge graph is proposed. Finally, the future development of intelligent decision-making of unmanned vehicles based on knowledge graph is prospected, and various possibilities of its future development are discussed. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.
KW  - Autonomous driving
KW  - Knowledge graph
KW  - Unmanned vehicles
KW  - Automobile drivers
KW  - Decision making
KW  - Knowledge graph
KW  - Semantics
KW  - Unmanned vehicles
KW  - Autonomous driving
KW  - Basic principles
KW  - Decision-making process
KW  - Development trends
KW  - Intelligent decision-making
KW  - Intelligent transportation
KW  - Knowledge graphs
KW  - Target recognition
KW  - Technology-based
KW  - Vehicle technology
KW  - Autonomous vehicles
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Nery, S.B.M.
AU  - Araújo, S.M.
AU  - Magalhães, B.G.
AU  - de Almeida, K.J.S.
AU  - Gaspar, P.D.
TI  - Parkinson’s Disease Severity Index Based on Non-Motor Symptoms by Self-Organizing Maps
PY  - 2024
T2  - Electronics (Switzerland)
VL  - 13
IS  - 8
C7  - 1523
DO  - 10.3390/electronics13081523
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191358197&doi=10.3390%2felectronics13081523&partnerID=40&md5=3bde1e265c2a17f106b84a79e4e35ef8
AB  - Parkinson’s disease, a progressive neurodegenerative disorder of the motor system, shows non-motor symptoms up to 10 years before classic motor signs, highlighting the importance of early detection for effective treatment. This study proposes a severity index using an Artificial Neural Network (ANN) trained by the Self-Organizing Maps (SOM) algorithm, with data from the FOX Insight database. After pre-processing, 41,892 questionnaires were selected, covering 25 questions about non-motor symptoms, defined by a neurologist, and divided into four classes representing stages of the disease. The goal is to offer a tool to classify patients based on these symptoms, allowing for accurate monitoring and personalized interventions. Validation was carried out with data from patients responding to the questionnaire at spaced moments, simulating medical consultations. The study was successful in developing the severity index, highlighting the importance of gastrointestinal and urinary symptoms at different stages. The persistence of difficulty sleeping in group 3 indicates special attention must be paid to this symptom in the initial stages. These results highlight the clinical and practical relevance of the index, although more studies with real patients are needed for validation. © 2024 by the authors.
KW  - artificial neuronal network
KW  - non-motor symptoms
KW  - Parkinson’s disease
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Cordeiro, L.C.
AU  - Daggitt, M.L.
AU  - Girard-Satabin, J.
AU  - Isac, O.
AU  - Johnson, T.T.
AU  - Katz, G.
AU  - Komendantskaya, E.
AU  - Lemesle, A.
AU  - Manino, E.
AU  - Šinkarovs, A.
AU  - Wu, H.
TI  - Neural Network Verification is a Programming Language Challenge
PY  - 2025
T2  - Lecture Notes in Computer Science
VL  - 15694 LNCS
SP  - 206
EP  - 235
DO  - 10.1007/978-3-031-91118-7_9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004790346&doi=10.1007%2f978-3-031-91118-7_9&partnerID=40&md5=f17032b2d5e45bda387d0ac72202c614
AB  - Neural network verification is a new and rapidly developing field of research. So far, the main priority has been establishing efficient verification algorithms and tools, while proper support from the programming language perspective has been considered secondary or unimportant. Yet, there is mounting evidence that insights from the programming language community may make a difference in the future development of this domain. In this paper, we formulate neural network verification challenges as programming language challenges and suggest possible future solutions. © The Author(s) 2025.
KW  - Domain Specific Languages
KW  - Neural Networks
KW  - Verification
KW  - Domains specific languages
KW  - Neural-networks
KW  - Possible futures
KW  - Verification algorithms
KW  - Verification tools
KW  - Computer programming languages
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Mohammad, F.
AU  - Al Mansoor, K.M.
TI  - MDD: A Unified Multimodal Deep Learning Approach for Depression Diagnosis Based on Text and Audio Speech
PY  - 2024
T2  - Computers, Materials and Continua
VL  - 81
IS  - 3
SP  - 4125
EP  - 4147
DO  - 10.32604/cmc.2024.056666
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212865304&doi=10.32604%2fcmc.2024.056666&partnerID=40&md5=fd60f495b1507826bbba98b97b31c693
AB  - Depression is a prevalent mental health issue affecting individuals of all age groups globally. Similar to other mental health disorders, diagnosing depression presents significant challenges for medical practitioners and clinical experts, primarily due to societal stigma and a lack of awareness and acceptance. Although medical interventions such as therapies, medications, and brain stimulation therapy provide hope for treatment, there is still a gap in the efficient detection of depression. Traditional methods, like in-person therapies, are both time-consuming and labor-intensive, emphasizing the necessity for technological assistance, especially through Artificial Intelligence. Alternative to this, in most cases it has been diagnosed through questionnaire-based mental status assessments. However, this method often produces inconsistent and inaccurate results. Additionally, there is currently a lack of a comprehensive diagnostic framework that could be effective achieving accurate and robust diagnostic outcomes. For a considerable time, researchers have sought methods to identify symptoms of depression through individuals’ speech and responses, leveraging automation systems and computer technology. This research proposed MDD which composed of multimodal data collection, preprocessing, and feature extraction (utilizing the T5 model for text features and the WaveNet model for speech features). Canonical Correlation Analysis (CCA) is then used to create correlated projections of text and audio features, followed by feature fusion through concatenation. Finally, depression detection is performed using a neural network with a sigmoid output layer. The proposed model achieved remarkable performance, on the Distress Analysis Interview Corpus-Wizard (DAIC-WOZ) dataset, it attained an accuracy of 92.75%, precision of 92.05%, and recall of 92.22%. For the E-DAIC dataset, it achieved an accuracy of 91.74%, precision of 90.35%, and recall of 90.95%. Whereas, on CD-III dataset (Custom Dataset for Depression), the model demonstrated an accuracy of 93.05%, precision of 92.12%, and recall of 92.85%. These results underscore the model’s robust capability in accurately diagnosing depressive disorder, demonstrating the efficacy of advanced feature extraction methods and improved classification algorithm. Copyright © 2024 The Authors.
KW  - CCA
KW  - deep learning
KW  - Depression
KW  - neural network
KW  - T5
KW  - WaveNet
KW  - Deep neural networks
KW  - Diseases
KW  - mHealth
KW  - Canonical correlations analysis
KW  - Deep learning
KW  - Depression
KW  - Learning approach
KW  - Mental health
KW  - Multi-modal
KW  - Neural-networks
KW  - T5
KW  - Text feature
KW  - Wavenet
KW  - Diagnosis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Kejriwal, M.
TI  - Essential features in a theory of context for enabling artificial general intelligence
PY  - 2021
T2  - Applied Sciences (Switzerland)
VL  - 11
IS  - 24
C7  - 11991
DO  - 10.3390/app112411991
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121294790&doi=10.3390%2fapp112411991&partnerID=40&md5=3bd660bcd40b0ca2350bc694db31878f
AB  - Despite recent Artificial Intelligence (AI) advances in narrow task areas such as face recognition and natural language processing, the emergence of general machine intelligence continues to be elusive. Such an AI must overcome several challenges, one of which is the ability to be aware of, and appropriately handle, context. In this article, we argue that context needs to be rigorously treated as a first-class citizen in AI research and discourse for achieving true general machine intelligence. Unfortunately, context is only loosely defined, if at all, within AI research. This article aims to synthesize the myriad pragmatic ways in which context has been used, or implicitly assumed, as a core concept in multiple AI sub-areas, such as representation learning and commonsense reasoning. While not all definitions are equivalent, we systematically identify a set of seven features associated with context in these sub-areas. We argue that such features are necessary for a sufficiently rich theory of context, as applicable to practical domains and applications in AI. © 2021 by the author. Licensee MDPI, Basel, Switzerland.
KW  - Artificial general intelligence
KW  - Commonsense reasoning
KW  - Context
KW  - Context-rich AI
KW  - Explainable AI
KW  - Knowledge graphs
KW  - Representation learning
KW  - Semantic web
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Agiollo, A.
AU  - Rafanelli, A.
AU  - Magnini, M.
AU  - Ciatto, G.
AU  - Omicini, A.
TI  - Symbolic knowledge injection meets intelligent agents: QoS metrics and experiments
PY  - 2023
T2  - Autonomous Agents and Multi-Agent Systems
VL  - 37
IS  - 2
C7  - 27
DO  - 10.1007/s10458-023-09609-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162972232&doi=10.1007%2fs10458-023-09609-6&partnerID=40&md5=0cff8d30b4562bd5a5cf18708402fde5
AB  - Bridging intelligent symbolic agents and sub-symbolic predictors is a long-standing research goal in AI. Among the recent integration efforts, symbolic knowledge injection (SKI) proposes algorithms aimed at steering sub-symbolic predictors’ learning towards compliance w.r.t. pre-existing symbolic knowledge bases. However, state-of-the-art contributions about SKI mostly tackle injection from a foundational perspective, often focussing solely on improving the predictive performance of the sub-symbolic predictors undergoing injection. Technical contributions, in turn, are tailored on individual methods/experiments and therefore poorly interoperable with agent technologies as well as among each others. Intelligent agents may exploit SKI to serve many purposes other than predictive performance alone—provided that, of course, adequate technological support exists: for instance, SKI may allow agents to tune computational, energetic, or data requirements of sub-symbolic predictors. Given that different algorithms may exist to serve all those many purposes, some criteria for algorithm selection as well as a suitable technology should be available to let agents dynamically select and exploit the most suitable algorithm for the problem at hand. Along this line, in this work we design a set of quality-of-service (QoS) metrics for SKI, and a general-purpose software API to enable their application to various SKI algorithms—namely, platform for symbolic knowledge injection (PSyKI). We provide an abstract formulation of four QoS metrics for SKI, and describe the design of PSyKI according to a software engineering perspective. Then we discuss how our QoS metrics are supported by PSyKI. Finally, we demonstrate the effectiveness of both our QoS metrics and PSyKI via a number of experiments, where SKI is both applied and assessed via our proposed API. Our empirical analysis demonstrates both the soundness of our proposed metrics and the versatility of PSyKI as the first software tool supporting the application, interchange, and numerical assessment of SKI techniques. To the best of our knowledge, our proposals represent the first attempt to introduce QoS metrics for SKI, and the software tools enabling their practical exploitation for both human and computational agents. In particular, our contributions could be exploited to automate and/or compare the manifold SKI algorithms from the state of the art. Hence moving a concrete step forward the engineering of efficient, robust, and trustworthy software applications that integrate symbolic agents and sub-symbolic predictors. © 2023, The Author(s).
KW  - Efficiency
KW  - Intelligent agents
KW  - Neuro-symbolic integration
KW  - PSyKI
KW  - Quality of service
KW  - Robustness
KW  - Symbolic knowledge injection
KW  - Trustworthiness
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - JOUR
AU  - Ali, G.A.
AU  - Abubakar, H.
AU  - Alzaeemi, S.A.S.
AU  - Almawgani, A.H.M.
AU  - Sulaiman, A.
AU  - Tay, K.G.
TI  - Artificial dragonfly algorithm in the Hopfield neural network for optimal Exact Boolean k satisfiability representation
PY  - 2023
T2  - PLoS ONE
VL  - 18
IS  - 9 September
C7  - e0286874
DO  - 10.1371/journal.pone.0286874
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172241278&doi=10.1371%2fjournal.pone.0286874&partnerID=40&md5=45baff05219fb600132b577e74be8766
AB  - This study proposes a novel hybrid computational approach that integrates the artificial dragonfly algorithm (ADA) with the Hopfield neural network (HNN) to achieve an optimal representation of the Exact Boolean kSatisfiability (EBkSAT) logical rule. The primary objective is to investigate the effectiveness and robustness of the ADA algorithm in expediting the training phase of the HNN to attain an optimized EBkSAT logic representation. To assess the performance of the proposed hybrid computational model, a specific Exact Boolean kSatisfiability problem is constructed, and simulated data sets are generated. The evaluation metrics employed include the global minimum ratio (GmR), root mean square error (RMSE), mean absolute percentage error (MAPE), and network computational time (CT) for EBkSAT representation. Comparative analyses are conducted between the results obtained from the proposed model and existing models in the literature. The findings demonstrate that the proposed hybrid model, ADA-HNN-EBkSAT, surpasses existing models in terms of accuracy and computational time. This suggests that the ADA algorithm exhibits effective compatibility with the HNN for achieving an optimal representation of the EBkSAT logical rule. These outcomes carry significant implications for addressing intricate optimization problems across diverse domains, including computer science, engineering, and business. © 2023 Ali et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
KW  - Algorithms
KW  - Benchmarking
KW  - Commerce
KW  - Engineering
KW  - Neural Networks, Computer
KW  - Article
KW  - artificial dragonfly algorithm
KW  - artificial neural network
KW  - classification
KW  - computer model
KW  - exact boolean ksatisfiability
KW  - global minimum ratio
KW  - Hopfield neural network
KW  - human
KW  - information science
KW  - machine learning
KW  - mean absolute error
KW  - mean absolute percentage error
KW  - metaheuristics
KW  - network computational time
KW  - root mean squared error
KW  - simulation
KW  - statistical concepts
KW  - algorithm
KW  - benchmarking
KW  - commercial phenomena
KW  - engineering
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - JOUR
AU  - Solovjev, D.
TI  - COMPETENCE COEFFICIENTS CALCULATION METHOD OF PARTICIPANTS IN GROUP DECISION-MAKING FOR SELECTING THE BEST ALTERNATIVE WITH THE MULTIVARIATE OF THE RESULT
ST  - МЕТОД РАСЧЕТА КОЭФФИЦИЕНТОВ КОМПЕТЕНТНОСТИ УЧАСТНИКОВ ГРУППОВОГО ПРИНЯТИЯ РЕШЕНИЙ ДЛЯ ВЫБОРА НАИЛУЧШЕЙ АЛЬТЕРНАТИВЫ ПРИ МУЛЬТИВАРИАНТНОСТИ РЕЗУЛЬТАТА
PY  - 2024
T2  - Informatics and Automation
VL  - 23
IS  - 1
SP  - 169
EP  - 193
DO  - 10.15622/ia.23.1.6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183023048&doi=10.15622%2fia.23.1.6&partnerID=40&md5=b48dd83e3051c4ef5bccd77726e75355
AB  - The problem of obtaining the best alternative using decision-making methods based on the experience of specialists and mathematical calculations is considered in the article. Group decision-making is appropriate for solving this problem. However, it can lead to the selection of several best alternatives (multivariate of the result). Accounting for competence will prioritize the decision of more competent participants and eliminate the emergence of several best alternatives in the process of group decision-making. The problem of determining the competence coefficients for participants in group decision-making has been formulated. The selection of the best alternative with the multivariate of the result is provided in the problem. A method for solving the problem has been developed. It involves discretizing the range of input variables and refining the competence coefficients values of group decision-making participants in it to select the best alternative, either by the majority principle or with the decision-maker's involvement. Further calculation of the competence coefficients for participants in group decision-making is carried out using local linear interpolation of the refined competence coefficient at surrounding points from the discretized range. The use of the proposed method for solving the problem is considered using the example of group decision-making according to the main types of the majoritarian principle for selecting an electrodeposition variant. The results show that the proposed method for calculating the competence coefficients of participants in group decision-making through local linear interpolation is the most effective for selecting the best alternative with a multivariate result based on the relative majority. © 2024 Chinese Journal of Obstetrics and Gynecology/Zhonghua Fu Chan Ke Za Zhi. All rights reserved.
KW  - competence coefficients
KW  - group decision-making
KW  - multivariate of the result
KW  - selection of the best alternative
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Abubakar, H.
AU  - Danrimi, M.L.
TI  - Hopfield type of artificial neural network via election algorithm as heuristic search method for Random Boolean kSatisfiability
PY  - 2021
T2  - International Journal of Computing and Digital Systems
VL  - 10
IS  - 1
SP  - 659
EP  - 673
DO  - 10.12785/IJCDS/100163
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106634817&doi=10.12785%2fIJCDS%2f100163&partnerID=40&md5=906ce309269a4e6c80d9f6fc764058b0
AB  - This study proposed a hybrid computational model by incorporating Election Algorithm (EA) as a heuristics search technique in a Hopfield type of artificial neural network (HNN). The main objective is to improve the learning phase of Hopfield type artificial neural network (HNN) for optimal Random Boolean kSatisfiability representation for higher-order logic. Many researchers in the area of artificial intelligence (AI), machine learning (ML), and artificial neural networks (ANNs) are motived by the multiple processing units that work together to learn, identify patterns and predict information which provides a powerful mechanism for optimizations/search problems and other decision-making problem. Election algorithm (EA) has been utilized due to the policy of extending the power and rule play by the political parties beyond its borders to seek endorsement from voters. This policy plays an important role in accelerating the learning process of Hopfield type of artificial neural network (HNN) for optimal random Boolean kSatisfiability representation. In this work, a different number of neurons (NN) has been manipulated invalidating the robustness and efficiency of EA in HNN for RANkSAT logical clauses. The proposed model has been compared with other existing model-based the global minima ratio, statistical error accumulations, and time complexity during the learning process. The simulated results generated have been presented in the form of graphs. Based on the result of this study, the proposed HNN-RAN-kSAT-EA agreed with the existing HNN-RANkSAT-ACO model but outperformed HNN-RANkSAT-ES in term of statistical measures used in this study. © 2021 University of Bahrain. All rights reserved.
KW  - Artificial Neural Networks
KW  - Election algorithm
KW  - Hopfield type of Artificial neural network
KW  - Random Boolean Satisfiability
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 12
ER  -

TY  - CONF
AU  - Xie, X.
AU  - Zhang, F.
AU  - Hu, X.
AU  - Ma, L.
TI  - DeepGemini: Verifying Dependency Fairness for Deep Neural Networks
PY  - 2023
T2  - Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023
VL  - 37
SP  - 15251
EP  - 15259
DO  - 10.1609/aaai.v37i12.26779
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167986765&doi=10.1609%2faaai.v37i12.26779&partnerID=40&md5=bdeb5e6d5cbeb7b861e5122dff7aa5f6
AB  - Deep neural networks (DNNs) have been widely adopted in many decision-making industrial applications. Their fairness issues, i.e., whether there exist unintended biases in the DNN, receive much attention and become critical concerns, which can directly cause negative impacts in our daily life and potentially undermine the fairness of our society, especially with their increasing deployment at an unprecedented speed. Recently, some early attempts have been made to provide fairness assurance of DNNs, such as fairness testing, which aims at finding discriminatory samples empirically, and fairness certification, which develops sound but not complete analysis to certify the fairness of DNNs. Nevertheless, how to formally compute discriminatory samples and fairness scores (i.e., the percentage of fair input space), is still largely uninvestigated. In this paper, we propose DeepGemini, a novel fairness formal analysis technique for DNNs, which contains two key components: discriminatory sample discovery and fairness score computation. To uncover discriminatory samples, we encode the fairness of DNNs as safety properties and search for discriminatory samples by means of state-of-the-art verification techniques for DNNs. This reduction enables us to be the first to formally compute discriminatory samples. To compute the fairness score, we develop counterexample guided fairness analysis, which utilizes four heuristics to efficiently approximate a lower bound of fairness score. Extensive experimental evaluations demonstrate the effectiveness and efficiency of DeepGemini on commonly-used benchmarks, and DeepGemini outperforms state-of-the-art DNN fairness certification approaches in terms of both efficiency and scalability. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.
KW  - Decision making
KW  - Efficiency
KW  - % reductions
KW  - Analysis techniques
KW  - Daily lives
KW  - Decisions makings
KW  - Formal analysis
KW  - Input space
KW  - Low bound
KW  - Safety property
KW  - State of the art
KW  - Verification techniques
KW  - Deep neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - CONF
AU  - Tran, H.-D.
AU  - Choi, S.
AU  - Yang, X.
AU  - Yamaguchi, T.
AU  - Hoxha, B.
AU  - Prokhorov, D.
TI  - Verification of Recurrent Neural Networks with Star Reachability
PY  - 2023
T2  - HSCC 2023 - Proceedings of the 26th ACM International Conference on Hybrid Systems: Computation and Control, Part of CPS-IoT Week
C7  - 6
DO  - 10.1145/3575870.3587128
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160568643&doi=10.1145%2f3575870.3587128&partnerID=40&md5=0845e312cb1068fbfef88c8e0bc4c96a
AB  - The paper extends the recent star reachability method to verify the robustness of recurrent neural networks (RNNs) for use in safety-critical applications. RNNs are a popular machine learning method for various applications, but they are vulnerable to adversarial attacks, where slightly perturbing the input sequence can lead to an unexpected result. Recent notable techniques for verifying RNNs include unrolling, and invariant inference approaches. The first method has scaling issues since unrolling an RNN creates a large feedforward neural network. The second method, using invariant sets, has better scalability but can produce unknown results due to the accumulation of overapproximation errors over time. This paper introduces a complementary verification method for RNNs that is both sound and complete. A relaxation parameter can be used to convert the method into a fast overapproximation method that still provides soundness guarantees. The method is designed to be used with NNV, a tool for verifying deep neural networks and learning-enabled cyber-physical systems. Compared to state-of-the-art methods, the extended exact reachability method is 10× faster, and the overapproximation method is 100× to 5000× faster. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.
KW  - Reachability Analysis
KW  - Recurrent Neural Networks
KW  - Verification
KW  - Algebra
KW  - Cyber Physical System
KW  - Deep neural networks
KW  - Embedded systems
KW  - Feedforward neural networks
KW  - Learning systems
KW  - Safety engineering
KW  - Stars
KW  - Input sequence
KW  - Invariant set
KW  - Machine learning methods
KW  - Over-approximation method
KW  - Reachability
KW  - Reachability analysis
KW  - Safety critical applications
KW  - Scalings
KW  - Sound and complete
KW  - Verification method
KW  - Recurrent neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 9
ER  -

TY  - CONF
AU  - Peralta, D.
AU  - Qin, X.
TI  - Exploring Flexible Road Reconstruction in Godot Simulator
PY  - 2025
T2  - Proceedings of the ACM/IEEE 16th International Conference on Cyber-Physical Systems, ICCPS 2025, held as part of the CPS-IoT Week 2025
C7  - 47
DO  - 10.1145/3716550.3725164
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007284874&doi=10.1145%2f3716550.3725164&partnerID=40&md5=807a395e8c94a55e6137011ded4fd017
AB  - Cyber-physical systems (CPS) combine cyber and physical components engineered to make decisions and interact within dynamic environments. Ensuring the safety of CPS is of great importance, requiring extensive testing across diverse and complex scenarios. To generate as many testing scenarios as possible, previous efforts have focused on describing scenarios using formal languages to generate scenes. In this paper, we introduce an alternative approach: reconstructing roads inside the open-source game engine, Godot. We have developed a pipeline that enables the reconstruction of testing roads directly from provided images of scenarios. These reconstructed roads can then be deployed within simulated environments to assess a CPS. We demonstrate our methods on real world images.  © 2025 Copyright held by the owner/author(s).
KW  - Cyber Physical System
KW  - Intelligent systems
KW  - Open systems
KW  - Cybe-physical systems
KW  - Cyber-physical systems
KW  - Dynamic environments
KW  - Extensive testing
KW  - Open source game engine
KW  - Physical components
KW  - Real-world image
KW  - Road reconstruction
KW  - Simulated environment
KW  - Embedded systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Kang, M.
AU  - Gürel, N.M.
AU  - Li, L.
AU  - Li, B.
TI  - COLEP: CERTIFIABLY ROBUST LEARNING-REASONING CONFORMAL PREDICTION VIA PROBABILISTIC CIRCUITS
PY  - 2024
T2  - 12th International Conference on Learning Representations, ICLR 2024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197575127&partnerID=40&md5=327ef38442c6619b392963aec040ef0a
AB  - Conformal prediction has shown spurring performance in constructing statistically rigorous prediction sets for arbitrary black-box machine learning models, assuming the data is exchangeable. However, even small adversarial perturbations during the inference can violate the exchangeability assumption, challenge the coverage guarantees, and result in a subsequent decline in prediction coverage. In this work, we propose the first certifiably robust learning-reasoning conformal prediction framework (COLEP) via probabilistic circuits, which comprises a data-driven learning component that trains statistical models to learn different semantic concepts, and a reasoning component that encodes knowledge and characterizes the relationships among the statistical knowledge models for logic reasoning. To achieve exact and efficient reasoning, we employ probabilistic circuits (PCs) to construct the reasoning component. Theoretically, we provide end-to-end certification of prediction coverage for COLEP under ℓ2 bounded adversarial perturbations. We also provide certified coverage considering the finite size of the calibration set. Furthermore, we prove that COLEP achieves higher prediction coverage and accuracy over a single model as long as the utilities of knowledge models are non-trivial. Empirically, we show the validity and tightness of our certified coverage, demonstrating the robust conformal prediction of COLEP on various datasets. © 2024 12th International Conference on Learning Representations, ICLR 2024. All rights reserved.
KW  - Learning systems
KW  - Semantics
KW  - Timing circuits
KW  - Black boxes
KW  - Conformal predictions
KW  - Data driven
KW  - Knowledge model
KW  - Machine learning models
KW  - Performance
KW  - Probabilistics
KW  - Reasoning components
KW  - Robust learning
KW  - Statistic modeling
KW  - Forecasting
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - CONF
AU  - Dai, L.
AU  - Jiang, Y.-H.
AU  - Chen, Y.
AU  - Guo, Z.
AU  - Liu, T.-Y.
AU  - Shao, X.
TI  - Agent4EDU: Advancing AI for Education with Agentic Workflows
PY  - 2025
T2  - Proceedings of 2024 3rd International Conference on Artificial Intelligence and Education, ICAIE 2024
SP  - 180
EP  - 185
DO  - 10.1145/3722237.3722268
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005268986&doi=10.1145%2f3722237.3722268&partnerID=40&md5=ab0dfd5c976afd516424bc20c4606cd8
AB  - The vigorous development of artificial intelligence (AI) represented by large language models (LLMs) has rapidly promoted the updating and development of educational technology. Agentic workflows (AWs) built based on LLMs can realize complex tasks in the field of education, which allows the emergence of swarm intelligence (SI) through multi-agent collaboration[1]. This study introduces the Agent4EDU (agent for education) framework, which outlines 4 application models in education from the two dimensions of degree of agency and degree of interaction, including human-AI collaboration, AI assistant, instruction execution, and general type. The proposed Agent4EDU framework discusses the paradigm of educational applications of AI agents and promotes the development of the field of AI for education.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
KW  - agentic workflow
KW  - AI agent
KW  - AI for education
KW  - large language model
KW  - multi-agent system
KW  - Swarm intelligence
KW  - Teaching
KW  - Agent collaboration
KW  - Agentic workflow
KW  - Artificial intelligence agent
KW  - Artificial intelligence for education
KW  - Complex task
KW  - Language model
KW  - Large language model
KW  - Multi agent
KW  - Multiagent systems (MASs)
KW  - Work-flows
KW  - Educational robots
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Szabó, G.
AU  - Pető, J.
AU  - Vidács, A.
TI  - Deployment options of AI components for network resource management in 5G-enabled agile industrial production cell
PY  - 2025
T2  - International Journal of Communication Systems
VL  - 38
IS  - 3
C7  - e5983
DO  - 10.1002/dac.5983
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203269707&doi=10.1002%2fdac.5983&partnerID=40&md5=5ef8f0884c1a9ba0ddd6dff39c953538
AB  - On-demand manufacturing in Industry 4.0 requires flexibility of the networks which can be provided with the fifth generation (5G) of mobile communications wireless connectivity. A key component in the efficient utilization of the radio resources in a manufacturing scenario is network resource management (NRM). We show how NRM can be automated with artificial intelligence (AI). We introduce several futuristic industrial use cases that require AI in various parts of the process. We analyze the AI components' benefits and disadvantages in several deployment scenarios. The findings can be used by business stakeholders interested in deploying the 5G cellular wireless network to choose the best NRM and AI implementation strategy for a particular use case. We show that there are many viable options for the AI component in the process automation, but the cost of AI has to be considered in all cases. Also, we point out that an essential component, the standardized information flow on the status of the productivity key performance indicators (KPIs), is needed for the successful deployment and application of the 5G AI. © 2024 The Author(s). International Journal of Communication Systems published by John Wiley & Sons Ltd.
KW  - artificial intelligence
KW  - manufacturing/assembly
KW  - network resource management
KW  - wireless
KW  - 5G mobile communication systems
KW  - Agile manufacturing systems
KW  - Industry 4.0
KW  - Lean production
KW  - Smart manufacturing
KW  - Communications systems
KW  - Industrial production
KW  - International journals
KW  - Manufacturing assembly
KW  - Mobile communications
KW  - Network resource management
KW  - On demands
KW  - Production cells
KW  - Radio resources
KW  - Wireless connectivities
KW  - Resource allocation
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Chowdhury, M.
TI  - Icon: an intelligent resource slicing and task coordination framework for Web 3.0 and metaverse-based service execution over 6G-based immersive edge computing network
PY  - 2023
T2  - International Journal of Ad Hoc and Ubiquitous Computing
VL  - 44
IS  - 3
SP  - 167
EP  - 202
DO  - 10.1504/IJAHUC.2023.134763
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176937402&doi=10.1504%2fIJAHUC.2023.134763&partnerID=40&md5=003a37f71dc72d677a84503fe7346a17
AB  - Web 3.0 is referred to as immersive web technology in which human users can use metaverse platforms and experience digital realities. Metaverse is a virtual world in which users can interact with other users/services in an immersive manner. The existing research articles did not provide any unified resource slicing and task service coordination framework for both current/Web 3.0 and previous generation/Web 2.0-based task execution by considering intelligent resource slicing, worker selection, task types, and deadlines. To bridle these issues, this paper delivers an intelligent resource slicing scheme with multi-task scheduling and task service coordination framework for Web 2.0, Web 3.0, and metaverse-based task execution over 6G enhanced immersive networks by scrutinising resources, different current and previous generation tasks with deadline requirements, delay, and utility gain, into account. The results notified that 59.90% delay and 78% utility gain is attained in the proposed scheme over the benchmark scheme. Copyright © 2023 Inderscience Enterprises Ltd.
KW  - 6G
KW  - blockchain
KW  - digital twin
KW  - dissipated energy value
KW  - metaverse
KW  - mobile edge computing
KW  - quality maintain ratio
KW  - resource slicing
KW  - service realisation delay
KW  - task coordination
KW  - users economic cost
KW  - utility
KW  - Web 3.0
KW  - Blockchain
KW  - Human resource management
KW  - Mobile edge computing
KW  - Virtual reality
KW  - 6g
KW  - Block-chain
KW  - Dissipated energy
KW  - Dissipated energy value
KW  - Economic costs
KW  - Energy value
KW  - Metaverses
KW  - Quality maintain ratio
KW  - Resource slicing
KW  - Service realization delay
KW  - Task coordination
KW  - User economic cost
KW  - Utility
KW  - Web 3.0
KW  - Energy dissipation
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Sterbini, A.
AU  - Temperini, M.
TI  - Q2A-II, a System to Support Peer Assessment on Homework: A Study on Four Years of Use
PY  - 2024
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14607 LNCS
SP  - 249
EP  - 262
DO  - 10.1007/978-981-97-4246-2_20
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200564844&doi=10.1007%2f978-981-97-4246-2_20&partnerID=40&md5=ef2459350ea89deb449ccc8b19cefb63
AB  - Automated assessment of homework assignments is a challenging topic in programming courses. For some years we have been using our Q2A-II system, that supports 1) automated grading of homework programs, and 2) formative peer assessment, performed by students on the algorithm descriptions they submit with the homework. Here we present some of the data we collected during 4 years of activity with Q2A-II, in the framework of a university course on Basics of Computer Programming. Each year, 4 homework were administered to 300–500 learners, with about 8.600 submissions (each made of program + algorithmic description), overall, and about 23.300 peer evaluations. On such data we propose several observations, aiming to rate the effectiveness of the initiative, in view of a more in depth analysis. On the algorithm descriptions we performed a basic textual categorization, using BERTopic-based text embedding topic extraction. The classification aim is exclusively to assess whether a text can or cannot be considered as an algorithm description: in two of the research questions we try to validate the classification and to see how different can be the behavior of the authors of such descriptions during the peer assessment activity. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.
KW  - Homework Classification
KW  - Peer Assessment
KW  - Technology Enhanced Learning
KW  - Grading
KW  - Learning systems
KW  - Text processing
KW  - Algorithm description
KW  - Algorithmics
KW  - Automated assessment
KW  - Automated grading
KW  - Homework assignments
KW  - Homework classification
KW  - Peer assessment
KW  - Programming course
KW  - Technology enhanced learning
KW  - University course
KW  - Computer programming
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Khan, A.A.
AU  - Laghari, A.A.
AU  - Inam, S.A.
AU  - Ullah, S.
AU  - Shahzad, M.
AU  - Syed, D.
TI  - A survey on multimedia-enabled deepfake detection: state-of-the-art tools and techniques, emerging trends, current challenges & limitations, and future directions
PY  - 2025
T2  - Discover Computing
VL  - 28
IS  - 1
C7  - 48
DO  - 10.1007/s10791-025-09550-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003808041&doi=10.1007%2fs10791-025-09550-0&partnerID=40&md5=9e7574bd7d31da57c55134ccd2abac61
AB  - Rapid technological breakthroughs in recent years, like Deepfake, have made it feasible to produce synthetic media that is remarkably lifelike, but they also present significant hazards to public trust, privacy, and security. This survey paper reviews the latest techniques for detecting deepfakes, focussing on important components as image and video manipulation, audio spoofing, and multimodal synthesis. It features state-of-the-art methods including machine learning (ML), deep learning (DL), and multimodal architectures that are especially made to address the previously described deepfake criteria. The report provides a critical review of assessment measures used to assess detection model performance, including precision, accuracy, recall, computing effectiveness and efficiency, and fast responses to adversarial attacks. In order to assist direct future research, this highlights recent advancements in the subject, including explainable AI, federated learning, and self-supervised learning hierarchy. In order to examine the problems with adversarial attacks, scalability across different datasets, and the ethical implications of detection techniques, it is also vital to look into the technological and societal challenges surrounding multimedia-enabled deepfake detection. In particular, the usage of Blockchain Distributed Ledger Technology (BDLT) for traceability, lightweight modelling, and resilient systems forms for cross-model deepfake evaluation are discussed in this review study along with potential solutions to these limitations and areas for further research. This paper offers a comprehensive resource for future research, experts, and practitioners looking to combat the growing threat of deepfake, especially in the social media space, using innovative and useful detection tools. © The Author(s) 2025.
KW  - Blockchain Distributed Ledger Technology (BDLT)
KW  - Deep Learning (DL)
KW  - Deepfakes
KW  - Machine Learning (ML)
KW  - Multimedia Systems
KW  - Reinforcement Learning (RL)
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Liu, J.
AU  - Yi, L.
AU  - Chen, W.
AU  - Song, C.
AU  - Qian, Z.
AU  - Yi, Q.
TI  - LinKRID: Vetting Imbalance Reference Counting in Linux kernel with Symbolic Execution
PY  - 2022
T2  - Proceedings of the 31st USENIX Security Symposium, Security 2022
SP  - 125
EP  - 142
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140985254&partnerID=40&md5=dec38e1fea995fef1ed269482fafa3b8
AB  - Linux kernel employs reference counters, which record the number of references to a shared kernel object, to track its lifecycle and prevent memory errors like use-after-free. However, the usage of reference counters can be tricky and often error-prone, especially considering unique kernel conventions of managing reference counters (e.g., external vs. internal reference counters). In this paper, we aim to automatically discover incorrect usage of reference counters, overcoming two key challenges: (1) scalability and (2) the aforementioned unique kernel conventions. Specifically, we develop a tiered program analysis based solution to efficiently and precisely check the imbalances between the change in the actual number of references and the corresponding reference counter. We apply our tool to the 4.14.0 kernel (with allyesconfig) and find 118 bugs, out of which 87 are new. The result shows our tool is scalable and effective. © USENIX Security Symposium, Security 2022.All rights reserved.
KW  - Life cycle
KW  - Program debugging
KW  - Error prones
KW  - Linux kernel
KW  - Memory error
KW  - Program analysis
KW  - Reference counting
KW  - Symbolic execution
KW  - Linux
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 14
ER  -

TY  - JOUR
AU  - Bena, N.
AU  - Anisetti, M.
AU  - Gianini, G.
AU  - Ardagna, C.A.
TI  - Certifying Accuracy, Privacy, and Robustness of ML-Based Malware Detection
PY  - 2024
T2  - SN Computer Science
VL  - 5
IS  - 6
C7  - 710
DO  - 10.1007/s42979-024-03024-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198465901&doi=10.1007%2fs42979-024-03024-8&partnerID=40&md5=bb0d3566e4337456cf6f1973776c6627
AB  - Recent advances in artificial intelligence (AI) are radically changing how systems and applications are designed and developed. In this context, new requirements and regulations emerge, such as the AI Act, placing increasing focus on strict non-functional requirements, such as privacy and robustness, and how they are verified. Certification is considered the most suitable solution for non-functional verification of modern distributed systems, and is increasingly pushed forward in the verification of AI-based applications. In this paper, we present a novel dynamic malware detector driven by the requirements in the AI Act, which goes beyond standard support for high accuracy, and also considers privacy and robustness. Privacy aims to limit the need of malware detectors to examine the entire system in depth requiring administrator-level permissions; robustness refers to the ability to cope with malware mounting evasion attacks to escape detection. We then propose a certification scheme to evaluate non-functional properties of malware detectors, which is used to comparatively evaluate our malware detector and two representative deep-learning solutions in literature. © The Author(s) 2024.
KW  - Accuracy
KW  - Certification
KW  - Machine learning
KW  - Malware detection
KW  - Privacy
KW  - Robustness
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Suciu, D.
TI  - Probabilistic Databases for All
PY  - 2020
T2  - Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems
SP  - 19
EP  - 31
DO  - 10.1145/3375395.3389129
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086274181&doi=10.1145%2f3375395.3389129&partnerID=40&md5=e3fb3766f8b16d8435e354369d7debcb
AB  - In probabilistic databases the data is uncertain and is modeled by a probability distribution. The central problem in probabilistic databases is query evaluation, which requires performing not only traditional data processing such as joins, projections, unions, but also probabilistic inference in order to compute the probability of each item in the answer. At their core, probabilistic databases are a proposal to integrate logic with probability theory. This paper accompanies a talk given as part of the Gems of PODS series, and describes several results in probabilistic databases, explaining their significance in the broader context of model counting, probabilistic inference, and Statistical Relational Models. © 2020 Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. All rights reserved.
KW  - knowledge compilation
KW  - model counting
KW  - probabilistic inference
KW  - query processing
KW  - Data handling
KW  - Database systems
KW  - Query processing
KW  - Central problems
KW  - Model Counting
KW  - Probabilistic database
KW  - Probabilistic inference
KW  - Probability theory
KW  - Query evaluation
KW  - Relational Model
KW  - Probability distributions
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 11
ER  -

TY  - JOUR
AU  - Luan, Z.
AU  - Lai, Y.
AU  - Huang, R.
AU  - Bai, S.
AU  - Zhang, Y.
AU  - Zhang, H.
AU  - Wang, Q.
TI  - Enhancing Robot Task Planning and Execution through Multi-Layer Large Language Models
PY  - 2024
T2  - Sensors
VL  - 24
IS  - 5
C7  - 1687
DO  - 10.3390/s24051687
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187479733&doi=10.3390%2fs24051687&partnerID=40&md5=baead71d0d8c288c18f2b8b62946d41e
AB  - Large language models have found utility in the domain of robot task planning and task decomposition. Nevertheless, the direct application of these models for instructing robots in task execution is not without its challenges. Limitations arise in handling more intricate tasks, encountering difficulties in effective interaction with the environment, and facing constraints in the practical executability of machine control instructions directly generated by such models. In response to these challenges, this research advocates for the implementation of a multi-layer large language model to augment a robot’s proficiency in handling complex tasks. The proposed model facilitates a meticulous layer-by-layer decomposition of tasks through the integration of multiple large language models, with the overarching goal of enhancing the accuracy of task planning. Within the task decomposition process, a visual language model is introduced as a sensor for environment perception. The outcomes of this perception process are subsequently assimilated into the large language model, thereby amalgamating the task objectives with environmental information. This integration, in turn, results in the generation of robot motion planning tailored to the specific characteristics of the current environment. Furthermore, to enhance the executability of task planning outputs from the large language model, a semantic alignment method is introduced. This method aligns task planning descriptions with the functional requirements of robot motion, thereby refining the overall compatibility and coherence of the generated instructions. To validate the efficacy of the proposed approach, an experimental platform is established utilizing an intelligent unmanned vehicle. This platform serves as a means to empirically verify the proficiency of the multi-layer large language model in addressing the intricate challenges associated with both robot task planning and execution. © 2024 by the authors.
KW  - large language models
KW  - natural language
KW  - robots
KW  - semantic alignment method
KW  - Computational linguistics
KW  - Intelligent robots
KW  - Motion planning
KW  - Robot programming
KW  - Semantics
KW  - Visual languages
KW  - Alignment methods
KW  - Language model
KW  - Large language model
KW  - Multi-layers
KW  - Natural languages
KW  - Robot tasks
KW  - Semantic alignment method
KW  - Semantic alignments
KW  - Task executions
KW  - Task planning
KW  - article
KW  - controlled study
KW  - decomposition
KW  - human
KW  - language model
KW  - large language model
KW  - sensor
KW  - Alignment
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Zhang, S.
AU  - Sridharan, M.
TI  - A survey of knowledge-based sequential decision-making under uncertainty
PY  - 2022
T2  - AI Magazine
VL  - 43
IS  - 2
SP  - 249
EP  - 266
DO  - 10.1002/aaai.12053
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134428014&doi=10.1002%2faaai.12053&partnerID=40&md5=2a8c783e9618610f962aefb5633eaef1
AB  - Reasoning with declarative knowledge (RDK) and sequential decision-making (SDM) are two key research areas in artificial intelligence. RDK methods reason with declarative domain knowledge, including commonsense knowledge, that is either provided a priori or acquired over time, while SDMmethods (probabilistic planning [PP] and reinforcement learning [RL]) seek to compute action policies thatmaximize the expected cumulative utility over a time horizon; both classes of methods reason in the presence of uncertainty.Despite the rich literature in these two areas, researchers have not fully explored their complementary strengths. In this paper, we survey algorithms that leverage RDK methods while making sequential decisions under uncertainty. We discuss significant developments, open problems, and directions for future work. © 2022 The Authors.
KW  - Decision making
KW  - Domain Knowledge
KW  - Reinforcement learning
KW  - Action policies
KW  - Commonsense knowledge
KW  - Declarative knowledge
KW  - Domain knowledge
KW  - Knowledge based
KW  - Probabilistic planning
KW  - Reinforcement learnings
KW  - Research areas
KW  - Sequential decision making
KW  - Sequential decision making under uncertainties
KW  - Surveys
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 9
ER  -

TY  - CONF
AU  - Sabu, K.M.
AU  - Renoux, J.
AU  - Saffiotti, A.
TI  - Deliberative Communication for Human-Agent Interaction: A Position Paper
PY  - 2024
T2  - HAI 2024 - Proceedings of the 12th International Conference on Human-Agent Interaction
SP  - 11
EP  - 16
DO  - 10.1145/3687272.3688299
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215510952&doi=10.1145%2f3687272.3688299&partnerID=40&md5=13cba5357d3235ff13b570651feea689
AB  - In this position paper, we argue for the need for deliberation in communication for artificial agents that perform tasks together with humans. Existing works use a set of terms and concepts with different meanings, resulting in ambiguity which does not allow for a general framework. As an initial step towards such a framework, we propose the notion of deliberative communication, clarify the necessary concepts and terminology, highlight the capabilities required in using deliberation for agents that communicate with human users, and discuss the main challenges.  © 2024 Owner/Author.
KW  - Human-Robot Interaction
KW  - Human-Virtual Agent Interaction
KW  - Chatbots
KW  - Intelligent virtual agents
KW  - Microrobots
KW  - Agent interaction
KW  - Artificial agents
KW  - Human users
KW  - Human-agent interaction
KW  - Human-virtual agent interaction
KW  - Humans-robot interactions
KW  - Position papers
KW  - Virtual agent
KW  - Human robot interaction
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Zhang, Y.
AU  - Jiang, M.
AU  - Zhao, Q.
TI  - Query and Attention Augmentation for Knowledge-Based Explainable Reasoning
PY  - 2022
T2  - Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition
VL  - 2022-June
SP  - 15555
EP  - 15564
DO  - 10.1109/CVPR52688.2022.01513
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137167866&doi=10.1109%2fCVPR52688.2022.01513&partnerID=40&md5=8cff4030edb89cd84107840bac354d9b
AB  - Explainable visual question answering (VQA) models have been developed with neural modules and query-based knowledge incorporation to answer knowledge-requiring questions. Yet, most reasoning methods cannot effectively generate queries or incorporate external knowledge during the reasoning process, which may lead to suboptimal results. To bridge this research gap, we present Query and Attention Augmentation, a general approach that augments neural module networks to jointly reason about visual and external knowledge. To take both knowledge sources into account during reasoning, it parses the input question into a functional program with queries augmented through a novel reinforcement learning method, and jointly directs augmented attention to visual and external knowledge based on intermediate reasoning results. With extensive experiments on multiple VQA datasets, our method demonstrates significant performance, explainability, and generalizability over state-of-the-art models in answering questions requiring different extents of knowledge. Our source code is available at https://github.com/SuperJohnZhang/QAA. © 2022 IEEE.
KW  - Explainable computer vision
KW  - Vision + language
KW  - Visual reasoning
KW  - Knowledge based systems
KW  - Learning systems
KW  - Query processing
KW  - Reinforcement learning
KW  - Visual languages
KW  - Explainable computer vision
KW  - External knowledge
KW  - Knowledge based
KW  - Knowledge incorporation
KW  - Question Answering
KW  - Reasoning methods
KW  - Reasoning process
KW  - Vision + language
KW  - Visual knowledge
KW  - Visual reasoning
KW  - Computer vision
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 15
ER  -

TY  - JOUR
AU  - Raj, R.
AU  - Kos, A.
TI  - Artificial Intelligence: Evolution, Developments, Applications, and Future Scope
ST  - Sztuczna inteligencja: rozwój, zastosowanie i przyszłość
PY  - 2023
T2  - Przeglad Elektrotechniczny
VL  - 99
IS  - 2
SP  - 1
EP  - 13
DO  - 10.15199/48.2023.02.01
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147122134&doi=10.15199%2f48.2023.02.01&partnerID=40&md5=0c592e361590231ad9b55e88057c3df5
AB  - Artificial intelligence (AI) or Machine Intelligence (MI) is the most important and interesting technology in recent decades due to its vast application in almost every field of science and engineering. The MI techniques are the study of making intelligent machines that have human-like behaviors. The speedy advancement in this area has triggered the curiosity of many technologists, and researchers around the world, and various companies across several domains are inquisitive to explore its capabilities. AI technology is continuously changing the landscape of businesses as well as the personal and social activities of human beings due to advancements and research in this field. For any field which has obtained so much popularity in a very short duration, it is essential that technologists who focus on endeavors in AI, study its evolution, developments, applications, and future aspects of augmentation to achieve a better intuition into the area. This paper presents a comprehensive study of the past, present, and future aspects of AI technology for researchers and technologists. In this paper, we discuss the evolution, historical developments, important breakthroughs in continuous research, real-world applications, challenges of AI implication, and the future perspective of AI technology. Finally, we have discussed the role of AI in the optimization of the Integrated Circuit (IC). © 2023 Wydawnictwo SIGMA-NOT. All rights reserved.
KW  - Artificial Intelligence
KW  - deep learning
KW  - integrated circuit
KW  - machine learning
KW  - neural networks
KW  - Turing test
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 22
ER  -

TY  - JOUR
AU  - Adriana Cárdenas-Robledo, L.
AU  - Hernández-Uribe, Ó.
AU  - Reta, C.
AU  - Antonio Cantoral-Ceballos, J.
TI  - Extended reality applications in industry 4.0. – A systematic literature review
PY  - 2022
T2  - Telematics and Informatics
VL  - 73
C7  - 101863
DO  - 10.1016/j.tele.2022.101863
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135101218&doi=10.1016%2fj.tele.2022.101863&partnerID=40&md5=a645b85499d42a624e04462df547276a
AB  - Extended reality technologies such as virtual reality, augmented reality, and mixed reality represents a paradigm that enhances and supports industry 4.0 in diverse settings. To spread such a revolutionary environment, this systematic review focuses on analyzing extendend reality essence and application and reporting the assessment of 287 approaches gathered from 2011 to 2022, classified and characterized in the proposed taxonomy. Based on the sample of analyzed works, the results indicate that industry 4.0 has embraced the use of these technologies. Heterogeneous solution proposals in various fields of application and activities were found. Notwithstanding, the research articles report similar advantages and benefits (e.g., high performance on human tasks or robot collaboration, high-quality rates for specific products, among others). In addition, we present the most widespread equipment and devices that are currently preferred to develop extended reality applications, which allows us to identify hardware patterns commonly shared in a variety of fields. Whilst, with the aid of association rules, we reveal further insights among the items of the proposed taxonomy. Furthermore, we also present a thorough analysis of trends and research directions in the extended reality field for industry 4.0. Finally, from our results, we show that the accessibility and accelerated progress in technological devices, incorporating advanced algorithms, ergonomic features, built-in cameras, and sensors, have encouraged a massive adoption and extensive application development in a wide spectrum of industry 4.0 domains. © 2022 Elsevier Ltd
KW  - Augmented reality
KW  - Extended reality
KW  - Industry 4.0
KW  - Mixed reality
KW  - Virtual reality
KW  - Augmented reality
KW  - Industry 4.0
KW  - Taxonomies
KW  - Application development
KW  - Classifieds
KW  - Extended reality
KW  - High quality
KW  - Human robots
KW  - Human tasks
KW  - Mixed reality
KW  - Performance
KW  - Systematic literature review
KW  - Systematic Review
KW  - Mixed reality
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 105
ER  -

TY  - CONF
AU  - Prifti, L.
AU  - Cico, B.
AU  - Karras, D.
TI  - Smart Contract Vulnerability Detection Using Deep Learning Algorithms on EVM bytecode
PY  - 2024
T2  - 2024 13th Mediterranean Conference on Embedded Computing, MECO 2024
DO  - 10.1109/MECO62516.2024.10577852
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199495923&doi=10.1109%2fMECO62516.2024.10577852&partnerID=40&md5=dcc2d72183ca77f34b966f8f56e7f9a0
AB  - In the quickly changing world of blockchain technology, it is critical to guarantee the security of the self-executing contracts, written in programming languages like Solidity called smart contracts. Not all security vulnerabilities in smart contracts will be found by human code reviews and security audits using traditional methods. Deep learning networks have become a promising answer to this problem. In this paper, we present the architecture of two models - using convolutional and recurrent neural networks - that are intended to effectively discover five vulnerabilities in smart contracts. To train and validate the models, we used a dataset that includes 106474 audited smart contracts taken from the public Ethereum blockchain. Instead of the source code that is typically used by most deep learning-based solutions, the models receive input in the form of Ethereum Virtual Machine (EVM) bytecode. Across all five vulnerabilities, the Recurrent Neural Network model has an average micro F1-score of 0.93, whereas the Convolutional Neural Network achieves an average micro F1-score of 0.89. Through comparative research with various deep learning systems and static analysis tools, we have determined that EVM bytecode may be leveraged as a feature to detect vulnerabilities in smart contracts.  © 2024 IEEE.
KW  - Deep Learning
KW  - Security
KW  - Smart Contracts
KW  - Blockchain
KW  - Codes (symbols)
KW  - Convolution
KW  - Ethereum
KW  - Learning algorithms
KW  - Learning systems
KW  - Network security
KW  - Recurrent neural networks
KW  - Static analysis
KW  - Block-chain
KW  - Bytecodes
KW  - Code review
KW  - Code security
KW  - Deep learning
KW  - F1 scores
KW  - Security
KW  - Security audit
KW  - Security vulnerabilities
KW  - Vulnerability detection
KW  - Smart contract
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CHAP
AU  - Porikli, F.
TI  - Challenges of Computer Vision Research from an Industry Perspective
PY  - 2024
T2  - Computer Vision: Challenges, Trends, and Opportunities
SP  - 18
EP  - 32
DO  - 10.1201/9781003328957-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206028090&doi=10.1201%2f9781003328957-2&partnerID=40&md5=954208de8c1cd5a9da8f6a4e61f2fced
AB  - This chapter presents a composition of personal observations experienced in industrial research lab settings over many years. It is not structured in a conventional paper style. Instead, it intends to serve as a humble reference for researchers, engineers, technical managers, and computer vision practitioners in their efforts toward bringing ideas to life. It aims to provide elementary—and hopefully practical—insights into the landscape of computer vision research challenges from an industry perspective. It dissects the industrial research effort into the conception of ideas and execution phases. The first part offers perspectives into innovative processes, need-oriented and exploratory research motivations, and research culture. Here, it introduces an octagram of idea cultivation. The second part sheds light on performance objectives, how such objectives evolve during the different phases of the projects, challenges relating to datasets, the role of baselines, platform factors, and agile development strategies. This part also looks into the mechanisms of project development, the role of teamwork, and the importance of self-growth. The chapter finally probes open problems and lists active research areas, from fundamental computer vision tasks to outstanding challenges in machine learning to systems aspects. © 2025 selection and editorial matter, Md Atiqur Rahman Ahad, Upal Mahbub, Matthew Turk, Richard Hartley.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Wang, H.
AU  - Gonzalez-Pumariega, G.
AU  - Sharma, Y.
AU  - Choudhury, S.
TI  - Demo2Code: From Summarizing Demonstrations to Synthesizing Code via Extended Chain-of-Thought
PY  - 2023
T2  - Advances in Neural Information Processing Systems
VL  - 36
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185432075&partnerID=40&md5=bb1f966d0c48dae53bc8336598ca8e0f
AB  - Language instructions and demonstrations are two natural ways for users to teach robots personalized tasks. Recent progress in Large Language Models (LLMs) has shown impressive performance in translating language instructions into code for robotic tasks. However, translating demonstrations into task code continues to be a challenge due to the length and complexity of both demonstrations and code, making learning a direct mapping intractable. This paper presents Demo2Code, a novel framework that generates robot task code from demonstrations via an extended chain-of-thought and defines a common latent specification to connect the two. Our framework employs a robust two-stage process: (1) a recursive summarization technique that condenses demonstrations into concise specifications, and (2) a code synthesis approach that expands each function recursively from the generated specifications. We conduct extensive evaluation on various robot task benchmarks, including a novel game benchmark Robotouille, designed to simulate diverse cooking tasks in a kitchen environment. The project's website is at https://portal-cornell.github.io/demo2code/. © 2023 Neural information processing systems foundation. All rights reserved.
KW  - Robots
KW  - Specifications
KW  - Translation (languages)
KW  - Code synthesis
KW  - Direct mapping
KW  - Language model
KW  - Performance
KW  - Project website
KW  - Recent progress
KW  - Robot tasks
KW  - Robotic tasks
KW  - Two-stage process
KW  - Demonstrations
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - CONF
AU  - Castri, L.
AU  - Beraldo, G.
AU  - Mghames, S.
AU  - Hanheide, M.
AU  - Bellotto, N.
TI  - Experimental Evaluation of ROS-Causal in Real-World Human-Robot Spatial Interaction Scenarios
PY  - 2024
T2  - IEEE International Workshop on Robot and Human Communication, RO-MAN
SP  - 1603
EP  - 1609
DO  - 10.1109/RO-MAN60168.2024.10731290
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209803042&doi=10.1109%2fRO-MAN60168.2024.10731290&partnerID=40&md5=0ee3cbb80ef9aa471a1c03478bd8ff60
AB  - Deploying robots in human-shared environments requires a deep understanding of how nearby agents and objects interact. Employing causal inference to model cause-and-effect relationships facilitates the prediction of human behaviours and enables the anticipation of robot interventions. However, a significant challenge arises due to the absence of implementation of existing causal discovery methods within the ROS ecosystem, the standard de-facto framework in robotics, hindering effective utilisation on real robots. To bridge this gap, in our previous work we proposed ROS-Causal, a ROS-based framework designed for onboard data collection and causal discovery in human-robot spatial interactions. In this work, we present an experimental evaluation of ROS-Causal both in simulation and on a new dataset of human-robot spatial interactions in a lab scenario, to assess its performance and effectiveness. Our analysis demonstrates the efficacy of this approach, showcasing how causal models can be extracted directly onboard by robots during data collection. The online causal models generated from the simulation are consistent with those from lab experiments. These findings can help researchers to enhance the performance of robotic systems in shared environments, firstly by studying the causal relations between variables in simulation without real people, and then facilitating the actual robot deployment in real human environments. ROS-Causal: https://lcastri.github.io/roscausal  © 2024 IEEE.
KW  - Adversarial machine learning
KW  - Human robot interaction
KW  - Microrobots
KW  - Nanorobots
KW  - Causal inferences
KW  - Causal modeling
KW  - Cause-and-effect relationships
KW  - Data collection
KW  - Experimental evaluation
KW  - Human behaviors
KW  - Human robots
KW  - Performance
KW  - Real-world
KW  - Spatial interaction
KW  - Chatbots
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Liu, Z.
AU  - Qian, P.
AU  - Wang, X.
AU  - Zhuang, Y.
AU  - Qiu, L.
AU  - Wang, X.
TI  - Combining Graph Neural Networks with Expert Knowledge for Smart Contract Vulnerability Detection
PY  - 2023
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 35
IS  - 2
SP  - 1296
EP  - 1310
DO  - 10.1109/TKDE.2021.3095196
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109397423&doi=10.1109%2fTKDE.2021.3095196&partnerID=40&md5=7bd04392f0c0af5571c7a03762d62919
AB  - Smart contract vulnerability detection draws extensive attention in recent years due to the substantial losses caused by hacker attacks. Existing efforts for contract security analysis heavily rely on rigid rules defined by experts, which are labor-intensive and non-scalable. More importantly, expert-defined rules tend to be error-prone and suffer the inherent risk of being cheated by crafty attackers. Recent researches focus on the symbolic execution and formal analysis of smart contracts for vulnerability detection, yet to achieve a precise and scalable solution. Although several methods have been proposed to detect vulnerabilities in smart contracts, there is still a lack of effort that considers combining expert-defined security patterns with deep neural networks. In this paper, we explore using graph neural networks and expert knowledge for smart contract vulnerability detection. Specifically, we cast the rich control- and data- flow semantics of the source code into a contract graph. To highlight the critical nodes in the graph, we further design a node elimination phase to normalize the graph. Then, we propose a novel temporal message propagation network to extract the graph feature from the normalized graph, and combine the graph feature with designed expert patterns to yield a final detection system. Extensive experiments are conducted on all the smart contracts that have source code in Ethereum and VNT Chain platforms. Empirical results show significant accuracy improvements over the state-of-the-art methods on three types of vulnerabilities, where the detection accuracy of our method reaches 89.15, 89.02, and 83.21 percent for reentrancy, timestamp dependence, and infinite loop vulnerabilities, respectively. © 1989-2012 IEEE.
KW  - blockchain
KW  - Deep learning
KW  - expert knowledge
KW  - smart contract
KW  - vulnerability detection
KW  - Backpropagation
KW  - Blockchain
KW  - Data flow analysis
KW  - Deep neural networks
KW  - Feature extraction
KW  - Flow graphs
KW  - Graph neural networks
KW  - Network security
KW  - Personal computing
KW  - Program debugging
KW  - Semantics
KW  - Block-chain
KW  - Computer bugs
KW  - Deep learning
KW  - Expert knowledge
KW  - Features extraction
KW  - Graph neural networks
KW  - Security
KW  - Source codes
KW  - Vulnerability detection
KW  - Smart contract
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 167
ER  -

TY  - JOUR
AU  - Vohra, A.
AU  - Garg, R.
TI  - Deep learning based sentiment analysis of public perception of working from home through tweets
PY  - 2023
T2  - Journal of Intelligent Information Systems
VL  - 60
IS  - 1
SP  - 255
EP  - 274
DO  - 10.1007/s10844-022-00736-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136861316&doi=10.1007%2fs10844-022-00736-2&partnerID=40&md5=52b685aed7e9314b84fd955b22c75dbd
AB  - Nowadays, we are witnessing a paradigm shift from the conventional approach of working from office spaces to the emerging culture of working virtually from home. Even during the COVID-19 pandemic, many organisations were forced to allow employees to work from their homes, which led to worldwide discussions of this trend on Twitter. The analysis of this data has immense potential to change the way we work but extracting useful information from this valuable data is a challenge. Hence in this study, the microblogging website Twitter is used to gather more than 450,000 English language tweets from 22nd January 2022 to 12th March 2022, consisting of keywords related to working from home. A state-of-the-art pre-processing technique is used to convert all emojis into text, remove duplicate tweets, retweets, username tags, URLs, hashtags etc. and then the text is converted to lowercase. Thus, the number of tweets is reduced to 358,823. In this paper, we propose a fine-tuned Convolutional Neural Network (CNN) model to analyse Twitter data. The input to our deep learning model is an annotated set of tweets that are effectively labelled into three sentiment classes, viz. positive negative and neutral using VADER (Valence Aware Dictionary for sEntiment Reasoning). We also use a variation in the input vector to the embedding layer, by using FastText embeddings with our model to train supervised word representations for our text corpus of more than 450,000 tweets. The proposed model uses multiple convolution and max pooling layers, dropout operation, and dense layers with ReLU and sigmoid activations to achieve remarkable results on our dataset. Further, the performance of our model is compared with some standard classifiers like Support Vector Machine (SVM), Naive Bayes, Decision Tree, and Random Forest. From the results, it is observed that on the given dataset, the proposed CNN with FastText word embeddings outperforms other classifiers with an accuracy of 0.925969. As a result of this classification, 54.41% of the tweets are found to show affirmation, 24.50% show a negative disposition, and 21.09% have neutral sentiments towards working from home. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
KW  - Big data
KW  - Deep learning
KW  - Opinion mining
KW  - Social media
KW  - VADER
KW  - Big data
KW  - Classification (of information)
KW  - Convolution
KW  - Convolutional neural networks
KW  - Decision trees
KW  - Deep learning
KW  - Embeddings
KW  - Office buildings
KW  - Social networking (online)
KW  - Support vector machines
KW  - Conventional approach
KW  - Convolutional neural network
KW  - Deep learning
KW  - Embeddings
KW  - Opinion mining
KW  - Paradigm shifts
KW  - Public perception
KW  - Sentiment analysis
KW  - Social media
KW  - Valence aware dictionary for sentiment reasoning
KW  - Sentiment analysis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 26
ER  -

TY  - JOUR
AU  - Ren, C.
AU  - Yu, H.
AU  - Peng, H.
AU  - Tang, X.
AU  - Zhao, B.
AU  - Yi, L.
AU  - Tan, A.Z.
AU  - Gao, Y.
AU  - Li, A.
AU  - Li, X.
AU  - Li, Z.
AU  - Yang, Q.
TI  - Advances and Open Challenges in Federated Foundation Models
PY  - 2025
T2  - IEEE Communications Surveys and Tutorials
DO  - 10.1109/COMST.2025.3552524
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000335921&doi=10.1109%2fCOMST.2025.3552524&partnerID=40&md5=57c9ff0cd02a77aec584d8ea382d79be
AB  - The integration of Foundation Models (FMs) with Federated Learning (FL) presents a transformative paradigm in Artificial Intelligence (AI). This integration offers enhanced capabilities, while addressing concerns of privacy, data decentralization and computational efficiency. This paper provides a comprehensive survey of the emerging field of Federated Foundation Models (FedFM), elucidating their synergistic relationship and exploring novel methodologies, challenges, and future directions that the FL research field needs to focus on in order to thrive in the age of FMs. A systematic multi-tiered taxonomy is proposed, categorizing existing FedFM approaches for model training, aggregation, trustworthiness, and incentivization. Key challenges, including how to enable FL to deal with high complexity of computational demands, privacy considerations, contribution evaluation, and communication efficiency, are thoroughly discussed. Moreover, this paper explores the intricate challenges of communication, scalability and security inherent in training/fine-tuning FMs via FL. It highlights the potential of quantum computing to revolutionize the processes of training, inference, optimization and security. This survey also introduces the implementation requirement of FedFM and some practical FedFM applications. It highlights lessons learned with a clear understanding of our findings for FedFM. Finally, this survey not only provides insights into the current state and challenges of FedFM, but also offers a blueprint for future research directions, emphasizing the need for developing trustworthy solutions. It serves as a foundational guide for researchers and practitioners interested in contributing to this interdisciplinary and rapidly advancing field.  © 2025 IEEE.
KW  - efficient training/aggregation
KW  - evaluation
KW  - federated foundation models
KW  - Federated learning
KW  - foundation models
KW  - incentivization
KW  - large language models
KW  - quantum computing
KW  - trustworthiness
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Differential privacy
KW  - Efficient training/aggregation
KW  - Evaluation
KW  - Federated foundation model
KW  - Foundation models
KW  - Incentivization
KW  - Language model
KW  - Large language model
KW  - Quantum Computing
KW  - Trustworthiness
KW  - Federated learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CHAP
AU  - Kucuksarac, B.
TI  - The Extended Reality Technology and Its Utilization in Metaverse
PY  - 2023
T2  - Studies in Big Data
VL  - 133
SP  - 65
EP  - 81
DO  - 10.1007/978-981-99-4641-9_5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175150914&doi=10.1007%2f978-981-99-4641-9_5&partnerID=40&md5=c548cf97b66b83b34412f47157baa2e1
AB  - In today's world, where digital changes and transitions are experienced with the developments in technology, many inventions and innovative applications enter daily life. The extended reality technology, which covers virtual reality, augmented reality, and mixed reality technologies, is among these innovative applications. These technologies not only change the way individuals get information, rejoice, make decisions, and act but also enable the creation of a participatory experience. For this reason, the extended reality technology, which has been increasingly used in many fields and disciplines, is one of the significant building blocks of the widely spoken Metaverse. Based on the convergence of technologies that enable multi-sensory interactions with extended reality technology, digital objects, and people, Metaverse is defined as a network of immersive environments with interconnected social networks on permanent multi-user platforms. Accordingly, in this network, it is possible to travel, work together, play games, shop, and engage in educational activities with avatars and digital twins created and controlled by users. In this study, extended reality technology, which is one of the significant building blocks of Metaverse, and the use of this technology in Metaverse were discussed. In this regard, the study, which has been planned as a descriptive study, includes literature analysis and definitions and explanations about extended reality technology and Metaverse; Afterward, the use of extended reality technology in Metaverse was explained by supporting it with current examples. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2023.
KW  - Augmented reality
KW  - Extended reality
KW  - Metaverse
KW  - Mixed reality
KW  - Virtual reality
KW  - Augmented reality
KW  - Social sciences computing
KW  - Building blockes
KW  - Convergence of technologies
KW  - Daily lives
KW  - Digital Objects
KW  - Extended reality
KW  - Immersive environment
KW  - Metaverses
KW  - Mixed reality
KW  - Mixed reality technologies
KW  - Multi-sensory interactions
KW  - Mixed reality
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Araghi, S.N.
AU  - Liu, Z.
AU  - Sarkar, A.
AU  - Louge, T.
AU  - Karray, M.H.
TI  - Digital Twin's Anatomy: A Cross-Sector Framework With Healthcare Validation
PY  - 2025
T2  - IEEE Access
VL  - 13
SP  - 21306
EP  - 21334
DO  - 10.1109/ACCESS.2025.3528736
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215217838&doi=10.1109%2fACCESS.2025.3528736&partnerID=40&md5=753be611c4a4f52e43f28d5af7f1f7d9
AB  - Digital twins (DT) in manufacturing, healthcare, and across different industrial domains are often over-simplified as solely a virtual representation of a physical object or service. Such a definition constitutes a dilemma in distinguishing DTs from digital models, digital shadows, digital threads, and cyber-physical systems. In this article, we aim to elucidate the concept of digital twins and its definition. Therefore, we go through the connotation of digital twins, which has its roots in space exploration and product-life cycle management, and describe the four evolution stages of DT developments. This article employs an ontological approach to clearly and comprehensively define digital twins and related key concepts, including digital models, assets, prototypes, shadows, and threads. Additionally, it presents a structured framework detailing the meta-model and the reference-level ontology of digital twins. To evaluate the proposed structure, definitions, and its important entities, we have examined our framework against 73 peer-reviewed papers in the healthcare sector from 2018 until July 2024. The evaluation and classification criteria of the selected works were based on four research questions. These criteria are driven by the core definitions provided by the main cross-domain digital twin researchers and this article's proposed anatomy of digital twins.  © 2025 The Authors.
KW  - cross-domain digital twin applications
KW  - cyber-physical systems
KW  - digital threads
KW  - digital transformation
KW  - Digital twins
KW  - Industry 4.0
KW  - model-based system engineering
KW  - ontology
KW  - Electronic health record
KW  - Ontology
KW  - Cross sectors
KW  - Cross-domain
KW  - Cross-domain digital twin application
KW  - Cybe-physical systems
KW  - Cyber-physical systems
KW  - Digital modeling
KW  - Digital thread
KW  - Digital transformation
KW  - Model-based system engineerings
KW  - Ontology's
KW  - Space research
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Carbonaro, A.
TI  - Interpretability of AI Systems in Electronic Governance
PY  - 2022
T2  - Communications in Computer and Information Science
VL  - 1666 CCIS
SP  - 109
EP  - 116
DO  - 10.1007/978-3-031-22950-3_9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148004047&doi=10.1007%2f978-3-031-22950-3_9&partnerID=40&md5=97c01f60e474b18f352df491b574adc2
AB  - Modern electronic governance systems require cutting-edge analytical techniques to manage available ever-larger and distributes data, with a known spread of unstructured and unlabeled text documents. Many organizations are turning to data governance to exercise control over the quality of their data and their processes in order to guarantee the delivery of trustworthy decisions. In this context, modern AI breakthroughs give new opportunities to impact many application scenarios, like knowledge extraction and exploration in electronic governance. In this paper we introduce the need to build interpretable AI systems for electronic governance in order to improve trust and consequently user acceptance, highlighting some emergent topics and open challenges, mainly linked to integrating quantitative and qualitative techniques, such as deep learning and knowledge graphs for semantic-aware models. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Computational intelligence
KW  - E-governance
KW  - Knowledge graphs
KW  - Neural-symbolic learning
KW  - Semantic web
KW  - Deep learning
KW  - e-government
KW  - E-learning
KW  - Information management
KW  - Knowledge graph
KW  - Learning systems
KW  - AI systems
KW  - Cutting edges
KW  - E-governance
KW  - Electronic governance
KW  - Governance systems
KW  - Interpretability
KW  - Knowledge graphs
KW  - Neural-symbolic learning
KW  - Semantic-Web
KW  - Symbolic learning
KW  - Semantic Web
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Lyu, M.
AU  - Li, F.
AU  - Lee, C.-H.
AU  - Chen, C.-H.
TI  - VALIO: Visual attention-based linear temporal logic method for explainable out-of-the-loop identification
PY  - 2024
T2  - Knowledge-Based Systems
VL  - 299
C7  - 112086
DO  - 10.1016/j.knosys.2024.112086
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196307440&doi=10.1016%2fj.knosys.2024.112086&partnerID=40&md5=bbafc707a462055e022a93a7cbf59760
AB  - The phenomenon of being Out-Of-The-Loop (OOTL) can significantly undermine pilots’ performance and pose a threat to aviation safety. Previous attempts to identify OOTL status have primarily utilized “black-box” machine learning techniques, which fail to provide explainable insights into their findings. To address this gap, our study introduces a novel application of Linear Temporal Logic (LTL) methods within a framework named Visual Attention LTLf for Identifying OOTL (VALIO), leveraging eye-tracking technology to non-intrusively capture the pilots’ attentional focus. By encoding Areas of Interest (AOIs) and gaze durations within the cockpit into Visual Attention Traces (VAT), the method captures the spatial and temporal dimensions of visual attention. It enables the LTL methods to generate interpretable formulas that classify pilot behaviors and provide insights into the understanding of the OOTL phenomenon. Through a case study of a simulated flight experiment, we compared the efficacy of this approach using different time windows from 10 s to 75 s. The results demonstrate that VALIO's performance is stable across all time windows with the best F1 score of 0.815 and the lowest F1 of 0.769. And it significantly outperforms the other machine learning methods when using time windows shorter than 30 s, signifying its ability to detect the OOTL status more in-timely. Moreover, the VALIO elucidates pilot behaviors through the derivation of human-readable LTLf formulas, offering the explainability of the results and insights into OOTL characteristics. Overall, this research proposes the VALIO framework as an improvement for OOTL identification in both performance and explainability. © 2024 Elsevier B.V.
KW  - Eye-tracking
KW  - Flight safety
KW  - Human-automation interaction
KW  - Neuro-symbolic AI
KW  - Pilot performance
KW  - Behavioral research
KW  - Computer circuits
KW  - Machine learning
KW  - Temporal logic
KW  - Eye-tracking
KW  - Flight safety
KW  - Human-automation interactions
KW  - Linear temporal logic
KW  - Logic method
KW  - Neuro-symbolic AI
KW  - Performance
KW  - Pilot behavior
KW  - Pilot performance
KW  - Visual Attention
KW  - Eye tracking
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - CONF
AU  - Calvaresi, D.
AU  - Ciatto, G.
AU  - Najjar, A.
AU  - Aydoğan, R.
AU  - Van der Torre, L.
AU  - Omicini, A.
AU  - Schumacher, M.
TI  - Expectation: Personalized Explainable Artificial Intelligence for Decentralized Agents with Heterogeneous Knowledge
PY  - 2021
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 12688 LNAI
SP  - 331
EP  - 343
DO  - 10.1007/978-3-030-82017-6_20
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113351710&doi=10.1007%2f978-3-030-82017-6_20&partnerID=40&md5=20f7d1d6cc2fa236457d63d5ef4dab79
AB  - Explainable AI (XAI) has emerged in recent years as a set of techniques and methodologies to interpret and explain machine learning (ML) predictors. To date, many initiatives have been proposed. Nevertheless, current research efforts mainly focus on methods tailored to specific ML tasks and algorithms, such as image classification and sentiment analysis. However, explanation techniques are still embryotic, and they mainly target ML experts rather than heterogeneous end-users. Furthermore, existing solutions assume data to be centralised, homogeneous, and fully/continuously accessible—circumstances seldom found altogether in practice. Arguably, a system-wide perspective is currently missing. The project named “Personalized Explainable Artificial Intelligence for Decentralized Agents with Heterogeneous Knowledge ” (Expectation) aims at overcoming such limitations. This manuscript presents the overall objectives and approach of the Expectation project, focusing on the theoretical and practical advance of the state of the art of XAI towards the construction of personalised explanations in spite of decentralisation and heterogeneity of knowledge, agents, and explainees (both humans or virtual). To tackle the challenges posed by personalisation, decentralisation, and heterogeneity, the project fruitfully combines abstractions, methods, and approaches from the multi-agent systems, knowledge extraction/injection, negotiation, argumentation, and symbolic reasoning communities. © 2021, Springer Nature Switzerland AG.
KW  - Chist-Era IV
KW  - Decentralisation
KW  - Expectation
KW  - eXplanable AI
KW  - Multi-agent systems
KW  - Personalisation
KW  - Intelligent agents
KW  - Sentiment analysis
KW  - Centralised
KW  - Decentralisation
KW  - Heterogeneous Knowledge
KW  - Knowledge extraction
KW  - Personalisation
KW  - Research efforts
KW  - State of the art
KW  - Symbolic reasoning
KW  - Multi agent systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 10
ER  -

TY  - JOUR
AU  - Li, Q.
AU  - Qin, L.
AU  - Xu, H.
AU  - Lin, Q.
AU  - Qin, Z.
AU  - Chu, F.
TI  - Transparent information fusion network: An explainable network for multi-source bearing fault diagnosis via self-organized neural-symbolic nodes
PY  - 2025
T2  - Advanced Engineering Informatics
VL  - 65
C7  - 103156
DO  - 10.1016/j.aei.2025.103156
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216480226&doi=10.1016%2fj.aei.2025.103156&partnerID=40&md5=92201d0a272fd6c1f6fea86b2f4a4221
AB  - In recent years, the integration of Artificial Intelligence (AI) into Intelligent Fault Diagnosis (IFD) through multi-source signal fusion has advanced significantly. However, the inherent opacity of AI-driven IFD models often hampers explainability, a crucial factor for fostering deeper collaboration between humans and intelligent systems to enhance the safety and reliability of industrial assets. This study introduces a novel and explainable methodology termed the Transparent Information Fusion Network (TIFN). TIFN incorporates multiple self-organized Neural-Symbolic Nodes (NSNs) equipped with signal processing and statistical operators, as opposed to conventional black-box neural networks or manually crafted expert systems. NSNs are interconnected through learnable signal-wise gates to construct the Signal Operator Layer (SOL) and Feature Operator Layer (FOL). The entire network is trainable using gradient-based learning methods in a self-organized manner. This enables accurate representation of fault signals and establishes a fully comprehensible semantic framework with an explainable decision-making process. The transparency, generalization, and capability to learn from limited samples of TIFN are demonstrated through two case studies on rotating machinery equipped with different sensors. Case 1 fuses vibration and piezoelectric signals, while Case 2 integrates piezoelectric and triboelectric signals to achieve comprehensive information fusion at both signal and feature levels. By incorporating learnable NSNs, signal-wise gates, TIFN achieves superior diagnostic performance with fewer parameters compared to traditional expert-organized models. This research underscores the potential of TIFN as a fully explainable tool for industrial diagnostics with multi-source signals, paving the way for enhanced human-machine collaboration in Industry 5.0, with a focus on trustworthiness, transparency, and accountability. © 2025 Elsevier Ltd
KW  - Full explainability
KW  - Neural-symbolic node
KW  - Rotating machinery
KW  - Self-organized learning
KW  - Transparent fault diagnosis
KW  - Bearings (machine parts)
KW  - Multilayer neural networks
KW  - Sensor data fusion
KW  - Bearing fault diagnosis
KW  - Faults diagnosis
KW  - Full explainability
KW  - Multi-Sources
KW  - Neural-symbolic node
KW  - Piezoelectric signals
KW  - Self organized learning
KW  - Self-organised
KW  - Source signals
KW  - Transparent fault diagnose
KW  - Expert systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Anisetti, M.
AU  - Ardagna, C.A.
AU  - Bena, N.
AU  - Giandomenico, V.
AU  - Gianini, G.
TI  - Lightweight Behavior-Based Malware Detection
PY  - 2024
T2  - Communications in Computer and Information Science
VL  - 2022 CCIS
SP  - 237
EP  - 250
DO  - 10.1007/978-3-031-51643-6_17
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192252146&doi=10.1007%2f978-3-031-51643-6_17&partnerID=40&md5=5caae14c5da1c3d18df1e56f00a11050
AB  - Modern malware detection tools rely on special permissions to collect data that can reveal the presence of suspicious software within a machine. Typical data that they collect for this task are the set of system calls, the content of network traffic, file system changes, and API calls. However, giving access to these data to an externally created program means granting the company that created that software complete control over the host machine. This is undesirable for many reasons. In this work, we propose an alternative approach for this task, which relies on easily accessible data, information about system performances (CPU, RAM, disk, and network usage), and does not need high-level permissions to be collected. To investigate the effectiveness of this approach, we collected these data in the form of a multivalued time series and ran a number of malware programs in a suitably devised sandbox. Then – to address the fact that deep learning models need large training sets – we augmented the dataset using a deep learning generative model (a Generative Adversarial Network). Finally, we trained an LSTM (Long Short Term Memory) network to capture the malware behavioral patterns. Our investigation found that this approach, based on easy-to-collect information, is very effective (we achieved 0.99 accuracy), despite the fact that the data used for training the detector are substantially different from the ones specifically targeted for this purpose. The real and synthetic datasets, as well as corresponding source code, are publicly available. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - behavior analysis
KW  - GAN
KW  - LSTM
KW  - Malware detection
KW  - Anomaly detection
KW  - Data acquisition
KW  - Generative adversarial networks
KW  - Large datasets
KW  - Learning systems
KW  - Long short-term memory
KW  - Random access storage
KW  - Behavior analysis
KW  - Behavior-based
KW  - Detection tools
KW  - Filesystem
KW  - GAN
KW  - Malware detection
KW  - Malwares
KW  - Network traffic
KW  - System calls
KW  - System change
KW  - Malware
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Wen, J.
AU  - Jiang, D.
AU  - Tu, G.
AU  - Liu, C.
AU  - Cambria, E.
TI  - Dynamic interactive multiview memory network for emotion recognition in conversation
PY  - 2023
T2  - Information Fusion
VL  - 91
SP  - 123
EP  - 133
DO  - 10.1016/j.inffus.2022.10.009
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140325783&doi=10.1016%2fj.inffus.2022.10.009&partnerID=40&md5=9d7a68d85ad425ca2522ed3fa64a5d84
AB  - When available, multimodal data is key for enhanced emotion recognition in conversation. Text, audio, and video in dialogues can facilitate and complement each other in analyzing speakers’ emotions. However, it is very challenging to effectively fuse multimodal features to understand the detailed contextual information in conversations. In this work, we focus on dynamic interactions during the information fusion process and propose a Dynamic Interactive Multiview Memory Network (DIMMN) model to integrate interaction information for recognizing emotions. Specifically, the information fusion within DIMMN is through multiple perspectives (combining different modalities). We designed multiview layers in attention networks to enable the model to mine the crossmodal dynamic dependencies between different groups in the process of dynamic modal interaction. In order to learn the long-term dependency information, temporal convolutional networks are introduced to synthesize contextual information of a single person. Then, the gated recurrent units and memory networks are used to model the global session to detect contextual dependencies for multi-round, multi-speaker interactive emotion information. Experimental results on IEMOCAP and MELD demonstrate that DIMMN achieves better and comparable performance to the state-of-the-art methods, with an accuracy of 64.7% and 60.6%, respectively. © 2022 Elsevier B.V.
KW  - Dynamic interactive multiview memory network
KW  - Emotion recognition in conversation
KW  - Multimodal fusion
KW  - Emotion Recognition
KW  - Multilayer neural networks
KW  - Network layers
KW  - Recurrent neural networks
KW  - Speech recognition
KW  - Audio and video
KW  - Contextual information
KW  - Dynamic interactive
KW  - Dynamic interactive multiview memory network
KW  - Emotion recognition
KW  - Emotion recognition in conversation
KW  - Memory network
KW  - Multi-modal data
KW  - Multi-modal fusion
KW  - Multi-views
KW  - Information fusion
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 68
ER  -

TY  - JOUR
AU  - Wu, J.
AU  - Huang, Z.
AU  - Hu, Z.
AU  - Lv, C.
TI  - Toward Human-in-the-Loop AI: Enhancing Deep Reinforcement Learning via Real-Time Human Guidance for Autonomous Driving
PY  - 2023
T2  - Engineering
VL  - 21
SP  - 75
EP  - 91
DO  - 10.1016/j.eng.2022.05.017
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146715634&doi=10.1016%2fj.eng.2022.05.017&partnerID=40&md5=a7c8b2f5fa66df258454b34d69968b55
AB  - Due to its limited intelligence and abilities, machine learning is currently unable to handle various situations thus cannot completely replace humans in real-world applications. Because humans exhibit robustness and adaptability in complex scenarios, it is crucial to introduce humans into the training loop of artificial intelligence (AI), leveraging human intelligence to further advance machine learning algorithms. In this study, a real-time human-guidance-based (Hug)-deep reinforcement learning (DRL) method is developed for policy training in an end-to-end autonomous driving case. With our newly designed mechanism for control transfer between humans and automation, humans are able to intervene and correct the agent's unreasonable actions in real time when necessary during the model training process. Based on this human-in-the-loop guidance mechanism, an improved actor-critic architecture with modified policy and value networks is developed. The fast convergence of the proposed Hug-DRL allows real-time human guidance actions to be fused into the agent's training loop, further improving the efficiency and performance of DRL. The developed method is validated by human-in-the-loop experiments with 40 subjects and compared with other state-of-the-art learning approaches. The results suggest that the proposed method can effectively enhance the training efficiency and performance of the DRL algorithm under human guidance without imposing specific requirements on participants’ expertise or experience. © 2022 THE AUTHOR
KW  - Autonomous driving
KW  - Deep reinforcement learning
KW  - Human guidance
KW  - Human-in-the-loop AI
KW  - Autonomous vehicles
KW  - Deep learning
KW  - Efficiency
KW  - Learning algorithms
KW  - Learning systems
KW  - Autonomous driving
KW  - Deep reinforcement learning
KW  - Efficiency and performance
KW  - Human guidance
KW  - Human-in-the-loop
KW  - Human-in-the-loop artificial intelligence
KW  - Machine-learning
KW  - Real- time
KW  - Real-world
KW  - Reinforcement learnings
KW  - Reinforcement learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 110
ER  -

TY  - JOUR
AU  - Wang, H.
AU  - Liu, H.
AU  - Li, W.
TI  - Crowd evacuation path planning and simulation method based on deep reinforcement learning and repulsive force field
PY  - 2025
T2  - Applied Intelligence
VL  - 55
IS  - 4
C7  - 297
DO  - 10.1007/s10489-024-06074-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217794179&doi=10.1007%2fs10489-024-06074-w&partnerID=40&md5=fd00f5349c38054d0a0fd233a7244746
AB  - Path planning is essential for simulating crowd evacuation. However, existing path planning methods encounter challenges, including unbalanced exit utilization, ineffective obstacle avoidance, and low evacuation efficiency. To address these issues, this paper presents a path planning method based on Deep Reinforcement Learning (DRL) and a Repulsive Force Field (RFF) for crowd evacuation simulation. First, a dynamic exit scoring mechanism is proposed and integrated into the DRL training process to balance exit utilization during evacuation. Additionally, we address the sparse reward issue in DRL by extracting key points from actual evacuation trajectories as short-term goals. Finally, we enhance the movement strategy output by constructing an RFF to improve obstacle avoidance in complex environments. Experimental results demonstrate that the proposed method effectively avoids obstacles and efficiently completes evacuation tasks. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2025.
KW  - Computer simulation
KW  - Crowd evacuation simulation
KW  - Deep reinforcement learning
KW  - Path planning
KW  - Adversarial machine learning
KW  - Deep learning
KW  - Motion planning
KW  - Reinforcement learning
KW  - Crowd evacuation
KW  - Crowd evacuation simulation
KW  - Evacuation simulation
KW  - Keypoints
KW  - Obstacles avoidance
KW  - Path planning method
KW  - Planning and simulations
KW  - Reinforcement learnings
KW  - Repulsive force field
KW  - Training process
KW  - Deep reinforcement learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Kpodo, J.
AU  - Nejadhashemi, A.P.
TI  - Navigating challenges/opportunities in developing smart agricultural extension platforms: Multi-media data mining techniques
PY  - 2025
T2  - Artificial Intelligence in Agriculture
VL  - 15
IS  - 3
SP  - 426
EP  - 448
DO  - 10.1016/j.aiia.2025.04.001
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002655982&doi=10.1016%2fj.aiia.2025.04.001&partnerID=40&md5=3b2d763c4ad7ada4a676d70c94154c62
AB  - Agricultural Extension (AE) research faces significant challenges in producing relevant and practical knowledge due to rapid advancements in artificial intelligence (AI). AE struggles to keep pace with these advancements, complicating the development of actionable information. One major challenge is the absence of intelligent platforms that enable efficient information retrieval and quick decision-making. Investigations have shown a shortage of AI-assisted solutions that effectively use AE materials across various media formats while preserving scientific accuracy and contextual relevance. Although mainstream AI systems can potentially reduce decision-making risks, their usage remains limited. This limitation arises primarily from the lack of standardized datasets and concerns regarding user data privacy. For AE datasets to be standardized, they must satisfy four key criteria: inclusion of critical domain-specific knowledge, expert curation, consistent structure, and acceptance by peers. Addressing data privacy issues involves adhering to open-access principles and enforcing strict data encryption and anonymization standards. To address these gaps, a conceptual framework is introduced. This framework extends beyond typical user-oriented platforms and comprises five core modules. It features a neurosymbolic pipeline integrating large language models with physically based agricultural modeling software, further enhanced by Reinforcement Learning from Human Feedback. Notable aspects of the framework include a dedicated human-in-the-loop process and a governance structure consisting of three primary bodies focused on data standardization, ethics and security, and accountability and transparency. Overall, this work represents a significant advancement in agricultural knowledge systems, potentially transforming how AE services deliver critical information to farmers and other stakeholders. © 2025 The Authors
KW  - Agriculture extension
KW  - Artificial intelligence
KW  - Decision-making
KW  - Large language models
KW  - Multi-media data mining
KW  - Agriculture extension
KW  - Artificial intelligence systems
KW  - Data-mining techniques
KW  - Decisions makings
KW  - Intelligent platform
KW  - Language model
KW  - Large language model
KW  - Media formats
KW  - Multi-Media
KW  - Multi-medium data mining
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Youssef, Y.M.
AU  - Müller, M.E.
TI  - A Review of Inductive Logic Programming Applications for Robotic Systems
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14363 LNAI
SP  - 154
EP  - 165
DO  - 10.1007/978-3-031-49299-0_11
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180764318&doi=10.1007%2f978-3-031-49299-0_11&partnerID=40&md5=160a5430619422ca4eec85b3759657d9
AB  - This study presents a review of applications of Inductive Logic Programming (ILP) for robotic systems. The aim of the paper is to demonstrate the different methods of applying ILP to a robotic system and to also highlight some of the limitations that already exist. ILP can aid in the development of explainable and trustworthy robotics systems. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Inductive Logic Programming
KW  - Review
KW  - Robotics
KW  - Inductive logic programming (ILP)
KW  - Robot programming
KW  - Inductive logic
KW  - Inductive logic programming
KW  - Logic-programming
KW  - Robotic systems
KW  - Computer circuits
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Knorozova, N.A.
AU  - Ronca, A.
TI  - On The Expressivity of Recurrent Neural Cascades (Extended Abstract)
PY  - 2024
T2  - CEUR Workshop Proceedings
VL  - 3819
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209353334&partnerID=40&md5=d8562ea0635c2b449151275013357b61
AB  - Recurrent Neural Cascades (RNCs) are the recurrent neural networks with no cyclic dependencies among recurrent neurons. This class of recurrent neural networks is successfully used in practice. Besides training methods for a fixed architecture such as backpropagation, the cascade architecture naturally allows for constructive learning methods, where recurrent nodes are added incrementally one at a time, often yielding smaller networks. Furthermore, acyclicity amounts to a structural prior that even for the same number of neurons yields a more favourable sample complexity compared to a fully-connected architecture. A central question is whether the advantages of the cascade architecture come at the cost of a reduced expressivity. We provide new insights into this question. We show that the regular languages captured by RNCs with sign and tanh activation with positive recurrent weights are the star-free regular languages. In order to establish our results we develop a novel framework where the capabilities of RNCs are assessed by analysing which semigroups and groups a single neuron is able to implement. A notable implication of our framework is that RNCs can achieve the expressivity of all regular languages by introducing neurons that can implement groups. © 2024 Copyright for this paper by its authors.
KW  - Algebraic Automata Theory
KW  - Automata Theory
KW  - Expressivity
KW  - Formal languages
KW  - Groups
KW  - Krohn-Rhodes Theory
KW  - Recurrent Neural Cascades
KW  - Recurrent Neural Networks
KW  - Semigroups
KW  - Star-free Regular Languages
KW  - Temporal Logic
KW  - Theory of Neural Networks
KW  - Architecture
KW  - Automata theory
KW  - Convolutional neural networks
KW  - Formal languages
KW  - Group theory
KW  - Neurons
KW  - Temporal logic
KW  - Algebraic automata theories
KW  - Expressivity
KW  - Group
KW  - Krohn-Rhodes theory
KW  - Neural-networks
KW  - Recurrent neural cascade
KW  - Semigroups
KW  - Star-free regular language
KW  - Theory of neural network
KW  - Recurrent neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - BOOK
AU  - Diveev, A.
AU  - Shmalko, E.
TI  - Machine learning control by symbolic regression
PY  - 2021
T2  - Machine Learning Control by Symbolic Regression
SP  - 1
EP  - 155
DO  - 10.1007/978-3-030-83213-1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130791893&doi=10.1007%2f978-3-030-83213-1&partnerID=40&md5=48bc30c532e4bae144742df4a978d44f
AB  - This book provides comprehensive coverage on a new direction in computational mathematics research: automatic search for formulas. Formulas must be sought in all areas of science and life: these are the laws of the universe, the macro and micro world, fundamental physics, engineering, weather and natural disasters forecasting; the search for new laws in economics, politics, sociology. Accumulating many years of experience in the development and application of numerical methods of symbolic regression to solving control problems, the authors offer new possibilities not only in the field of control automation, but also in the design of completely different optimal structures in many fields. For specialists in the field of control, Machine Learning Control by Symbolic Regression opens up a new promising direction of research and acquaints scientists with the methods of automatic construction of control systems.For specialists in the field of machine learning, the book opens up a new, much broader direction than neural networks: methods of symbolic regression. This book makes it easy to master this new area in machine learning and apply this approach everywhere neural networks are used. For mathematicians, the book opens up a new approach to the construction of numerical methods for obtaining analytical solutions to unsolvable problems; for example, numerical analytical solutions of algebraic equations, differential equations, non-trivial integrals, etc. For specialists in the field of artificial intelligence, the book offers a machine way to solve problems, framed in the form of analytical relationships. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2021. All rights reserved.
KW  - Analytic programming
KW  - Control synthesis
KW  - Genetic algorithm
KW  - Grammatical evolution
KW  - Identification
KW  - Machine learning
KW  - Mobile robot control
KW  - Multicriterial function search
KW  - Multicriterial function search
KW  - Network operator
KW  - Optimal control
KW  - Optimal control
KW  - Symbolic regression
KW  - Synergetic control
KW  - Training set
M3  - Book
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 35
ER  -

TY  - CONF
AU  - Khan, M.J.
AU  - Breslin, J.G.
AU  - Curry, E.
TI  - Expressive Scene Graph Generation Using Commonsense Knowledge Infusion for Visual Understanding and Reasoning
PY  - 2022
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 13261 LNCS
SP  - 93
EP  - 112
DO  - 10.1007/978-3-031-06981-9_6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131950361&doi=10.1007%2f978-3-031-06981-9_6&partnerID=40&md5=c872be05c3888bfddb869f1d26bcbedd
AB  - Scene graph generation aims to capture the semantic elements in images by modelling objects and their relationships in a structured manner, which are essential for visual understanding and reasoning tasks including image captioning, visual question answering, multimedia event processing, visual storytelling and image retrieval. The existing scene graph generation approaches provide limited performance and expressiveness for higher-level visual understanding and reasoning. This challenge can be mitigated by leveraging commonsense knowledge, such as related facts and background knowledge, about the semantic elements in scene graphs. In this paper, we propose the infusion of diverse commonsense knowledge about the semantic elements in scene graphs to generate rich and expressive scene graphs using a heterogeneous knowledge source that contains commonsense knowledge consolidated from seven different knowledge bases. The graph embeddings of the object nodes are used to leverage their structural patterns in the knowledge source to compute similarity metrics for graph refinement and enrichment. We performed experimental and comparative analysis on the benchmark Visual Genome dataset, in which the proposed method achieved a higher recall rate (R@ K= 29.89, 35.4, 39.12 for K= 20, 50, 100 ) as compared to the existing state-of-the-art technique (R@ K= 25.8, 33.3, 37.8 for K= 20, 50, 100 ). The qualitative results of the proposed method in a downstream task of image generation showed that more realistic images are generated using the commonsense knowledge-based scene graphs. These results depict the effectiveness of commonsense knowledge infusion in improving the performance and expressiveness of scene graph generation for visual understanding and reasoning tasks. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - commonsense knowledge
KW  - image generation
KW  - image representation
KW  - scene graph
KW  - visual reasoning
KW  - Graphic methods
KW  - Image retrieval
KW  - Knowledge management
KW  - Semantics
KW  - Commonsense knowledge
KW  - Graph generation
KW  - Image generations
KW  - Image representations
KW  - Knowledge sources
KW  - Performance
KW  - Reasoning tasks
KW  - Scene-graphs
KW  - Semantic element
KW  - Visual reasoning
KW  - Image representation
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 10
ER  -

TY  - JOUR
AU  - Wu, J.
AU  - Chen, L.
AU  - Fang, S.
AU  - Wu, C.
TI  - An Application Programming Interface (API) Sensitive Data Identification Method Based on the Federated Large Language Model
PY  - 2024
T2  - Applied Sciences (Switzerland)
VL  - 14
IS  - 22
C7  - 10162
DO  - 10.3390/app142210162
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210420696&doi=10.3390%2fapp142210162&partnerID=40&md5=201e38727e4698dd1f46f9555377a95e
AB  - The traditional methods for identifying sensitive data in APIs mainly encompass rule-based and machine learning-based approaches. However, these methods suffer from inadequacies in terms of security and robustness, exhibit high false positive rates, and struggle to cope with evolving threat landscapes. This paper proposes a method for detecting sensitive data in APIs based on the Federated Large Language Model (FedAPILLM). This method applies the large language model Qwen2.5 and the LoRA instruction tuning technique within the framework of federated learning (FL) to the field of data security. Under the premise of protecting data privacy, a domain-specific corpus and knowledge base are constructed for pre-training and fine-tuning, resulting in a large language model specifically designed for identifying sensitive data in APIs. This paper conducts comparative experiments involving Llama3 8B, Llama3.1 8B, and Qwen2.5 14B. The results demonstrate that Qwen2.5 14B can achieve similar or better performance levels compared to the Llama3.1 8B model with fewer training iterations. © 2024 by the authors.
KW  - API
KW  - data security
KW  - federated learning
KW  - large language model
KW  - sensitive data identification
KW  - Adversarial machine learning
KW  - Applications programming interfaces
KW  - Data identification
KW  - Identification method
KW  - Interface-sensitive
KW  - Language model
KW  - Large language model
KW  - Learning-based approach
KW  - Machine-learning
KW  - Rule-based learning
KW  - Sensitive data identification
KW  - Federated learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Jiang, D.
AU  - Liu, H.
AU  - Wei, R.
AU  - Tu, G.
TI  - CSAT-FTCN: A Fuzzy-Oriented Model with Contextual Self-attention Network for Multimodal Emotion Recognition
PY  - 2023
T2  - Cognitive Computation
VL  - 15
IS  - 3
SP  - 1082
EP  - 1091
DO  - 10.1007/s12559-023-10119-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147118655&doi=10.1007%2fs12559-023-10119-6&partnerID=40&md5=5a3f0f7e162ee29e7bcd219ea16f0943
AB  - Multimodal emotion analysis has become a hot trend because of its wide applications, such as the question-answering system. However, in a real-world scenario, people usually have mixed or partial emotions about evaluating objects. In this paper, we introduce a fuzzy temporal convolutional network based on contextual self-attention (CSAT-FTCN) to address these challenges, which has a membership function modeling various fuzzy emotions for understanding emotions in a more profound sense. Moreover, the CSAT-FTCN can obtain the dependency relationships of target utterances on internal own key information and external contextual information to understand emotions in a more profound sense. Additionally, as for multi-modality data, we introduce an attention fusion (ATF) mechanism to capture the dependency relationship between different modality information. The experimental results show that our CSAT-FTCN outperforms state-of-the-art models on tested datasets. The CSAT-FTCN network provides a novel method for multimodal emotion analysis. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
KW  - Attention fusion mechanism
KW  - Fuzzy network
KW  - Multimodal emotion analysis
KW  - Temporal convolutional network
KW  - Convolution
KW  - Emotion Recognition
KW  - Fuzzy inference
KW  - Fuzzy neural networks
KW  - Modal analysis
KW  - Attention fusion mechanism
KW  - Convolutional networks
KW  - Dependency relationship
KW  - Emotion analysis
KW  - Fusion mechanism
KW  - Fuzzy networks
KW  - Multi-modal
KW  - Multimodal emotion analyse
KW  - Multimodal emotion recognition
KW  - Temporal convolutional network
KW  - Membership functions
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 15
ER  -

TY  - CONF
AU  - Dreossi, T.
TI  - Bridging Deep Learning and Logic Programming for Explainability through ILP
PY  - 2025
T2  - Electronic Proceedings in Theoretical Computer Science, EPTCS
VL  - 416
SP  - 314
EP  - 323
DO  - 10.4204/EPTCS.416.31
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218639755&doi=10.4204%2fEPTCS.416.31&partnerID=40&md5=aedc8c3ed623c49086cc8b54064befd2
AB  - My research explores integrating deep learning and logic programming to set the basis for a new generation of AI systems. By combining neural networks with Inductive Logic Programming (ILP), the goal is to construct systems that make accurate predictions and generate comprehensible rules to validate these predictions. Deep learning models process and analyze complex data, while ILP techniques derive logical rules to prove the network's conclusions. Explainable AI methods, like eXplainable Answer Set Programming (XASP), elucidate the reasoning behind these rules and decisions. The focus is on applying ILP frameworks, specifically ILASP and FastLAS, to enhance explainability in various domains. My test cases span weather prediction, the legal field, and image recognition. In weather forecasting, the system will predict events and provides explanations using FastLAS, with plans to integrate recurrent neural networks in the future. In the legal domain, the research focuses on interpreting vague decisions and assisting legal professionals by encoding Italian legal articles and learning reasoning patterns from Court of Cassation decisions using ILASP. For biological laboratories, we will collaborate with a research group to automate spermatozoa morphology classification for Bull Breeding Soundness Evaluation using YOLO networks and ILP to explain classification outcomes. This hybrid approach aims to bridge the gap between the high performance of deep learning models and the transparency of symbolic reasoning, advancing AI by providing interpretable and trustworthy applications. © 2025 Open Publishing Association. All rights reserved.
KW  - Inductive logic programming (ILP)
KW  - Recurrent neural networks
KW  - Accurate prediction
KW  - AI systems
KW  - Complex data
KW  - Inductive logic
KW  - Learning models
KW  - Learning programming
KW  - Logic-programming
KW  - Modeling analyzes
KW  - Modeling process
KW  - Neural-networks
KW  - Weather forecasting
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Holmes, W.
AU  - Littlejohn, A.
TI  - Artificial intelligence for professional learning
PY  - 2024
T2  - Handbook of Artificial Intelligence at Work
SP  - 191
EP  - 211
DO  - 10.4337/9781800889972.00018
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189215855&doi=10.4337%2f9781800889972.00018&partnerID=40&md5=e5f3dd090edd113d402caf5874acffe6
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Inayathullah, S.
AU  - Buddala, R.
TI  - Review of machine learning applications in additive manufacturing
PY  - 2025
T2  - Results in Engineering
VL  - 25
C7  - 103676
DO  - 10.1016/j.rineng.2024.103676
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211600600&doi=10.1016%2fj.rineng.2024.103676&partnerID=40&md5=23fa5bc5e79dd0df59b8849a120c9243
AB  - The necessity to produce intricate components results in considerable progress in manufacturing methods. Additive manufacturing (AM) is a disruptive technology that allows intricate and custom-tailored components to be fabricated with great precision and efficiency. It is applied in advanced sectors like aerospace, healthcare, automotive industries, and it starts having their interest in many other areas. Machine learning (ML) has become a powerful tool for overcoming problems in AM, offering process efficiency, defect detection, quality assurance, and predictive modelling of mechanical properties. This review discusses how ML transforms AM by providing design evaluation, process optimization, and production control innovation. The approach taken in the study is systematic, examining the current literature and case studies of ML application to AM. Hybrid data collection techniques that combine machine settings with physics aware features and yield robust predictive models are the focus. Additionally, the review evaluates various ML algorithms used to predict mechanical properties, optimize process parameters, and characterize AM processes. The measurements indicate groundbreaking improvements in ML powered solutions, like process monitoring in real time, automatic parameter adaptation, and defect mitigation that offer greater accuracy, ease, and reliability in AM. Yet, data scarcity, computational challenges and a gap between research and industrial applications of ML exist. To realize the full potential of ML in AM it is critical to address these challenges. It closes with the identification of promising research directions including standardization of data improvement, developing new advanced ML algorithms, and building an interdisciplinary research effort to spur additional progress in this field. © 2024
KW  - 3D printing
KW  - Additive manufacturing
KW  - Artificial Intelligence
KW  - Deep learning
KW  - Defect detection
KW  - Machine learning
KW  - Process optimization
KW  - Aerospace industry
KW  - Automotive industry
KW  - Model predictive control
KW  - Smart manufacturing
KW  - 3-D printing
KW  - 3D-printing
KW  - Deep learning
KW  - Defect detection
KW  - Machine learning applications
KW  - Machine-learning
KW  - Mechanical
KW  - Predictive models
KW  - Process optimisation
KW  - Property
KW  - Quality assurance
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 18
ER  -

TY  - CONF
AU  - Leoveanu-Condrei, C.
AU  - Holzleitner, M.
AU  - Zellinger, W.
AU  - Hochreiter, S.
TI  - SYMBOLICAI: A FRAMEWORK FOR LOGIC-BASED APPROACHES COMBINING GENERATIVE MODELS AND SOLVERS
PY  - 2024
T2  - Proceedings of Machine Learning Research
VL  - 274
SP  - 869
EP  - 914
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216821458&partnerID=40&md5=fff1b4cdd6ccc0d763f67aa17ffd84f4
AB  - We introduce SymbolicAI, a versatile and modular framework employing a logic-based approach to concept learning and flow management in generative processes. SymbolicAI enables the seamless integration of generative models with a diverse range of solvers by treating large language models (LLMs) as semantic parsers that execute tasks based on both natural and formal language instructions, thus bridging the gap between symbolic reasoning and generative AI. We leverage probabilistic programming principles to tackle complex tasks, and utilize differentiable and classical programming paradigms with their respective strengths. The framework introduces a set of polymorphic, compositional, and self-referential operations for multi-modal data that connects multi-step generative processes and aligns their outputs with user objectives in complex workflows. As a result, we can transition between the capabilities of various foundation models with in-context learning capabilities and specialized, fine-tuned models or solvers proficient in addressing specific problems. Through these operations based on in-context learning our framework enables the creation and evaluation of explainable computational graphs. Finally, we introduce a quality measure and its empirical score for evaluating these computational graphs, and propose a benchmark that compares various state-of-the-art LLMs across a set of complex workflows. We refer to the empirical score as the”Vector Embedding for Relational Trajectory Evaluation through Cross-similarity”, or VERTEX score for short. The framework codebase1 and benchmark2 are linked below. © 2024 CoLLAs. All Rights Reserved.
KW  - Benchmarking
KW  - Generative adversarial networks
KW  - Graph embeddings
KW  - Natural language processing systems
KW  - Probabilistic logics
KW  - Complex workflows
KW  - Computational graph
KW  - Concept learning
KW  - Context learning
KW  - Generative model
KW  - Generative process
KW  - In contexts
KW  - Language model
KW  - Logic-based approach
KW  - Modular framework
KW  - Semantics
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Saeedi, S.
AU  - Fong, A.C.M.
AU  - Mohanty, S.P.
AU  - Gupta, A.K.
AU  - Carr, S.
TI  - Consumer Artificial Intelligence Mishaps and Mitigation Strategies
PY  - 2022
T2  - IEEE Consumer Electronics Magazine
VL  - 11
IS  - 3
SP  - 13
EP  - 24
DO  - 10.1109/MCE.2021.3075329
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105081274&doi=10.1109%2fMCE.2021.3075329&partnerID=40&md5=17e892c36c7b09a53d4d11bce723718d
AB  - Although artificial intelligence (AI) promises to deliver ever more user-friendly consumer applications, recent mishaps involving fake information and biased treatment serve as vivid reminders of the pitfalls of AI. AI can harbor latent biases and flaws that can cause harm in diverse and unexpected ways. Before AI becomes interwoven into human society, it is important to understand how and when AI can fail. This article presents a timely survey of AI-induced mishaps that relate to consumer applications. The article also offers suggestions on mitigating strategies to manage the undesirable side effects of using AI for consumer applications. It, therefore, serves a dual purpose of creating awareness of current issues and encouraging other researchers in the consumer technology community to build better AI consumer applications. © 2012 IEEE.
KW  - Artificial intelligence
KW  - Demography
KW  - Natural language processing systems
KW  - Consumer applications
KW  - Human society
KW  - Language processing
KW  - Medical services
KW  - Mitigation strategy
KW  - Natural language processing
KW  - Natural languages
KW  - Side effect
KW  - User friendly
KW  - Video
KW  - Face recognition
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 11
ER  -

TY  - JOUR
AU  - Wu, J.
TI  - Physical scene understanding
PY  - 2024
T2  - AI Magazine
VL  - 45
IS  - 1
SP  - 156
EP  - 164
DO  - 10.1002/aaai.12148
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184923920&doi=10.1002%2faaai.12148&partnerID=40&md5=ac94043dac6e214de747c59cf11c9202
AB  - Current AI systems still fail to match the flexibility, robustness, and generalizability of human intelligence: how even a young child can manipulate objects to achieve goals of their own invention or in cooperation, or can learn the essentials of a complex new task within minutes. We need AI with such embodied intelligence: transforming raw sensory inputs to rapidly build a rich understanding of the world for seeing, finding, and constructing things, achieving goals, and communicating with others. This problem of physical scene understanding is challenging because it requires a holistic interpretation of scenes, objects, and humans, including their geometry, physics, functionality, semantics, and modes of interaction, building upon studies across vision, learning, graphics, robotics, and AI. My research aims to address this problem by integrating bottom-up recognition models, deep networks, and inference algorithms with top-down structured graphical models, simulation engines, and probabilistic programs. © 2024 The Authors. AI Magazine published by John Wiley & Sons Ltd on behalf of Association for the Advancement of Artificial Intelligence.
KW  - Human robot interaction
KW  - Semantics
KW  - 'current
KW  - AI systems
KW  - Bottom up
KW  - Human intelligence
KW  - Learn+
KW  - Scene object
KW  - Scene understanding
KW  - Sensory input
KW  - Vision learning
KW  - Young children
KW  - Inference engines
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Aad, S.
AU  - Hardey, M.
TI  - Generative AI: hopes, controversies and the future of faculty roles in education
PY  - 2025
T2  - Quality Assurance in Education
VL  - 33
IS  - 2
SP  - 267
EP  - 282
DO  - 10.1108/QAE-02-2024-0043
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203178743&doi=10.1108%2fQAE-02-2024-0043&partnerID=40&md5=b8f7bbad6910a602707515492eb9d20b
AB  - Purpose: Generative artificial intelligence (GAI) has seen exponential growth in recent years due to its capability to generate original content through natural language processing and comprehensive language models. This paper aims to investigate the transformative impact of GAI on higher education, focusing on the evolving roles of faculty in the classroom. Design/methodology/approach: Using a phenomenological perspective and a process approach, the study involved 25 semi-structured interviews with academicians in higher education. Findings: The findings reveal that GAI currently creates biased and commercially driven learning environments, challenging traditional pedagogical models. Despite its potential for enhancing education, the autonomous nature of GAI often prioritizes commercial interests over pedagogical goals. Research limitations/implications: The study is limited to faculty perspectives, suggesting future research should include student viewpoints and diverse educational contexts. Practical implications: The study highlights the need for higher education institutions to develop comprehensive policies, provide training for faculty and students and design new courses that leverage GAI for personalized learning experiences and enhanced faculty research. Originality/value: This paper contributes to the emerging literature on GAI’s impact on education, highlighting its dual nature as both a transformative tool and a potential threat to traditional educational roles and outcomes. © 2024, Emerald Publishing Limited.
KW  - Ethics
KW  - Faculty role
KW  - Generative AI
KW  - Higher education
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Fei, L.
AU  - Li, T.
AU  - Ding, W.
TI  - Dempster–Shafer theory-based information fusion for natural disaster emergency management: A systematic literature review
PY  - 2024
T2  - Information Fusion
VL  - 112
C7  - 102585
DO  - 10.1016/j.inffus.2024.102585
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199206634&doi=10.1016%2fj.inffus.2024.102585&partnerID=40&md5=30ea9d883461330e366e8dd110a80137
AB  - The frequency and unpredictability of natural disasters pose serious challenges to emergency management in modern society. Effective emergency management requires not only rapid response, but also accurate assessment of the situation, rational allocation of resources and scientific decision-making. Dempster–Shafer theory (DST), as a powerful information fusion tool, has been widely used in natural disaster emergency management in recent years. This study sorted out the core related articles of DST in various directions in the field of natural disaster emergency management, and formed a systematic literature review. In order to support and guide the completion of this work, keywords were selected according to the rules of Systematic literature review (SLR) and the requirements of article content research to screen and determine the literatures. On this basis, relevant information of the selected literatures was analyzed, including authors, institutions, countries, keywords, etc. Then, according to the theoretical framework of integrated emergency management, fifteen structured research questions are put forward, involving various aspects of integrated emergency management system, and these questions are answered in detail. After that, it discussed the literature, and summarized the contribution and future development direction of DST based on information fusion in natural disaster emergency management. The final results show that in the field of natural disaster emergency management, DST plays various and important roles, among which one of the most important roles is the integration of decision-making evidence at various stages of disasters, so as to make better decisions. By combining with other methods, DST improves its limitations. And in the process to expand their scope of use. Then, it focuses on how to solve the extended theory, practical application dimension and related defects of DST in the field of natural disaster emergency management. © 2024 Elsevier B.V.
KW  - Dempster–Shafer theory
KW  - Emergency management
KW  - Information fusion
KW  - Natural disaster
KW  - Quantitative analysis
KW  - Civil defense
KW  - Decision making
KW  - Emergency services
KW  - Information management
KW  - Risk management
KW  - Decisions makings
KW  - Dempster-Shafer theory
KW  - Emergency management
KW  - Emergency management systems
KW  - Natural disasters
KW  - Rapid response
KW  - Research questions
KW  - Scientific decisions
KW  - Systematic literature review
KW  - Theoretical framework
KW  - Information fusion
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 14
ER  -

TY  - JOUR
AU  - Adhikary, A.
AU  - Munir, M.S.
AU  - Raha, A.D.
AU  - Qiao, Y.
AU  - Han, Z.
AU  - Hong, C.S.
TI  - Integrated Sensing, Localization, and Communication in Holographic MIMO-Enabled Wireless Network: A Deep Learning Approach
PY  - 2024
T2  - IEEE Transactions on Network and Service Management
VL  - 21
IS  - 1
SP  - 789
EP  - 809
DO  - 10.1109/TNSM.2023.3292269
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164421346&doi=10.1109%2fTNSM.2023.3292269&partnerID=40&md5=38d871b5a204e3c167df7b1bdcb1835a
AB  - The impending sixth-generation wireless communication networks are anticipated to guarantee mass connectivity, high integration, and lower power consumption for generating the required beamforming. To achieve these goals, an artificial intelligence (AI) framework is proposed by utilizing holographic MIMO-assisted integrated sensing, localization, and communication. The proposed AI framework ensures lower power consumption to activate the minimum number of grids from the holographic grid array for the generation of holographic beamforming. An optimization problem is formulated to maximize the signal-to-interference-plus-noise ratio received by the users, which in turn maximizes the utility function for sensing considering the user distances, beampattern gains, sensing-communication loss, and dense locations controlling parameter. A novel AI-based framework is proposed to solve the formulated NP-hard optimization problem by decomposing it into two subproblems: the sensing problem and the communication resource allocation problem. First, a variational autoencoder (VAE) based mechanism is devised to solve the sensing problem mitigating the disputes to obtain the users' exact location. Second, a sequential neural network-based scheme is utilized to allocate the communication resources to the heterogeneous users for generating the desired beamforming based on the findings of the VAE-based mechanism. Moreover, an extreme case power allocation strategy is presented once a large number of users enter the system. The extreme case power allocation strategy applies when the total power prediction exceeds the total system power for allocating the communication resources to the users. Finally, simulation results validate that the proposed AI-based framework outperforms the long short-term memory method with a cumulative power savings of 34.02% taking the ground truth power into account. Therefore, the proposed AI framework generates effective beamforming to serve the communication users.  © 2004-2012 IEEE.
KW  - and communication
KW  - artificial intelligence framework
KW  - dense location
KW  - holographic beamforming
KW  - holographic MIMO
KW  - localization
KW  - Sensing
KW  - sensing utility function
KW  - Array processing
KW  - Beam forming networks
KW  - Deep learning
KW  - Electric power utilization
KW  - Holography
KW  - Location
KW  - MIMO systems
KW  - Optimization
KW  - Problem solving
KW  - Resource allocation
KW  - Signal interference
KW  - Signal to noise ratio
KW  - Array signal processing
KW  - Artificial intelligence framework
KW  - Dense location
KW  - Holographic beamforming
KW  - Holographic MIMO
KW  - Localisation
KW  - Location awareness
KW  - Phased-arrays
KW  - Resource management
KW  - Sensing
KW  - Sensing utility function
KW  - Utility functions
KW  - Wireless communications
KW  - Beamforming
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 21
ER  -

TY  - CONF
AU  - Anisimova, A.S.
AU  - Potemkina, A.
AU  - Chervakov, P.
AU  - Komza, V.
AU  - Maksimov, D.
AU  - Panin, I.
AU  - Vaselyuk, A.
AU  - Samsonovich, A.V.
TI  - Artificial Psychologist: An intelligent virtual/robotic assistant based on a cognitive modeling framework
PY  - 2022
T2  - Procedia Computer Science
VL  - 213
IS  - C
SP  - 793
EP  - 800
DO  - 10.1016/j.procs.2022.11.136
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146116477&doi=10.1016%2fj.procs.2022.11.136&partnerID=40&md5=8a8c2698ed404ed9ce8dac6765060aee
AB  - Applications of socially emotional artificial intelligence are demanded in many practical areas, including psychological counselling and psychotherapy. A person who is potentially in trouble and needs help has to overcome an internal barrier before deciding to see a psychiatrist. On the other hand, obtaining an anonymous online consultation or taking an online test is psychologically easy and acceptable for the many. At the same time, state-of-the-art solutions of this sort are limited. Here a concept of an intelligent system is proposed that should help to alleviate the problem. The system can be implemented as an embodied actor based on a virtual environment, VR/XR, or a robotic platform with social-emotional capabilities. The actor is controlled by a cognitive architecture with a possibility of its replacement by a deep neural network model. Interaction with the user is based on a multimodal human-computer interface. Possibilities that will be provided by this virtual psychologist system will enable conducting an initial screening, the results of which can later be used at the next session with a specialist, if chosen by the user. The key issue of ethics, privacy and anonymity is discussed. Systems of this sort could be used beyond psychological counseling and are expected to have an impact on the healthcare system in general. © 2022 Elsevier B.V.. All rights reserved.
KW  - emotional intelligence
KW  - intelligent virtual agents
KW  - multimodal human-computer interface
KW  - psychological profiling
KW  - psychotherapy
KW  - Deep neural networks
KW  - Intelligent virtual agents
KW  - Cognitive model
KW  - Emotional intelligence
KW  - Internal barriers
KW  - Modelling framework
KW  - Multimodal human-computer-interfaces
KW  - Online tests
KW  - Psychological profiling
KW  - Psychotherapy
KW  - Robotic assistants
KW  - Virtual robotics
KW  - Intelligent systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Abbas, K.
AU  - Hasan, M.K.
AU  - Abbasi, A.
AU  - Mokhtar, U.A.
AU  - Khan, A.
AU  - Abdullah, S.N.H.S.
AU  - Dong, S.
AU  - Islam, S.
AU  - Alboaneen, D.
AU  - Ahmed, F.R.A.
TI  - Predicting the Future Popularity of Academic Publications Using Deep Learning by Considering It as Temporal Citation Networks
PY  - 2023
T2  - IEEE Access
VL  - 11
SP  - 83052
EP  - 83068
DO  - 10.1109/ACCESS.2023.3290906
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163443928&doi=10.1109%2fACCESS.2023.3290906&partnerID=40&md5=fd2276adb4203ae85271c257afc224f6
AB  - One of the key goals of Informetrics is to identify citation-based popular articles among so many other aspects, such as determining popular research topics, identifying influential scholars, and predicting hot trends in science. These can be achieved by applying network science approaches to scientific networks and formulating the problem as a popular (most-cited) node ranking task. To rank the papers based on their future citation gain. In this work a deep learning based framework is proposed. Which helps in automatic node level feature extraction and can make node level prediction in dynamic graphs such as citation networks. To achieve this we have learned global ranking preserve d dimensional node embedding. We have only considered temporal features, which makes it suitable for generalisation to other networks. Although our model can consider node level explicit features also. Further we have given novel cost function which can be easily solve ranking problem for dynamic graphs using probabilistic regression method. Which can be easily optimised. Another novelty of our work is that our model can be trained using different snapshots of the graph and different time. Further trained model can be used to make future prediction. The proposed model has been tested on an arXiv paper citation network using six standard information retrieval-based metrics. The results show that our proposed model outperforms, on average, other state-of-the-art static models as well as dynamic node ranking models. The outcome of this research study leads to informed data-driven decision-making in science, such as the allocation and distribution of research funds and investment in strategic research centers. When considering past time window size as 10 months and making prediction after 10 months our proposed model's performance on various ranking based evaluation metrics are as follows: AUC-0.974, Kendal's rank correlation tau-0.455, Precision- 0.643, Novelty-0.0456, Temporal novelty-0.375 and on NDCG-0.949. Our model is able to make long term trend prediction with just training on short time window.  © 2013 IEEE.
KW  - and popularity prediction
KW  - citation networks
KW  - Citation prediction
KW  - deep learning
KW  - node ranking
KW  - temporal networks
KW  - Cost functions
KW  - Decision making
KW  - Deep learning
KW  - Information retrieval
KW  - Regression analysis
KW  - Academic publications
KW  - Citation networks
KW  - Citation prediction
KW  - Deep learning
KW  - Dynamic graph
KW  - Informetrics
KW  - Node ranking
KW  - Popularity predictions
KW  - Research topics
KW  - Temporal networks
KW  - Forecasting
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 19
ER  -

TY  - JOUR
AU  - Shen, X.
AU  - Han, D.
AU  - Chang, C.-C.
AU  - Oad, A.
AU  - Wu, H.
TI  - GFSNet: Gaussian Fourier with sparse attention network for visual question answering
PY  - 2025
T2  - Artificial Intelligence Review
VL  - 58
IS  - 6
C7  - 159
DO  - 10.1007/s10462-025-11163-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000141373&doi=10.1007%2fs10462-025-11163-4&partnerID=40&md5=e309502d20c68115b759a0daa75fbbef
AB  - Visual question answering (VQA), a core task in multimodal learning, requires models to effectively integrate visual and natural language information to perform reasoning and semantic understanding in complex scenarios. However, self-attention mechanisms often struggle to capture multi-scale information and key region features within images comprehensively. Moreover, VQA involves multidimensional and deep reasoning about image content, particularly in scenarios involving spatial relationships and frequency-domain features. Existing methods face limitations in modeling multi-scale features and filtering irrelevant information effectively. This paper proposes an innovative Gaussian Fourier with Sparse Attention Network (GFSNet) to address these challenges. GFSNet leverages Fourier transforms to map image attention weights generated by the self-attention mechanism from the spatial domain to the frequency domain, enabling comprehensive modeling of multi-scale frequency information. This enhances the model’s adaptability to complex structures and its capacity for relational modeling. To further improve feature robustness, a Gaussian filter is introduced to suppress high-frequency noise in the frequency domain, preserving critical visual information. Additionally, a sparse attention mechanism dynamically selects optimized frequency-domain features, effectively reducing interference from redundant information while improving interpretability and computational efficiency. Without increasing parameter counts or computational complexity, GFSNet achieves efficient modeling of multi-scale visual information. Experimental results on benchmark VQA datasets (VQA v2, GQA, and CLEVR) demonstrate that GFSNet significantly enhances reasoning capabilities and cross-modal alignment performance, validating its superiority and effectiveness. The code is available at https://github.com/shenxiang-vqa/GFSNet. © The Author(s) 2025.
KW  - Fourier transform
KW  - Gaussian filter
KW  - Multi-scale feature modeling
KW  - Sparse attention mechanism
KW  - Visual question answering
KW  - Benchmarking
KW  - Fourier transforms
KW  - Gaussian distribution
KW  - Gaussian noise (electronic)
KW  - Image coding
KW  - Image enhancement
KW  - Information filtering
KW  - Modeling languages
KW  - Natural language processing systems
KW  - Photomapping
KW  - Semantic Segmentation
KW  - Semantics
KW  - Wiener filtering
KW  - Attention mechanisms
KW  - Feature models
KW  - Fourier
KW  - Gaussian filters
KW  - Gaussians
KW  - Multi-scale feature modeling
KW  - Multi-scale features
KW  - Question Answering
KW  - Sparse attention mechanism
KW  - Visual question answering
KW  - Question answering
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Wagg, D.J.
TI  - Modelling, Reductionism and the Implications for Digital Twins
PY  - 2025
T2  - CISM International Centre for Mechanical Sciences, Courses and Lectures
VL  - 614
SP  - 1
EP  - 57
DO  - 10.1007/978-3-031-67499-0_1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212250525&doi=10.1007%2f978-3-031-67499-0_1&partnerID=40&md5=b8cc599825471d44ae265751a0385efe
AB  - In this Chapter we will discuss modelling and reductionism in science and engineering, and how this relates to the new idea of digital twins. In particular, we focus on the historical context of modelling and reductionism for dynamics and control of engineering systems. Both active and passive control methods will be discussed, including the novel ideas associated with the inerter. Based on a selected review of the philosophy of modelling, we consider the role of knowledge and complexity in model making. The related topics of systems engineering, uncertainty analysis and artificial intelligence are also briefly discussed in the context of digital twins. We will argue that utility, trust and insight are the three key properties of models that will ideally be extended to digital twins. We then consider how digital twins will require the dynamic assembly of digital objects in order to recreate emergent behaviours. In order to implement a digital twin, an operational platform is required. We briefly present an aircraft example of a digital twin operational platform. Lastly we consider digital twin knowledge models and ontologies, and how this topic might help shape digital twins in the future. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Rahman, M.M.
AU  - Watanobe, Y.
AU  - Nakamura, K.
AU  - Bures, M.
TI  - A Neural Network Based Intelligent Support Model for Program Code Completion
PY  - 2020
T2  - Scientific Programming
VL  - 2020
C7  - 7426461
DO  - 10.1155/2020/7426461
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091922661&doi=10.1155%2f2020%2f7426461&partnerID=40&md5=2aac01094e29c7ecba5466a6fe3862b2
AB  - In recent years, millions of source codes are generated in different languages on a daily basis all over the world. A deep neural network-based intelligent support model for source code completion would be a great advantage in software engineering and programming education fields. Vast numbers of syntax, logical, and other critical errors that cannot be detected by normal compilers continue to exist in source codes, and the development of an intelligent evaluation methodology that does not rely on manual compilation has become essential. Even experienced programmers often find it necessary to analyze an entire program in order to find a single error and are thus being forced to waste valuable time debugging their source codes. With this point in mind, we proposed an intelligent model that is based on long short-term memory (LSTM) and combined it with an attention mechanism for source code completion. Thus, the proposed model can detect source code errors with locations and then predict the correct words. In addition, the proposed model can classify the source codes as to whether they are erroneous or not. We trained our proposed model using the source code and then evaluated the performance. All of the data used in our experiments were extracted from Aizu Online Judge (AOJ) system. The experimental results obtained show that the accuracy in terms of error detection and prediction of our proposed model approximately is 62% and source code classification accuracy is approximately 96% which outperformed a standard LSTM and other state-of-the-art models. Moreover, in comparison to state-of-the-art models, our proposed model achieved an interesting level of success in terms of error detection, prediction, and classification when applied to long source code sequences. Overall, these experimental results indicate the usefulness of our proposed model in software engineering and programming education arena. © 2020 Md. Mostafizer Rahman et al.
KW  - Codes (symbols)
KW  - Computer programming languages
KW  - Deep neural networks
KW  - Error detection
KW  - Forecasting
KW  - Network coding
KW  - Program debugging
KW  - Software engineering
KW  - Attention mechanisms
KW  - Intelligent evaluation
KW  - Intelligent modeling
KW  - Intelligent support
KW  - Online judges
KW  - Program code
KW  - Programming education
KW  - State of the art
KW  - Long short-term memory
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 31
ER  -

TY  - JOUR
AU  - Wang, W.
AU  - Zhang, Y.
AU  - Sui, Y.
AU  - Wan, Y.
AU  - Zhao, Z.
AU  - Wu, J.
AU  - Yu, P.S.
AU  - Xu, G.
TI  - Reinforcement-Learning-Guided Source Code Summarization Using Hierarchical Attention
PY  - 2022
T2  - IEEE Transactions on Software Engineering
VL  - 48
IS  - 1
SP  - 102
EP  - 119
DO  - 10.1109/TSE.2020.2979701
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123167506&doi=10.1109%2fTSE.2020.2979701&partnerID=40&md5=254d699acf5c86d4fcbd7b7444dcd570
AB  - Code summarization (aka comment generation) provides a high-level natural language description of the function performed by code, which can benefit the software maintenance, code categorization and retrieval. To the best of our knowledge, the state-of-the-art approaches follow an encoder-decoder framework which encodes source code into a hidden space and later decodes it into a natural language space. Such approaches suffer from the following drawbacks: (a) they are mainly input by representing code as a sequence of tokens while ignoring code hierarchy; (b) most of the encoders only input simple features (e.g., tokens) while ignoring the features that can help capture the correlations between comments and code; (c) the decoders are typically trained to predict subsequent words by maximizing the likelihood of subsequent ground truth words, while in real world, they are excepted to generate the entire word sequence from scratch. As a result, such drawbacks lead to inferior and inconsistent comment generation accuracy. To address the above limitations, this paper presents a new code summarization approach using hierarchical attention network by incorporating multiple code features, including type-augmented abstract syntax trees and program control flows. Such features, along with plain code sequences, are injected into a deep reinforcement learning (DRL) framework (e.g., actor-critic network) for comment generation. Our approach assigns weights (pays 'attention') to tokens and statements when constructing the code representation to reflect the hierarchical code structure under different contexts regarding code features (e.g., control flows and abstract syntax trees). Our reinforcement learning mechanism further strengthens the prediction results through the actor network and the critic network, where the actor network provides the confidence of predicting subsequent words based on the current state, and the critic network computes the reward values of all the possible extensions of the current state to provide global guidance for explorations. Eventually, we employ an advantage reward to train both networks and conduct a set of experiments on a real-world dataset. The experimental results demonstrate that our approach outperforms the baselines by around 22 to 45 percent in BLEU-1 and outperforms the state-of-the-art approaches by around 5 to 60 percent in terms of S-BLEU and C-BLEU. © 1976-2012 IEEE.
KW  - Code summarization
KW  - hierarchical attention
KW  - reinforcement learning
KW  - C (programming language)
KW  - Decoding
KW  - Forecasting
KW  - Reinforcement learning
KW  - Signal encoding
KW  - Syntactics
KW  - Trees (mathematics)
KW  - 'current
KW  - Abstract Syntax Trees
KW  - Actor-network
KW  - Code summarization
KW  - Control-flow
KW  - Critic network
KW  - Hierarchical attention
KW  - Natural languages
KW  - Source codes
KW  - State-of-the-art approach
KW  - Deep learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 64
ER  -

TY  - JOUR
AU  - Bhattacharyya, A.
AU  - Chatterjee, S.
AU  - Sen, S.
AU  - Sinitca, A.
AU  - Kaplun, D.
AU  - Sarkar, R.
TI  - A deep learning model for classifying human facial expressions from infrared thermal images
PY  - 2021
T2  - Scientific Reports
VL  - 11
IS  - 1
C7  - 20696
DO  - 10.1038/s41598-021-99998-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117714075&doi=10.1038%2fs41598-021-99998-z&partnerID=40&md5=8e57ff8148683cbf8f97ca417312e9f4
AB  - The analysis of human facial expressions from the thermal images captured by the Infrared Thermal Imaging (IRTI) cameras has recently gained importance compared to images captured by the standard cameras using light having a wavelength in the visible spectrum. It is because infrared cameras work well in low-light conditions and also infrared spectrum captures thermal distribution that is very useful for building systems like Robot interaction systems, quantifying the cognitive responses from facial expressions, disease control, etc. In this paper, a deep learning model called IRFacExNet (InfraRed Facial Expression Network) has been proposed for facial expression recognition (FER) from infrared images. It utilizes two building blocks namely Residual unit and Transformation unit which extract dominant features from the input images specific to the expressions. The extracted features help to detect the emotion of the subjects in consideration accurately. The Snapshot ensemble technique is adopted with a Cosine annealing learning rate scheduler to improve the overall performance. The performance of the proposed model has been evaluated on a publicly available dataset, namely IRDatabase developed by RWTH Aachen University. The facial expressions present in the dataset are Fear, Anger, Contempt, Disgust, Happy, Neutral, Sad, and Surprise. The proposed model produces 88.43% recognition accuracy, better than some state-of-the-art methods considered here for comparison. Our model provides a robust framework for the detection of accurate expression in the absence of visible light. © 2021, The Author(s).
KW  - Cognition
KW  - Deep Learning
KW  - Emotions
KW  - Facial Expression
KW  - Facial Recognition
KW  - Female
KW  - Humans
KW  - Spectrophotometry, Infrared
KW  - cognition
KW  - emotion
KW  - facial expression
KW  - facial recognition
KW  - female
KW  - human
KW  - infrared spectrophotometry
KW  - physiology
KW  - procedures
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 42
ER  -

TY  - CONF
AU  - D'Ambrosio, G.
AU  - Vinco, D.D.
TI  - The Metaverse through the Eyes of University Students
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3574
SP  - 73
EP  - 82
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179620088&partnerID=40&md5=2b6fe721f66185155baf8c7552654f07
AB  - The Metaverse is perceived as a promising approach that can possibly transform HCI guaranteeing high engagement and promoting participation and cooperation even at a distance. Its adoption is increasing in the last few years, with different areas and domains starting to use it and exploring if the Metaverse can be beneficial for them. This article explores university students' opinions regarding contexts and applications that can take advantage of the Metaverse and which benefits can be achieved. According to the results, students are aligned with the literature, considering the Metaverse useful in many application contexts thanks to its immersiveness and engaging environment promoting high-quality collaboration. However, their optimistic point of view should be mitigated by making them aware of the challenges the Metaverse poses in terms of (economic) sustainability and security concerns. © 2023 CEUR-WS. All rights reserved.
KW  - advantages
KW  - application
KW  - challenges
KW  - context
KW  - Metaverse
KW  - student
KW  - survey
KW  - university
KW  - Sustainable development
KW  - Advantage
KW  - Application contexts
KW  - Challenge
KW  - Context
KW  - High quality
KW  - Immersiveness
KW  - Metaverses
KW  - Optimistics
KW  - University
KW  - University students
KW  - Students
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Shyalika, C.
AU  - Wickramarachchi, R.
AU  - Sheth, A.P.
TI  - A Comprehensive Survey on Rare Event Prediction
PY  - 2024
T2  - ACM Computing Surveys
VL  - 57
IS  - 3
C7  - 70
DO  - 10.1145/3699955
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211331723&doi=10.1145%2f3699955&partnerID=40&md5=67e16671d21b01122ca4fd327800023a
AB  - Rare event prediction involves identifying and forecasting events with a low probability using machine learning (ML) and data analysis. Due to the imbalanced data distributions, where the frequency of common events vastly outweighs that of rare events, it requires using specialized methods within each step of the ML pipeline, that is, from data processing to algorithms to evaluation protocols. Predicting the occurrences of rare events is important for real-world applications, such as Industry 4.0, and is an active research area in statistical and ML. This article comprehensively reviews the current approaches for rare event prediction along four dimensions: rare event data, data processing, algorithmic approaches, and evaluation approaches. Specifically, we consider 73 datasets from different modalities (i.e., numerical, image, text, and audio), four major categories of data processing, five major algorithmic groupings, and two broader evaluation approaches. This article aims to identify gaps in the current literature and highlight the challenges of predicting rare events. It also suggests potential research directions, which can help guide practitioners and researchers. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
KW  - anomaly prediction
KW  - Event-prediction
KW  - forecasting
KW  - rare-events
KW  - time-series
KW  - 'current
KW  - Anomaly predictions
KW  - Evaluation approach
KW  - Event prediction
KW  - Imbalanced data
KW  - Lower probabilities
KW  - Machine data
KW  - Machine-learning
KW  - Rare-event
KW  - Times series
KW  - Prediction models
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Thorisson, K.R.
TI  - IWSSL: Introduction to This Volume
PY  - 2022
T2  - Proceedings of Machine Learning Research
VL  - 192
SP  - 1
EP  - 4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171445913&partnerID=40&md5=e4020dc6f3409064227a87b1102659eb
M3  - Editorial
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Wahid, A.
AU  - Yahya, M.
AU  - Zaman, F.
AU  - Zhou, B.
AU  - Breslin, J.G.
AU  - Intizar, M.A.
AU  - Kharlamov, E.
TI  - Integrating I4.0 Knowledge Graphs with Large Language Models Beyond SPARQL Endpoints
PY  - 2024
T2  - CEUR Workshop Proceedings
VL  - 3830
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210885367&partnerID=40&md5=84f44fce68aee092a8964af6520465d5
AB  - Industry 4.0 (I4.0) knowledge graphs are a common way to represent industrial information models. Conventional SPARQL querying systems require the users to be familiar with the data schema and SPARQL syntax. However, this is often very difficult for many users in industrial production, who have mostly an engineering background, instead of a semantic web. Recent developments in large language models (LLMs) make it possible for non-semantic experts to use natural language to query knowledge graphs (KG). In this work, we present a framework and preliminary results of integrating Industry 4.0 KGs with LLMs to improve how data is represented, reasoned, and processed in manufacturing contexts, facilitating user interaction with KGs and contributing to operational efficiency. Our technique enhances Language Models (LLMs) by utilising the semantic complexity and interdependence of Knowledge Graphs (KGs). This allows us to incorporate domain-specific knowledge. We used the FAISS library and LLaMA2 to optimise the storage and retrieval of vectors, which improved the system’s performance and scalability. This integration allows for advanced fault detection, proactive maintenance, and process optimisation, resulting in decreased periods of inactivity and improved productivity. We introduce the framework’s architecture, implementation strategy, and possible advantages while also discussing the difficulties associated with data integration and scalability. The results of our study show that the integration of KG-LLM surpasses traditional approaches in terms of operational efficiency, as evidenced by enhanced fault detection, proactive maintenance, and process optimisation, thereby opening up possibilities for the advancement of more intelligent and resilient production systems. © 2022 Copyright for this paper by its authors.
KW  - Deep Learning
KW  - Knowledge Graphs
KW  - Large Language Model (LLM)
KW  - LLaMa
KW  - SPARQL
KW  - Query languages
KW  - Scalability
KW  - Semantics
KW  - Structured Query Language
KW  - Deep learning
KW  - Faults detection
KW  - Knowledge graphs
KW  - Language model
KW  - Large language model
KW  - LLaMa
KW  - Operational efficiencies
KW  - Proactive maintenance
KW  - Proactive process
KW  - SPARQL
KW  - Knowledge graph
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Biswas, S.
AU  - Chaudhuri, K.D.
AU  - Mitra, P.
AU  - Rao, K.S.
TI  - Relation Predictions in Comorbid Disease Centric Knowledge Graph Using Heterogeneous GNN Models
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 13920 LNBI
SP  - 343
EP  - 356
DO  - 10.1007/978-3-031-34960-7_24
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165068895&doi=10.1007%2f978-3-031-34960-7_24&partnerID=40&md5=78fff5a00586e386fc1bb101af21d7e4
AB  - Disease comorbidity has been an important topic of research for the last decade. This topic has become more popular due to the recent outbreak of COVID-19 disease. A comorbid condition due to multiple concurrent diseases is more fatal than a single disease. These comorbid conditions can be caused due to different genetic as well as drug-related side effects on an individual. There are already successful methods for predicting comorbid disease associations. This disease-associated genetic or drug-invasive information can help infer more target factors that cause common diseases. This may further help find out effective drugs for treating a pair of concurrent diseases. In addition to that, the common drug side-effects causing a disease phenotype and the gene associated with that can be helpful in finding important biomarkers for further prognosis of the comorbid disease. In this paper, we use the knowledge graph (KG) from our previous study to find out target-specific relations apart from sole disease-disease associations. We use four different heterogeneous graph neural network models to perform link prediction among different entities in the knowledge graph and we perform a comparative analysis among them. It is found that our best heterogeneous GNN model outperforms existing state-of-the-art models on a few target-specific relationships. Further, we also predict a few novel drug-disease, drug-phenotype, disease-phenotype, and gene-phenotype associations. These interrelated associations are further used to find out the common phenotypes associated with a comorbid disease as well as caused by the direct side effects of a treating drug. In this regard, our methodology also predicts some novel biomarkers and therapeutics for different fatal prevalent diseases. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Disease comorbidity
KW  - graph neural network
KW  - knowledge graph
KW  - Biomarkers
KW  - Diagnosis
KW  - Drug interactions
KW  - Forecasting
KW  - Genes
KW  - Graph neural networks
KW  - Co-morbid conditions
KW  - Common disease
KW  - Comorbidities
KW  - Disease associations
KW  - Disease comorbidity
KW  - Disease phenotypes
KW  - Drug side-effects
KW  - Graph neural networks
KW  - Knowledge graphs
KW  - Side effect
KW  - Knowledge graph
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Kaliardos, W.N.
TI  - Enough Fluff: Returning to Meaningful Perspectives on Automation
PY  - 2022
T2  - AIAA/IEEE Digital Avionics Systems Conference - Proceedings
VL  - 2022-September
DO  - 10.1109/DASC55683.2022.9925804
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141938497&doi=10.1109%2fDASC55683.2022.9925804&partnerID=40&md5=540fdde197e69bdc5b4c4b8591b47f2b
AB  - As society progresses towards increased automation in aviation - such as with Advanced Air Mobility and Unmanned Aircraft Systems - it is important to have a common understanding and perspective about automation among the many stakeholders, including aviation system designers, operators, maintainers, and regulatory authorities. Unfortunately, the discourse is hindered by misleading perspectives, assumptions, claims, and terminology.There are many examples. The term "automation"can be simply defined, but it is often confounded with "autonomous"and other descriptions of the function being automated, and further confounded by our subjective opinions on which functions are considered "advanced"or "intelligent". Automation is often discussed not as a tool that can be leveraged to achieve goals of the aviation community, but rather as a technocentric goal in itself. We often refer to automation as "an AI"(artificial intelligence) or a "team member", or other ways in which we anthropomorphize machines, yet do not clearly define functions for automated components of these desired systems. We argue that humans are prone to errors and that more automation therefore means fewer errors, without a fair balance that considers humans as valuable functional elements. We talk about operator trust as if the idea is unique to AI, when in fact the basic principles for human-automation interaction have not changed. We try to treat automation as a one-dimensional variable, such as with automation levels, but this hides important detail and has limited value in applications such as design, operations, and approvals of complex human-automation systems.This paper identifies issues in recent automation and human-automation discourse, and provides clarifications and recommendations to improve progress towards the integration of increased automation in aviation systems. © 2022 IEEE.
KW  - artificial intelligence
KW  - automation
KW  - autonomy
KW  - function allocation
KW  - HAT
KW  - HCI
KW  - HMI
KW  - HSI
KW  - human error
KW  - human-automation
KW  - human-computer
KW  - human-machine
KW  - intelligent
KW  - levels of automation
KW  - machine learning
KW  - neurosymbolic
KW  - teaming
KW  - teams
KW  - Errors
KW  - Human computer interaction
KW  - Machine learning
KW  - Man machine systems
KW  - Unmanned aerial vehicles (UAV)
KW  - Autonomy
KW  - Function allocations
KW  - HAT
KW  - HMI
KW  - HSI
KW  - Human errors
KW  - Human-automation
KW  - Human-computer
KW  - Human-machine
KW  - Intelligent
KW  - Levels of automation
KW  - Machine-learning
KW  - Neurosymbolic
KW  - Team
KW  - Teaming
KW  - Automation
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CHAP
AU  - Papadimitriou, F.
TI  - Spatial Artificial Intelligence
PY  - 2025
T2  - SpringerBriefs in Applied Sciences and Technology
VL  - Part F66
SP  - 1
EP  - 98
DO  - 10.1007/978-3-031-82136-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000487709&doi=10.1007%2f978-3-031-82136-3&partnerID=40&md5=96280a04f2be52f7e5f60e10029ddf1a
AB  - This is the first book that focuses on the full range of spatial aspects of Artificial Intelligence. Spatial AI is defined here as - AI that is generated from spatial data, or - AI that is used for spatial analysis and spatial problem-solving, or - AI that is embedded in spatial (physical and/or digital) domains. The reader is presented with a comprehensive exploration of the rise of Spatial AI in the last decades, its applications in spatial analysis and its relationships with GeoAI, Evolutionary AI and Spatial Computing. With chapters addressing the spatial aspects of AI in the context of GenAI, AR, robotics, digital twins etc, it is a valuable resource for those who seek to explore the immense potential of Spatial AI, its possible limitations in terms of energy and computability, as well as its future prospects towards spatially-enabled AGI and Artificial Super-Intelligence. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
KW  - Artificial General Intelligence
KW  - Artificial Superintelligence
KW  - Complexity
KW  - Computability
KW  - Evolutionary AI
KW  - Generative AI
KW  - Geography
KW  - Geospatial AI
KW  - Maps
KW  - Spatial AI
KW  - Spatial Artificial Intelligence
KW  - Spatial Computing
KW  - Artificial general intelligences
KW  - Artificial superintelligence
KW  - Complexity
KW  - Computability
KW  - Evolutionary AI
KW  - Generative AI
KW  - Geo-spatial
KW  - Geography
KW  - Geospatial AI
KW  - Spatial AI
KW  - Spatial artificial intelligence
KW  - Spatial computing
KW  - Superintelligence
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Choi, S.W.
AU  - Li, Y.
AU  - Yang, X.
AU  - Yamaguchi, T.
AU  - Hoxha, B.
AU  - Fainekos, G.
AU  - Prokhorov, D.
AU  - Tran, H.-D.
TI  - Reachability analysis of recurrent neural networks
PY  - 2025
T2  - Nonlinear Analysis: Hybrid Systems
VL  - 56
C7  - 101581
DO  - 10.1016/j.nahs.2025.101581
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218277553&doi=10.1016%2fj.nahs.2025.101581&partnerID=40&md5=18ec6921645be7c9502a479330f9488f
AB  - The paper proposes a new sparse star set representation and extends the recent star reachability method to verify the robustness of vanilla, long short-term memory (LSTM), and gated recurrent units (GRU) recurrent neural networks (RNNs) for safety-critical applications. RNNs are a popular machine learning method for various applications, but they are vulnerable to adversarial attacks, where slightly perturbing the input sequence can lead to an unexpected result. Recent notable techniques for verifying RNNs include unrolling and invariant inference approaches. The first method has scaling issues since unrolling an RNN creates a large feedforward neural network. The second method, using invariant sets, has better scalability but can produce unknown results due to the accumulation of over-approximation errors over time. This paper introduces a complementary verification method for RNNs that is both sound and complete. A relaxation parameter can be used to convert the method into a fast over-approximation method that still provides soundness guarantees. The vanilla RNN verification method is designed to be used with NNV, a tool for verifying deep neural networks and learning-enabled cyber–physical systems, while the verification approach of LSTM and GRU RNNs are implemented on StarV. Compared to state-of-the-art methods for verifying a vanilla RNN, the extended exact reachability method is 10× faster, and the over-approximation method is 100× to 5000× faster. Although the sparse star set is slow compared to state-of-the-art methods, it was able to verify more robust cases in general than them. © 2025 Elsevier Ltd
KW  - GRU
KW  - LSTM
KW  - Reachability analysis
KW  - Recurrent neural networks
KW  - Verification
KW  - Deep neural networks
KW  - Feedforward neural networks
KW  - Generative adversarial networks
KW  - Long short-term memory
KW  - Gated recurrent unit
KW  - Neural-networks
KW  - Over-approximation method
KW  - Reachability
KW  - Reachability analysis
KW  - Safety critical applications
KW  - Set representation
KW  - Short term memory
KW  - State-of-the-art methods
KW  - Verification method
KW  - Stars
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Yu, W.
AU  - Li, C.
AU  - Hu, X.
AU  - Zhu, W.
AU  - Cambria, E.
AU  - Jiang, D.
TI  - Dialogue emotion model based on local–global context encoder and commonsense knowledge fusion attention
PY  - 2024
T2  - International Journal of Machine Learning and Cybernetics
VL  - 15
IS  - 7
SP  - 2811
EP  - 2825
DO  - 10.1007/s13042-023-02066-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181871478&doi=10.1007%2fs13042-023-02066-3&partnerID=40&md5=da95fcdc46a859c59c4c0b5a9f406f23
AB  - Emotion Recognition in Conversation (ERC) is a task aimed at predicting the emotions conveyed by an utterance in a dialogue. It is common in ERC research to integrate intra-utterance, local contextual, and global contextual information to obtain the utterance vectors. However, there exist complex semantic dependencies among these factors, and failing to model these dependencies accurately can adversely affect the effectiveness of emotion recognition. Moreover, to enhance the semantic dependencies within the context, researchers commonly introduce external commonsense knowledge after modeling it. However, injecting commonsense knowledge into the model simply without considering its potential impact can introduce unexpected noise. To address these issues, we propose a dialogue emotion model based on local–global context encoder and commonsense knowledge fusion attention. The local–global context encoder effectively integrates the information of intra-utterance, local context, and global context to capture the semantic dependencies among them. To provide more accurate external commonsense information, we present a fusion module to filter the commonsense information through multi-head attention. Our proposed method has achieved competitive results on four datasets and exhibits advantages compared with mainstream models using commonsense knowledge. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.
KW  - Commonsense knowledge
KW  - Emotion recognition in conversation
KW  - Local–global encoder
KW  - Multihead attention
KW  - Semantics
KW  - Signal encoding
KW  - Speech recognition
KW  - Commonsense knowledge
KW  - Emotion models
KW  - Emotion recognition
KW  - Emotion recognition in conversation
KW  - Global context
KW  - Local–global encoder
KW  - Model-based OPC
KW  - Multihead
KW  - Multihead attention
KW  - Semantic dependency
KW  - Emotion Recognition
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - CHAP
AU  - Hutson, J.
AU  - Plate, D.
TI  - Disrupting algorithmic culture: Redefining the human(ities)
PY  - 2023
T2  - Generative AI in Teaching and Learning
SP  - 1
EP  - 30
DO  - 10.4018/979-8-3693-0074-9.ch001
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182303683&doi=10.4018%2f979-8-3693-0074-9.ch001&partnerID=40&md5=809ba4db612adf23d9bae84f0072edb5
AB  - Academia must reevaluate its model in the face of AI and ML. Disciplinary boundaries are outdated, requiring interdisciplinary research and collaboration to understand algorithms and ML. Institutions should integrate new technologies while recognizing the importance of human oversight and collaboration in the human-AI partnership. The "human-in-the-loop" model enables new knowledge creation. Human fact-checking and critical evaluation are vital due to AI limitations. Empathy builds trust between humans and AI, ensuring alignment with human values. The illogical, irrational, and emotional aspects of human cognition drive creativity. Through interdisciplinary collaboration, human oversight, empathy, and leveraging unique human qualities, academia can navigate technological advancements and foster a symbiotic relationship with AI. © 2024, IGI Global.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Franciscatto, M.H.
AU  - Erpen de Bona, L.C.
AU  - Trois, C.
AU  - Didonet Del FabroFabro, M.
AU  - Damasceno Lima, J.C.
TI  - Situational Data Integration in Question Answering systems: a survey over two decades
PY  - 2024
T2  - Knowledge and Information Systems
VL  - 66
IS  - 10
SP  - 5875
EP  - 5918
DO  - 10.1007/s10115-024-02136-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196262950&doi=10.1007%2fs10115-024-02136-0&partnerID=40&md5=10882e30ff13d0db4f2ea9af7db0d6d4
AB  - Question Answering (QA) systems provide accurate answers to questions; however, they lack the ability to consolidate data from multiple sources, making it difficult to manage complex questions that could be answered with additional data retrieved and integrated on the fly. This integration is inherent to Situational Data Integration (SDI) approaches that deal with dynamic requirements of ad hoc queries that neither traditional database management systems, nor search engines are effective in providing an answer. Thus, if QA systems include SDI characteristics, they could be able to return validated and immediate information for supporting users decisions. For this reason, we surveyed QA-based systems, assessing their capabilities to support SDI features, i.e., Ad hoc Data Retrieval, Data Management, and Timely Decision Support. We also identified patterns concerning these features in the surveyed studies, highlighting them in a timeline that shows the SDI evolution in the QA domain. To the best of your knowledge, this study is precursor in the joint analysis of SDI and QA, showing a combination that can favor the way systems support users. Our analyses show that most of SDI features are rarely addressed in QA systems, and based on that, we discuss directions for further research. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.
KW  - Data integration
KW  - Decision support
KW  - Information Retrieval
KW  - Question Answering
KW  - Situational data
KW  - Source Discovery
KW  - Decision support systems
KW  - Information management
KW  - Information retrieval
KW  - Query languages
KW  - Query processing
KW  - Search engines
KW  - Additional datum
KW  - Complex questions
KW  - Decision supports
KW  - Integration approach
KW  - Multiple source
KW  - On-the-fly
KW  - Question Answering
KW  - Question answering systems
KW  - Situational data
KW  - Source discovery
KW  - Data integration
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Loevenich, J.
AU  - Adler, E.
AU  - Hürten, T.
AU  - Lopes, R.R.F.
TI  - Design and evaluation of an Autonomous Cyber Defence agent using DRL and an augmented LLM
PY  - 2025
T2  - Computer Networks
VL  - 262
C7  - 111162
DO  - 10.1016/j.comnet.2025.111162
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000141585&doi=10.1016%2fj.comnet.2025.111162&partnerID=40&md5=4458aa65c961a6dde15490b6f9f98474
AB  - In this paper, we design and evaluate an Autonomous Cyber Defence (ACD) agent to monitor and act within critical network segments connected to untrusted infrastructure hosting active adversaries. We assume that modern network segments use software-defined controllers with the means to host ACD agents and other cybersecurity tools that implement hybrid AI models. Our agent uses a hybrid AI architecture that integrates deep reinforcement learning (DRL), augmented Large Language Models (LLMs), and rule-based systems. This architecture can be implemented in software-defined network controllers, enabling automated defensive actions such as monitoring, analysis, decoy deployment, service removal, and recovery. A core contribution of our work is the construction of three cybersecurity knowledge graphs that organise and map data from network logs, open source Cyber Threat Intelligence (CTI) reports, and vulnerability frameworks. These graphs enable automatic mapping of Common Vulnerabilities and Exposures (CVEs) to offensive tactics and techniques defined in the MITRE ATT&CK framework using Bidirectional Encoder Representations from Transformers (BERT) and Generative Pre-trained Transformer (GPT) models. Our experimental evaluation of the knowledge graphs shows that BERT-based models perform better, with precision (83.02%), recall (75.92%), and macro F1 scores (58.70%) significantly outperforming GPT models. The ACD agent was evaluated in a Cyber Operations Research (ACO) gym against eleven DRL models, including Proximal Policy Optimisation (PPO), Hierarchical PPO, and ensembles under two different attacker strategies. The results show that our ACD agent outperformed baseline implementations, with its DRL models effectively mitigating attacks and recovering compromised systems. In addition, we implemented and evaluated a chatbot using Retrieval-Augmented Generation (RAG) and a prompting agent augmented with the CTI reports represented in the cybersecurity knowledge graphs. The chatbot achieved high scores on generation metrics such as relevance (0.85), faithfulness (0.83), and semantic similarity (0.88), as well as retrieval metrics such as contextual precision (0.91). The experimental results suggest that the integration of hybrid AI systems with knowledge graphs can enable the automation and improve the precision of cyber defence operations, and also provide a robust interface for cybersecurity experts to interpret and respond to advanced cybersecurity threats. © 2025
KW  - Autonomous Cyber Defence
KW  - Autonomous Cyber Operation Gym
KW  - Cybersecurity Knowledge Graph
KW  - Deep Reinforcement Learning
KW  - Hybrid AI Approach
KW  - Large Language Model
KW  - Performance Comparison
KW  - Proximal Policy Optimization
KW  - Retrieval-Augmented Generation
KW  - Autonomous agents
KW  - Chatbots
KW  - Conformal mapping
KW  - Critical infrastructures
KW  - Cyber attacks
KW  - Decision trees
KW  - Deep learning
KW  - Deep reinforcement learning
KW  - Emotional intelligence
KW  - Fuzzy logic
KW  - Hierarchical systems
KW  - Open source software
KW  - Photomapping
KW  - Problem oriented languages
KW  - Reinforcement learning
KW  - Resource allocation
KW  - Autonomous cybe defense
KW  - Autonomous cybe operation gym
KW  - Cyber operations
KW  - Cyber security
KW  - Cyber-defense
KW  - Cybersecurity knowledge graph
KW  - Hybrid AI approach
KW  - Knowledge graphs
KW  - Language model
KW  - Large language model
KW  - Performance comparison
KW  - Policy optimization
KW  - Proximal policy optimization
KW  - Reinforcement learnings
KW  - Retrieval-augmented generation
KW  - Knowledge graph
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Pérez-Pons, M.E.
AU  - Parra-Dominguez, J.
AU  - Hernández, G.
AU  - Bichindaritz, I.
AU  - Corchado, J.M.
TI  - OCI-CBR: A hybrid model for decision support in preference-aware investment scenarios
PY  - 2023
T2  - Expert Systems with Applications
VL  - 211
C7  - 118568
DO  - 10.1016/j.eswa.2022.118568
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137162939&doi=10.1016%2fj.eswa.2022.118568&partnerID=40&md5=5ffa4277d74e292c2e87ed017c29becc
AB  - This article proposes an adaptable hybrid model for recommending effective investments in different scenarios. Currently, a wide variety of methodologies are used for company valuation, especially those that take into account financial statements. However, for private held companies, there is no method that would be capable of predicting, with full certainty, the future success of an investment. The Optimal Capital Investment Case-Base Reasoning (OCI-CBR) consists of a case-based reasoning system that uses a classification algorithm to prune the case base according to a projected increase in certain company attributes. Once the cases have been pruned and the case is fed with the most profitable investment opportunities, the case-based reasoning system recommends optimal investments to potential investors. The complete model is conceived as an intelligent hybrid model that optimizes the case base by employing different algorithms for data retrieval and reuse. The system makes recommendations based on the investor's preferences and the investment decisions of other investors with similar profiles or interests. © 2022 The Author(s)
KW  - Capital investment
KW  - Case-base reasoning
KW  - Hybrid models
KW  - Machine learning
KW  - Recommender systems
KW  - Case based reasoning
KW  - Decision support systems
KW  - Machine learning
KW  - Recommender systems
KW  - Capital investment
KW  - Case base
KW  - Case-base reasonings
KW  - Case-based reasoning systems
KW  - Classification algorithm
KW  - Decision supports
KW  - Financial statements
KW  - Hybrid model
KW  - Investment opportunities
KW  - Machine-learning
KW  - Investments
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Kazienko, P.
AU  - Bielaniewicz, J.
AU  - Gruza, M.
AU  - Kanclerz, K.
AU  - Karanowski, K.
AU  - Miłkowski, P.
AU  - Kocoń, J.
TI  - Human-centered neural reasoning for subjective content processing: Hate speech, emotions, and humor
PY  - 2023
T2  - Information Fusion
VL  - 94
SP  - 43
EP  - 65
DO  - 10.1016/j.inffus.2023.01.010
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147249322&doi=10.1016%2fj.inffus.2023.01.010&partnerID=40&md5=da7384f847b03f686a9f5ce54e7b9b09
AB  - Some tasks in content processing, e.g., natural language processing (NLP), like hate or offensive speech and emotional or funny text detection, are subjective by nature. Each human may perceive some content individually. The existing reasoning methods commonly rely on agreed output values, the same for all recipients. We propose fundamentally different — personalized solutions applicable to any subjective NLP task. Our five new deep learning models take into account not only the textual content but also the opinions and beliefs of a given person. They differ in their approaches to learning Human Bias (HuBi) and fusion with content (text) representation. The experiments were carried out on 14 tasks related to offensive, emotional, and humorous texts. Our personalized HuBi methods radically outperformed the generalized ones for all NLP problems. Personalization also has a greater impact on reasoning quality than commonly explored pre-trained and fine-tuned language models. We discovered a high correlation between human bias calculated using our dedicated formula and that learned by the model. Multi-task solutions achieved better outcomes than single-task architectures. Human and word embeddings also provided additional insights. © 2023
KW  - Content perception
KW  - Emotion recognition
KW  - Hate speech
KW  - Human bias
KW  - Humor detection
KW  - Information fusion
KW  - Learning human representations
KW  - NLP
KW  - Offensive content
KW  - Personalized NLP
KW  - Subjective NLP tasks
KW  - Text classification
KW  - Behavioral research
KW  - Classification (of information)
KW  - Emotion Recognition
KW  - Speech recognition
KW  - Content perception
KW  - Emotion recognition
KW  - Hate speech
KW  - Human bias
KW  - Humor detection
KW  - Language processing
KW  - Learning human representation
KW  - Natural language processing
KW  - Natural languages
KW  - Offensive content
KW  - Personalized natural language processing
KW  - Subjective natural language processing task
KW  - Text classification
KW  - Deep learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 27
ER  -

TY  - CONF
AU  - An, Z.
AU  - Wang, X.
AU  - T. Johnson, T.
AU  - Sprinkle, J.
AU  - Ma, M.
TI  - Runtime Monitoring of Accidents in Driving Recordings with Multi-type Logic in Empirical Models
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14245 LNCS
SP  - 376
EP  - 388
DO  - 10.1007/978-3-031-44267-4_21
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174630274&doi=10.1007%2f978-3-031-44267-4_21&partnerID=40&md5=6a9ad463db8549ea4ec0ade7d70804a2
AB  - Video capturing devices with limited storage capacity have become increasingly common in recent years. As a result, there is a growing demand for techniques that can effectively analyze and understand these videos. While existing approaches based on data-driven methods have shown promise, they are often constrained by the availability of training data. In this paper, we focus on dashboard camera videos and propose a novel technique for recognizing important events, detecting traffic accidents, and trimming accident video evidence based on anomaly detection results. By leveraging meaningful high-level time-series abstraction and logical reasoning methods with state-of-the-art data-driven techniques, we aim to pinpoint critical evidence of traffic accidents in driving videos captured under various traffic conditions with promising accuracy, continuity, and integrity. Our approach highlights the importance of utilizing a formal system of logic specifications to deduce the relational features extracted from a sequence of video frames and meets the practical limitations of real-time deployment. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Logic Specifications for Images and Videos
KW  - Runtime Assurance
KW  - Systems with Learning-Enabled Components
KW  - Accidents
KW  - Anomaly detection
KW  - Computer circuits
KW  - Specifications
KW  - Empirical model
KW  - Limited storage
KW  - Logic specification for image and video
KW  - Logic specifications
KW  - Runtime assurance
KW  - Runtime Monitoring
KW  - Runtimes
KW  - Storage capacity
KW  - System with learning-enabled component
KW  - Video capturing
KW  - Digital storage
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 9
ER  -

TY  - CHAP
AU  - Hai-Jew, S.
TI  - Professionally ethical ways to harness an art-making generative AI to support innovative instructional design work
PY  - 2023
T2  - Generative AI in Teaching and Learning
SP  - 239
EP  - 273
DO  - 10.4018/979-8-3693-0074-9.ch010
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182293225&doi=10.4018%2f979-8-3693-0074-9.ch010&partnerID=40&md5=372dcbebdfab4d5df271834a3943b541
AB  - Instructional designers often pride themselves on using the most cutting-edge commercial authoring and other tools available to achieve their work. Their creations have to meet high technical standards in order to function in a digital environment, in learning management systems, content management systems, on social media, on digital content platforms, and others. In the present moment, generative AI tools enable the making of novel texts and digital visuals, among others. A major extant question is how best to harness generative art-making AIs in instructional design work. In this case, this work explores professionally ethical (and legal) ways to use a generative art-making AIs for ID work, as an innovative approach based on a review of the literature, a year of using several free web-facing art-making generative AIs (CrAIyon, Deep Dream Generator, and others) in open or public beta, and learning from applied instructional design work (over several decades). © 2024, IGI Global.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Chen, H.
AU  - Ni, Y.
AU  - Huang, W.
AU  - Imani, M.
TI  - Scalable and Interpretable Brain-Inspired Hyper-Dimensional Computing Intelligence with Hardware-Software Co-Design
PY  - 2024
T2  - Proceedings of the Custom Integrated Circuits Conference
DO  - 10.1109/CICC60959.2024.10529049
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193930748&doi=10.1109%2fCICC60959.2024.10529049&partnerID=40&md5=f350634e2cd1efbb4e83ae876322511f
AB  - During the advancement of modern deep learning algorithms, models become increasingly demanding in computing resources and power-hungry, such that they are considered less hardware-friendly for many real-world deployments. The motivation behind brain-inspired computing, or neuromorphic computing, is that the human brain remains the most sophisticated yet efficient learning module ever. We focus on HyperDimensional Computing (HDC), which aims to realize efficient learning via brain-like high-dimensional vector operations. Prior research works have shown that HDC is a lightweight alternative to deep learning in various applications, such as classification and reinforcement learning. HDC can also serve as a reasoning machine on graph datasets and an efficient information retrieval method for genomic sequencing. In this paper, we revisit hardware-software codesigns of HDC, covering the latest developments in both HDC algorithms and accelerator designs. We also carried out extensive comparisons between HDC works and the state-of-the-art. © 2024 IEEE.
KW  - Brain
KW  - Deep learning
KW  - Hardware-software codesign
KW  - Reinforcement learning
KW  - Algorithm model
KW  - Brain-inspired
KW  - Brain-inspired computing
KW  - Computing Intelligence
KW  - Computing power
KW  - Computing resource
KW  - Efficient learning
KW  - Hardware/software codesign
KW  - Neuromorphic computing
KW  - Real world deployment
KW  - Learning algorithms
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - CHAP
AU  - Yadav, P.
AU  - Kim, S.
TI  - OODA loop for learning open-world novelty problems
PY  - 2024
T2  - Advances in Computers
VL  - 134
SP  - 91
EP  - 130
DO  - 10.1016/bs.adcom.2023.06.002
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165009788&doi=10.1016%2fbs.adcom.2023.06.002&partnerID=40&md5=c22534033af15bd6b922bb982e09dff2
AB  - Open-world learning is a machine learning paradigm that deals with learning from a dynamic and open environment where new categories or classes can be added or removed at any time. In an open-world environment, an intelligent agent is expected to learn the goal independently by interacting with the environment and adapting well to unseen changes. This chapter discusses a proposed RL framework called OODA-RL. It is derived from the four stages of Boyd's OODA loop, popularly used in warfare strategy planning and implementation. O stands for Observe, the second O stands for Orient, D stands for Decide, and A stands for Act. In the “Observe stage,” the Agent receives raw unstructured data as observations from the environment about the surroundings. In the “Decide stage,” the primary role is of a decision-maker, deciding whether the learned state representations are classified as a seen or unseen scenario. Next, the orient stage plays two roles: (i) it creates a continual learning simulated environment based on the raw observations it receives from the observe stage, and (ii) it acts as the expert system in the AL loop between the decide and orient stages. Finally, in the “Act stage,” the Agent takes appropriate action as decided through the OODA-RL loop. Compared to the abstract definition of the classical RL framework, OODA-RL broadens the Agent's internal composition to enable RL researchers to integrate novelty adaptation techniques as an additional feature into both current state-of-the-art and future RL algorithms. In addition, this chapter discusses some of the current works to highlight different approaches to developing open-world learning agents. © 2024 Elsevier Inc.
KW  - OODA-RL
KW  - Open-world learning
KW  - Open-world novelty detection
KW  - Out-of-distribution detection
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Garcia, K.
AU  - Vontobel, J.
AU  - Mayer, S.
TI  - A Digital Companion Architecture for Ambient Intelligence
PY  - 2024
T2  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 8
IS  - 2
C7  - 66
DO  - 10.1145/3659610
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193465812&doi=10.1145%2f3659610&partnerID=40&md5=c7d5d9ea3d20b48f22643057d2cb614b
AB  - Ambient Intelligence (AmI) focuses on creating environments capable of proactively and transparently adapting to users and their activities. Traditionally, AmI focused on the availability of computational devices, the pervasiveness of networked environments, and means to interact with users. In this paper, we propose a renewed AmI architecture that takes into account current technological advancements while focusing on proactive adaptation for assisting and protecting users. This architecture consist of four phases: Perceive, Interpret, Decide, and Interact. The AmI systems we propose, called Digital Companions (DC), can be embodied in a variety of ways (e.g., through physical robots or virtual agents) and are structured according to these phases to assist and protect their users. We further categorize DCs into Expert DCs and Personal DCs, and show that this induces a favorable separation of concerns in AmI systems, where user concerns (including personal user data and preferences) are handled by Personal DCs and environment concerns (including interfacing with environmental artifacts) are assigned to Expert DCs; this separation has favorable privacy implications as well. Herein, we introduce this architecture and validate it through a prototype in an industrial scenario where robots and humans collaborate to perform a task.  © 2024 Owner/Author.
KW  - ambient intelligence
KW  - architecture
KW  - connected devices
KW  - digital companion systems
KW  - industrial environments
KW  - knowledge graph
KW  - mixed reality
KW  - scene graph generation algorithm
KW  - Ambient intelligence
KW  - Digital devices
KW  - Knowledge graph
KW  - Ambient intelligence systems
KW  - Connected device
KW  - Digital companion system
KW  - Generation algorithm
KW  - Graph generation
KW  - Industrial environments
KW  - Knowledge graphs
KW  - Mixed reality
KW  - Scene graph generation algorithm
KW  - Scene-graphs
KW  - Mixed reality
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Yoshii, K.
AU  - Kimura, D.
AU  - Kosugi, A.
AU  - Shinkawa, K.
AU  - Takase, T.
AU  - Kobayashi, M.
AU  - Yamada, Y.
AU  - Nemoto, M.
AU  - Watanabe, R.
AU  - Ota, M.
AU  - Higashi, S.
AU  - Nemoto, K.
AU  - Arai, T.
AU  - Nishimura, M.
TI  - Screening of Mild Cognitive Impairment through Conversations with Humanoid Robots: Exploratory Pilot Study
PY  - 2023
T2  - JMIR Formative Research
VL  - 7
C7  - e42792
DO  - 10.2196/42792
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149107694&doi=10.2196%2f42792&partnerID=40&md5=4a2f0d47f15547171bc24c54bf4a834e
AB  - Background: The rising number of patients with dementia has become a serious social problem worldwide. To help detect dementia at an early stage, many studies have been conducted to detect signs of cognitive decline by prosodic and acoustic features. However, many of these methods are not suitable for everyday use as they focus on cognitive function or conversational speech during the examinations. In contrast, conversational humanoid robots are expected to be used in the care of older people to help reduce the work of care and monitoring through interaction. Objective: This study focuses on early detection of mild cognitive impairment (MCI) through conversations between patients and humanoid robots without a specific examination, such as neuropsychological examination. Methods: This was an exploratory study involving patients with MCI and cognitively normal (CN) older people. We collected the conversation data during neuropsychological examination (Mini-Mental State Examination [MMSE]) and everyday conversation between a humanoid robot and 94 participants (n=47, 50%, patients with MCI and n=47, 50%, CN older people). We extracted 17 types of prosodic and acoustic features, such as the duration of response time and jitter, from these conversations. We conducted a statistical significance test for each feature to clarify the speech features that are useful when classifying people into CN people and patients with MCI. Furthermore, we conducted an automatic classification experiment using a support vector machine (SVM) to verify whether it is possible to automatically classify these 2 groups by the features identified in the statistical significance test. Results: We obtained significant differences in 5 (29%) of 17 types of features obtained from the MMSE conversational speech. The duration of response time, the duration of silent periods, and the proportion of silent periods showed a significant difference (P<.001) and met the reference value r=0.1 (small) of the effect size. Additionally, filler periods (P<.01) and the proportion of fillers (P=.02) showed a significant difference; however, these did not meet the reference value of the effect size. In contrast, we obtained significant differences in 16 (94%) of 17 types of features obtained from the everyday conversations with the humanoid robot. The duration of response time, the duration of speech periods, jitter (local, relative average perturbation [rap], 5-point period perturbation quotient [ppq5], difference of difference of periods [ddp]), shimmer (local, amplitude perturbation quotient [apq]3, apq5, apq11, average absolute differences between the amplitudes of consecutive periods [dda]), and F0cov (coefficient of variation of the fundamental frequency) showed a significant difference (P<.001). In addition, the duration of response time, the duration of silent periods, the filler period, and the proportion of fillers showed significant differences (P<.05). However, only jitter (local) met the reference value r=0.1 (small) of the effect size. In the automatic classification experiment for the classification of participants into CN and MCI groups, the results showed 66.0% accuracy in the MMSE conversational speech and 68.1% accuracy in everyday conversations with the humanoid robot. Conclusions: This study shows the possibility of early and simple screening for patients with MCI using prosodic and acoustic features from everyday conversations with a humanoid robot with the same level of accuracy as the MMSE. ©Kenta Yoshii, Daiki Kimura, Akihiro Kosugi, Kaoru Shinkawa, Toshiro Takase, Masatomo Kobayashi, Yasunori Yamada, Miyuki Nemoto, Ryohei Watanabe, Miho Ota, Shinji Higashi, Kiyotaka Nemoto, Tetsuaki Arai, Masafumi Nishimura.
KW  - Alzheimer disease
KW  - humanoid robot
KW  - mild cognitive impairment
KW  - monitoring
KW  - neuropsychiatric symptoms
KW  - neuropsychological
KW  - neuropsychological assessment
KW  - robot
KW  - simple screening
KW  - symptoms
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Soni, A.
AU  - Al-Sarayreh, M.
AU  - Reis, M.M.
AU  - Brightwell, G.
TI  - Hyperspectral imaging and deep learning for quantification of Clostridium sporogenes spores in food products using 1D- convolutional neural networks and random forest model
PY  - 2021
T2  - Food Research International
VL  - 147
C7  - 110577
DO  - 10.1016/j.foodres.2021.110577
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110367424&doi=10.1016%2fj.foodres.2021.110577&partnerID=40&md5=e519d3577554893ec0833e7f0c9db550
AB  - Clostridium sporogenes spores are used as surrogates for Clostridium botulinum, to verify thermal exposure and lethality in sterilization regimes by food industries. Conventional methods to detect spores are time-consuming and labour intensive. The objectives of this study were to evaluate the feasibility of using hyperspectral imaging (HSI) and deep learning approaches, firstly to identify dead and live forms of C. sporogenes spores and secondly, to estimate the concentration of spores on culture media plates and ready-to-eat mashed potato (food matrix). C. sporogenes spores were inoculated by either spread plating or drop plating on sheep blood agar (SBA) and tryptic soy agar (TSA) plates and by spread plating on the surface of mashed potato. Reflectance in the spectral range of 547–1701 nm from the region of interest was used for principal component analysis (PCA). PCA was successful in distinguishing dead and live spores and different levels of inoculum (102 to 106 CFU/ml) on both TSA and SBA plates, however, was not efficient on the mashed potato (food matrix). Hence, deep learning classification frameworks namely 1D- convolutional neural networks (CNN) and random forest (RF) model were used. CNN model outperformed the RF model and the accuracy for quantification of spores was improved by 4% and 8% in the presence and absence, respectively of dead spores. The screening system used in this study was a combination of HSI and deep learning modelling, which resulted in an overall accuracy of 90–94% when the dead/inactivated spores were present and absent, respectively. The only discrepancy detected was during the prediction of samples with low inoculum levels (<102 CFU/ml). In summary, it was evident that HSI in combination with a deep learning approach showed immense potential as a tool to detect and quantify spores on nutrient media as well as on specific food matrix (mashed potato). However, the presence of dead spores in any sample is postulated to affect the accuracy and would need replicates and confirmatory assays. © 2021 Elsevier Ltd
KW  - Clostridium spores
KW  - CNN
KW  - Deep learning
KW  - HSI
KW  - Hyperspectral imaging
KW  - Networks modelling
KW  - Clostridium
KW  - Clostridium botulinum
KW  - Deep Learning
KW  - Hyperspectral Imaging
KW  - Neural Networks, Computer
KW  - Spores, Bacterial
KW  - Convolution
KW  - Decision trees
KW  - Deep learning
KW  - Food products
KW  - Hyperspectral imaging
KW  - Image segmentation
KW  - Polysaccharides
KW  - Spectroscopy
KW  - Clostridium spore
KW  - Clostridium sporogenes
KW  - Convolutional neural network
KW  - Deep learning
KW  - Food matrixes
KW  - HyperSpectral
KW  - Hyperspectral imaging
KW  - Learning approach
KW  - Network models
KW  - Random forest modeling
KW  - bacterial spore
KW  - Clostridium
KW  - Clostridium botulinum
KW  - Principal component analysis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 42
ER  -

TY  - JOUR
AU  - Bernasconi, E.
AU  - Redavid, D.
AU  - Ferilli, S.
TI  - Enhancing Personalised Learning with a Context-Aware Intelligent Question-Answering System and Automated Frequently Asked Question Generation
PY  - 2025
T2  - Electronics (Switzerland)
VL  - 14
IS  - 7
C7  - 1481
DO  - 10.3390/electronics14071481
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002369199&doi=10.3390%2felectronics14071481&partnerID=40&md5=e82a359e99c1ef550f7d0a9607c21792
AB  - The increasing integration of Artificial Intelligence (AI) in education has led to the development of innovative tools like Intelligent Question-Answering Systems (IQASs), aiming to revolutionize traditional learning paradigms. However, many existing IQAS struggle with the nuances of natural language and the complexities of student questions. This research focuses on developing a context-aware IQAS that leverages advanced Natural Language Processing (NLP) techniques and contextual information, including student learning history and educational content, to provide personalised support. This study also introduces a software tool that utilizes NLP techniques to automatically generate FAQs from educational materials. Employing a hybrid approach combining rule-based and machine learning techniques, the IQAS demonstrated high accuracy in interpreting and responding to a wide range of student queries. The software tool effectively automated the generation of FAQs, creating a valuable resource for personalised learning. The findings suggest that these tools can significantly improve student engagement, motivation, and learning outcomes, highlighting the potential of AI to transform education and pave the way for more personalised, adaptive, and effective learning environments. © 2025 by the authors.
KW  - adaptive learning systems
KW  - AI-driven personalisation
KW  - educational data mining
KW  - educational technology
KW  - intelligent question answering
KW  - knowledge graphs
KW  - natural language processing
KW  - student learning enhancement
KW  - transformers in education
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Zhou, B.
AU  - Zheng, Z.
AU  - Zhou, D.
AU  - Cheng, G.
AU  - Jiménez-Ruiz, E.
AU  - Tran, T.-K.
AU  - Stepanova, D.
AU  - Gad-Elrab, M.H.
AU  - Nikolov, N.
AU  - Soylu, A.
AU  - Kharlamov, E.
TI  - The Data Value Quest: A Holistic Semantic Approach at Bosch
PY  - 2022
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 
VL  - 13384 LNCS
SP  - 287
EP  - 290
DO  - 10.1007/978-3-031-11609-4_42
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135066178&doi=10.1007%2f978-3-031-11609-4_42&partnerID=40&md5=a7cc436b1d4d4664054a5451d1f94962
AB  - Introduction. Modern industry witnesses a fast growth in volume and complexity of heterogeneous manufacturing (big) data [1, 2] thanks to the technological advances of Industry 4.0 [1, 3], including development in perception, communication, processing, and actuation. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Communications processing
KW  - Data values
KW  - Fast growths
KW  - Holistic semantics
KW  - Semantic approach
KW  - Technological advances
KW  - Semantics
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 8
ER  -

TY  - CONF
AU  - Liventsev, V.
AU  - Grishina, A.
AU  - Härmä, A.
AU  - Moonen, L.
TI  - Fully Autonomous Programming with Large Language Models
PY  - 2023
T2  - GECCO 2023 - Proceedings of the 2023 Genetic and Evolutionary Computation Conference
SP  - 1146
EP  - 1155
DO  - 10.1145/3583131.3590481
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167675554&doi=10.1145%2f3583131.3590481&partnerID=40&md5=f29a3409330818628b6cd1f2ca13f55a
AB  - Current approaches to program synthesis with Large Language Models (LLMs) exhibit a "near miss syndrome": They tend to generate programs that semantically resemble the correct answer (as measured by text similarity metrics or human evaluation), but achieve a low or even zero accuracy as measured by unit tests due to small imperfections, such as the wrong input or output format. This calls for an approach known as Synthesize, Execute, Debug (SED), whereby a draft of the solution is generated first, followed by a program repair phase addressing the failed tests. To effectively apply this approach to instruction-driven LLMs, one needs to determine which prompts perform best as instructions for LLMs, as well as strike a balance between repairing unsuccessful programs and replacing them with newly generated ones. We explore these trade-offs empirically, comparing replace-focused, repair-focused, and hybrid debug strategies, as well as different template-based and model-based prompt-generation techniques. We use OpenAI Codex as the LLM and Program Synthesis Benchmark 2 as a database of problem descriptions and tests for evaluation. The resulting framework outperforms both conventional usage of Codex without the repair phase and traditional genetic programming approaches.  © 2023 Owner/Author(s).
KW  - automatic programming
KW  - large language models
KW  - program repair
KW  - Automatic programming
KW  - Computational linguistics
KW  - Economic and social effects
KW  - Genetic algorithms
KW  - Program debugging
KW  - Repair
KW  - Software testing
KW  - 'current
KW  - Language model
KW  - Large language model
KW  - Metric evaluation
KW  - Near-misses
KW  - Program repair
KW  - Program synthesis
KW  - Repair phasis
KW  - Similarity metrics
KW  - Text similarity
KW  - Genetic programming
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 24
ER  -

TY  - JOUR
AU  - Prakash, A.J.
AU  - Prakasam, P.
TI  - An intelligent fruits classification in precision agriculture using bilinear pooling convolutional neural networks
PY  - 2023
T2  - Visual Computer
VL  - 39
IS  - 5
SP  - 1765
EP  - 1781
DO  - 10.1007/s00371-022-02443-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126816278&doi=10.1007%2fs00371-022-02443-z&partnerID=40&md5=d162bb4d7ab54e03264e116e2d50908f
AB  - With an increase in the consumption of fruits day by day, the yielding and production around the world are also increasing at a steady rate. Meanwhile, the workforce in the field becomes more challenging, there arises a need for automated solutions to maintain consistent output and quality of the product. An accurate, competent and consistent approach to classifying fruits and other agricultural products in precision agriculture is the foundation for a machine vision system to be successful and cost-effective. In this research work, Convolutional Neural Network (CNN)-based intelligent fruits classification utilizing the bilinear pooling with heterogeneous streams is proposed. The fruits classification problem is viewed as a fine-grained visual classification (FGVC) and the heterogeneous bilinear network is developed and compared with the normal implementations. The proposed CNN network is initialized with ImageNet weights and the pre-trained networks are used as components in the Bilinear Pooling CNN (BP-CNN). The CNNs used in the bilinear network function as feature extractors are then combined using the bilinear pooling function. The proposed BP-CNN-based intelligent classifier is trained and tested with Fruits-360, Imagenet and VegFru which are used by many researchers recently. The performance of the proposed BP-CNN model is validated using various metrics and compared with other existing CNN models. It is found that it outperforms all other methods with a classification accuracy of 99.69% and an F1 score of 0.9968. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
KW  - Bilinear pooling
KW  - Confusion matrix
KW  - Convolutional neural network
KW  - Fruit classification
KW  - Machine vision
KW  - Convolution
KW  - Convolutional neural networks
KW  - Cost effectiveness
KW  - Fruits
KW  - Precision agriculture
KW  - Automated solutions
KW  - Bilinear pooling
KW  - Confusion matrix
KW  - Convolutional neural network
KW  - Cost effective
KW  - Fruit classification
KW  - Machine vision systems
KW  - Machine-vision
KW  - Network-based
KW  - Precision Agriculture
KW  - Computer vision
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 18
ER  -

TY  - CONF
AU  - Chong, D.
AU  - Zhang, J.
AU  - Boland, N.
AU  - Chen, L.
TI  - Automatically Inferring Image Base Addresses of ARM32 Binaries Using Architecture Features
PY  - 2024
T2  - Communications in Computer and Information Science
VL  - 2034 CCIS
SP  - 450
EP  - 461
DO  - 10.1007/978-981-97-1274-8_29
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189611627&doi=10.1007%2f978-981-97-1274-8_29&partnerID=40&md5=f3855455bcdfac65deac8dbba67c9776
AB  - We designed an innovative method, namely iBase, which automatically infers the image base address of an ARM32 binary by statistically, structurally, and semantically correlating the absolute and the relative addresses contained in the binary. iBase exploits ARM32’s architecture features, and hence it is immune to variances introduced by software development and compilation. In addition, iBase is parameter-free and it requires no manual configuration. We implemented iBase and performed evaluation using 20 ARM32 binaries. Our evaluation results have shown that iBase successfully detects base addresses for all of them and outperforms start-of-the-art tools including Ghidra and Radare2. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.
KW  - Binary Analysis
KW  - Embedded Systems
KW  - Image Base Address
KW  - Microcontrollers
KW  - Reverse Engineering
KW  - ARM processors
KW  - Embedded systems
KW  - Reverse engineering
KW  - Software design
KW  - Binary analysis
KW  - Embedded-system
KW  - Evaluation results
KW  - Image base address
KW  - Images basis
KW  - Innovative method
KW  - Microcontrollers
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Aygun, S.
AU  - Najafi, M.H.
TI  - Sobol Sequence Optimization for Hardware-Efficient Vector Symbolic Architectures
PY  - 2025
T2  - IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems
VL  - 44
IS  - 3
SP  - 937
EP  - 950
DO  - 10.1109/TCAD.2024.3463544
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204468483&doi=10.1109%2fTCAD.2024.3463544&partnerID=40&md5=c9aaf46e8654704f8de3e68b1ff3eb28
AB  - Hyperdimensional computing (HDC) is an emerging computing paradigm with significant promise for efficient and robust learning. In HDC, objects are encoded with high-dimensional vector symbolic sequences called hypervectors. The quality of hypervectors, defined by their distribution and independence, directly impacts the performance of HDC systems. Despite a large body of work on the processing parts of HDC systems, little to no attention has been paid to data encoding and the quality of hypervectors. Most prior studies have generated hypervectors using inherent random functions, such as MATLAB’s or Python’s random function. This work introduces an optimization technique for generating hypervectors by employing quasi-random sequences. These sequences have recently demonstrated their effectiveness in achieving accurate and low-discrepancy data encoding in stochastic computing systems. The study outlines the optimization steps for utilizing Sobol sequences to produce high-quality hypervectors in HDC systems. An optimization algorithm is proposed to select the most suitable Sobol sequences via indexes for generating minimally correlated hypervectors, particularly in applications related to symbol-oriented architectures. The performance of the proposed technique is evaluated in comparison to two traditional approaches of generating hypervectors based on linear-feedback shift registers and MATLAB random functions. The evaluation is conducted for three applications: 1) language; 2) headline; and 3) medical image classification. Our experimental results demonstrate accuracy improvements of up to 10.79%, depending on the vector size. Additionally, the proposed encoding hardware exhibits reduced energy consumption and a superior area-delay product. © 2024 IEEE.
KW  - Hyperdimensional computing (HDC)
KW  - language processing
KW  - optimization
KW  - Sobol sequences
KW  - stochastic computing (SC)
KW  - Computer architecture
KW  - Digital storage
KW  - Encoding (symbols)
KW  - Image coding
KW  - Medical image processing
KW  - Shift registers
KW  - Signal encoding
KW  - Computing system
KW  - Data encoding
KW  - Hyperdimensional computing
KW  - Language processing
KW  - Optimisations
KW  - Performance
KW  - Random functions
KW  - Sequence optimization
KW  - Sobol's sequences
KW  - Stochastic computing
KW  - Stochastic systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Tran, H.-D.
AU  - Choi, S.
AU  - Okamoto, H.
AU  - Hoxha, B.
AU  - Fainekos, G.
AU  - Prokhorov, D.
TI  - Quantitative Verification for Neural Networks using ProbStars
PY  - 2023
T2  - HSCC 2023 - Proceedings of the 26th ACM International Conference on Hybrid Systems: Computation and Control, Part of CPS-IoT Week
C7  - 4
DO  - 10.1145/3575870.3587112
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160510685&doi=10.1145%2f3575870.3587112&partnerID=40&md5=6ca6f8b70e342949624f1d702993a137
AB  - Most deep neural network (DNN) verification research focuses on qualitative verification, which answers whether or not a DNN violates a safety/robustness property. This paper proposes an approach to convert qualitative verification into quantitative verification for neural networks. The resulting quantitative verification method not only can answer YES or NO questions but also can compute the probability of a property being violated. To do that, we introduce the concept of a probabilistic star (or shortly ProbStar), a new variant of the well-known star set, in which the predicate variables belong to a Gaussian distribution and propose an approach to compute the probability of a probabilistic star in high-dimensional space. Unlike existing works dealing with constrained input sets, our work considers the input set as a truncated multivariate normal (Gaussian) distribution, i.e., besides the constraints on the input variables, the input set has a probability of the constraints being satisfied. The input distribution is represented as a probabilistic star set and is propagated through a network to construct the output reachable set containing multiple ProbStars, which are used to verify the safety or robustness properties of the network. In case of a property is violated, the violation probability can be computed precisely by an exact verification algorithm or approximately by an overapproximate verification algorithm. The proposed approach is implemented in a tool named StarV and is evaluated using the well-known ACASXu networks and a rocket landing benchmark. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.
KW  - Probability distributions
KW  - Rockets
KW  - Stars
KW  - High dimensional spaces
KW  - Input set
KW  - Neural-networks
KW  - Probabilistics
KW  - Property
KW  - Quantitative verification
KW  - Research focus
KW  - Robustness properties
KW  - Verification algorithms
KW  - Verification method
KW  - Deep neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 8
ER  -

TY  - JOUR
AU  - Kang, Z.
AU  - Zhou, D.
AU  - Guo, Z.
AU  - Zhou, Q.
AU  - Wu, H.
TI  - An ontology-based knowledge representation framework for aircraft maintenance processes to support work optimization
PY  - 2024
T2  - International Journal of Advanced Manufacturing Technology
VL  - 134
IS  - 11-12
SP  - 5577
EP  - 5601
DO  - 10.1007/s00170-024-14428-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204534754&doi=10.1007%2fs00170-024-14428-4&partnerID=40&md5=c6b6d1f973397d4d2be6493358c85078
AB  - As a critical business activity in the aircraft life cycle, maintenance processes are highly complex and require multidisciplinary knowledge. Knowledge integration and representation oriented toward aircraft maintenance processes are necessary to improve work efficiency. Nonetheless, conventional approaches lack effective unified management, which obstructs domain knowledge sharing and ultimately impedes maintenance work. In this context, this paper proposes a knowledge representation framework based on the benefits of ontology, which formalizes multidisciplinary knowledge for aircraft maintenance processes. An ontology of aircraft maintenance processes is developed for knowledge conceptualization and reuse. On this basis, a domain knowledge extraction model based on the bidirectional encoder representation from transformers (BERT) is constructed to automatically extract entities and relationships related to maintenance processes. With a series of Semantic Web Rule Language (SWRL) rules, a knowledge reasoning method is proposed based on the aircraft maintenance process ontology to mine hidden knowledge. We evaluate the developed ontology and demonstrate the feasibility and usefulness of the proposed knowledge reasoning method in a case study. The results show that the proposed knowledge representation framework provides an effective knowledge formalization method for complex knowledge in aircraft maintenance processes to support work optimization. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.
KW  - Aircraft Maintenance
KW  - BERT
KW  - Knowledge Management
KW  - Ontology
KW  - Case based reasoning
KW  - Domain Knowledge
KW  - Ontology
KW  - Aircraft maintenance
KW  - Bidirectional encoder representation from transformer
KW  - Critical business
KW  - Knowledge reasoning
KW  - Knowledge-representation
KW  - Maintenance process
KW  - Ontology's
KW  - Ontology-based
KW  - Optimisations
KW  - Reasoning methods
KW  - Knowledge representation
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Pal, N.
AU  - Lee, S.
AU  - Johnson, T.T.
TI  - Benchmark: Formal Verification of Semantic Segmentation Neural Networks
PY  - 2024
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14380 LNCS
SP  - 311
EP  - 330
DO  - 10.1007/978-3-031-46002-9_20
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180620255&doi=10.1007%2f978-3-031-46002-9_20&partnerID=40&md5=67ec78d7dfd3c2b054fba023e247bf55
AB  - Formal verification utilizes a rigorous approach to ensure the absence of critical errors and validate models against predefined properties. While significant progress has been made in verification methods for various deep neural networks (DNNs), such as feed-forward neural networks (FFNNs) and convolutional neural networks (CNNs), the application of these techniques to semantic segmentation remains largely unexplored. Semantic segmentation networks are vital in computer vision applications, where they assign semantic labels to individual pixels within an image. Given their deployment in safety-critical domains, ensuring the correctness of these networks becomes paramount. This paper presents a comprehensive benchmark study on applying formal verification techniques to semantic segmentation networks. We explore a diverse set of state-of-the-art semantic segmentation datasets and generate neural network models, including fully-convolutional networks and encoder-decoder architectures. Our investigation encompasses a wide range of verification properties, focusing on the robustness of these models against bounded adversarial vulnerabilities. To evaluate the networks’ performance, we employ set-based reachability algorithms to calculate the output reachable set(s) and some state-of-the-art performance measures for a comparative study among the networks. This benchmark paper aims to provide the formal verification community with several semantic segmentation networks and their robustness specifications for future use cases in different neural network verification competitions. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Adversarial Attack
KW  - Benchmarking
KW  - Reachability
KW  - Robustness
KW  - Semantic Segmentation
KW  - VNN-Comp
KW  - Convolution
KW  - Deep neural networks
KW  - Feedforward neural networks
KW  - Safety engineering
KW  - Semantic Segmentation
KW  - Semantic Web
KW  - Semantics
KW  - Adversarial attack
KW  - Feed forward neural net works
KW  - Neural-networks
KW  - Property
KW  - Reachability
KW  - Rigorous approach
KW  - Robustness
KW  - Semantic segmentation
KW  - Verification method
KW  - VNN-comp
KW  - Benchmarking
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Anand, S.K.
AU  - Kumar, S.
TI  - Ontology-based soft computing and machine learning model for efficient retrieval
PY  - 2024
T2  - Knowledge and Information Systems
VL  - 66
IS  - 2
SP  - 1371
EP  - 1402
DO  - 10.1007/s10115-023-01990-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173959033&doi=10.1007%2fs10115-023-01990-8&partnerID=40&md5=a32317efbdb4bcf116b1b2ce2d6584d8
AB  - Unstructured and unorganized data always degrade the performance of search techniques and produce irrelevant results in response to the query as well as decrease the speed of retrieval results. Ontology in semantic web (SW) provides an adequate solution to represent the knowledge, because of its backbone knowledge of an application or domain. But, domain ontology has three basic problems while retrieving useful knowledge from a domain ontology: (a) structuring/arrangement, (b) unnecessary knowledge reduction, selection and extraction, and (c) speeding up the retrieval process. To resolve these problems, we proposed multi-level k-mean clustering approach with rough set and Bayesian network model for ontology (MLK-rBO). The proposed model works in four different phases—clustering, knowledge discovery, building a probabilistic network, and model evaluation. The model ensembles three different techniques, namely clustering, rough set (RS), and Bayesian network (BN). Finally, the proposed model is tested with statistical parameters and compared with other models, namely decision tree (DT), random forest (RF), and support vector machine (SVM) to evaluate performance. By analyzing experimental results, we observed that the MLK-rBO gives better accuracy: 98.36% for survey data (fever) and 86% for Wine quality data than available models. © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.
KW  - Information retrieval
KW  - Knowledge representation
KW  - Machine learning
KW  - Ontology
KW  - Soft computing
KW  - Uncertainty
KW  - Bayesian networks
KW  - Decision trees
KW  - K-means clustering
KW  - Knowledge representation
KW  - Learning systems
KW  - Nearest neighbor search
KW  - Rough set theory
KW  - Soft computing
KW  - Support vector machines
KW  - Clusterings
KW  - Domain ontologies
KW  - Knowledge-representation
KW  - Machine-learning
KW  - Ontology's
KW  - Ontology-based
KW  - Performance
KW  - Soft machine
KW  - Soft-Computing
KW  - Uncertainty
KW  - Ontology
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Khan, A.U.
AU  - Kuehne, H.
AU  - Duarte, K.
AU  - Gan, C.
AU  - Lobo, N.
AU  - Shah, M.
TI  - Found a Reason for me? Weakly-supervised Grounded Visual Question Answering using Capsules
PY  - 2021
T2  - Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition
SP  - 8461
EP  - 8470
DO  - 10.1109/CVPR46437.2021.00836
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110727704&doi=10.1109%2fCVPR46437.2021.00836&partnerID=40&md5=bc47430aff76724cecfcb4d213639213
AB  - The problem of grounding VQA tasks has seen an increased attention in the research community recently, with most attempts usually focusing on solving this task by using pretrained object detectors. However, pre-trained object detectors require bounding box annotations for detecting relevant objects in the vocabulary, which may not always be feasible for real-life large-scale applications. In this paper, we focus on a more relaxed setting: The grounding of relevant visual entities in a weakly supervised manner by training on the VQA task alone. To address this problem, we propose a visual capsule module with a query-based selection mechanism of capsule features, that allows the model to focus on relevant regions based on the textual cues about visual information in the question. We show that integrating the proposed capsule module in existing VQA systems significantly improves their performance on the weakly supervised grounding task. Overall, we demonstrate the effectiveness of our approach on two state-of-the-art VQA systems, stacked NMN and MAC, on the CLEVR-Answers benchmark, our new evaluation set based on CLEVR scenes with groundtruth bounding boxes for objects that are relevant for the correct answer, as well as on GQA, a real world VQA dataset with compositional questions. We show that the systems with the proposed capsule module consistently outperform the respective baseline systems in terms of answer grounding, while achieving comparable performance on VQA task. © 2021 IEEE.
KW  - Computer vision
KW  - Petroleum reservoir evaluation
KW  - Bounding-box
KW  - Large-scale applications
KW  - Object detectors
KW  - Performance
KW  - Question Answering
KW  - Region-based
KW  - Research communities
KW  - Selection mechanism
KW  - Visual entities
KW  - Visual information
KW  - Object detection
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 30
ER  -

TY  - JOUR
AU  - Nasarian, E.
AU  - Alizadehsani, R.
AU  - Acharya, U.R.
AU  - Tsui, K.-L.
TI  - Designing interpretable ML system to enhance trust in healthcare: A systematic review to proposed responsible clinician-AI-collaboration framework
PY  - 2024
T2  - Information Fusion
VL  - 108
C7  - 102412
DO  - 10.1016/j.inffus.2024.102412
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189938333&doi=10.1016%2fj.inffus.2024.102412&partnerID=40&md5=c350f539774b809b5e2c2fbe18bd9d05
AB  - Background: Artificial intelligence (AI)-based medical devices and digital health technologies, including medical sensors, wearable health trackers, telemedicine, mobile health (mHealth), large language models (LLMs), and digital care twins (DCTs), significantly influence the process of clinical decision support systems (CDSS) in healthcare and medical applications. However, given the complexity of medical decisions, it is crucial that results generated by AI tools not only be correct but also carefully evaluated, understandable, and explainable to end-users, especially clinicians. The lack of interpretability in communicating AI clinical decisions can lead to mistrust among decision-makers and a reluctance to use these technologies. Objective: This paper systematically reviews the processes and challenges associated with interpretable machine learning (IML) and explainable artificial intelligence (XAI) within the healthcare and medical domains. Its main goals are to examine the processes of IML and XAI, their related methods, applications, and the implementation challenges they pose in digital health interventions (DHIs), particularly from a quality control perspective, to help understand and improve communication between AI systems and clinicians. The IML process is categorized into pre-processing interpretability, interpretable modeling, and post-processing interpretability. This paper aims to foster a comprehensive understanding of the significance of a robust interpretability approach in clinical decision support systems (CDSS) by reviewing related experimental results. The goal is to provide future researchers with insights for creating clinician-AI tools that are more communicable in healthcare decision support systems and offer a deeper understanding of their challenges. Methods: Our research questions, eligibility criteria, and primary goals were proved using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guideline and the PICO (population, intervention, control, and outcomes) method. We systematically searched PubMed, Scopus, and Web of Science databases using sensitive and specific search strings. Subsequently, duplicate papers were removed using EndNote and Covidence. A two-phase selection process was then carried out on Covidence, starting with screening by title and abstract, followed by a full-text appraisal. The Meta Quality Appraisal Tool (MetaQAT) was used to assess the quality and risk of bias. Finally, a standardized data extraction tool was employed for reliable data mining. Results: The searches yielded 2,241 records, from which 555 duplicate papers were removed. During the title and abstract screening step, 958 papers were excluded, and the full-text review step excluded 482 studies. Subsequently, in quality and risk of bias assessment, 172 papers were removed. 74 publications were selected for data extraction, which formed 10 insightful reviews and 64 related experimental studies. Conclusion: The paper provides general definitions of explainable artificial intelligence (XAI) in the medical domain and introduces a framework for interpretability in clinical decision support systems structured across three levels. It explores XAI-related health applications within each tier of this framework, underpinned by a review of related experimental findings. Furthermore, the paper engages in a detailed discussion of quality assessment tools for evaluating XAI in intelligent health systems. It also presents a step-by-step roadmap for implementing XAI in clinical settings. To direct future research toward bridging current gaps, the paper examines the importance of XAI models from various angles and acknowledges their limitations. © 2024 Elsevier B.V.
KW  - AI-based medical devices
KW  - Explainable casual analysis
KW  - Human-computer-interaction
KW  - Interpretable ML
KW  - Medical large language models
KW  - Responsible AI
KW  - Unstructured data
KW  - Wearable medical devices
KW  - Abstracting
KW  - Decision making
KW  - Decision support systems
KW  - Diagnosis
KW  - Digital devices
KW  - Human computer interaction
KW  - Medical applications
KW  - mHealth
KW  - Natural language processing systems
KW  - Quality control
KW  - Wearable technology
KW  - Artificial intelligence-based medical device
KW  - Explainable casual analyse
KW  - Interpretability
KW  - Interpretable ML
KW  - Language model
KW  - Medical Devices
KW  - Medical large language model
KW  - Responsible artificial intelligence
KW  - Unstructured data
KW  - Wearable medical devices
KW  - Artificial intelligence
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 35
ER  -

TY  - JOUR
AU  - Hashemi, N.
AU  - Hoxha, B.
AU  - Prokhorov, D.
AU  - Fainekos, G.
AU  - Deshmukh, J.V.
TI  - Scaling Learning-based Policy Optimization for Temporal Logic Tasks by Controller Network Dropout
PY  - 2024
T2  - ACM Transactions on Cyber-Physical Systems
VL  - 8
IS  - 4
C7  - ART42
DO  - 10.1145/3696112
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210960066&doi=10.1145%2f3696112&partnerID=40&md5=1cd22f299f048b8932cec3ee9e1582f8
AB  - This article introduces a model-based approach for training feedback controllers for an autonomous agent operating in a highly non-linear (albeit deterministic) environment. We desire the trained policy to ensure that the agent satisfies specific task objectives and safety constraints, both expressed in Discrete-Time Signal Temporal Logic (DT-STL). One advantage for reformulation of a task via formal frameworks, like DT-STL, is that it permits quantitative satisfaction semantics. In other words, given a trajectory and a DT-STL formula, we can compute the robustness, which can be interpreted as an approximate signed distance between the trajectory and the set of trajectories satisfying the formula. We utilize feedback control, and we assume a feed forward neural network for learning the feedback controller. We show how this learning problem is similar to training recurrent neural networks (RNNs), where the number of recurrent units is proportional to the temporal horizon of the agent’s task objectives. This poses a challenge: RNNs are susceptible to vanishing and exploding gradients, and naïve gradient descent-based strategies to solve long-horizon task objectives thus suffer from the same problems. To address this challenge, we introduce a novel gradient approximation algorithm based on the idea of dropout or gradient sampling. One of the main contributions is the notion of controller network dropout, where we approximate the NN controller in several timesteps in the task horizon by the control input obtained using the controller in a previous training step. We show that our control synthesis methodology can be quite helpful for stochastic gradient descent to converge with less numerical issues, enabling scalable back-propagation over longer time horizons and trajectories over higher-dimensional state spaces. We demonstrate the efficacy of our approach on various motion planning applications requiring complex spatio-temporal and sequential tasks ranging over thousands of timesteps. © 2024 Copyright held by the owner/author(s).
KW  - Dropout
KW  - Feedback Control
KW  - Gradient Descent
KW  - Neural Network Control
KW  - Signal Temporal Logic
KW  - Adaptive control systems
KW  - Control system synthesis
KW  - Discrete time control systems
KW  - Feedback control
KW  - Feedforward neural networks
KW  - Gradient methods
KW  - Motion planning
KW  - Recurrent neural networks
KW  - Stochastic control systems
KW  - Stochastic models
KW  - Temporal logic
KW  - Discrete-time signals
KW  - Dropout
KW  - Feedback controller
KW  - Gradient-descent
KW  - Neural network control
KW  - Neural-networks
KW  - Policy optimization
KW  - Scalings
KW  - Signal temporal logic
KW  - Time step
KW  - Stochastic systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Su, P.
AU  - Chen, D.
TI  - Designing a knowledge-enhanced framework to support supply chain information management
PY  - 2025
T2  - Journal of Industrial Information Integration
VL  - 47
C7  - 100874
DO  - 10.1016/j.jii.2025.100874
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007549833&doi=10.1016%2fj.jii.2025.100874&partnerID=40&md5=d2d7e3e832443c65ba22fd927ebcf3e6
AB  - With globalization and outsourcing trends, modern industrial companies often rely on an extensive network of suppliers to construct sophisticated products. To maintain effective production planning and scheduling, integrating and managing the extensive information from supply chain has become increasingly critical. In particular, industrial companies, particularly those aiming to achieve Industry 4.0, enable to collect and analyze data related to their supply chains. Due to the vast amount of collected data, there is a continuous challenge in integrating and analyzing dependencies within the supplier network. While the development of Artificial Intelligence (AI) offers a promising solution for extracting and analyzing features from data, the inherently opaque and training-intensive nature of AI-enabled methods still present obstacles to effectively and efficiently analyzing information. To cope with this issue, this paper presents a knowledge-enhanced framework to support supply chain information integration and analysis by combining Knowledge Base (KB) and Graph Neural Networks (GNN). Specifically, constructing a KB enables the integration of extensive collected data with domain knowledge to generate structured and relational information. These knowledge-enhanced data support the training of GNN to encode information about supply chains. The resulting embeddings enable multiple inference tasks for analyzing graph-based data, supporting supply chain management. The case studies cover the usage of encoded embeddings for node classification, link prediction, and scenario classification. The proposed GNN outperforms baseline methods, demonstrating a promising solution for analyzing graph-based data in the context of supply chain management. © 2025
KW  - Graph Neural Network
KW  - Knowledge base construction
KW  - Knowledge graph
KW  - Supply chain management
KW  - Graph algorithms
KW  - Inference engines
KW  - Knowledge acquisition
KW  - Knowledge graph
KW  - Knowledge organization
KW  - Knowledge transfer
KW  - Network theory (graphs)
KW  - Outsourcing
KW  - Chain management
KW  - Embeddings
KW  - Globalisation
KW  - Graph neural networks
KW  - Graph-based
KW  - Industrial companies
KW  - Knowledge graphs
KW  - Knowledge-base construction
KW  - Production planning and scheduling
KW  - Supplier networks
KW  - Supply chain management
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Hidalgo, R.
AU  - Varde, A.S.
AU  - Parron, J.
AU  - Wang, W.
TI  - Incorporating Commonsense Knowledge to Enhance Robot Perception
PY  - 2025
T2  - IEEE Transactions on Automation Science and Engineering
VL  - 22
SP  - 15488
EP  - 15501
DO  - 10.1109/TASE.2025.3565191
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004037992&doi=10.1109%2fTASE.2025.3565191&partnerID=40&md5=b6db5df1656d5daab62060760a7144b6
AB  - Robots have been significantly employed across various avenues in recent years. However, their application has been largely limited to controlled environments where variables are few and predictable. To address this challenge, we propose Robo-CSK-Organizer, a novel system that enhances robotic perception by integrating commonsense knowledge (CSK) for improved object organization, classification, and decision-making. By combining ConceptNet for semantic reasoning, DETIC for object identification, and BLIP for contextual analysis, Robo-CSK-Organizer achieves superior ambiguity resolution, task adaptation, and explainability compared to models without CSK. Testing in a real-world robotics setting demonstrates notable gains in transparency, user trust, and error handling, making this approach valuable for advancing AI transparency and the development of versatile robotic applications in automation and engineering. Future directions of this work are also comprehensively discussed. Note to Practitioners - This paper introduces the Robo-CSK-Organizer, a system designed to enhance robotic decision-making through the integration of commonsense knowledge (CSK). Developed with the goal of improving both the efficiency and transparency of robots in task execution, this work addresses the critical need for advanced object organization and classification capabilities in multipurpose robotics, especially in domestic household settings. By leveraging a classical commonsense knowledge base alongside cutting-edge object detection and context discernment technologies, Robo-CSK-Organizer demonstrates significant improvements in ambiguity resolution, placement consistency, and explainable AI (XAI), highlighted by its superior performance over a baseline model using ChatGPT for comparison. Practitioners engaged in design and implementation of robotic systems will find Robo-CSK-Organizer truly valuable for its adequate use of commonsense reasoning (inherent in humans) due to which it is adaptable to numerous real-world applications.  © 2025 IEEE.
KW  - adaptability
KW  - AI-driven robotics
KW  - commonsense reasoning
KW  - explainable models
KW  - next-generation AI systems
KW  - Decision making
KW  - Expert systems
KW  - Industrial robots
KW  - Intelligent robots
KW  - Knowledge engineering
KW  - Robot applications
KW  - Robot Operating System
KW  - SLAM robotics
KW  - Tactile sensors
KW  - Adaptability
KW  - AI systems
KW  - AI-driven robotic
KW  - Commonsense knowledge
KW  - Commonsense reasoning
KW  - Controlled environment
KW  - Decisions makings
KW  - Next-gen AI system
KW  - Robot perception
KW  - XAI
KW  - Robot learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Luo, X.
AU  - Qin, M.
AU  - Gao, Z.
AU  - Yan, H.
AU  - Yang, X.
TI  - Ground abstract structure concepts of scaffolding systems for automatic compliance checking based on reasoning segmentation
PY  - 2025
T2  - Expert Systems with Applications
VL  - 270
C7  - 126563
DO  - 10.1016/j.eswa.2025.126563
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215589798&doi=10.1016%2fj.eswa.2025.126563&partnerID=40&md5=8fda03a1c1655a7e0a7242c01be5cbee
AB  - Manual scaffolding inspection is time-consuming and subjective, often overlooking compliance issues that contribute to collapses. This has sparked interest in automatic systems for improved safety verification. However, translating expert scaffolding specifications into computable guidelines—especially abstract structure concepts—poses challenges for fully automatic compliance checking. Although multi-modal large language models have made significant progress in grounding entity concepts, limitations remain when dealing with abstract structure concepts in the construction scaffolding domain. Specifically, models often incorrectly segment the background of tube-like shapes as target tubes or omit some target tubes. To this end, we introduce a new reasoning segmentation method that fuses shallow and deep image features using a multi-head attention mechanism. This approach enables the model to concentrate on boundary details, thereby enhancing the grounding ability of abstract structure concepts. The experimental results show that our fusion module improves the segmentation accuracy of the model under the GIoU and CIoU metrics from 54.6% and 60.7% to 60.4% and 64.2% for the reasoning segmentation approach, corresponding to an improvement of 5.8% and 3.5% in accuracy, respectively. In addition, we constructed a specialized dataset to optimize the model's training effectiveness on scaffolding abstract structure concepts of scaffolding systems. © 2025 Elsevier Ltd
KW  - Abstract structure concepts
KW  - Concept grounding
KW  - Feature fusion
KW  - Reasoning segmentation
KW  - Expert systems
KW  - Image segmentation
KW  - Abstract structure concept
KW  - Abstract structures
KW  - Automatic systems
KW  - Compliance checking
KW  - Concept grounding
KW  - Features fusions
KW  - Multi-modal
KW  - Reasoning segmentation
KW  - Safety verification
KW  - Scaffolding systems
KW  - Scaffolds
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Wagg, D.J.
AU  - Burr, C.
AU  - Shepherd, J.
AU  - Xuereb Conti, Z.
AU  - Enzer, M.
AU  - Niederer, S.
TI  - The philosophical foundations of digital twinning
PY  - 2025
T2  - Data-Centric Engineering
VL  - 6
C7  - e12
DO  - 10.1017/dce.2025.4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219085759&doi=10.1017%2fdce.2025.4&partnerID=40&md5=ed61b7cc31c195cdc9c9034d881c5811
AB  - Digital twins are a new paradigm for our time, offering the possibility of interconnected virtual representations of the real world. The concept is very versatile and has been adopted by multiple communities of practice, policymakers, researchers, and innovators. A significant part of the digital twin paradigm is about interconnecting digital objects, many of which have previously not been combined. As a result, members of the newly forming digital twin community are often talking at cross-purposes, based on different starting points, assumptions, and cultural practices. These differences are due to the philosophical world-view adopted within specific communities. In this paper, we explore the philosophical context which underpins the digital twin concept. We offer the building blocks for a philosophical framework for digital twins, consisting of 21 principles that are intended to help facilitate their further development. Specifically, we argue that the philosophy of digital twins is fundamentally holistic and emergentist. We further argue that in order to enable emergent behaviors, digital twins should be designed to reconstruct the behavior of a physical twin by dynamically assembling multiple digital components. We also argue that digital twins naturally include aspects relating to the philosophy of artificial intelligence, including learning and exploitation of knowledge. We discuss the following four questions (i) What is the distinction between a model and a digital twin? (ii) What previously unseen results can we expect from a digital twin? (iii) How can emergent behaviours be predicted? (iv) How can we assess the existence and uniqueness of digital twin outputs?  © The Author(s), 2025.
KW  - artificial intelligence
KW  - complexity
KW  - digital twin
KW  - modelling
KW  - philosophy
KW  - systems
KW  - Communities of Practice
KW  - Complexity
KW  - Digital Objects
KW  - Emergent behaviours
KW  - Modeling
KW  - Philosophy
KW  - Policy makers
KW  - Real-world
KW  - System
KW  - Virtual representations
KW  - Philosophical aspects
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Gomaa, A.
AU  - Reyes, G.
AU  - Feld, M.
AU  - Krüger, A.
TI  - Looking for a better fit? An Incremental Learning Multimodal Object Referencing Framework adapting to Individual Drivers
PY  - 2024
T2  - ACM International Conference Proceeding Series
SP  - 1
EP  - 13
DO  - 10.1145/3640543.3645152
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190970642&doi=10.1145%2f3640543.3645152&partnerID=40&md5=57f8b76126298e51f450714effe0a695
AB  - The rapid advancement of the automotive industry towards automated and semi-automated vehicles has rendered traditional methods of vehicle interaction, such as touch-based and voice command systems, inadequate for a widening range of non-driving related tasks, such as referencing objects outside of the vehicle. Consequently, research has shifted toward gestural input (e.g., hand, gaze, and head pose gestures) as a more suitable mode of interaction during driving. However, due to the dynamic nature of driving and individual variation, there are significant differences in drivers' gestural input performance. While, in theory, this inherent variability could be moderated by substantial data-driven machine learning models, prevalent methodologies lean towards constrained, single-instance trained models for object referencing. These models show a limited capacity to continuously adapt to the divergent behaviors of individual drivers and the variety of driving scenarios. To address this, we propose IcRegress, a novel regression-based incremental learning approach that adapts to changing behavior and the unique characteristics of drivers engaged in the dual task of driving and referencing objects. We suggest a more personalized and adaptable solution for multimodal gestural interfaces, employing continuous lifelong learning to enhance driver experience, safety, and convenience. Our approach was evaluated using an outside-the-vehicle object referencing use case, highlighting the superiority of the incremental learning models adapted over a single trained model across various driver traits such as handedness, driving experience, and numerous driving conditions. Finally, to facilitate reproducibility, ease deployment, and promote further research, we offer our approach as an open-source framework at https://github.com/amrgomaaelhady/IcRegress. © 2024 ACM.
KW  - Adaptive Models
KW  - Gaze Tracking
KW  - Human-Centered Artificial Intelligence
KW  - Incremental Learning
KW  - Object Referencing
KW  - Online Learning
KW  - Personalization
KW  - Pointing
KW  - Artificial intelligence
KW  - Automation
KW  - Automotive industry
KW  - E-learning
KW  - Learning systems
KW  - User interfaces
KW  - Vehicles
KW  - Adaptive models
KW  - Automated vehicles
KW  - Gaze-tracking
KW  - Human-centered artificial intelligence
KW  - Incremental learning
KW  - Multi-modal
KW  - Object referencing
KW  - Online learning
KW  - Personalizations
KW  - Pointing
KW  - Eye tracking
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Monaco, J.D.
AU  - Hwang, G.M.
TI  - Neurodynamical Computing at the Information Boundaries of Intelligent Systems
PY  - 2024
T2  - Cognitive Computation
VL  - 16
IS  - 5
SP  - 1
EP  - 13
DO  - 10.1007/s12559-022-10081-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144911499&doi=10.1007%2fs12559-022-10081-9&partnerID=40&md5=1f4f90a6b40688ae953daee1ec4f798c
AB  - Artificial intelligence has not achieved defining features of biological intelligence despite models boasting more parameters than neurons in the human brain. In this perspective article, we synthesize historical approaches to understanding intelligent systems and argue that methodological and epistemic biases in these fields can be resolved by shifting away from cognitivist brain-as-computer theories and recognizing that brains exist within large, interdependent living systems. Integrating the dynamical systems view of cognition with the massive distributed feedback of perceptual control theory highlights a theoretical gap in our understanding of nonreductive neural mechanisms. Cell assemblies—properly conceived as reentrant dynamical flows and not merely as identified groups of neurons—may fill that gap by providing a minimal supraneuronal level of organization that establishes a neurodynamical base layer for computation. By considering information streams from physical embodiment and situational embedding, we discuss this computational base layer in terms of conserved oscillatory and structural properties of cortical-hippocampal networks. Our synthesis of embodied cognition, based in dynamical systems and perceptual control, aims to bypass the neurosymbolic stalemates that have arisen in artificial intelligence, cognitive science, and computational neuroscience. © The Author(s) 2022.
KW  - Artificial intelligence
KW  - Computational neuroscience
KW  - Dynamical systems
KW  - Embodied cognition
KW  - Perceptual control theory
KW  - Robotics
KW  - Cognitive systems
KW  - Computation theory
KW  - Control theory
KW  - Intelligent systems
KW  - Neurology
KW  - Base layers
KW  - Computational neuroscience
KW  - Distributed feedback
KW  - Embodied cognition
KW  - Human brain
KW  - Living systems
KW  - Neural mechanisms
KW  - Perceptual control
KW  - Perceptual control theory
KW  - Systems view
KW  - Dynamical systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CHAP
AU  - Garg, M.
TI  - Spiritual Artificial Intelligence (SAI): Towards a New Horizon
PY  - 2025
T2  - Signals and Communication Technology
VL  - Part F3591
SP  - 1
EP  - 150
DO  - 10.1007/978-3-031-73719-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217045661&doi=10.1007%2f978-3-031-73719-0&partnerID=40&md5=1d5fc9ac8401ca553fabe0a37daf10b5
AB  - This unique book delves into the convergence of artificial intelligence (AI) principles—rooted in scientific knowledge and technological advancements—with the concept of spiritual wellness, exploring their significance in our increasingly automated and digitized world. The author offers a synthesis of two domains often perceived as distinct, appealing to both technologists and spiritual thinkers. Beginning with an exploration of the definitions and scope of "spiritual AI," the book encourages the quantification of spiritual wellness, illustrated through examples from current literature. It sheds light on the evolution of the spiritual quotient, presenting it as an integration of intelligence quotient (IQ) and emotional quotient (EQ), enhanced by dimensions of spirituality. The discussion spans various application domains and delves into the mind's entanglement-like phenomena, raising critical questions: Can a machine truly attain consciousness? How do spiritual wellness and quantum mechanics intertwine? The author invites readers to ask their own questions, contemplate the boundless possibilities of spiritual AI, and challenge existing paradigms. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
KW  - AI Ethics
KW  - Machine Morality
KW  - Neuro-Spirituality
KW  - Neuro-Symbolic AI
KW  - Quantum Mechanics
KW  - Spiritual Artificial Intelligence (SAI)
KW  - Vagus Nerve Stimulation (VNS)
KW  - Ethical aspects
KW  - Artificial intelligence ethic
KW  - Machine morality
KW  - Nerve stimulation
KW  - Neuro-spirituality
KW  - Neuro-symbolic artificial intelligence
KW  - Scientific knowledge
KW  - Spiritual artificial intelligence
KW  - Technological advancement
KW  - Vagus nerve
KW  - Vagus nerve stimulation
KW  - Quantum entanglement
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Mavridis, A.
AU  - Tegos, S.
AU  - Anastasiou, C.
AU  - Papoutsoglou, M.
AU  - Meditskos, G.
TI  - Large language models for intelligent RDF knowledge graph construction: results from medical ontology mapping
PY  - 2025
T2  - Frontiers in Artificial Intelligence
VL  - 8
C7  - 1546179
DO  - 10.3389/frai.2025.1546179
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004439718&doi=10.3389%2ffrai.2025.1546179&partnerID=40&md5=cd845a149627fd53e3c7c058ee9359ef
AB  - The exponential growth of digital data, particularly in specialized domains like healthcare, necessitates advanced knowledge representation and integration techniques. RDF knowledge graphs offer a powerful solution, yet their creation and maintenance, especially for complex medical ontologies like Systematized Nomenclature of Medicine - Clinical Terms (SNOMED CT), remain challenging. Traditional methods often struggle with the scale, heterogeneity, and semantic complexity of medical data. This paper introduces a methodology leveraging the contextual understanding and reasoning capabilities of Large Language Models (LLMs) to automate and enhance medical ontology mapping for Resource Description Framework (RDF) knowledge graph construction. We conduct a comprehensive comparative analysis of six systems–GPT-4o, Claude 3.5 Sonnet v2, Gemini 1.5 Pro, Llama 3.3 70B, DeepSeek R1, and BERTMap—using a novel evaluation framework that combines quantitative metrics (precision, recall, and F1-score) with qualitative assessments of semantic accuracy. Our approach integrates a data preprocessing pipeline with an LLM-powered semantic mapping engine, utilizing BioBERT embeddings and ChromaDB vector database for efficient concept retrieval. Experimental results on a dataset of 108 medical terms demonstrate the superior performance of modern LLMs, particularly GPT-4o, achieving a precision of 93.75% and an F1-score of 96.26%. These findings highlight the potential of LLMs in bridging the gap between structured medical data and semantic knowledge representation, toward more accurate and interoperable medical knowledge graphs. Copyright © 2025 Mavridis, Tegos, Anastasiou, Papoutsoglou and Meditskos.
KW  - health data
KW  - knowledge graph
KW  - LLM
KW  - ontology
KW  - RDF
KW  - SNOMED CT
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Alrasheedi, N.D.N.
AU  - Masseran, N.
AU  - Tajuddin, R.R.M.
TI  - A Systematic Literature Review on the Estimation of High Air Pollution Periods Using Machine Learning Approaches
PY  - 2025
T2  - Contemporary Mathematics (Singapore)
VL  - 6
IS  - 3
SP  - 3184
EP  - 3208
DO  - 10.37256/cm.6320255760
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006987853&doi=10.37256%2fcm.6320255760&partnerID=40&md5=00d6c9006058954342580191faf8da1b
AB  - Air pollution remains a pressing global issue, presenting serious threats to environmental sustainability and public health. This systematic review examines the application of machine learning (ML) techniques for predicting periods of elevated air pollution between 2016 and 2023, guided by the preferred reporting items for systematic reviews and meta-analyses (PRISMA) framework. The review encompasses a range of ML approaches-including classical algorithms, deep learning, ensemble methods, and hybrid models-evaluating their performance in improving prediction accuracy. Particular attention is given to the role of key pollutants, such as nitrogen oxides (NOx), and localized emission sources in influencing model outputs. While deep learning techniques effectively capture complex temporal patterns, ensemble and hybrid models demonstrate superior robustness and adaptability, especially in modeling spatial heterogeneity. Despite these advancements, notable challenges persist, including high computational requirements, limited generalizability across regions, and issues with data quality. By tracing the progression of ML applications in this field, the review synthesizes current achievements, outlines existing limitations, and offers strategic recommendations to enhance model scalability, interpretability, and practical deployment. The findings aim to guide researchers, policymakers, and environmental practitioners in advancing accurate and actionable air pollution forecasting through machine learning. ©2025 Nawwal Dhwaiher N Alrasheedi, et al.
KW  - air pollution estimation
KW  - environmental healths
KW  - forecasting
KW  - machine learning
KW  - systematic literature review
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Zhang, J.
AU  - Ilievski, F.
AU  - Ma, K.
AU  - Kollaa, A.
AU  - Francis, J.
AU  - Oltramari, A.
TI  - A Study of Situational Reasoning for Traffic Understanding
PY  - 2023
T2  - Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining
SP  - 3262
EP  - 3272
DO  - 10.1145/3580305.3599246
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171324019&doi=10.1145%2f3580305.3599246&partnerID=40&md5=f11530083e23f3e434260a12bc17c452
AB  - Intelligent Traffic Monitoring (ITMo) technologies hold the potential for improving road safety/security and for enabling smart city infrastructure. Understanding traffic situations requires a complex fusion of perceptual information with domain-specific and causal commonsense knowledge. Whereas prior work has provided benchmarks and methods for traffic monitoring, it remains unclear whether models can effectively align these information sources and reason in novel scenarios. To address this assessment gap, we devise three novel text-based tasks for situational reasoning in the traffic domain: i) BDD-QA, which evaluates the ability of Language Models (LMs) to perform situational decision-making, ii) TV-QA, which assesses LMs' abilities to reason about complex event causality, and iii) HDT-QA, which evaluates the ability of models to solve human driving exams. We adopt four knowledge-enhanced methods that have shown generalization capability across language reasoning tasks in prior work, based on natural language inference, commonsense knowledge-graph self-supervision, multi-QA joint training, and dense retrieval of domain information. We associate each method with a relevant knowledge source, including knowledge graphs, relevant benchmarks, and driving manuals. In extensive experiments, we benchmark various knowledge-aware methods against the three datasets, under zero-shot evaluation; we provide in-depth analyses of model performance on data partitions and examine model predictions categorically, to yield useful insights on traffic understanding, given different background knowledge and reasoning strategies.  © 2023 ACM.
KW  - language models
KW  - question answering
KW  - traffic understanding
KW  - zero-shot evaluation
KW  - Benchmarking
KW  - Computational linguistics
KW  - Decision making
KW  - Motor transportation
KW  - Natural language processing systems
KW  - Commonsense knowledge
KW  - Intelligent traffics
KW  - Knowledge graphs
KW  - Language model
KW  - Monitoring technologies
KW  - Question Answering
KW  - Road safety
KW  - Traffic monitoring
KW  - Traffic understanding
KW  - Zero-shot evaluation
KW  - Knowledge graph
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Alam, M.M.
AU  - Raff, E.
AU  - Biderman, S.
AU  - Oates, T.
AU  - Holt, J.
TI  - Holographic Global Convolutional Networks for Long-Range Prediction Tasks in Malware Detection
PY  - 2024
T2  - Proceedings of Machine Learning Research
VL  - 238
SP  - 4042
EP  - 4050
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194146273&partnerID=40&md5=173ef5ca190afe60a8380e0126c633bd
AB  - Malware detection is an interesting and valuable domain to work in because it has significant real-world impact and unique machine-learning challenges. We investigate existing long-range techniques and benchmarks and find that they’re not very suitable in this problem area. In this paper, we introduce Holographic Global Convolutional Networks (HGConv) that utilize the properties of Holographic Reduced Representations (HRR) to encode and decode features from sequence elements. Unlike other global convolutional methods, our method does not require any intricate kernel computation or crafted kernel design. HGConv kernels are defined as simple parameters learned through backpropagation. The proposed method has achieved new SOTA results on Microsoft Malware Classification Challenge, Drebin, and EMBER malware benchmarks. With log-linear complexity in sequence length, the empirical results demonstrate substantially faster run-time by HGConv compared to other methods achieving far more efficient scaling even with sequence length ≥ 100, 000. Copyright 2024 by the author(s).
KW  - Convolution
KW  - Holography
KW  - Machine learning
KW  - Convolutional networks
KW  - Holographic reduced representations
KW  - Long range prediction
KW  - Machine-learning
KW  - Malware detection
KW  - Prediction tasks
KW  - Problem areas
KW  - Property
KW  - Real-world
KW  - Sequence lengths
KW  - Malware
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Suryodiningrat, S.P.
AU  - Prabowo, H.
AU  - Ramadhan, A.
AU  - Santoso, H.B.
TI  - Identifying The Types and Platforms of the Metaverse - a Systematic Literature Review
PY  - 2022
T2  - 2022 IEEE Creative Communication and Innovative Technology, ICCIT 2022
DO  - 10.1109/ICCIT55355.2022.10118659
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159965893&doi=10.1109%2fICCIT55355.2022.10118659&partnerID=40&md5=329ea8c7301be29db7e5daa0167ae8b9
AB  - Metaverse is gaining a lot of traction lately, especially after Mark Zuckerberg's Facebook changed its name to Meta as a preparation to enter another universe called metaverse. The eXtended Reality (XR) technology is also rapidly growing since the birth of Virtual Reality (VR), followed by Augmented Reality (AR), and Mixed Reality is the latest development of XR technology. As the XR technology is the perfect companion to support the metaverse and the understanding of the metaverse is already clear but unfortunately, there is a lot of misconception about the types of the metaverse as well as the platform for each type. This paper aims to point out the types and platforms of the metaverse. 49 articles have been collected and reviewed carefully as a quality assessment process, and 45 articles have been selected for further review. This review informs everybody that there are many types and platforms of the metaverse nowadays.  © 2022 IEEE.
KW  - Metaverse
KW  - metaverse platforms
KW  - metaverse types
KW  - Augmented reality
KW  - Facebook
KW  - Latest development
KW  - Metaverse platform
KW  - Metaverse type
KW  - Metaverses
KW  - Mixed reality
KW  - Quality assessment
KW  - Systematic literature review
KW  - Mixed reality
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Castellano, G.
AU  - Vessio, G.
TI  - Deep learning approaches to pattern extraction and recognition in paintings and drawings: an overview
PY  - 2021
T2  - Neural Computing and Applications
VL  - 33
IS  - 19
SP  - 12263
EP  - 12282
DO  - 10.1007/s00521-021-05893-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103639194&doi=10.1007%2fs00521-021-05893-z&partnerID=40&md5=214e5d87960c6e964332c2c61e5083f8
AB  - This paper provides an overview of some of the most relevant deep learning approaches to pattern extraction and recognition in visual arts, particularly painting and drawing. Recent advances in deep learning and computer vision, coupled with the growing availability of large digitized visual art collections, have opened new opportunities for computer science researchers to assist the art community with automatic tools to analyse and further understand visual arts. Among other benefits, a deeper understanding of visual arts has the potential to make them more accessible to a wider population, ultimately supporting the spread of culture. © 2021, The Author(s).
KW  - Computer vision
KW  - Deep learning
KW  - Digital humanities
KW  - Literary review
KW  - Visual arts
KW  - Arts computing
KW  - Extraction
KW  - Pattern recognition
KW  - Automatic tools
KW  - Learning approach
KW  - Pattern extraction
KW  - Visual arts
KW  - Deep learning
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 64
ER  -

TY  - JOUR
AU  - Na, J.
TI  - Policy support for the promotion of the CG industry in Korea–focusing on evaluation of importance and priority
PY  - 2023
T2  - Asian Journal of Technology Innovation
VL  - 31
IS  - 2
SP  - 233
EP  - 259
DO  - 10.1080/19761597.2023.2179501
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149291345&doi=10.1080%2f19761597.2023.2179501&partnerID=40&md5=c94ac3a953ce8a90a58cc9025a2b8db5
AB  - As the COVID-19 pandemic continues, online-based business models are growing rapidly, and the demand for computer graphic (CG) technology is increasing. To boost the invigoration of the CG industry through effective support, it is necessary to understand the factors to be considered in the domestic CG industry. Accordingly, this study developed evaluation indicators to be considered for the invigoration of this industry and weighed them using AHP analysis. Specifically, a draft was created based on literature review and expert consultation, and the indicators were determined using the two-time Delphi method. The three evaluation areas of research and development, cultivation of talented people, and fostering the industry include a total of 15 evaluation indicators. The AHP results showed that ‘fostering the industry’ was the most important one among the main factors, and ‘fostering converged and combined workforce’ was the most important one among the detailed factors. The content and results of this study are expected to be used as basic data to preferentially refer to when planning and supporting policies for the invigoration of the CG industry are established with the industry, academia, and research collaboration. © KOSIME, ASIALICS, STEPI 2023.
KW  - CG industry
KW  - combined workforce
KW  - Computer graphic
KW  - digital content
KW  - XR
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Vallati, M.
AU  - Chrpa, L.
TI  - In Defence of Good Old-Fashioned Artificial Intelligence Approaches in Intelligent Transportation Systems
PY  - 2023
T2  - IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC
SP  - 4913
EP  - 4918
DO  - 10.1109/ITSC57777.2023.10422348
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180627102&doi=10.1109%2fITSC57777.2023.10422348&partnerID=40&md5=926f4565cf16b202f5d9bc89ca48fcce
AB  - In recent years, Artificial Intelligence (AI) has been increasingly used in traffic management and control, particularly in the smart city context. However, the vast majority of recent AI-based approaches rely on data-driven black-box models that hinder the ability to understand the behaviour and dynamics that lead to a given output. On the contrary, Good Old-Fashioned Artificial Intelligence approaches that are based on symbolic models, such as automated planning, can provide the transparency and explainability needed in real-world applications. This paper focuses on the benefits of using automated planning techniques in Intelligent Transportation Systems (ITS), with a focus on explainability. A case study is presented to demonstrate how the components of an automated planning system can support explainability, the types of explanations that can be obtained, and the way in which such explanations can be generated. © 2023 IEEE.
KW  - Automation
KW  - Intelligent vehicle highway systems
KW  - Automated planning
KW  - Automated planning systems
KW  - Black box modelling
KW  - Case-studies
KW  - Data driven
KW  - Intelligent transportation systems
KW  - Planning techniques
KW  - Real-world
KW  - Symbolic modeling
KW  - Traffic management and controls
KW  - Intelligent systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Cisneros-Limón, R.
AU  - Dallard, A.
AU  - Benallegue, M.
AU  - Kaneko, K.
AU  - Kaminaga, H.
AU  - Gergondet, P.
AU  - Tanguy, A.
AU  - Singh, R.P.
AU  - Sun, L.
AU  - Chen, Y.
AU  - Fournier, C.
AU  - Lorthioir, G.
AU  - Tsuru, M.
AU  - Chefchaouni-Moussaoui, S.
AU  - Osawa, Y.
AU  - Caron, G.
AU  - Chappellet, K.
AU  - Morisawa, M.
AU  - Escande, A.
AU  - Ayusawa, K.
AU  - Houhou, Y.
AU  - Kumagai, I.
AU  - Ono, M.
AU  - Shirasaka, K.
AU  - Wada, S.
AU  - Wada, H.
AU  - Kanehiro, F.
AU  - Kheddar, A.
TI  - A Cybernetic Avatar System to Embody Human Telepresence for Connectivity, Exploration, and Skill Transfer
PY  - 2025
T2  - International Journal of Social Robotics
VL  - 17
IS  - 3
SP  - 535
EP  - 562
DO  - 10.1007/s12369-023-01096-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001583080&doi=10.1007%2fs12369-023-01096-9&partnerID=40&md5=9f013ed19494cea0abe0ada05de74cdc
AB  - This paper describes the cybernetic avatar system developed by Team JANUS for connectivity, exploration, and skill transfer: the core domains targeted by the ANA Avatar XPRIZE competition, for which Team JANUS was a finalist. We used as an avatar a humanoid robot with a human-like appearance and shape that is capable of reproducing facial expressions and walking, and built an avatar control system that allowed the operator to control the avatar through equivalent mechanisms of motion; that is, by replicating the upper-body movement with naturalness and by stepping to command locomotion. In this way, we aimed to achieve high-fidelity telepresence and managed to be well evaluated from the point of view of the operator during the competition. We introduce our solutions to the integration challenges and present experimental results to asses our avatar system, together with current limitations and how we are planning to mitigate them in future work. © The Author(s), under exclusive licence to Springer Nature B.V. 2024.
KW  - Visual communication
KW  - Body movements
KW  - Current limitation
KW  - Equivalent mechanisms
KW  - Facial Expressions
KW  - High-fidelity
KW  - Human like
KW  - Humanoid robot
KW  - Skill transfer
KW  - Telepresence
KW  - Upper bodies
KW  - Anthropomorphic robots
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Ilievski, F.
AU  - Oltramari, A.
AU  - Ma, K.
AU  - Zhang, B.
AU  - McGuinness, D.L.
AU  - Szekely, P.
TI  - Dimensions of commonsense knowledge[Formula presented]
PY  - 2021
T2  - Knowledge-Based Systems
VL  - 229
C7  - 107347
DO  - 10.1016/j.knosys.2021.107347
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111834448&doi=10.1016%2fj.knosys.2021.107347&partnerID=40&md5=6167f155cba1e6390a97009d5a9cafe3
AB  - Commonsense knowledge is essential for many AI applications, including those in natural language processing, visual processing, and planning. Consequently, many sources that include commonsense knowledge have been designed and constructed over the past decades. Recently, the focus has been on large text-based sources, which facilitate easier integration with neural (language) models and application to textual tasks, typically at the expense of the semantics of the sources and their harmonization. Efforts to consolidate commonsense knowledge have yielded partial success, with no clear path towards a comprehensive solution. We aim to organize these sources around a common set of dimensions of commonsense knowledge. We survey a wide range of popular commonsense sources with a special focus on their relations. We consolidate these relations into 13 knowledge dimensions. This consolidation allows us to unify the separate sources and to compute indications of their coverage, overlap, and gaps with respect to the knowledge dimensions. Moreover, we analyze the impact of each dimension on downstream reasoning tasks that require commonsense knowledge, observing that the temporal and desire/goal dimensions are very beneficial for reasoning on current downstream tasks, while distinctness and lexical knowledge have little impact. These results reveal preferences for some dimensions in current evaluation, and potential neglect of others. © 2021 Elsevier B.V.
KW  - Commonsense knowledge
KW  - Knowledge graphs
KW  - Reasoning
KW  - Semantics
KW  - Natural language processing systems
KW  - Visual languages
KW  - AI applications
KW  - Commonsense knowledge
KW  - Down-stream
KW  - Harmonisation
KW  - Knowledge graphs
KW  - Language modeling
KW  - Language processing
KW  - Natural languages
KW  - Reasoning
KW  - Visual-processing
KW  - Semantics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 37
ER  -

TY  - JOUR
AU  - Gao, L.
AU  - Zhang, L.
AU  - Zhang, L.
AU  - Huang, J.
TI  - RSVN: A RoBERTa Sentence Vector Normalization Scheme for Short Texts to Extract Semantic Information
PY  - 2022
T2  - Applied Sciences (Switzerland)
VL  - 12
IS  - 21
C7  - 11278
DO  - 10.3390/app122111278
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141867347&doi=10.3390%2fapp122111278&partnerID=40&md5=102e0565a3116a14c9b353447ff71c49
AB  - With the explosive growth in short texts on the Web and an increasing number of Web corpora consisting of short texts, short texts are playing an important role in various Web applications. Entity linking is a crucial task in knowledge graphs and a key technology in the field of short texts that affects the accuracy of many downstream tasks in natural language processing. However, compared to long texts, the entity-linking task of Chinese short text is a challenging problem due to the serious colloquialism and insufficient contexts. Moreover, existing methods for entity linking in Chinese short text underutilize semantic information and ignore the interaction between label information and the original short text. In this paper, we propose a RoBERTa sentence vector normalization scheme for short texts to fully extract the semantic information. Firstly, the proposed model utilizes RoBERTa to fully capture contextual semantic information. Secondly, the anisotropy of RoBERTa’s output sentence vectors is revised by utilizing the standard Gaussian of flow model, which enables the sentence vectors to more precisely characterize the semantics. In addition, the interaction between label embedding and text embedding is employed to improve the NIL entity classification. Experimental results demonstrate that the proposed model outperforms existing research results and mainstream deep learning methods for entity linking in two Chinese short text datasets. © 2022 by the authors.
KW  - Chinese short text
KW  - entity linking
KW  - flow model
KW  - label embedding
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Kanth, R.K.
AU  - Ramaswamy, A.
AU  - Kumar, A.A.
AU  - Gubbi, J.
AU  - Balamuralidhar, P.
TI  - STP-Net: Spatio-Temporal Polarization Network for action recognition using polarimetric videos
PY  - 2022
T2  - Proceedings - 2022 IEEE/CVF Winter Conference on Applications of Computer Vision Workshops, WACVW 2022
SP  - 767
EP  - 776
DO  - 10.1109/WACVW54805.2022.00084
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126783916&doi=10.1109%2fWACVW54805.2022.00084&partnerID=40&md5=fc0603462501cb343fd7d31420f9e9cb
AB  - Deep learning has brought tremendous progress in computer vision and natural language processing, and is used in multiple non-critical applications. A major bottleneck for its use in many other areas is the black box nature of these algorithms, resulting in a lack of explainability in their decisions. One of the key problems identified is the confounding effect, which causes confusion between the desired causes and other irrelevant factors affecting an outcome. This is more pronounced in the spatio-temporal case, such as the bias on the static background in the classification of a video. A way to handle this is by making use of sensors that capture additional scene properties, to mitigate spurious associations. In this work, we integrate the polarimetric videos with deep learning and evaluate it on the popular action recognition problem. We construct a dataset of polarimetric videos for fine-grained actions and study the effect of various parameters, extracted from the polarimetric video frames, as inputs to a deep network. Using these observations, we design a spatio-temporal polarization network (STP-Net) to effectively extract polarimetric features. This is evaluated on the recent HumanAct12 dataset for human activity recognition. Extensive evaluation clearly shows that the polarimetric modality is able to localize the correct action regions, leading to better generalizability.  © 2022 IEEE.
KW  - Computer vision
KW  - Deep learning
KW  - Natural language processing systems
KW  - Action recognition
KW  - Black boxes
KW  - Critical applications
KW  - Fine grained
KW  - Human activity recognition
KW  - Polarimetric features
KW  - Property
KW  - Spatio-temporal
KW  - Static background
KW  - Video frame
KW  - Polarization
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Cavalcanti, A.P.
AU  - Barbosa, A.
AU  - Carvalho, R.
AU  - Freitas, F.
AU  - Tsai, Y.-S.
AU  - Gašević, D.
AU  - Mello, R.F.
TI  - Automatic feedback in online learning environments: A systematic literature review
PY  - 2021
T2  - Computers and Education: Artificial Intelligence
VL  - 2
C7  - 100027
DO  - 10.1016/j.caeai.2021.100027
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123935761&doi=10.1016%2fj.caeai.2021.100027&partnerID=40&md5=64e9f4f06cd1e91526e76f2b203c5aa3
AB  - Feedback is an essential component of scaffolding for learning. Feedback provides insights into the assistance of learners in terms of achieving learning goals and improving self-regulated skills. In online courses, feedback becomes even more critical since instructors and students are separated geographically and physically. In this context, feedback allows the instructor to customize learning content according to the students' needs. However, giving feedback is a challenging task for instructors, especially in contexts of large cohorts. As a result, several automatic feedback systems have been proposed to reduce the workload on the part of the instructor. Although these systems have started gaining research attention, there have been limited studies that systematically analyze the progress achieved so far as reported in the literature. Thus, this article presents a systematic literature review on automatic feedback generation in learning management systems. The main findings of this review are: (1) 65.07% of the studies demonstrate that automatic feedback increases student performance in activities; (2) 46.03% of the studies demonstrated that there is no evidence that automatic feedback eases instructors’ workload; (3) 82.53% of the studies showed that there is no evidence that manual feedback is more efficient than automatic feedback; and (4) the main method used for automatic feedback provision is the comparison with a desired answer in some subject (such as logic circuits or programming). © 2021 The Authors
KW  - Automatic feedback
KW  - Educational feedback
KW  - Online learning environments
KW  - Systematic review
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 255
ER  -

TY  - CONF
AU  - Bogdanović, B.
AU  - Obradović, Đ.
AU  - Segedinac, M.
AU  - Konjović, Z.
TI  - BAB Framework – Towards an Extensible Software Platform for AI-Augmented Process Aware Business Information Systems
PY  - 2024
T2  - Lecture Notes in Networks and Systems
VL  - 860 LNNS
SP  - 197
EP  - 212
DO  - 10.1007/978-3-031-71419-1_18
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206353941&doi=10.1007%2f978-3-031-71419-1_18&partnerID=40&md5=c40a0b263a762a3c9d3108845981c379
AB  - Modern businesses are client-centered, adaptable, and change-responsive systems. As such, they require information systems able to perceive, reason and act in accordance with a changeable goal. Research in the field is moving towards the development and application of business information systems with the aforementioned characteristics. However, we are still pretty far from the desired solutions, in particular those that match the needs and meet the limitations of smaller business systems where resources, specifically human, for continuous development and deployment are severely limited. This research proposes a BAB framework intended to facilitate the continuous delivery of business information systems software for smaller businesses. The proposed solution is based on the Process Aware In-formation System (PAIS) approach, semantic technologies, and open-source software. The paper presents the BAB model, the prototype implementation of the BAB tool based on the Java platform, and a proof of concept through the development of the simple real PAIS using the BAB tool. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - Artificial Intelligence
KW  - Business Information Systems
KW  - Ontology
KW  - Open Source
KW  - PAIS
KW  - Software
KW  - Artificial intelligence
KW  - Business information systems
KW  - Business systems
KW  - Development and applications
KW  - Formation systems
KW  - Ontology's
KW  - Open-source
KW  - Process aware in-formation system
KW  - Small business
KW  - Software
KW  - Software platforms
KW  - Open source software
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Finzel, B.
TI  - Toward trustworthy AI with integrative explainable AI frameworks
PY  - 2025
T2  - IT - Information Technology
DO  - 10.1515/itit-2025-0007
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003919264&doi=10.1515%2fitit-2025-0007&partnerID=40&md5=d684b6a40aac15a7242df8bdf17b5bb5
AB  - As artificial intelligence (AI) increasingly permeates high-stakes domains such as healthcare, transportation, and law enforcement, ensuring its trustworthiness has become a critical challenge. This article proposes an integrative Explainable AI (XAI) framework to address the challenges of interpretability, explainability, interactivity, and robustness. By combining XAI methods, incorporating human-AI interaction and using suitable evaluation techniques, the implementation of this framework serves as a holistic XAI approach. The article discusses the framework's contribution to trustworthy AI and gives an outlook on open challenges related to interdisciplinary collaboration, AI generalization and AI evaluation.  © 2025 the author(s), published by De Gruyter, Berlin/Boston.
KW  - EU AI act
KW  - explainable AI
KW  - integrative XAI frameworks
KW  - trustworthy AI
KW  - XAI in medicine
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Mannucci, T.
AU  - De Oliveira Filho, J.
TI  - Runtime Verification of Learning Properties for Reinforcement Learning Algorithms
PY  - 2023
T2  - Electronic Proceedings in Theoretical Computer Science, EPTCS
VL  - 395
SP  - 205
EP  - 219
DO  - 10.4204/EPTCS.395.15
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178996340&doi=10.4204%2fEPTCS.395.15&partnerID=40&md5=34d5cb770d7ccc6c90c4e02582b5d65e
AB  - Reinforcement learning (RL) algorithms interact with their environment in a trial-and-error fashion. Such interactions can be expensive, inefficient, and timely when learning on a physical system rather than in a simulation. This work develops new runtime verification techniques to predict when the learning phase has not met or will not meet qualitative and timely expectations. This paper presents three verification properties concerning the quality and timeliness of learning in RL algorithms. With each property, we propose design steps for monitoring and assessing the properties during the system's operation. © 2023 Open Publishing Association. All rights reserved.
KW  - Learning algorithms
KW  - Design steps
KW  - Learning phasis
KW  - Physical systems
KW  - Property
KW  - Reinforcement learning algorithms
KW  - Run-time verification
KW  - Systems operation
KW  - Trial and error
KW  - Verification properties
KW  - Verification techniques
KW  - Reinforcement learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Katz, G.E.
AU  - Davis, G.P.
AU  - Gentili, R.J.
AU  - Reggia, J.A.
TI  - Tunable Neural Encoding of a Symbolic Robotic Manipulation Algorithm
PY  - 2021
T2  - Frontiers in Neurorobotics
VL  - 15
C7  - 744031
DO  - 10.3389/fnbot.2021.744031
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120738485&doi=10.3389%2ffnbot.2021.744031&partnerID=40&md5=add480ddef5b30c2ad4f61647809e561
AB  - We present a neurocomputational controller for robotic manipulation based on the recently developed “neural virtual machine” (NVM). The NVM is a purely neural recurrent architecture that emulates a Turing-complete, purely symbolic virtual machine. We program the NVM with a symbolic algorithm that solves blocks-world restacking problems, and execute it in a robotic simulation environment. Our results show that the NVM-based controller can faithfully replicate the execution traces and performance levels of a traditional non-neural program executing the same restacking procedure. Moreover, after programming the NVM, the neurocomputational encodings of symbolic block stacking knowledge can be fine-tuned to further improve performance, by applying reinforcement learning to the underlying neural architecture. Copyright © 2021 Katz, Akshay, Davis, Gentili and Reggia.
KW  - explainable AI
KW  - neurosymbolic architectures
KW  - policy optimization
KW  - reinforcement learning
KW  - robotic manipulation
KW  - Encoding (symbols)
KW  - Network security
KW  - Recurrent neural networks
KW  - Reinforcement learning
KW  - Robotics
KW  - Virtual machine
KW  - Blocks worlds
KW  - Explainable AI
KW  - Neural encoding
KW  - Neurosymbolic architecture
KW  - Policy optimization
KW  - Restacking
KW  - Robotic manipulation
KW  - Symbolic algorithms
KW  - Tunables
KW  - Turing-complete
KW  - article
KW  - reinforcement learning (machine learning)
KW  - Signal encoding
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Ren, H.
AU  - Galkin, M.
AU  - Zhu, Z.
AU  - Leskovec, J.
AU  - Cochez, M.
TI  - Neural Graph Reasoning: A Survey on Complex Logical Query Answering
PY  - 2024
T2  - Transactions on Machine Learning Research
VL  - 2024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219574871&partnerID=40&md5=960e42fef954f454750f53265b715125
AB  - Complex logical query answering (CLQA) is a recently emerged task of graph machine learning that goes beyond simple one-hop link prediction and solves the far more complex task of multi-hop logical reasoning over massive, potentially incomplete graphs. The task received significant traction in the community; numerous works expanded the field along theoretical and practical axes to tackle different types of complex queries and graph modalities with efficient systems. In this paper, we provide a holistic survey of CLQA with a detailed taxonomy studying the field from multiple angles, including graph types (modality, reasoning domain, background semantics), modeling aspects (encoder, processor, decoder), supported queries (operators, patterns, projected variables), datasets, evaluation metrics, and appli-cations. Finally, we point out promising directions, unsolved problems and applications of CLQA for future research. © 2024, Transactions on Machine Learning Research. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Wang, R.
AU  - Wong, R.
AU  - Sun, D.
AU  - Ranjan, R.
TI  - SIB: Sorted-Integers-Based Index for Compact and Fast Caching in Top-Down Logic Rule Mining Targeting KB Compression
PY  - 2025
T2  - Software - Practice and Experience
VL  - 55
IS  - 6
SP  - 1071
EP  - 1085
DO  - 10.1002/spe.3415
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217013619&doi=10.1002%2fspe.3415&partnerID=40&md5=b87df0d221f38181228d5b53a7ea6689
AB  - Background: Mining logic rules from structured knowledge bases is the basis of knowledge engineering. Due to the NP-hardness of the rule mining problem, logic rules cannot be efficiently induced from knowledge bases, especially large-scale ones. Idea: In this article, we propose a compact and efficient index structure for the maintenance of the intermediate data during top-down rule mining, such that the memory consumption can be reduced and mining efficiency can be improved. Developing Points: The index is based on a mapping from constant symbols to integers and the sorting of the mapped integers. Index update has been dissembled into four basic operations. Moreover, the index itself acts as the cache during top-down mining. Value: Most contributions in existing works employ algorithmic and architectural optimizations to improve efficiency. Data-oriented optimizations have also been explored to some extent, but the data efficiency is relatively low, and the memory consumption is thus becoming a new challenge for state-of-the-art systems. We tackle this challenge in this article, and our technique has been proven more efficient than state-of-the-art systems. We evaluate our method on six datasets which contain up to 160 K records and are frequently used as benchmarks in tasks related to knowledge engineering. The experimental results show that the proposed technique speeds up the rule mining procedure by (Formula presented.) on average and reduces memory consumption by up to 70%. The space overhead of the data structure is about twice that of the indexed records, which is more than 80% lower than that of the state-of-the-art technique. © 2025 The Author(s). Software: Practice and Experience published by John Wiley & Sons Ltd.
KW  - data efficiency
KW  - data structures
KW  - indexing
KW  - knowledge bases
KW  - optimization
KW  - rule mining
KW  - Benchmarking
KW  - Cache memory
KW  - Indexing (of information)
KW  - Data efficiency
KW  - Indexing
KW  - Knowledge base
KW  - Logic rules
KW  - Memory consumption
KW  - Optimisations
KW  - Rule mining
KW  - Software practices
KW  - State-of-the-art system
KW  - Topdown
KW  - Data mining
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Tlili, A.
AU  - Huang, R.
AU  - Shehata, B.
AU  - Liu, D.
AU  - Zhao, J.
AU  - Metwally, A.H.S.
AU  - Wang, H.
AU  - Denden, M.
AU  - Bozkurt, A.
AU  - Lee, L.-H.
AU  - Beyoglu, D.
AU  - Altinay, F.
AU  - Sharma, R.C.
AU  - Altinay, Z.
AU  - Li, Z.
AU  - Liu, J.
AU  - Ahmad, F.
AU  - Hu, Y.
AU  - Salha, S.
AU  - Abed, M.
AU  - Burgos, D.
TI  - Is Metaverse in education a blessing or a curse: a combined content and bibliometric analysis
PY  - 2022
T2  - Smart Learning Environments
VL  - 9
IS  - 1
C7  - 24
DO  - 10.1186/s40561-022-00205-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133513544&doi=10.1186%2fs40561-022-00205-x&partnerID=40&md5=823bb330ba2bd1b55966322294daa8a4
AB  - The Metaverse has been the centre of attraction for educationists for quite some time. This field got renewed interest with the announcement of social media giant Facebook as it rebranding and positioning it as Meta. While several studies conducted literature reviews to summarize the findings related to the Metaverse in general, no study to the best of our knowledge focused on systematically summarizing the finding related to the Metaverse in education. To cover this gap, this study conducts a systematic literature review of the Metaverse in education. It then applies both content and bibliometric analysis to reveal the research trends, focus, and limitations of this research topic. The obtained findings reveal the research gap in lifelogging applications in educational Metaverse. The findings also show that the design of Metaverse in education has evolved over generations, where generation Z is more targeted with artificial intelligence technologies compared to generation X or Y. In terms of learning scenarios, there have been very few studies focusing on mobile learning, hybrid learning, and micro learning. Additionally, no study focused on using the Metaverse in education for students with disabilities. The findings of this study provide a roadmap of future research directions to be taken into consideration and investigated to enhance the adoption of the Metaverse in education worldwide, as well as to enhance the learning and teaching experiences in the Metaverse. © 2022, The Author(s).
KW  - Artificial intelligence
KW  - Avatar
KW  - Cyber worlds
KW  - Digital twin
KW  - Metaverse
KW  - Mirror world
KW  - Virtual worlds
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 388
ER  -

TY  - CONF
AU  - Bacellar, A.T.L.
AU  - Susskind, Z.
AU  - Breternitz, M.
AU  - John, E.
AU  - John, L.K.
AU  - Lima, P.M.V.
AU  - França, F.M.G.
TI  - Differentiable Weightless Neural Networks
PY  - 2024
T2  - Proceedings of Machine Learning Research
VL  - 235
SP  - 2277
EP  - 2295
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203790142&partnerID=40&md5=751f8f38db40db7adb576397088d5214
AB  - We introduce the Differentiable Weightless Neural Network (DWN), a model based on interconnected lookup tables. Training of DWNs is enabled by a novel Extended Finite Difference technique for approximate differentiation of binary values. We propose Learnable Mapping, Learnable Reduction, and Spectral Regularization to further improve the accuracy and efficiency of these models. We evaluate DWNs in three edge computing contexts: (1) an FPGA-based hardware accelerator, where they demonstrate superior latency, throughput, energy efficiency, and model area compared to state-of-the-art solutions, (2) a low-power microcontroller, where they achieve preferable accuracy to XGBoost while subject to stringent memory constraints, and (3) ultra-low-cost chips, where they consistently outperform small models in both accuracy and projected hardware area. DWNs also compare favorably against leading approaches for tabular datasets, with higher average rank. Overall, our work positions DWNs as a pioneering solution for edge-compatible high-throughput neural networks. https://github.com/alanbacellar/DWN. Copyright 2024 by the author(s)
KW  - Neural network models
KW  - Table lookup
KW  - % reductions
KW  - Binary values
KW  - Edge computing
KW  - Finite-difference techniques
KW  - FPGA-based hardware accelerators
KW  - Is-enabled
KW  - Lookups
KW  - Model-based OPC
KW  - Regularisation
KW  - Weightless neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Fatnassi, W.
AU  - Khedr, H.
AU  - Yamamoto, V.
AU  - Shoukry, Y.
TI  - BERN-NN: Tight Bound Propagation For Neural Networks Using Bernstein Polynomial Interval Arithmetic
PY  - 2023
T2  - HSCC 2023 - Proceedings of the 26th ACM International Conference on Hybrid Systems: Computation and Control, Part of CPS-IoT Week
C7  - 19
DO  - 10.1145/3575870.3587126
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160536670&doi=10.1145%2f3575870.3587126&partnerID=40&md5=ddc7c720aa1289797b2637ff4949b794
AB  - In this paper, we present BERN-NN as an efficient tool to perform bound propagation of Neural Networks (NNs). Bound propagation is a critical step in wide range of NN model checkers and reachability analysis tools. Given a bounded input set, bound propagation algorithms aim to compute tight bounds on the output of the NN. So far, linear and convex optimizations have been used to perform bound propagation. Since neural networks are highly non-convex, state-of-the-art bound propagation techniques suffer from introducing large errors. To circumvent such drawback, BERN-NN approximates the bounds of each neuron using a class of polynomials called Bernstein polynomials. Bernstein polynomials enjoy several interesting properties that allow BERN-NN to obtain tighter bounds compared to those relying on linear and convex approximations. BERN-NN is efficiently parallelized on graphic processing units (GPUs). Extensive numerical results show that bounds obtained by BERN-NN are orders of magnitude tighter than those obtained by state-of-the-art verifiers such as linear programming and linear interval arithmetic. Moreoveer, BERN-NN is both faster and produces tighter outputs compared to convex programming approaches like alpha-CROWN. © 2023 Copyright held by the owner/author(s).
KW  - Abstraction Refinement
KW  - Bernstein Polynomials
KW  - Neural Networks
KW  - Backpropagation
KW  - Graphics processing unit
KW  - Linear programming
KW  - Model checking
KW  - Polynomials
KW  - Program processors
KW  - Abstraction-refinement
KW  - Bernstein polynomial
KW  - Critical steps
KW  - Interval arithmetic
KW  - Model checker
KW  - Neural network model
KW  - Neural-networks
KW  - Reachability analysis
KW  - State of the art
KW  - Tight bound
KW  - Convex optimization
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Škrlj, B.
AU  - Bevec, M.
AU  - Lavrač, N.
TI  - Multimodal AutoML via Representation Evolution
PY  - 2023
T2  - Machine Learning and Knowledge Extraction
VL  - 5
IS  - 1
SP  - 1
EP  - 13
DO  - 10.3390/make5010001
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151073153&doi=10.3390%2fmake5010001&partnerID=40&md5=93b710824686957e7408cee79549c19d
AB  - With the increasing amounts of available data, learning simultaneously from different types of inputs is becoming necessary to obtain robust and well-performing models. With the advent of representation learning in recent years, lower-dimensional vector-based representations have become available for both images and texts, while automating simultaneous learning from multiple modalities remains a challenging problem. This paper presents an AutoML (automated machine learning) approach to automated machine learning model configuration identification for data composed of two modalities: texts and images. The approach is based on the idea of representation evolution, the process of automatically amplifying heterogeneous representations across several modalities, optimized jointly with a collection of fast, well-regularized linear models. The proposed approach is benchmarked against 11 unimodal and multimodal (texts and images) approaches on four real-life benchmark datasets from different domains. It achieves competitive performance with minimal human effort and low computing requirements, enabling learning from multiple modalities in automated manner for a wider community of researchers. © 2022 by the authors.
KW  - AutoML
KW  - evolution
KW  - multimodal learning
KW  - representation learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Ivanov, D.
TI  - Conceptual and formal models for design, adaptation, and control of digital twins in supply chain ecosystems
PY  - 2025
T2  - Omega (United Kingdom)
VL  - 137
C7  - 103356
DO  - 10.1016/j.omega.2025.103356
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004388039&doi=10.1016%2fj.omega.2025.103356&partnerID=40&md5=a46386134dd6dc489cc9bc85e42c3818
AB  - The design and adaptation of digital twins in supply chains are of high relevance for academia and industry alike. While numerous prototype-based use cases have been reported, the literature lacks studies revealing generalizable methodological principles. This paper elaborates on conceptual and formal models of digital twins in the supply chain. First, we define a new notion named digital supply chain ecosystem extending the recently developed intelligent digital twin framework. A digital ecosystem is a set of digital technologies, AI-based knowledge management systems, cloud spaces, and platforms that encapsulate supply chain data enabling digital twins and simulation models. Second, we elaborate on a digital twin as a complex phenomenon comprising systems, technological-organizational models, and management decision-making support perspectives. We offer a dynamic, quantitative framework for digital twins as a decision-making support and modeling environment using control theory. Third, we introduce two views of building and adapting digital twins, i.e., object-driven and data-driven approaches. Their principle schemes are defined and discussed. Finally, we outline a generalized framework of the cyber-physical supply chain comprised of a digital ecosystem, digital twin, human-AI collaboration space, and the physical supply chain. Application scenarios are considered, e.g., using digital twins for stress testing of supply chain resilience in the setting of tariff-driven shocks as well as building resilient and viable agricultural ecosystems. © 2025 The Author(s)
KW  - Artificial intelligence
KW  - Cyber-physical
KW  - Digital ecosystem
KW  - Digital twin
KW  - Resilience
KW  - Simulation
KW  - Supply chain
KW  - Information management
KW  - Knowledge engineering
KW  - Supply chain management
KW  - Conceptual model
KW  - Cyber physicals
KW  - Design adaptations
KW  - Design control
KW  - Digital ecosystem
KW  - Digital supply chain
KW  - Digital technologies
KW  - Formal modeling
KW  - Resilience
KW  - Simulation
KW  - Risk perception
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Chen, J.
AU  - Wang, J.
AU  - Song, C.
AU  - Yin, H.
TI  - JIGSAW: Efficient and Scalable Path Constraints Fuzzing
PY  - 2022
T2  - Proceedings - IEEE Symposium on Security and Privacy
VL  - 2022-May
SP  - 18
EP  - 35
DO  - 10.1109/SP46214.2022.9833796
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135915402&doi=10.1109%2fSP46214.2022.9833796&partnerID=40&md5=16da83e7156d136bd1c6387942ba5aa3
AB  - Coverage-guided testing has shown to be an effective way to find bugs. If we model coverage-guided testing as a search problem (i.e., finding inputs that can cover more branches), then its efficiency mainly depends on two factors: (1) the accuracy of the searching algorithm and (2) the number of inputs that can be evaluated per unit time. Therefore, improving the search throughput has shown to be an effective way to improve the performance of coverage-guided testing.In this work, we present a novel design to improve the search throughput: by evaluating newly generated inputs with JIT-compiled path constraints. This approach allows us to significantly improve the single thread throughput as well as scaling to multiple cores. We also developed several optimization techniques to eliminate major bottlenecks during this process. Evaluation of our prototype JIGSAW shows that our approach can achieve three orders of magnitude higher search throughput than existing fuzzers and can scale to multiple cores. We also find that with such high throughput, a simple gradient-guided search heuristic can solve path constraints collected from a large set of real-world programs faster than SMT solvers with much more sophisticated search heuristics. Evaluation of end-to-end coverage-guided testing also shows that our JIGSAW-powered hybrid fuzzer can outperform state-of-the-art testing tools.  © 2022 IEEE.
KW  - Software testing
KW  - Its efficiencies
KW  - Model coverage
KW  - Novel design
KW  - Path constraint
KW  - Per unit
KW  - Performance
KW  - Scalings
KW  - Search heuristics
KW  - Search problem
KW  - Searching algorithms
KW  - Heuristic algorithms
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 17
ER  -

TY  - JOUR
AU  - Beniwal, R.
AU  - Saraswat, P.
TI  - A hybrid BERT-CPSO model for multi-class depression detection using pure hindi and hinglish multimodal data on social media
PY  - 2024
T2  - Computers and Electrical Engineering
VL  - 120
C7  - 109786
DO  - 10.1016/j.compeleceng.2024.109786
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207952687&doi=10.1016%2fj.compeleceng.2024.109786&partnerID=40&md5=5f0bf2f7de99243c5514ce54f3bc548b
AB  - Due to the psychological strain that depression causes, there has been a noticeable increase in the number of persons compromising their lives in recent years. Social media platforms provide researchers with an entirely novel viewpoint on identifying individuals who are depressed. Previous research on automatic learning models for depression detection revealed low detection accuracy and an absence of optimizing techniques that could enhance detection accuracy. Furthermore, there is no such dataset, and very little study has been done on the multimodal pure Hindi and code-mixed Hinglish language domains. In light of this, we developed a Hindi dataset and suggested reliable methods for depression detection based on multimodal data, i.e., text and images, using the Hindi and Hinglish languages. This study aims to accomplish three things: first, it will evaluate text data using an effective Bidirectional Encoder Representations from Transformers (BERT) approach and compare it with other transfer learning variants; second, it will analyze image data by suggesting a Convolutional Neural Network (CNN) optimized with a nature-inspired algorithm, namely Particle Swarm Optimization (PSO), or CPSO; and third, it will classify the multimodal data into depressive and non-depressive posts by suggesting a hybrid of the best-performing models on text and images, namely BERT-CPSO (BTCPSO). The results produced with the BERT model showed the best accuracy of 95% for text data, in contrast to RoBERTa, DistilBERT, and XLNet. Further, CPSO outperforms other Machine Learning (ML) and Deep Learning (DL) algorithms for image data with an accuracy of 95%. Additionally, comparing the proposed CPSO with a basic CNN revealed that integrating the PSO technique with CNN increased the model's accuracy in detecting depressed posts by 5%. In conclusion, hybrid BERT-CPSO outperforms other BERT combinations with ML and DL algorithms for multimodal data, achieving 97%, 95%, 98%, and 96%, respectively, in accuracy, recall, precision, and F1-scores. As a result, the findings of comparing the suggested technique with the earlier models show the effectiveness of the approach that has been provided and can help medical professionals diagnose depression with precision. © 2024 Elsevier Ltd
KW  - Bidirectional encoder representations from transformers
KW  - Convolutional neural network
KW  - Deep learning
KW  - Depression diagnosis
KW  - Machine learning
KW  - Particle swarm optimization
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Deep neural networks
KW  - Particle swarm optimization (PSO)
KW  - Bidirectional encoder representation from transformer
KW  - Convolutional neural network
KW  - Deep learning
KW  - Depression diagnose
KW  - Detection accuracy
KW  - Machine-learning
KW  - Multi-modal
KW  - Particle swarm
KW  - Particle swarm optimization
KW  - Swarm optimization
KW  - Convolutional neural networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Chao, J.
AU  - Piotrowski, W.
AU  - Stern, R.
AU  - Ortiz-Peña, H.
AU  - Manzanares, M.
AU  - Mohan, S.
AU  - Lange, D.
TI  - Novelty Accommodating Multi-Agent Planning in High Fidelity Simulated Open World
PY  - 2024
T2  - Frontiers in Artificial Intelligence and Applications
VL  - 392
SP  - 4610
EP  - 4617
DO  - 10.3233/FAIA241055
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216651117&doi=10.3233%2fFAIA241055&partnerID=40&md5=1704595c6c7e2f384e032b33d0c4fc70
AB  - Autonomous agents operating within real-world environments often rely on automated planners to ascertain optimal actions towards desired goals or the optimization of a specified objective function. Integral to these agents are common architectural components such as schedulers, tasked with determining the timing for executing planned actions, and execution engines, responsible for carrying out these scheduled actions while monitoring their outcomes. We address the significant challenge that arises when unexpected phenomena, termed novelties, emerge within the environment, altering its fundamental characteristics, composition, and dynamics. This challenge is inherent in all deployed real-world applications and may manifest suddenly and without prior notice or explanation. The introduction of novelties into the environment can lead to inaccuracies within the planner’s internal model, rendering previously generated plans obsolete. Recent research introduced agent design aimed at detecting and adapting to such novelties. However, these designs lack consideration for action scheduling in continuous time-space, coordination of concurrent actions by multiple agents, or memory-based novelty accommodation. Additionally, the application has been primarily demonstrated in lower fidelity environments. In our study, we propose a general purpose AI agent framework designed to detect, characterize, and adapt to novelties in highly noisy, complex, and stochastic environments that support concurrent actions and external scheduling. We showcase the efficacy of our agent through experimentation within a high-fidelity simulator for realistic military scenarios. © 2024 The Authors.
KW  - Autonomous agents
KW  - Continuous time systems
KW  - Intelligent agents
KW  - Multi agent systems
KW  - Stochastic models
KW  - Architectural components
KW  - Execution engine
KW  - High-fidelity
KW  - Multi-agent planning
KW  - Objective functions
KW  - Open world
KW  - Optimal actions
KW  - Optimisations
KW  - Planned action
KW  - Real world environments
KW  - Stochastic systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Jiang, Y.-H.
AU  - Liu, T.-Y.
AU  - Zhuang, X.
AU  - Hu, H.
AU  - Li, R.
AU  - Jia, R.
TI  - Enhancing educational practices with multi-agent systems: A review
PY  - 2024
T2  - Enhancing Educational Practices: Strategies for Assessing and Improving Learning Outcomes
SP  - 47
EP  - 65
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209600714&partnerID=40&md5=4c23dba105e7c4f4659370c1e3d06632
AB  - Large Language Models (LLMs), as a kind of robust technology in natural language processing, exhibit sophisticated language comprehension and generation capabilities. Recent advancements in LLMs have spurred the rapid development of Multi-Agent Systems (MAS), which have found extensive applications in education, ushering in novel opportunities for the field. This Chapter delves into the utilization and impact of LLM-based methodologies in education. LLM- based MAS fosters more seamless and intelligent interactions with students by offering tailored teaching materials and learning assistance, thereby expanding the horizons for improving educational practices. Moreover, we examine the paradigmatic shift in MAS's role in advancing artificial intelligence (AI) for education, encompassing the transition from singular Agents to MASs from predetermined modes to LLM-driven methodologies, and from general domains to subjectspecific pedagogy. These transitions respectively facilitate the emergence of swarm intelligence, the evolution of Agents' cognitive capacities, and the acquisition of knowledge. Through a systematic review of existing literature and case studies on MAS applications in educational settings, this Chapter aims to provide comprehensive insights and inspiration for both research and practical implementations in the field of education. Additionally, it explores the potential benefits of MAS and diversified application scenarios in education, while addressing Human-Computer Interaction in MAS-driven teaching and learning environments and elucidating current challenges and future prospects. By undertaking this review, we aspire to furnish valuable references for scholars and practitioners in the educational technology domain, envisioning forthcoming technological advancements in education propelled by MAS. © 2024 Nova Science Publishers, Inc. All rights reserved. All rights reserved.
KW  - AI Agent
KW  - AI for education
KW  - Human-computer interaction
KW  - Large language model
KW  - Multi-Agent system
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - González-González, J.
AU  - de Arriba-Pérez, F.
AU  - García-Méndez, S.
AU  - Busto-Castiñeira, A.
AU  - González-Castaño, F.J.
TI  - Automatic explanation of the classification of Spanish legal judgments in jurisdiction-dependent law categories with tree estimators
PY  - 2023
T2  - Journal of King Saud University - Computer and Information Sciences
VL  - 35
IS  - 7
C7  - 101634
DO  - 10.1016/j.jksuci.2023.101634
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164335445&doi=10.1016%2fj.jksuci.2023.101634&partnerID=40&md5=933b68fd8e0ea9d782dbea25cad9c337
AB  - Automatic legal text classification systems have been proposed in the literature to address knowledge extraction from judgments and detect their aspects. However, most of these systems are black boxes even when their models are interpretable. This may raise concerns about their trustworthiness. Accordingly, this work contributes with a system combining Natural Language Processing (NLP) with Machine Learning (ML) to classify legal texts in an explainable manner. We analyze the features involved in the decision and the threshold bifurcation values of the decision paths of tree structures and present this information to the users in natural language. This is the first work on automatic analysis of legal texts combining NLP and ML along with Explainable Artificial Intelligence techniques to automatically make the models’ decisions understandable to end users. Furthermore, legal experts have validated our solution, and this knowledge has also been incorporated into the explanation process as “expert-in-the-loop” dictionaries. Experimental results on an annotated data set in law categories by jurisdiction demonstrate that our system yields competitive classification performance, with accuracy values well above 90%, and that its automatic explanations are easily understandable even to non-expert users. © 2023 The Author(s)
KW  - Human-in-the-loop
KW  - Interpretable and transparent models
KW  - Legal analysis
KW  - Machine learning
KW  - Natural language generation
KW  - Natural language processing
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 8
ER  -

TY  - JOUR
AU  - Chhetri, T.R.
AU  - Hohenegger, A.
AU  - Fensel, A.
AU  - Kasali, M.A.
AU  - Adekunle, A.A.
TI  - Towards improving prediction accuracy and user-level explainability using deep learning and knowledge graphs: A study on cassava disease
PY  - 2023
T2  - Expert Systems with Applications
VL  - 233
C7  - 120955
DO  - 10.1016/j.eswa.2023.120955
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165633499&doi=10.1016%2fj.eswa.2023.120955&partnerID=40&md5=db49fa0d731719b5c8826cc0438bd7bd
AB  - Food security is currently a major concern due to the growing global population, the exponential increase in food demand, the deterioration of soil quality, the occurrence of numerous diseases, and the effects of climate change on crop yield. Sustainable agriculture is necessary to solve this food security challenge. Disruptive technologies, such as of artificial intelligence, especially, deep learning techniques can contribute to agricultural sustainability. For example, applying deep learning techniques for early disease classification allows us to take timely action, thereby helping to increase the yield without inflicting unnecessary environmental damage, such as excessive use of fertilisers or pesticides. Several studies have been conducted on agricultural sustainability using deep learning techniques and also semantic web technologies such as ontologies and knowledge graphs. However, the three major challenges remain: (i) the lack of explainability of deep learning-based systems (e.g. disease information), especially to non-experts like farmers; (ii) a lack of contextual information (e.g. soil or plant information) and domain-expert knowledge in deep learning-based systems; and (iii) the lack of pattern learning ability of systems based on the semantic web, despite their ability to incorporate domain knowledge. Therefore, this paper presents the work on disease classification, addressing the challenges as mentioned earlier by combining deep learning and semantic web technologies, namely ontologies and knowledge graphs. The findings are: (i) 0.905 (90.5%) prediction accuracy on large noisy dataset; (ii) ability to generate user-level explanations about disease and incorporate contextual and domain knowledge; (iii) the average prediction latency of 3.8514 s on 5268 samples; (iv) 95% of users finding the explanation of the proposed method useful; and (v) 85% of users being able to understand generated explanations easily—show that the proposed method is superior to the state-of-the-art in terms of performance and explainability and is also suitable for real-world scenarios. © 2023 The Author(s)
KW  - Agricultural sustainability
KW  - Cassava
KW  - Deep learning
KW  - Explainable AI (XAI)
KW  - Knowledge graphs
KW  - Agriculture
KW  - Climate change
KW  - Deterioration
KW  - Domain Knowledge
KW  - Food supply
KW  - Forecasting
KW  - Graphic methods
KW  - Knowledge graph
KW  - Large dataset
KW  - Learning algorithms
KW  - Learning systems
KW  - Ontology
KW  - Plants (botany)
KW  - Semantic Web
KW  - Sustainable development
KW  - Agricultural sustainability
KW  - Cassavum
KW  - Deep learning
KW  - Disease classification
KW  - Explainable AI (XAI)
KW  - Food security
KW  - Knowledge graphs
KW  - Learning techniques
KW  - Prediction accuracy
KW  - User levels
KW  - Deep learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 23
ER  -

TY  - JOUR
AU  - Bezdek, M.A.
AU  - Nguyen, T.T.
AU  - Hall, C.S.
AU  - Braver, T.S.
AU  - Bobick, A.F.
AU  - Zacks, J.M.
TI  - The multi-angle extended three-dimensional activities (META) stimulus set: A tool for studying event cognition
PY  - 2023
T2  - Behavior Research Methods
VL  - 55
IS  - 7
SP  - 3629
EP  - 3644
DO  - 10.3758/s13428-022-01980-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139686277&doi=10.3758%2fs13428-022-01980-8&partnerID=40&md5=2ecca1c9fe127799335c10f98a26f01d
AB  - To study complex human activity and how it is perceived and remembered, it is valuable to have large-scale, well-characterized stimuli that are representative of such activity. We present the Multi-angle Extended Three-dimensional Activities (META) stimulus set, a structured and highly instrumented set of extended event sequences performed in naturalistic settings. Performances were captured with two color cameras and a Kinect v2 camera with color and depth sensors, allowing the extraction of three-dimensional skeletal joint positions. We tracked the positions and identities of objects for all chapters using a mixture of manual coding and an automated tracking pipeline, and hand-annotated the timings of high-level actions. We also performed an online experiment to collect normative event boundaries for all chapters at a coarse and fine grain of segmentation, which allowed us to quantify event durations and agreement across participants. We share these materials publicly to advance new discoveries in the study of complex naturalistic activity. © 2022, The Psychonomic Society, Inc.
KW  - Action perception
KW  - Event cognition
KW  - Event segmentation
KW  - Naturalistic stimuli
KW  - Norms
KW  - Cognition
KW  - Humans
KW  - adult
KW  - article
KW  - cognition
KW  - female
KW  - grain
KW  - human
KW  - human experiment
KW  - male
KW  - perception
KW  - pipeline
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Babanejad, N.
AU  - Davoudi, H.
AU  - Agrawal, A.
AU  - An, A.
AU  - Papagelis, M.
TI  - The Role of Preprocessing for Word Representation Learning in Affective Tasks
PY  - 2024
T2  - IEEE Transactions on Affective Computing
VL  - 15
IS  - 1
SP  - 254
EP  - 272
DO  - 10.1109/TAFFC.2023.3270115
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159726780&doi=10.1109%2fTAFFC.2023.3270115&partnerID=40&md5=50983f7807d99909e94f0756ce96f431
AB  - Affective tasks, including sentiment analysis, emotion classification, and sarcasm detection have drawn a lot of attention in recent years due to a broad range of useful applications in various domains. The main goal of affect detection tasks is to recognize states such as mood, sentiment, and emotions from textual data (e.g., news articles or product reviews). Despite the importance of utilizing preprocessing steps in different stages (i.e., word representation learning and building a classification model) of affect detection tasks, this topic has not been studied well. To that end, we explore whether applying various preprocessing methods (stemming, lemmatization, stopword removal, punctuation removal and so on) and their combinations in different stages of the affect detection pipeline can improve the model performance. The are many preprocessing approaches that can be utilized in affect detection tasks. However, their influence on the final performance depends on the type of preprocessing and the stages that they are applied. Moreover, the preprocessing impacts vary across different affective tasks. Our analysis provides thorough insights into how preprocessing steps can be applied in building an effect detection pipeline and their respective influence on performance.  © 2010-2012 IEEE.
KW  - Affective tasks
KW  - emotion classification
KW  - language representation
KW  - pretrained language models
KW  - sarcasm detection
KW  - sentiment analysis
KW  - text preprocessing
KW  - word embeddings
KW  - word representation
KW  - Data mining
KW  - Job analysis
KW  - Modeling languages
KW  - Pipelines
KW  - Affective task
KW  - Context models
KW  - Embeddings
KW  - Emotion classification
KW  - Language model
KW  - Language representation
KW  - Pretrained language model
KW  - Sarcasm detection
KW  - Sentiment analysis
KW  - Task analysis
KW  - Text preprocessing
KW  - Word embedding
KW  - Word representations
KW  - Sentiment analysis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 8
ER  -

TY  - CHAP
AU  - Schmid, T.
TI  - Constructivist machine learning
PY  - 2023
T2  - Compendium of Neurosymbolic Artificial Intelligence
SP  - 114
EP  - 124
DO  - 10.3233/FAIA230138
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172819814&doi=10.3233%2fFAIA230138&partnerID=40&md5=09cfe195bb32c3cd8c576d73d65eb13c
AB  - While neuro-inspired and symbolic artficial intelligence have for a long time been considered ideal complements, approaches to hybridize these concepts often lack an unifying grand theory. The way the philosophical concept of constructivism has been adapted for eductional purposes, however, provides a fruitful source of inspiration for this purpose. To this end, we have developed a framework termed Constructivist Machine Learning, which applies constructivist learning principles and exploits metadata on the grounds of Stachowiak's General Model Theory in order to bridge the gap between neuro-spired and symbolic approaches. In this chapter, we summarize our previous work in order to introduce the reader to the most important ideas and concepts. © 2023 The authors and IOS Press. All rights reserved.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Krzanowski, R.
AU  - Polak, P.
TI  - The meta-ontology of AI systems with human-level intelligence
PY  - 2022
T2  - Zagadnienia Filozoficzne w Nauce
IS  - 73
SP  - 197
EP  - 230
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151354922&partnerID=40&md5=1bd807cd03c6ae6f77b4e2ee0201b5ce
AB  - In this paper, we examine the meta-ontology of AI systems with human-level intelligence, with us denoting such AI systems as AIE. Meta-ontology in philosophy is a discourse centered on ontology, ontological commitment, and the truth condition of ontological theories. We therefore discuss how meta-ontology is conceptualized for AIE systems. We posit that the meta-ontology of AIE systems is not concerned with computational representations of reality in the form of structures, data constructs, or computational concepts, while the ontological commitment of AIE systems is directed toward what exists in the outside world. Furthermore, the truth condition of the ontology (which is meta-ontological assumption) of AIE systems does not require consistency with closed conceptual schema or ontological theories but rather with reality, or in other words, “what is the world” (Smith, 2019, p.57). In addition, the truth condition of AIE systems is verified through operational success rather than by coherence with theories. This work builds on ontological postulates about AI systems that were formulated by Brian Cantwell Smith (2019). © 2022 Copernicus Center Press. All rights reserved.
KW  - AI Paradigm
KW  - Brian Cantwell Smith
KW  - Hubert Dreyfus
KW  - human-level intelligence AI
KW  - John Haugeland
KW  - Marvin Minsky
KW  - meta-ontology of AI Paradigm
KW  - ontological commitment of AI Paradigm
KW  - ontology of AI Paradigm
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Toit, T.D.
AU  - Kruger, H.
AU  - Merwe, A.V.D.
TI  - Automated Terrain Classification with a Bayesian Hyperparameter Optimized Deep Supervised Autoencoder Model
PY  - 2023
T2  - Journal of Computer Science
VL  - 19
IS  - 9
SP  - 1073
EP  - 1086
DO  - 10.3844/JCSSP.2023.1073.1086
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175327484&doi=10.3844%2fJCSSP.2023.1073.1086&partnerID=40&md5=4d1948fa2e05429dc331fd38d82f3fb4
AB  - Terrain classification according to specific terrain attributes, has become increasingly important in certain decision-making scenarios. Automated robots are often utilized to traverse a specific surface to collect data that can be used in classification models to identify a specific terrain. In this study, a supervised autoencoder model (i.e., an autoencoder combined with a supervised learner such as a multilayer perceptron) is proposed to perform the classification of different terrains. Furthermore, a Bayes hyperparameter optimization approach is employed to determine optimum hyperparameter values. The dataset used for model building and training was obtained by driving a Lego Mindstorm EV3 mobile robot, fitted with a Raspberry Pi computer and a Sense HAT inertial measurement unit over six different terrain surfaces, i.e., asphalt, dirt, epoxy, grass, paving, and stone surfaces. The final dataset contains 281 232 data points which were used for model building. The results of the proposed supervised autoencoder were compared and contextualized with three other models, i.e., an SVM model, a logistic regression model, and an XGBoost model. Results indicate that it is not only feasible but also desirable to consider the use of a supervised autoencoder model when there is a need for terrain classifications. © 2023 Tiny du Toit, Hennie Kruger and Annette Van Der Merwe.
KW  - Bayesian Optimization
KW  - Hyperparameter Optimization
KW  - Supervised Autoencoder
KW  - Terrain Classification
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Belle, V.
TI  - Logic, Probability and Action: A Situation Calculus Perspective
PY  - 2020
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 12322 LNAI
SP  - 52
EP  - 67
DO  - 10.1007/978-3-030-58449-8_4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092087872&doi=10.1007%2f978-3-030-58449-8_4&partnerID=40&md5=b1e03664ec8e72d38b0e535b7f377c70
AB  - The unification of logic and probability is a long-standing concern in AI, and more generally, in the philosophy of science. In essence, logic provides an easy way to specify properties that must hold in every possible world, and probability allows us to further quantify the weight and ratio of the worlds that must satisfy a property. To that end, numerous developments have been undertaken, culminating in proposals such as probabilistic relational models. While this progress has been notable, a general-purpose first-order knowledge representation language to reason about probabilities and dynamics, including in continuous settings, is still to emerge. In this paper, we survey recent results pertaining to the integration of logic, probability and actions in the situation calculus, which is arguably one of the oldest and most well-known formalisms. We then explore reduction theorems and programming interfaces for the language. These results are motivated in the context of cognitive robotics (as envisioned by Reiter and his colleagues) for the sake of concreteness. Overall, the advantage of proving results for such a general language is that it becomes possible to adapt them to any special-purpose fragment, including but not limited to popular probabilistic relational models. © 2020, Springer Nature Switzerland AG.
KW  - Calculations
KW  - Computer circuits
KW  - Knowledge representation
KW  - Probability
KW  - Relational database systems
KW  - Cognitive robotics
KW  - Knowledge representation language
KW  - Logic and probability
KW  - Philosophy of science
KW  - Possible worlds
KW  - Probabilistic relational models
KW  - Programming interface
KW  - Situation calculus
KW  - Probabilistic logics
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Sarkar, S.
AU  - Gaur, M.
AU  - Chen, L.K.
AU  - Garg, M.
AU  - Srivastava, B.
TI  - A review of the explainability and safety of conversational agents for mental health to identify avenues for improvement
PY  - 2023
T2  - Frontiers in Artificial Intelligence
VL  - 6
C7  - 1229805
DO  - 10.3389/frai.2023.1229805
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174957328&doi=10.3389%2ffrai.2023.1229805&partnerID=40&md5=860c0e7744a534c04017c9f492d518de
AB  - Virtual Mental Health Assistants (VMHAs) continuously evolve to support the overloaded global healthcare system, which receives approximately 60 million primary care visits and 6 million emergency room visits annually. These systems, developed by clinical psychologists, psychiatrists, and AI researchers, are designed to aid in Cognitive Behavioral Therapy (CBT). The main focus of VMHAs is to provide relevant information to mental health professionals (MHPs) and engage in meaningful conversations to support individuals with mental health conditions. However, certain gaps prevent VMHAs from fully delivering on their promise during active communications. One of the gaps is their inability to explain their decisions to patients and MHPs, making conversations less trustworthy. Additionally, VMHAs can be vulnerable in providing unsafe responses to patient queries, further undermining their reliability. In this review, we assess the current state of VMHAs on the grounds of user-level explainability and safety, a set of desired properties for the broader adoption of VMHAs. This includes the examination of ChatGPT, a conversation agent developed on AI-driven models: GPT3.5 and GPT-4, that has been proposed for use in providing mental health services. By harnessing the collaborative and impactful contributions of AI, natural language processing, and the mental health professionals (MHPs) community, the review identifies opportunities for technological progress in VMHAs to ensure their capabilities include explainable and safe behaviors. It also emphasizes the importance of measures to guarantee that these advancements align with the promise of fostering trustworthy conversations. Copyright © 2023 Sarkar, Gaur, Chen, Garg and Srivastava.
KW  - conversational AI
KW  - evaluation metrics
KW  - explainable AI
KW  - knowledge-infused learning
KW  - mental health
KW  - safety
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 15
ER  -

TY  - JOUR
AU  - Mutlu, F.B.
AU  - Cicek, D.C.
AU  - Guler, R.B.
AU  - Kozat, S.S.
TI  - navTD3: An End-to-End Learning Approach for Indoor Navigation
PY  - 2025
T2  - Signal, Image and Video Processing
VL  - 19
IS  - 9
C7  - 725
DO  - 10.1007/s11760-025-04329-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007771698&doi=10.1007%2fs11760-025-04329-8&partnerID=40&md5=5cdb3109ff1d98d5edd1961b9536d732
AB  - Current state-of-the-art deterministic deep reinforcement learning (RL) algorithms that work on continuous action space may fail in problem-specific tasks such as autonomous driving. This work investigates why these algorithms perform poorly and proposes methods to remedy the identified problems. We present an end-to-end deep RL algorithm, navTD3, for autonomous driving tasks. navTD3 controls the throttle rather than the velocity to make our approach applicable to different autonomous vehicles. Moreover, classic deep-RL methods struggle, especially when training on autonomous driving tasks begins. In our algorithm, we develop a new exploration process to cover the state and action space of the task correctly and present a novel regularization technique called Tanh Regularization to prevent gradients from vanishing in the early stages of training. In a simulated office environment, we verify navTD3 on an autonomous ground vehicle equipped with an IMU sensor, three depth cameras, and a Bird’s Eye View map. We compare our approach with conventional deep RL algorithms, deep-deterministic policy gradients (DDPG), and twin delayed deep-deterministic policy gradients (TD3). navTD3 tackles the problems that DDPG, TD3, PPO and SAC suffer and outperforms them in terms of final performance, sample efficiency, and generalization ability. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2025.
KW  - Autonomous driving
KW  - Continuous control
KW  - Deep RL
KW  - End-to-end learning
KW  - Automobiles
KW  - Autonomous vehicles
KW  - Bicycles
KW  - Buses
KW  - Deep learning
KW  - Off road vehicles
KW  - Reinforcement learning
KW  - Action spaces
KW  - Autonomous driving
KW  - Continuous control
KW  - Deterministics
KW  - Driving tasks
KW  - End to end
KW  - End-to-end learning
KW  - Policy gradient
KW  - Reinforcement learning algorithms
KW  - Reinforcement learnings
KW  - Magnetic levitation vehicles
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Ge, Y.
AU  - Zhang, S.
AU  - Cai, Y.
AU  - Lu, T.
AU  - Wen, D.
AU  - Wang, H.
AU  - Wang, S.
TI  - A survey on applications of ontology knowledge representation in robotics
ST  - 本体知识表示方法在机器人领域的应用研究综述
PY  - 2022
T2  - Chinese Journal of Intelligent Science and Technology
VL  - 4
IS  - 2
SP  - 212
EP  - 222
DO  - 10.11959/j.issn.2096-6652.202224
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141408746&doi=10.11959%2fj.issn.2096-6652.202224&partnerID=40&md5=0e31a2d7924e325872956946e878b2fe
AB  - The technology about knowledge representation plays an increasingly important role in the autonomous operation of robots facing the complex and unstructured working environment. Knowledge representation focuses on the model of knowledge symbols and how to realize knowledge processing through reasoning procedures automatically. The robot knowledge representation framework and the latest application progress based on ontology representation and reasoning were reviewed. The technical background, realization methods of knowledge representation and reasoning, and recent research progress in the robotics field were summarized from deterministic knowledge and uncertain knowledge. And the future research direction of knowledge-enabled robots was predicted. © 2022 Japan Society for Technology of Plasticity. All rights reserved.
KW  - knowledge reasoning
KW  - knowledge representation
KW  - knowledge-enabled robot
KW  - ontology
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Trivedi, D.
AU  - Zhang, J.
AU  - Sun, S.-H.
AU  - Lim, J.J.
TI  - Learning to Synthesize Programs as Interpretable and Generalizable Policies
PY  - 2021
T2  - Advances in Neural Information Processing Systems
VL  - 30
SP  - 25146
EP  - 25163
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126901546&partnerID=40&md5=100de917732bae0b94dfdd6f284ddd25
AB  - Recently, deep reinforcement learning (DRL) methods have achieved impressive performance on tasks in a variety of domains. However, neural network policies produced with DRL methods are not human-interpretable and often have difficulty generalizing to novel scenarios. To address these issues, prior works explore learning programmatic policies that are more interpretable and structured for generalization. Yet, these works either employ limited policy representations (e.g. decision trees, state machines, or predefined program templates) or require stronger supervision (e.g. input/output state pairs or expert demonstrations). We present a framework that instead learns to synthesize a program, which details the procedure to solve a task in a flexible and expressive manner, solely from reward signals. To alleviate the difficulty of learning to compose programs to induce the desired agent behavior from scratch, we propose to first learn a program embedding space that continuously parameterizes diverse behaviors in an unsupervised manner and then search over the learned program embedding space to yield a program that maximizes the return for a given task. Experimental results demonstrate that the proposed framework not only learns to reliably synthesize task-solving programs but also outperforms DRL and program synthesis baselines while producing interpretable and more generalizable policies. We also justify the necessity of the proposed two-stage learning scheme as well as analyze various methods for learning the program embedding. Website at https://clvrai.com/leaps. © 2021 Neural information processing systems foundation. All rights reserved.
KW  - Decision trees
KW  - Embeddings
KW  - Reinforcement learning
KW  - Embeddings
KW  - Generalisation
KW  - Learn+
KW  - Network policy
KW  - Neural-networks
KW  - Performance
KW  - Program templates
KW  - Programmatics
KW  - Reinforcement learning method
KW  - State-machine
KW  - Deep learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 42
ER  -

TY  - JOUR
AU  - Giménez-García, J.M.
AU  - Vega-Gorgojo, G.
AU  - Ordóñez, C.
AU  - Crespo-Lera, N.
AU  - Bravo, F.
TI  - Improving availability and utilization of forest inventory and land use map data using Linked Open Data
PY  - 2024
T2  - Frontiers in Forests and Global Change
VL  - 7
C7  - 1329812
DO  - 10.3389/ffgc.2024.1329812
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205949013&doi=10.3389%2fffgc.2024.1329812&partnerID=40&md5=21e7c92c3d7f35b3302e14ba6c7a0deb
AB  - Introduction: Modern forestry increasingly relies on the management of large datasets, such as forest inventories and land cover maps. Governments are typically in charge of publishing these datasets, but they typically employ disparate data formats (sometimes proprietary ones) and published datasets are commonly disconnected from other sources, including previous versions of such datasets. As a result, the usage of forestry data is very challenging, especially if we need to combine multiple datasets. Methods and results: Semantic Web technologies, standardized by the World Wide Web Consortium (W3C), have emerged in the last decades as a solution to publish heterogeneous data in an interoperable way. They enable the publication of self-describing data that can easily interlink with other sources. The concepts and relationships between them are described using ontologies, and the data can be published as Linked Data on the Web, which can be downloaded or queried online. National and international agencies promote the publication of governmental data as Linked Open Data, and research fields such as biosciences or cultural heritage make an extensive use of Semantic Web technologies. In this study, we present the result of the European Cross-Forest project, addressing the integration and publication of national forest inventories and land cover maps from Spain and Portugal using Semantic Web technologies. We used a bottom-up methodology to design the ontologies, with the goal of being generalizable to other countries and forestry datasets. First, we created an ontology for each dataset to describe the concepts (plots, trees, positions, measures, and so on) and relationships between the data in detail. We converted the source data into Linked Open Data by using the ontology to annotate the data such as species taxonomies. As a result, all the datasets are integrated into one place this is the Cross-Forest dataset and are available for querying and analysis through a SPARQL endpoint. These data have been used in real-world use cases such as (1) providing a graphical representation of all the data, (2) combining it with spatial planning data to reveal the forestry resources under the management of Spanish municipalities, and (3) facilitating data selection and ingestion to predict the evolution of forest inventories and simulate how different actions and conditions impact this evolution. Discussion: The work started in the Cross-Forest project continues in current lines of research, including the addition of the temporal dimension to the data, aligning the ontologies and data with additional well-known vocabularies and datasets, and incorporating additional forestry resources. Copyright © 2024 Giménez-García, Vega-Gorgojo, Ordóñez, Crespo-Lera and Bravo.
KW  - forest inventories
KW  - land use maps
KW  - Linked Open Data
KW  - ontologies
KW  - transnational
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Chen, H.
AU  - Dreizin, D.
AU  - Gomez, C.
AU  - Zapaishchykova, A.
AU  - Unberath, M.
TI  - Interpretable Severity Scoring of Pelvic Trauma Through Automated Fracture Detection and Bayesian Inference
PY  - 2025
T2  - IEEE Transactions on Medical Imaging
VL  - 44
IS  - 1
SP  - 130
EP  - 141
DO  - 10.1109/TMI.2024.3428836
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199332242&doi=10.1109%2fTMI.2024.3428836&partnerID=40&md5=66c2bbbc772ba42fabceb8ba614e5ab0
AB  - Pelvic ring disruptions result from blunt injury mechanisms and are potentially lethal mainly due to associated injuries and massive pelvic hemorrhage. The severity of pelvic fractures in trauma victims is frequently assessed by grading the fracture according to the Tile AO/OTA classification in whole-body Computed Tomography (CT) scans. Due to the high volume of whole-body CT scans generated in trauma centers, the overall information content of a single whole-body CT scan and low manual CT reading speed, an automatic approach to Tile classification would provide substantial value, e.g., to prioritize the reading sequence of the trauma radiologists or enable them to focus on other major injuries in multi-trauma patients. In such a high-stakes scenario, an automated method for Tile grading should ideally be transparent such that the symbolic information provided by the method follows the same logic a radiologist or orthopedic surgeon would use to determine the fracture grade. This paper introduces an automated yet interpretable pelvic trauma decision support system to assist radiologists in fracture detection and Tile grading. To achieve interpretability despite processing high-dimensional whole-body CT images, we design a neurosymbolic algorithm that operates similarly to human interpretation of CT scans. The algorithm first detects relevant pelvic fractures on CTs with high specificity using Faster-RCNN. To generate robust fracture detections and associated detection (un)certainties, we perform test-time augmentation of the CT scans to apply fracture detection several times in a self-ensembling approach. The fracture detections are interpreted using a structural causal model based on clinical best practices to infer an initial Tile grade. We apply a Bayesian causal model to recover likely co-occurring fractures that may have been rejected initially due to the highly specific operating point of the detector, resulting in an updated list of detected fractures and corresponding final Tile grade. Our method is transparent in that it provides fracture location and types, as well as information on important counterfactuals that would invalidate the system's recommendation. Our approach achieves an AUC of 0.89/0.74 for translational and rotational instability,which is comparable to radiologist performance. Despite being designed for human-machine teaming, our approach does not compromise on performance compared to previous black-box methods.  © 1982-2012 IEEE.
KW  - Bayesian inference
KW  - deep learning
KW  - explainable machine learning
KW  - human-computer interaction
KW  - Algorithms
KW  - Bayes Theorem
KW  - Fractures, Bone
KW  - Humans
KW  - Pelvic Bones
KW  - Tomography, X-Ray Computed
KW  - Whole Body Imaging
KW  - Automation
KW  - Bayesian networks
KW  - Classification (of information)
KW  - Decision support systems
KW  - Deep learning
KW  - Grading
KW  - Human computer interaction
KW  - Inference engines
KW  - Three dimensional displays
KW  - Bayes method
KW  - Bayesian inference
KW  - Computed tomography
KW  - Deep learning
KW  - Explainable machine learning
KW  - Features extraction
KW  - Injury
KW  - Machine-learning
KW  - Three-dimensional display
KW  - age
KW  - Article
KW  - automation
KW  - Bayes theorem
KW  - Bayesian learning
KW  - best practice
KW  - causality
KW  - clinical significance
KW  - comparative study
KW  - computer assisted tomography
KW  - convolutional neural network
KW  - cross validation
KW  - data interpretation
KW  - decision support system
KW  - diastatic sacral fracture
KW  - disease severity
KW  - explainable artificial intelligence
KW  - false negative result
KW  - false positive result
KW  - frequency analysis
KW  - human
KW  - pelvis fracture
KW  - prediction
KW  - sacrum fracture
KW  - whole body CT
KW  - algorithm
KW  - diagnostic imaging
KW  - fracture
KW  - injury
KW  - pelvic girdle
KW  - procedures
KW  - whole body imaging
KW  - x-ray computed tomography
KW  - Feature extraction
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Li, T.
AU  - Zhang, X.
TI  - Combining Formal and Informal Information in Bayesian Program Analysis via Soft Evidences
PY  - 2025
T2  - Proceedings of the ACM on Programming Languages
VL  - 9
IS  - OOPSLA1
C7  - 143
DO  - 10.1145/3720508
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003394621&doi=10.1145%2f3720508&partnerID=40&md5=c3e25a7573758f8d38f0c03ccc5f506a
AB  - We propose a neural-symbolic style of program analysis that systematically incorporates informal information in a Datalog program analysis. The analysis is converted into a probabilistic analysis by attaching probabilities to its rules. And its output becomes a ranking of possible alarms based on their probabilities. We apply a neural network to judge how likely an analysis fact holds based on informal information such as variable names and String constants. This information is encoded as a soft evidence in the probabilistic analysis, which is a “noisy sensor” of the fact. With this information, the probabilistic analysis produces a better ranking of the alarms. We have demonstrated the effectiveness of our approach by improving a pointer analysis based on variable names on eight Java benchmarks, and a taint analysis that considers inter-component communication on eight Android applications. On average, our approach has improved the inversion count between true alarms and false alarms, mean rank of true alarms, and median rank of true alarms by 55.4%, 44.9%, and 58% on the pointer analysis, and 67.2%, 44.7%, and 37.6% on the taint analysis respectively. We also demonstrated the generality of our soft evidence mechanism by improving a taint analysis and an interval analysis for C programs using dynamic information from program executions. © 2025 Copyright held by the owner/author(s).
KW  - Bayesian Inference
KW  - Neural Networks
KW  - Program Analysis
KW  - Soft Evidences
KW  - Benchmarking
KW  - Inference engines
KW  - Markov processes
KW  - Program debugging
KW  - Bayesian
KW  - Bayesian inference
KW  - Datalog programs
KW  - Informal information
KW  - Neural-networks
KW  - Noisy sensors
KW  - Pointer analysis
KW  - Probabilistic analysis
KW  - Program analysis
KW  - Soft evidences
KW  - C (programming language)
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Suro, F.
AU  - Michel, F.
AU  - Stratulat, T.
TI  - Integration of memory systems supporting non-symbolic representations in an architecture for lifelong development of artificial agents
PY  - 2024
T2  - Artificial Intelligence
VL  - 337
C7  - 104228
DO  - 10.1016/j.artint.2024.104228
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203815273&doi=10.1016%2fj.artint.2024.104228&partnerID=40&md5=7fc497df3159e9eff2781d01c2236a30
AB  - Compared to autonomous agent learning, lifelong agent learning tackles the additional challenge of accumulating skills in a way favourable to long term development. What an agent learns at a given moment can be an element for the future creation of behaviours of greater complexity, whose purpose cannot be anticipated. Beyond its initial low-level sensorimotor development phase, the agent is expected to acquire, in the same manner as skills, values and goals which support the development of complex behaviours beyond the reactive level. To do so, it must have a way to represent and memorize such information. In this article, we identify the properties suitable for a representation system supporting the lifelong development of agents through a review of a wide range of memory systems and related literature. Following this analysis, our second contribution is the proposition and implementation of such a representation system in MIND, a modular architecture for lifelong development. The new variable module acts as a simple memory system which is strongly integrated to the hierarchies of skill modules of MIND, and allows for the progressive structuration of behaviour around persistent non-symbolic representations. Variable modules have many applications for the development and structuration of complex behaviours, but also offer designers and operators explicit models of values and goals facilitating human interaction, control and explainability. We show through experiments two possible uses of variable modules. In the first experiment, skills exchange information by using a variable representing the concept of “target”, which allows the generalization of navigation behaviours. In the second experiment, we show how a non-symbolic representation can be learned and memorized to develop beyond simple reactive behaviour, and keep track of the steps of a process whose state cannot be inferred by observing the environment. © 2024 The Author(s)
KW  - Artificial behaviour
KW  - Internal representation
KW  - Learning agents
KW  - Lifelong learning
KW  - Memory system
KW  - Modular architecture
KW  - Adversarial machine learning
KW  - Autonomous agents
KW  - Contrastive Learning
KW  - Federated learning
KW  - Learning systems
KW  - Agent learning
KW  - Artificial behavior
KW  - Internal representation
KW  - Learning agents
KW  - Life long learning
KW  - Memory systems
KW  - Modular architectures
KW  - Simple++
KW  - Structuration
KW  - Symbolic representation
KW  - Memory architecture
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Kolides, A.
AU  - Nawaz, A.
AU  - Rathor, A.
AU  - Beeman, D.
AU  - Hashmi, M.
AU  - Fatima, S.
AU  - Berdik, D.
AU  - Al-Ayyoub, M.
AU  - Jararweh, Y.
TI  - Artificial intelligence foundation and pre-trained models: Fundamentals, applications, opportunities, and social impacts
PY  - 2023
T2  - Simulation Modelling Practice and Theory
VL  - 126
C7  - 102754
DO  - 10.1016/j.simpat.2023.102754
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152094562&doi=10.1016%2fj.simpat.2023.102754&partnerID=40&md5=6a0d12075650755dabd1c12f84bc98ba
AB  - With the emergence of foundation models (FMs) that are trained on large amounts of data at scale and adaptable to a wide range of downstream applications, AI is experiencing a paradigm revolution. BERT, T5, ChatGPT, GPT-3, Codex, DALL-E, Whisper, and CLIP are now the foundation for new applications ranging from computer vision to protein sequence study and from speech recognition to coding. Earlier models had a reputation of starting from scratch with each new challenge. The capacity to experiment with, examine, and comprehend the capabilities and potentials of next-generation FMs is critical to undertaking this research and guiding its path. Nevertheless, these models are currently inaccessible as the resources required to train these models are highly concentrated in industry, and even the assets (data, code) required to replicate their training are frequently not released due to their demand in the real-time industry. At the moment, only large tech companies such as OpenAI, Google, Facebook, and Baidu can afford to construct FMs. We attempt to analyze and examine the main capabilities, key implementations, technological fundamentals, and socially constructed possible consequences of these models inside this research. Despite the expected widely publicized use of FMs, we still lack a comprehensive knowledge of how they operate, why they underperform, and what they are even capable of because of their emerging global qualities. To deal with these problems, we believe that much critical research on FMs would necessitate extensive multidisciplinary collaboration, given their essentially social and technical structure. Throughout the investigation, we will also have to deal with the problem of misrepresentation created by these systems. If FMs live up to their promise, AI might see far wider commercial use. As researchers studying the ramifications on society, we believe FMs will lead the way in massive changes. They are closely managed for the time being, so we should have time to comprehend their implications before they become a major concern. © 2023 Elsevier B.V.
KW  - Computer vision
KW  - Fine-tuning
KW  - Foundation models in robotics
KW  - Image processing
KW  - In-context learning
KW  - Machine learning models
KW  - Natural Language Processing
KW  - Pre-trained models
KW  - Self-attention
KW  - Self-supervised learning
KW  - Transfer learning
KW  - Transformers
KW  - Codes (symbols)
KW  - Foundations
KW  - Learning algorithms
KW  - Learning systems
KW  - Natural language processing systems
KW  - Speech recognition
KW  - Supervised learning
KW  - Context learning
KW  - Fine tuning
KW  - Foundation model in robotic
KW  - Foundation models
KW  - Images processing
KW  - In contexts
KW  - In-context learning
KW  - Language processing
KW  - Machine learning models
KW  - Natural language processing
KW  - Natural languages
KW  - Pre-trained model
KW  - Self-attention
KW  - Self-supervised learning
KW  - Transfer learning
KW  - Transformer
KW  - Computer vision
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 39
ER  -

TY  - CONF
AU  - Umanandhini, D.
AU  - Devi, M.S.
TI  - Arbitrary Kernel Embossed Linear Edge Filtered Residual Network Based Sports Ball Classification
PY  - 2024
T2  - 8th IEEE International Conference on Computational System and Information Technology for Sustainable Solutions, CSITSS 2024
DO  - 10.1109/CSITSS64042.2024.10816880
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216927682&doi=10.1109%2fCSITSS64042.2024.10816880&partnerID=40&md5=286884a05bf0189937dfa3f7871c2bf8
AB  - Sports ball categorization serves a number of vital purposes across several kinds of business sectors that includes sports analytics, education, recreational activities, and inventory management. These objectives are successfully met by automating and improving categorization processes using cutting-edge technologies like deep learning and computer vision. This promotes creativity and efficiency in a variety of applications. With this motivation, this paper proposes Kernel Embossed Edge Filtered ResNet (KEF-ResNet) that categorizes six classes of sports ball type more effectively. The Sports Ball Dataset that includes 2400 ball images that was used for implementation. Initially, the KEF-ResNet model divides ball images into six groups: football, rugby ball, baseball, cricket ball, bowling ball, and shuttlecock. During preprocessing, image labeling is done to the segregated images. Following the augmentation of data on the labelled ball images, ended with 50,400 ball images. To create Kernel Embossed Edge filtered (KEF) ball images, augmented ball images were subjected to the Kernel Embossed Edge with linear filter technique. The KEF ball images are used with both the proposed KEF-ResNet model and the current CNN techniques to assess the performance. With a high accuracy of 99.7%, the implementation shows that the suggested KEF-ResNet model performs well in the sports ball type classification task.  © 2024 IEEE.
KW  - accuracy
KW  - augmentation
KW  - classification
KW  - CNN
KW  - DL
KW  - filtering
KW  - kernel
KW  - ResNet
KW  - Cricket (Sports)
KW  - Deep learning
KW  - Enterprise resource management
KW  - Enterprise resource planning
KW  - Football
KW  - Information management
KW  - Labeled data
KW  - Accuracy
KW  - Activity managements
KW  - Augmentation
KW  - Ball-type
KW  - Business sector
KW  - DL
KW  - Kernel
KW  - Network-based
KW  - Recreational activities
KW  - Sports balls
KW  - Inventory control
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Zhang, Y.
AU  - Wang, Z.
AU  - Zhang, S.
AU  - Peng, Y.
AU  - Chen, M.
TI  - Boosting Robot Intelligence in Practice: Enhancing Robot Task Planning with Large Language Models
PY  - 2023
T2  - 2023 8th International Conference on Robotics and Automation Engineering, ICRAE 2023
SP  - 90
EP  - 94
DO  - 10.1109/ICRAE59816.2023.10458574
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188548721&doi=10.1109%2fICRAE59816.2023.10458574&partnerID=40&md5=55b35fbca4d50a4455847d9091745d29
AB  - Task planning capabilities are crucial for intelligent robots to operate autonomously in the physical world. However, traditional Planning Domain Definition Language (PDDL) based methods often suffer from combinatorial explosion and unsat-isfactory planning time. In this paper, we propose enhancing robot task planning with large language models (LLMs) in an innovative way - using LLMs to guide the search process of PDDL planners rather than replacing PDDL planning completely. The LLMs guide the search process of PDDL planners with learned heuristics and provide constraint reasoning to reduce the search space. To address potential pitfalls of LLMs, a verification mechanism is added at the execution stage to validate plan correctness. We evaluated our method on a real scenario, end-of-life vehicle battery disassembly. Experimental results demonstrate that incorporating LLMs into the planning pipeline can significantly improve planning efficiency and scalability while maintaining plan validity. This research provides a promising direction towards integrating language models with classical approaches to boost robot intelligence for practical applications. The proposed framework makes a solid step forward in en-hancing the task planning capability of future intelligent robotic systems. © 2023 IEEE.
KW  - LLM
KW  - robot
KW  - task planning
KW  - Computational linguistics
KW  - Robot programming
KW  - Language model
KW  - Large language model
KW  - Physical world
KW  - Planning capability
KW  - Planning domain definition language
KW  - Robot intelligences
KW  - Robot tasks
KW  - Search process
KW  - Task planning
KW  - Traditional planning
KW  - Intelligent robots
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Gutgarts, R.D.
TI  - Influence of algorithmization and interface for the preparation of management decisions
PY  - 2023
T2  - Business Informatics
VL  - 17
IS  - 3
SP  - 24
EP  - 37
DO  - 10.17323/2587-814X.2023.3.24.37
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176923468&doi=10.17323%2f2587-814X.2023.3.24.37&partnerID=40&md5=f3f8ee99d0ea18aaed5fda90f592084a
AB  - In modern conditions, managerial decision-making is carried out using automated systems under the general name “Decision Support Systems” (DSS). When creating them, it is important to consider two key points. The first is the algorithmic component, which reflects the logic of the system as a whole and its individual parts. The second is the application interface through which the user interacts with it. The interface is a graphical interpretation of the algorithms that are implemented within the system. Therefore, it is very important to design and create such a relationship between the algorithm and the interface so that the user is as comfortable as possible using the DSS to solve current tasks (information input, its processing, presentation and analysis for decision making). Thus, there is a directly proportional relationship between the interface and the algorithm. Moreover, despite the fact that there are many studies on these aspects, both theoretical and practical, there are still questions to which one should pay attention to in terms of application. The purpose of this study is to formulate practical recommendations to prevent the entry of incorrect information into the DSS database and to present the results in a form convenient for its analysis. The main tasks of the work are to show by means of examples which errors can contribute to the entry of unreliable information into the database, as well as how best to present information on the monitor screen in accordance with the psychophysiological characteristics of a person in order to reduce the time for its analysis and decision-making. © 2023 National Research University, Higher School of Econoimics. All rights reserved
KW  - decision support systems
KW  - error handling when entering information
KW  - features of algorithmization
KW  - interrelation of the interface and algorithms
KW  - presentation of information
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Amado, L.
AU  - Shainkopf, S.P.
AU  - Pereira, R.F.
AU  - Mirsky, R.
AU  - Meneguzzi, F.
TI  - A Survey on Model-Free Goal Recognition
PY  - 2024
T2  - IJCAI International Joint Conference on Artificial Intelligence
SP  - 7923
EP  - 7931
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204312919&partnerID=40&md5=e6d58d9c78a2727191f7f11be4f67e37
AB  - Goal Recognition is the task of inferring an agent's intentions from a set of observations. Existing recognition approaches have made considerable advances in domains such as human-robot interaction, intelligent tutoring systems, and surveillance. However, most approaches rely on explicit domain knowledge, often defined by a domain expert. Much recent research focus on mitigating the need for a domain expert while maintaining the ability to perform quality recognition, leading researchers to explore Model-Free Goal Recognition approaches. We comprehensively survey Model-Free Goal Recognition, and provide a perspective on the state-of-the-art approaches and their applications, showing recent advances. We categorize different approaches, introducing a taxonomy with a focus on their characteristics, strengths, weaknesses, and suitability for different scenarios. We compare the advances each approach made to the state-of-the-art and provide a direction for future research in Model-Free Goal Recognition. © 2024 International Joint Conferences on Artificial Intelligence. All rights reserved.
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Domain Knowledge
KW  - Educational robots
KW  - Federated learning
KW  - Human robot interaction
KW  - Intelligent robots
KW  - Intelligent systems
KW  - Machine learning
KW  - Teaching
KW  - Domain experts
KW  - Domain knowledge
KW  - Humans-robot interactions
KW  - Intelligent tutoring
KW  - Model free
KW  - Quality recognition
KW  - Recent researches
KW  - Research focus
KW  - State-of-the-art approach
KW  - Tutoring system
KW  - Chatbots
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Nagaraj, J.
AU  - Anny Leema, A.
TI  - An Exhaustive Study on Deep Neural Network-based Prediction of Heart Diseases and its Interpretations
PY  - 2023
T2  - Open Biomedical Engineering Journal 
VL  - 17
C7  - e187412072210310
DO  - 10.2174/18741207-v16-e221031-2022-HT27-3589-16
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161964935&doi=10.2174%2f18741207-v16-e221031-2022-HT27-3589-16&partnerID=40&md5=545f384233ecf6c283c6704bf39bf693
AB  - Cardiovascular disease prediction is important in day-to-day life. A tool to diagnose cardiovascular diseases is an Electrocardiogram (ECG), which records electrical activities happening in the heart through a wave. A determination is made by checking the wave changes in an ECG. Predicting wave changes and diagnosing the disease requires domain expertise like cardiologists/physicians. Deep Neural Network techniques extract the features accurately and automatically predict the type of disease. This article lists different types of cardiac disorders, and parallelly different disease interpretations of all types of diseases are discussed to manually identify the disease type; segmentation of leads, pre-trained models, and different detection techniques are discussed to predict the type of diseases from an ECG image. Finally, this article discussed the different challenges in predicting heart diseases, and solutions to some of the challenges are given. © 2023 Nagaraj and Leema A.
KW  - 12 Lead ECG
KW  - Cardiovascular Disease
KW  - Challenges
KW  - Deep Neural Network (DNN)
KW  - ECG image
KW  - Heart diseases
KW  - aged
KW  - cardiologist
KW  - cardiovascular disease
KW  - deep neural network
KW  - diagnosis
KW  - electric activity
KW  - electrocardiogram
KW  - electrocardiography
KW  - heart disease
KW  - human
KW  - major clinical study
KW  - prediction
KW  - review
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Zheng, J.
AU  - Hong, W.
TI  - Construction of Knowledge Graph of 3D Clothing Design Resources Based on Multimodal Clustering Network
PY  - 2022
T2  - Computational Intelligence and Neuroscience
VL  - 2022
C7  - 1168012
DO  - 10.1155/2022/1168012
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131850507&doi=10.1155%2f2022%2f1168012&partnerID=40&md5=0f96b3ab4929d686537966fba8f50ce2
AB  - The construction of 3D design model is a hotspot of applied research in the fields of clothing functional design system teaching and display. The simple 3D clothing visualization postprocessing lacks interactive functions, which is a hot issue that needs to be solved urgently at present. Based on analyzing the existing clothing modeling technology, template technology, and fusion technology, and based on the multimodal clustering network theory, this paper proposes a 3D clothing design resource knowledge graph modeling method with multiple fusion of features and templates. The position of each joint point is converted into the coordinate system centered on the torso point in advance and normalized to avoid the problem that the relative position of the camera and the collector cannot be determined, and the shape of different collectors is different. The paper provides a multimodal clustering network intelligence method, illustrates the interoperability of users switching between different design networks in the seamless connection movement, and combines the hybrid intelligence algorithm with the fuzzy logic interpretation algorithm to solve the problems in the field of 3D clothing design service quality. During the simulation process, the research scheme builds a logical multimodal clustering network framework, which integrates compatibility access and global access partition fusion of style templates to achieve information extraction of clothing parts. The experimental results show that the realistic 3D clothing modeling can be achieved by layering the 3D clothing map, contour features, clothing size features, and color texture features with the modeling template. The developed ActiveX control is mounted on MSN, and the system is compatible. The performance and integration rate reached 77.1% and 89.7%, respectively, which effectively strengthened the practical role of the 3D clothing design system.  © 2022 Jia Zheng and Wei Hong.
KW  - 3D modeling
KW  - Graph theory
KW  - Interoperability
KW  - Knowledge graph
KW  - Textures
KW  - Three dimensional computer graphics
KW  - 3-d designs
KW  - Clothing design
KW  - Clustering networks
KW  - Design models
KW  - Design resources
KW  - Design systems
KW  - Hotspots
KW  - Knowledge graphs
KW  - Multi-modal
KW  - Resources based
KW  - Fuzzy logic
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Kumar, A.
AU  - Singh, D.
AU  - Jain, R.
AU  - Jain, D.K.
AU  - Gan, C.
AU  - Zhao, X.
TI  - Advances in DeepFake detection algorithms: Exploring fusion techniques in single and multi-modal approach
PY  - 2025
T2  - Information Fusion
VL  - 118
C7  - 102993
DO  - 10.1016/j.inffus.2025.102993
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217076551&doi=10.1016%2fj.inffus.2025.102993&partnerID=40&md5=84400d41ba6e4fb38effcf96acb43f3e
AB  - In recent years, generative artificial intelligence has gained momentum and created extremely realistic synthetic multimedia content that can spread misinformation and mislead society. Deepfake detection is a technique consisting of frameworks, algorithms and approaches to predict manipulated contents namely, image, audio and video. To this end, we have analyzed and explored various deepfake detection frameworks by categorizing them as single-modal or multi-modal approaches. To provide better understanding and clarity, single-modal approaches are further categorized as conventional and advanced techniques. Conventional techniques extract complementary handcrafted features and classify them using machine-learning-based algorithms. On the other hand, advanced techniques adopt deep learning and hybrid algorithms to detect deepfakes. Multi-modal techniques utilize a mixture of two or more modalities for feature extraction and fuse them to obtain the final classification scores. These techniques are also categorized either as deep learning or hybrid techniques. The complementary features, multiple modalities, and deep learning models are fused adaptively using score-level or feature-level fusion. The advantages, features, practical applications, and limitations under each category are highlighted to address the challenges and determine future trends to counter deepfakes. In addition, recommendations are also elaborated to evaluate the potential of artificial intelligence in deepfake detection for providing a safer and more reliable digital world. © 2025
KW  - Artificial intelligence
KW  - DeepFake
KW  - Detection
KW  - Fusion algorithms
KW  - Generative adversarial network
KW  - Transformer
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Adversarial networks
KW  - Deepfake
KW  - Detection
KW  - Detection algorithm
KW  - Fusion algorithms
KW  - Fusion techniques
KW  - Multi-modal approach
KW  - Multimedia contents
KW  - Single-modal
KW  - Transformer
KW  - Generative adversarial networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Perisic, A.
AU  - Perisic, B.
TI  - Digital Twins Verification and Validation Approach through the Quintuple Helix Conceptual Framework
PY  - 2024
T2  - Electronics (Switzerland)
VL  - 13
IS  - 16
C7  - 3303
DO  - 10.3390/electronics13163303
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202691860&doi=10.3390%2felectronics13163303&partnerID=40&md5=fee3346da50747731e1e09e9a7f6920b
AB  - The concept of digital twins has been in the field for a long time, constantly challenging the specification, modeling, design, implementation, and exploitation of complex cyber–physical systems. Despite the various foundations, standards, and platforms in systems engineering, there are ongoing challenges with verification and validation methodology. This study aims to establish a generic framework that addresses the various aspects of digital twinning. The multifaceted nature of the problem requires raising the abstraction level in both the real (actual) and virtual domains, effective dissemination of information resources, and a design inspired by verification and validation. The proposed framework combines the quintuple helix model with the problem and operational domains of a real (actual) twin, the solution and implementation domains of a virtual twin, and the execution domain as the bridge that links them. Verification and validation dimensions follow the meta object facility abstraction layers (instance, model, meta-model, and meta-meta-model) mapping over five helices. Embedding the complexity reduction mechanisms in the proposed framework builds a suite for extendible and verifiable digital twinning in simulation and real-time scenarios. The application of main conceptual framework mechanisms in a real-world example study aids the verification of this research’s intentions. The validation is a matter of further research endeavors. © 2024 by the authors.
KW  - cyber-critical systems
KW  - digital twins
KW  - domain-specific modeling
KW  - helix models
KW  - meta object facility
KW  - quintuple helix model
KW  - system-of-systems
KW  - validation
KW  - verification
KW  - verification frameworks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Kozierok, R.
AU  - Aberdeen, J.
AU  - Clark, C.
AU  - Garay, C.
AU  - Goodman, B.
AU  - Korves, T.
AU  - Hirschman, L.
AU  - McDermott, P.L.
AU  - Peterson, M.W.
TI  - Assessing Open-Ended Human-Computer Collaboration Systems: Applying a Hallmarks Approach
PY  - 2021
T2  - Frontiers in Artificial Intelligence
VL  - 4
C7  - 670009
DO  - 10.3389/frai.2021.670009
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117889314&doi=10.3389%2ffrai.2021.670009&partnerID=40&md5=3f6b2a34f31a37963d2448a76f2630ca
AB  - There is a growing desire to create computer systems that can collaborate with humans on complex, open-ended activities. These activities typically have no set completion criteria and frequently involve multimodal communication, extensive world knowledge, creativity, and building structures or compositions through multiple steps. Because these systems differ from question and answer (Q&A) systems, chatbots, and simple task-oriented assistants, new methods for evaluating such collaborative computer systems are needed. Here, we present a set of criteria for evaluating these systems, called Hallmarks of Human-Machine Collaboration. The Hallmarks build on the success of heuristic evaluation used by the user interface community and past evaluation techniques used in the spoken language and chatbot communities. They consist of observable characteristics indicative of successful collaborative communication, grouped into eight high-level properties: robustness; habitability; mutual contribution of meaningful content; context-awareness; consistent human engagement; provision of rationale; use of elementary concepts to teach and learn new concepts; and successful collaboration. We present examples of how we used these Hallmarks in the DARPA Communicating with Computers (CwC) program to evaluate diverse activities, including story and music generation, interactive building with blocks, and exploration of molecular mechanisms in cancer. We used the Hallmarks as guides for developers and as diagnostics, assessing systems with the Hallmarks to identify strengths and opportunities for improvement using logs from user studies, surveying the human partner, third-party review of creative products, and direct tests. Informal feedback from CwC technology developers indicates that the use of the Hallmarks for program evaluation helped guide development. The Hallmarks also made it possible to identify areas of progress and major gaps in developing systems where the machine is an equal, creative partner. © Copyright © 2021 The MITRE Corporation.
KW  - assessment
KW  - collaborative assistants
KW  - dialogue
KW  - evaluation
KW  - human-machine teaming
KW  - multimodal
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Chatterjee, K.
AU  - Henzinger, T.A.
AU  - Lechner, M.
AU  - Žikelić, Đ.
TI  - A Learner-Verifier Framework for Neural Network Controllers and Certificates of Stochastic Systems
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 13993 LNCS
SP  - 3
EP  - 25
DO  - 10.1007/978-3-031-30823-9_1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161373548&doi=10.1007%2f978-3-031-30823-9_1&partnerID=40&md5=211ed8a3c4fed79f9f6a022f4027de88
AB  - Reinforcement learning has received much attention for learning controllers of deterministic systems. We consider a learner-verifier framework for stochastic control systems and survey recent methods that formally guarantee a conjunction of reachability and safety properties. Given a property and a lower bound on the probability of the property being satisfied, our framework jointly learns a control policy and a formal certificate to ensure the satisfaction of the property with a desired probability threshold. Both the control policy and the formal certificate are continuous functions from states to reals, which are learned as parameterized neural networks. While in the deterministic case, the certificates are invariant and barrier functions for safety, or Lyapunov and ranking functions for liveness, in the stochastic case the certificates are supermartingales. For certificate verification, we use interval arithmetic abstract interpretation to bound the expected values of neural network functions. © 2023, The Author(s).
KW  - Formal verification
KW  - Learning-based control
KW  - Martingales
KW  - Stochastic systems
KW  - Controllers
KW  - Formal verification
KW  - Learning systems
KW  - Reinforcement learning
KW  - Stochastic control systems
KW  - Control policy
KW  - Deterministic systems
KW  - Learning controllers
KW  - Learning-based control
KW  - Martingale
KW  - Neural network controllers
KW  - Property
KW  - Reachability
KW  - Reinforcement learnings
KW  - Safety property
KW  - Stochastic systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 10
ER  -

TY  - CONF
AU  - Sharma, P.
AU  - Torralba, A.
AU  - Andreas, J.
TI  - Skill Induction and Planning with Latent Language
PY  - 2022
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
VL  - 1
SP  - 1713
EP  - 1726
DO  - 10.18653/v1/2022.acl-long.120
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134406829&doi=10.18653%2fv1%2f2022.acl-long.120&partnerID=40&md5=ef0e323ecc3f6a0833c7f391e4bd2663
AB  - We present a framework for learning hierarchical policies from demonstrations, using sparse natural language annotations to guide the discovery of reusable skills for autonomous decision-making. We formulate a generative model of action sequences in which goals generate sequences of high-level subtask descriptions, and these descriptions generate sequences of low-level actions. We describe how to train this model using primarily unannotated demonstrations by parsing demonstrations into sequences of named high-level subtasks, using only a small number of seed annotations to ground language in action. In trained models, natural language commands index a combinatorial library of skills; agents can use these skills to plan by generating high-level instruction sequences tailored to novel goals. We evaluate this approach in the ALFRED household simulation environment, providing natural language annotations for only 10% of demonstrations. It achieves task completion rates comparable to state-of-the-art models (outperforming several recent methods with access to ground-truth plans during training and evaluation) while providing structured and human-readable high-level plans. © 2022 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Computer simulation languages
KW  - Decision making
KW  - Action sequences
KW  - Autonomous decision
KW  - Combinatorial library
KW  - Decisions makings
KW  - Generative model
KW  - Hierarchical policy
KW  - Natural languages
KW  - Simulation environment
KW  - State of the art
KW  - Subtask
KW  - Demonstrations
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 32
ER  -

TY  - JOUR
AU  - Zhang, Z.
AU  - Zhang, L.
AU  - Wu, J.
AU  - Guo, W.
TI  - Optical and Synthetic Aperture Radar Image Fusion for Ship Detection and Recognition: Current state, challenges, and future prospects
PY  - 2024
T2  - IEEE Geoscience and Remote Sensing Magazine
VL  - 12
IS  - 4
SP  - 132
EP  - 168
DO  - 10.1109/MGRS.2024.3404506
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196098128&doi=10.1109%2fMGRS.2024.3404506&partnerID=40&md5=47b53ed166cedb40ab2f70f04b01e8a8
AB  - The detection and recognition of ships hold crucial significance across various domains, including transportation, fishing, smuggling prevention, and rescue operations. To achieve accurate and efficient ship detection and recognition, remote sensing technologies, specifically optical and synthetic aperture radar (SAR) sensors, have been widely employed. However, each sensor modality presents its own limitations, such as cloud cover in optical images and interference in SAR images, resulting in restricted data availability and false alarms during detection. This paper provides a comprehensive summary of recent advancements in the fusion of optical and SAR images for ship detection and recognition. Meanwhile, the fusion of remote sensing images and in situ data, such as automatic identification system (AIS) data, is briefly summarized, considering their significant benefits and technical trends. This paper highlights the immense potential of integrating these two sensor modalities to overcome individual challenges and enhance overall system performance. One of the primary challenges addressed in this work pertains to accurately matching ship targets between optical and SAR images when ships change positions. However, recently developed multi-modal fusion networks and transfer learning techniques have the potential to tackle the challenges, even with unmatched optical and SAR image pairs. In addition to summarizing existing techniques, the paper delves into the future perspective of fusion-based ship detection and recognition. In conclusion, this survey highlights the current state of optical and SAR image fusion techniques, pinpoints existing challenges, and outlines future research prospects, emphasizing the significance of fusion-based approaches in shaping the future of maritime applications.  © 2013 IEEE.
KW  - Automation
KW  - Geometrical optics
KW  - Optical remote sensing
KW  - Radar imaging
KW  - Ships
KW  - Synthetic aperture radar
KW  - 'current
KW  - Future prospects
KW  - Optical-
KW  - Radar sensors
KW  - Remote sensing technology
KW  - Rescue operations
KW  - Sensor modality
KW  - Ship detection
KW  - Ship recognition
KW  - Synthetic aperture radar images
KW  - detection method
KW  - future prospect
KW  - image analysis
KW  - maritime transportation
KW  - satellite imagery
KW  - ship design
KW  - synthetic aperture radar
KW  - Image fusion
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 14
ER  -

TY  - CONF
AU  - Guaki, G.S.
AU  - Genove, G.P.
TI  - A Literature Review on Low Code and No Code (LCNC) Platforms in Reshaping Web and Application Development
PY  - 2025
T2  - AIP Conference Proceedings
VL  - 3287
IS  - 1
C7  - 030021
DO  - 10.1063/5.0262017
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002338114&doi=10.1063%2f5.0262017&partnerID=40&md5=055eca9b4b47a90d2ab2bf68f92d5b7d
AB  - This study aimed to scrutinize Low- Code and No Code (LCNC) development issues and challenges and solutions through literature survey method. There were 53 chosen literatures from different research databases that were used to realize these specific objectives: list the challenges involved in the development, integration and deployment of LCNC; identify solutions of the listed gaps; and identify emerging trends that can affect the use and capabilities of LCNC platforms. Findings for the challenges were the following: issues on integration with other technologies, customization limitations, limited technical knowledge of citizen developers, need of high- level testing automation and deployment constraints. On the other hand, solutions to these challenges can be solved by approaches such as the following: Linear Temporal Logic (LTL), Test Description Language (TDL), Model- based Testing (MBT) and integration of AI and ML. Lastly, it was noted by several authors AI and Machine Learning are the trending approaches to enhance capabilities of LCNC. © 2025 American Institute of Physics Inc.. All rights reserved.
KW  - low-code development
KW  - Low-Code-No-Code (LCNC)
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Kudalkar, V.
AU  - Hashemi, N.
AU  - Mukhopadhyay, S.
AU  - Mallick, S.
AU  - Budnik, C.
AU  - Nagaraja, P.
AU  - Deshmukh, J.V.
TI  - Sampling-Based and Gradient-Based Efficient Scenario Generation
PY  - 2025
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 
VL  - 15191 LNCS
SP  - 70
EP  - 88
DO  - 10.1007/978-3-031-74234-7_5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207660815&doi=10.1007%2f978-3-031-74234-7_5&partnerID=40&md5=61b2d9fd395a5678c2d253dd740571aa
AB  - Safety-critical autonomous systems often operate in highly uncertain environments. These environments consist of many agents, some of which are being designed, and some represent the uncertain aspects of the environment. Testing autonomous systems requires generating diverse scenarios. However, the space of scenarios is very large, and many scenarios do not represent edge cases of the system. We want to develop a framework for automatically generating interesting scenarios. We propose to describe scenarios using a formal language. We show how we can extract interesting scenarios using scenario specifications from sampling-based approaches for scenario generation. We also introduce another technique for edge-case scenario generation using the gradient computation over STL. We demonstrate the capability of our framework in scenario generation in two case studies of autonomous systems involving the autonomous driving domain and the safety of human-robot systems in an industrial manufacturing context. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
KW  - Autonomous Systems
KW  - Neurosymbolic Testing
KW  - Scenario Generation
KW  - Temporal Logic
KW  - Human robot interaction
KW  - Industrial robots
KW  - Specification languages
KW  - Autonomous driving
KW  - Autonomous system
KW  - Case-studies
KW  - Gradient based
KW  - Gradients computation
KW  - Neurosymbolic testing
KW  - Sampling-based
KW  - Scenario specification
KW  - Scenarios generation
KW  - Uncertain environments
KW  - Temporal logic
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Roy, K.
AU  - Garg, T.
AU  - Palit, V.
TI  - Knowledge Graph Guided Semantic Evaluation of Language Models For User Trust
PY  - 2023
T2  - Proceedings - 2023 IEEE Conference on Artificial Intelligence, CAI 2023
SP  - 234
EP  - 236
DO  - 10.1109/CAI54212.2023.00108
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168704444&doi=10.1109%2fCAI54212.2023.00108&partnerID=40&md5=c0ce1f2cb00152b17f9feca07f79c0e6
AB  - A fundamental question in natural language processing is - what kind of language structure and semantics is the language model capturing? Graph formats such as knowledge graphs are easy to evaluate as they explicitly express language semantics and structure. This study evaluates the semantics encoded in the self-attention transformers by leveraging explicit knowledge graph structures. We propose novel metrics to measure the reconstruction error when providing graph path sequences from a knowledge graph and trying to reproduce/reconstruct the same from the outputs of the self-attention transformer models. The opacity of language models has an immense bearing on societal issues of trust and explainable decision outcomes. Our findings suggest that language models are models of stochastic control processes for plausible language pattern generation. However, they do not ascribe object and concept-level meaning and semantics to the learned stochastic patterns such as those described in knowledge graphs. This has significant application-level user trust implications as stochastic patterns without a strong sense of meaning cannot be trusted in high-stakes applications.  © 2023 IEEE.
KW  - Graph Neural Networks
KW  - Knowledge Graph
KW  - Transformers
KW  - Computational linguistics
KW  - Graph neural networks
KW  - Graphic methods
KW  - Knowledge management
KW  - Natural language processing systems
KW  - Semantics
KW  - Stochastic control systems
KW  - Stochastic models
KW  - Stochastic systems
KW  - Graph neural networks
KW  - Knowledge graphs
KW  - Language model
KW  - Language processing
KW  - Language semantics
KW  - Language structure
KW  - Natural languages
KW  - Semantic evaluations
KW  - Stochastics
KW  - Transformer
KW  - Knowledge graph
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Hidalgo, R.
AU  - Parron, J.
AU  - Varde, A.S.
AU  - Wang, W.
TI  - Robo-CSK-Organizer: Commonsense Knowledge to Organize Detected Objects for Multipurpose Robots
PY  - 2025
T2  - Lecture Notes in Electrical Engineering
VL  - 1228
SP  - 65
EP  - 81
DO  - 10.1007/978-981-97-4784-9_5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218466593&doi=10.1007%2f978-981-97-4784-9_5&partnerID=40&md5=2ba79df4cb34d1f09a263c08183df19d
AB  - In the rapidly evolving field of robotics, integration of commonsense knowledge (CSK) in AI systems is becoming highly crucial to enhance the decision-making capabilities of robots, especially in next-generation multipurpose environments. This paper presents Robo-CSK-Organizer, a pioneering system that employs CSK, via a classical knowledge base, to facilitate sophisticated task-based object organization helpful in multipurpose robots. Unlike systems relying solely on deep learning tools such as ChatGPT, our Robo-CSK-Organizer system stands out in various crucial aspects. This includes (1) its ability to resolve ambiguities and maintain consistency in object placement; (2) its adaptability to diverse task-based classifications; and moreover, (3) its contributions to explainable AI (XAI), consequently helping to foster trust and human–robot collaboration. This system’s efficacy is underlined by DETIC (DEtector with Image Classes), an advanced extension of Detectron2 for object identification; BLIP (Bootstrapping Language-Image Pre-training) for context discernment; and most vitally by the adaptation of ConceptNet, a well-grounded commonsense knowledge base for reasoning based on semantic as well as pragmatic knowledge. While we deploy ConceptNet to extract CSK, the process in Robo-CSK-Organizer is generic enough to be replicated with other state-of-the-art knowledge bases. Controlled experiments and real-world applications, synopsized in this paper, make Robo-CSK-Organizer demonstrate superior performance in placing objects in contextually relevant locations, highlighting its clear capacity for commonsense-guided decision-making closer to the thresholds of human cognition. Hence, Robo-CSK-Organizer makes valuable contributions to Robotics and AI. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.
KW  - AI-robotics bridge
KW  - Commonsense reasoning
KW  - Explainable models
KW  - Multipurpose robots
KW  - Next-generation AI systems
KW  - Task classification
KW  - Adversarial machine learning
KW  - Case based reasoning
KW  - Decision making
KW  - Deep learning
KW  - Human robot interaction
KW  - Knowledge based systems
KW  - Semantics
KW  - AI systems
KW  - AI-robotic bridge
KW  - Commonsense knowledge
KW  - Commonsense reasoning
KW  - ConceptNet
KW  - Decisions makings
KW  - Explainable model
KW  - Next-generation AI system
KW  - Task classification
KW  - Task-based
KW  - Multipurpose robots
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - BOOK
AU  - Chun, W.H.
TI  - Foundations of Artificial Intelligence and Robotics: A Holistic View: Volume 1
PY  - 2024
T2  - Foundations of Artificial Intelligence and Robotics: A Holistic View: Volume 1
VL  - 1
SP  - 1
EP  - 323
DO  - 10.1201/9781032673134
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215230351&doi=10.1201%2f9781032673134&partnerID=40&md5=978313b49772e7143724f21dd00e907a
AB  - Artificial intelligence (AI) is a complicated science that combines philosophy, cognitive psychology, neuroscience, mathematics and logic (logicism), economics, computer science, computability, and software. Meanwhile, robotics is an engineering field that compliments AI. There can be situations where AI can function without a robot (e.g., Turing Test) and robotics without AI (e.g., teleoperation), but in many cases, each technology requires each other to exhibit a complete system: having “smart” robots and AI being able to control its interactions (i.e., effectors) with its environment. This book provides a complete history of computing, AI, and robotics from its early development to state-of-the-art technology, providing a roadmap of these complicated and constantly evolving subjects. Divided into two volumes covering the progress of symbolic logic and the explosion in learning/deep learning in natural language and perception, this first volume investigates the coming together of AI (the mind) and robotics (the body), and discusses the state of AI today. Key Features: • Provides a complete overview of the topic of AI, starting with philosophy, psychology, neuroscience, and logicism, and extending to the action of the robots and AI needed for a futuristic society. • Provides a holistic view of AI, and touches on all the misconceptions and tangents to the technologies through taking a systematic approach. • Provides a glossary of terms, list of notable people, and extensive references. • Provides the interconnections and history of the progress of technology for over 100 years as both the hardware (Moore’s Law, GPUs) and software, i.e., generative AI, have advanced. Intended as a complete reference, this book is useful to undergraduate and postgraduate students of computing, as well as the general reader. It can also be used as a textbook by course convenors. If you only had one book on AI and robotics, this set would be the first reference to acquire and learn about the theory and practice. © 2025 Wendell H. Chun.
M3  - Book
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Lim, D.H.
AU  - Lee, J.Y.
AU  - Park, S.
TI  - The Metaverse in the Workplace: Possibilities and Implications for Human Resource Development
PY  - 2024
T2  - Human Resource Development Review
VL  - 23
IS  - 2
SP  - 164
EP  - 198
DO  - 10.1177/15344843231217174
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178396423&doi=10.1177%2f15344843231217174&partnerID=40&md5=97e16ed3a3ad6564615a347199da67b4
AB  - This study reviews the potential applications of the metaverse to various areas of human resource development (HRD) and reflects on the applications’ significance for employee and organizational development. Adopting a narrative review approach to this study, we selected and reviewed 34 cases. From our review, we found several findings that contributes to the HRD field in several ways. First, it draws the attention of HRD researchers and practitioners to a critical emerging trend that has been overlooked in the field. Second, it offers an analytical view of the metaverse in comparison to other training or learning technologies, assessing its effectiveness in employee development. Third, this study enhances the perspectives of HRD researchers and practitioners regarding this new technology by providing practical and theoretical insights into how metaverse-based interventions can reshape organizational culture and improve employee performance in the workplace. Lastly, it addresses compelling theoretical and practical questions related to HRD issues arising from the metaverse. © The Author(s) 2023.
KW  - augmented reality
KW  - human resource development
KW  - lifelogging
KW  - metaverse
KW  - mirror worlds
KW  - virtual reality
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 11
ER  -

TY  - JOUR
AU  - Zhang, S.
AU  - Mao, R.
AU  - Zhang, J.
AU  - Xiao, L.
AU  - Cambria, E.
TI  - MATADOR: Multimodal traffic accident prediction enhanced by multi-source aggregated emotion recognition
PY  - 2025
T2  - Information Fusion
VL  - 124
C7  - 103335
DO  - 10.1016/j.inffus.2025.103335
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007042403&doi=10.1016%2fj.inffus.2025.103335&partnerID=40&md5=cd64015d4e3b81685a131dfaf913088e
AB  - While predicting traffic accidents is challenging, it is highly valuable as it can greatly improve public safety. Previous studies have mostly relied on time-series data capturing drivers’ physiological responses and behavior along with vehicle movement to predict collisions. However, focusing solely on the driver and target vehicle is insufficient, as driving behavior is also influenced by the external environment, especially in emergencies. In this work, we propose a multi-source aggregation model, termed MATADOR. The model aggregates and fuses data from various sources, including multimodal physiological and behavioral indicators of the driver, sensor data from the target vehicle and its surrounding vehicles, and static environmental data such as weather conditions and potential hazards to predict traffic accidents. MATADOR is built upon multi-source feature extraction, multimodal data fusion, and a novel assisting mechanism to detect driver anger, recognize emotion intensity, and predict traffic accident probability over the following 1, 3, and 5 s, respectively. Thus, MATADOR can provide timely alerts to the driver, helping to prevent potential accidents. This proactive approach sets MATADOR apart from previous studies, highlighting its usefulness in real-world applications. Moreover, recognizing the strong link between drivers’ emotional states and accidents, previous studies have utilized multi-task learning to enhance the accuracy of traffic accident prediction. However, they often treat tasks as isolated branches, failing to capture the dependencies between each other. To tackle this challenge, we developed a dynamic assisting mechanism that allows the model to capture the influence of the emotional states of a driver on accident prediction, thereby realizing task-relevance-driven dynamic optimization. Extensive experiments prove that MATADOR significantly outperforms state-of-the-art methods in traffic accident prediction. © 2025
KW  - Emotion recognition
KW  - Multi-task learning
KW  - Multimodal fusion
KW  - Traffic accident prediction
KW  - Brain
KW  - Highway accidents
KW  - Image fusion
KW  - Multimodal transportation
KW  - Physiological models
KW  - Sensor data fusion
KW  - Sensory perception
KW  - Accident prediction
KW  - Emotion recognition
KW  - Emotional state
KW  - Multi-modal
KW  - Multi-modal fusion
KW  - Multi-Sources
KW  - Multitask learning
KW  - Public safety
KW  - Target vehicles
KW  - Traffic accident prediction
KW  - Multi-task learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Flade, B.
AU  - Kohaut, S.
AU  - Eggert, J.
AU  - Dhami, D.S.
AU  - Kersting, K.
TI  - StaR Maps: Unveiling Uncertainty in Geospatial Relations
PY  - 2024
T2  - IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC
SP  - 497
EP  - 504
DO  - 10.1109/ITSC58415.2024.10920021
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001668969&doi=10.1109%2fITSC58415.2024.10920021&partnerID=40&md5=26523c7f325ccfc415b49f6f79b690a4
AB  - The growing complexity of intelligent transportation systems and their applications in public spaces has increased the demand for expressive and versatile knowledge representation. While various mapping efforts have achieved widespread coverage, including detailed annotation of features with semantic labels, it is essential to understand their inherent uncertainties, which are commonly underrepresented by the respective geographic information systems. Hence, it is critical to develop a representation that combines a statistical, probabilistic perspective with the relational nature of geospatial data. Further, such a representation should facilitate an honest view of the data's accuracy and provide an environment for high-level reasoning to obtain novel insights from task-dependent queries. Our work addresses this gap in two ways. First, we present Statistical Relational Maps (StaR Maps) as a representation of uncertain, semantic map data. Second, we demonstrate efficient computation of StaR Maps to scale the approach to wide urban spaces. Through experiments on real-world, crowd-sourced data, we underpin the application and utility of StaR Maps in terms of representing uncertain knowledge and reasoning for complex geospatial information. © 2024 IEEE.
KW  - Navigation
KW  - Probabilistic Logic
KW  - Statistical Relational AI
KW  - Data accuracy
KW  - Probabilistic logics
KW  - Data accuracy
KW  - Geo-spatial
KW  - Geographic information
KW  - Intelligent transportation systems
KW  - Knowledge-representation
KW  - Probabilistics
KW  - Public space
KW  - Semantic labels
KW  - Statistical relational AI
KW  - Uncertainty
KW  - Knowledge representation
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Başarslan, M.S.
AU  - Kayaalp, F.
TI  - Sentiment analysis using a deep ensemble learning model
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 14
SP  - 42207
EP  - 42231
DO  - 10.1007/s11042-023-17278-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174249458&doi=10.1007%2fs11042-023-17278-6&partnerID=40&md5=ff49021ae693875e43cff13248fcb5a8
AB  - The coronavirus pandemic has kept people away from social life and this has led to an increase in the use of social media over the past two years. Thanks to social media, people can now instantly share their thoughts on various topics such as their favourite movies, restaurants, hotels, etc. This has created a huge amount of data and many researchers from different sciences have focused on analysing this data. Natural Language Processing (NLP) is one of these areas of computer science that uses artificial technologies. Sentiment analysis is also one of the tasks of NLP, which is based on extracting emotions from huge post data. In this study, sentiment analysis was performed on two datasets of tweets about coronavirus and TripAdvisor hotel reviews. A frequency-based word representation method (Term Frequency-Inverse Document Frequency (TF-IDF)) and a prediction-based Word2Vec word embedding method were used to vectorise the datasets. Sentiment analysis models were then built using single machine learning methods (Decision Trees-DT, K-Nearest Neighbour-KNN, Naive Bayes-NB and Support Vector Machine-SVM), single deep learning methods (Long Short Term Memory-LSTM, Recurrent Neural Network-RNN) and heterogeneous ensemble learning methods (Stacking and Majority Voting) based on these single machine learning and deep learning methods. Accuracy was used as a performance measure. The heterogeneous model with stacking (LSTM-RNN) has outperformed the other models with accuracy values of 0.864 on the coronavirus dataset and 0.898 on the Trip Advisor dataset and they have been evaluated as promising results when compared to the literature. It has been observed that the use of single methods as an ensemble gives better results, which is consistent with the literature, which is a step forward in the detection of sentiments through posts. Investigating the performance of heterogeneous ensemble learning models based on different algorithms in sentiment analysis tasks is planned as future work. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.
KW  - Deep Ensemble Learning
KW  - Deep Learning
KW  - Ensemble Learning
KW  - Machine Learning
KW  - Sentiment Analysis
KW  - Text Representation
KW  - Word Embedding
KW  - Barium compounds
KW  - Coronavirus
KW  - Decision trees
KW  - Embeddings
KW  - Inverse problems
KW  - Long short-term memory
KW  - Nearest neighbor search
KW  - Social networking (online)
KW  - Support vector machines
KW  - Coronaviruses
KW  - Deep ensemble learning
KW  - Deep learning
KW  - Embeddings
KW  - Ensemble learning
KW  - Machine-learning
KW  - Sentiment analysis
KW  - Text representation
KW  - Word embedding
KW  - Sentiment analysis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - JOUR
AU  - Holmes, W.
AU  - Tuomi, I.
TI  - State of the art and practice in AI in education
PY  - 2022
T2  - European Journal of Education
VL  - 57
IS  - 4
SP  - 542
EP  - 570
DO  - 10.1111/ejed.12533
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138608160&doi=10.1111%2fejed.12533&partnerID=40&md5=774a670edaeac831314b0132fdbf63ca
AB  - Recent developments in Artificial Intelligence (AI) have generated great expectations for the future impact of AI in education and learning (AIED). Often these expectations have been based on misunderstanding current technical possibilities, lack of knowledge about state-of-the-art AI in education, and exceedingly narrow views on the functions of education in society. In this article, we provide a review of existing AI systems in education and their pedagogic and educational assumptions. We develop a typology of AIED systems and describe different ways of using AI in education and learning, show how these are grounded in different interpretations of what AI and education is or could be, and discuss some potential roadblocks on the AIED highway. © 2022 The Authors. European Journal of Education published by John Wiley & Sons Ltd.
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 317
ER  -

TY  - JOUR
AU  - Tu, G.
AU  - Liang, B.
AU  - Jiang, D.
AU  - Xu, R.
TI  - Sentiment- Emotion- and Context-Guided Knowledge Selection Framework for Emotion Recognition in Conversations
PY  - 2023
T2  - IEEE Transactions on Affective Computing
VL  - 14
IS  - 3
SP  - 1803
EP  - 1816
DO  - 10.1109/TAFFC.2022.3223517
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144033713&doi=10.1109%2fTAFFC.2022.3223517&partnerID=40&md5=68d60e2f3501f2ca9981d233a040b7c4
AB  - Emotion recognition in conversations (ERC) needs to detect the emotion of each utterance in conversations. However, it is difficult for machines to recognize the emotion of utterances like humans, partly because of the lack of commonsense knowledge. Despite existing efforts gradually incorporate knowledge in ERC, they can not adaptively adjust knowledge according to different utterances and their context. In this article, we propose a knowledge selection framework SKSEC (Select Knowledge in light of Sentiment Emotion and Context). In the SKSEC framework, first, external knowledge is eliminated by three Knowledge Elimination (KE) modules. More concretely, In word-level KE, the concept knowledge different from the sentiment corresponding to the word in utterances is randomly eliminated. In utterance- or context-level KE, If the similarity between the knowledge representation and the emotion label representation of the current utterance or its context is less than the preset threshold, the knowledge will be eliminated. Then we refine the weight of knowledge using two Graph ATtention (GAT) mechanisms. Specifically, In Sentics GAT, we employ a dimensional emotion model to measure words in utterances and their corresponding knowledge and adjust the weight of knowledge according to their emotional similarity. In Semantics GAT, the weight of knowledge is adjusted according to the semantic similarity between context and incorporated knowledge. Finally, we feed the selected knowledge to the most advanced models to evaluate the quality of knowledge. The experimental results show that the SKSEC framework can effectively improve the performance of the model by eliminating and refining external knowledge in different size and domain datasets.  © 2010-2012 IEEE.
KW  - Conversational emotion recognition
KW  - knowledge elimination
KW  - knowledge refinement
KW  - Emotion Recognition
KW  - Knowledge representation
KW  - Speech recognition
KW  - Context models
KW  - Conversational emotion recognition
KW  - Emotion recognition
KW  - Knowledge elimination
KW  - Knowledge refinement
KW  - Knowledge-based systems
KW  - Oral communication
KW  - Psychology
KW  - Selection framework
KW  - Semantics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 16
ER  -

TY  - CONF
AU  - Schön, O.
AU  - Götte, R.-S.
AU  - Timmermann, J.
TI  - Multi-Objective Physics-Guided Recurrent Neural Networks for Identifying Non-Autonomous Dynamical Systems∗
PY  - 2022
T2  - IFAC-PapersOnLine
VL  - 55
IS  - 12
SP  - 19
EP  - 24
DO  - 10.1016/j.ifacol.2022.07.282
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134705238&doi=10.1016%2fj.ifacol.2022.07.282&partnerID=40&md5=dbf705bf191049d49a351e8214b7c9ac
AB  - While trade-offs between modeling effort and model accuracy remain a major concern with system identification, resorting to data-driven methods often leads to a complete disregard for physical plausibility. To address this issue, we propose a physics-guided hybrid approach for modeling non-autonomous systems under control. Starting from a traditional physics-based model, this is extended by a recurrent neural network and trained using a sophisticated multi-objective strategy yielding physically plausible models. While purely data-driven methods fail to produce satisfying results, experiments conducted on real data reveal substantial accuracy improvements by our approach compared to a physics-based model. © 2022 Elsevier B.V.. All rights reserved.
KW  - data-driven
KW  - dynamical systems
KW  - machine learning
KW  - multi-objective optimization
KW  - neural networks
KW  - physics-guided
KW  - system identification
KW  - Economic and social effects
KW  - Multiobjective optimization
KW  - Recurrent neural networks
KW  - Religious buildings
KW  - Data driven
KW  - Data-driven methods
KW  - Machine-learning
KW  - Multi objective
KW  - Multi-objectives optimization
KW  - Neural-networks
KW  - Nonautonomous
KW  - Physic-guided
KW  - Physics-based models
KW  - System-identification
KW  - Dynamical systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - JOUR
AU  - Azam, N.
AU  - Chak, A.
AU  - Michala, A.
AU  - Ansari, S.
AU  - Truong, N.B.
TI  - A practical solution for modelling GDPR-compliance based on defeasible logic reasoning
PY  - 2025
T2  - Expert Systems with Applications
VL  - 277
C7  - 127140
DO  - 10.1016/j.eswa.2025.127140
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000403291&doi=10.1016%2fj.eswa.2025.127140&partnerID=40&md5=3e2efdf3c3d07ab2d389f0ad5ee3fea9
AB  - The General Data Protection Regulation (GDPR), the EU/UK data protection legislation, has necessitated a critical need for compliance modelling to meet its strict and sophisticated requirements. Traditional techniques for modelling security and privacy-related threats fall short of addressing and mitigating the threats of non-compliance. This paper introduces a practical solution to modelling GDPR-compliance based on Defeasible Logic Programming (DeLP), which enhances the robustness and reasoning capabilities of compliance models in real-world scenarios. Furthermore, to overcome the challenges of UNDECIDED query outputs in logical reasoning, we incorporate explicit priorities for conflicting rules and suggest related knowledge for a query in an incomplete knowledge base. To finalize the compliance modelling system, we develop the threat mitigation mechanism that specifies the reasons in case there is a non-compliance threat, along with the suggested actions to mitigate the threats. The application of our approach is demonstrated through a case study on Fitbit, health tracking devices, focusing on non-compliance threats and resolving ”UNDECIDED” query results. Our findings show that the inference engine efficiently identifies non-compliance threats, handles UNDECIDED query results, and suggests appropriate threat mitigation measures. © 2025
KW  - Data privacy
KW  - Data protection
KW  - Defeasible logic programming (DeLP)
KW  - GDPR compliance
KW  - General data protection regulation (GDPR)
KW  - Threat modelling
KW  - Compliance model
KW  - Defeasible Logic Programming
KW  - General data protection regulation
KW  - General data protection regulation compliance
KW  - General data protection regulations
KW  - Non-compliance
KW  - Regulation compliance
KW  - Threat modeling
KW  - Differential privacy
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Kozłowski, M.
AU  - Racewicz, S.
AU  - Wierzbicki, S.
TI  - Image Analysis in Autonomous Vehicles: A Review of the Latest AI Solutions and Their Comparison
PY  - 2024
T2  - Applied Sciences (Switzerland)
VL  - 14
IS  - 18
C7  - 8150
DO  - 10.3390/app14188150
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205265639&doi=10.3390%2fapp14188150&partnerID=40&md5=3d0850dcf24d3abc98742a4bba055dcd
AB  - The integration of advanced image analysis using artificial intelligence (AI) is pivotal for the evolution of autonomous vehicles (AVs). This article provides a thorough review of the most significant datasets and latest state-of-the-art AI solutions employed in image analysis for AVs. Datasets such as Cityscapes, NuScenes, CARLA, and Talk2Car form the benchmarks for training and evaluating different AI models, with unique characteristics catering to various aspects of autonomous driving. Key AI methodologies, including Convolutional Neural Networks (CNNs), Transformer models, Generative Adversarial Networks (GANs), and Vision Language Models (VLMs), are discussed. The article also presents a comparative analysis of various AI techniques in real-world scenarios, focusing on semantic image segmentation, 3D object detection, vehicle control in virtual environments, and vehicle interaction using natural language. Simultaneously, the roles of multisensor datasets and simulation platforms like AirSim, TORCS, and SUMMIT in enriching the training data and testing environments for AVs are highlighted. By synthesizing information on datasets, AI solutions, and comparative performance evaluations, this article serves as a crucial resource for researchers, developers, and industry stakeholders, offering a clear view of the current landscape and future directions in autonomous vehicle image analysis technologies. © 2024 by the authors.
KW  - AI solutions
KW  - autonomous vehicles
KW  - image analysis
KW  - safety features
KW  - Magnetic levitation vehicles
KW  - Semantic Segmentation
KW  - Visual languages
KW  - Artificial intelligence solution
KW  - Autonomous driving
KW  - Autonomous Vehicles
KW  - Convolutional neural network
KW  - Image analyze
KW  - Image-analysis
KW  - Intelligence models
KW  - Safety features
KW  - State of the art
KW  - Transformer modeling
KW  - Convolutional neural networks
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 8
ER  -

TY  - JOUR
AU  - Aromaa, S.
AU  - Heikkilä, P.
AU  - Kaasinen, E.
AU  - Lammi, H.
AU  - Tammela, A.
AU  - Salminen, K.
TI  - Human factors and ergonomics considerations in the industrial metaverse
PY  - 2024
T2  - International Journal of Human Factors and Ergonomics
VL  - 11
IS  - 1
SP  - 4
EP  - 27
DO  - 10.1504/IJHFE.2024.137128
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187139711&doi=10.1504%2fIJHFE.2024.137128&partnerID=40&md5=5679d74a6990c247a19d179214a97772
AB  - The industrial metaverse is a new and emerging topic in smart manufacturing, extending the previous Industry 4.0 concept of cyber-physical systems in manufacturing. The trend is in its early phase, and the definition of the concept is still forming. The goal of this paper is to study the industrial metaverse from the human factors and ergonomics (HF/E) point of view to ensure that the related design and development efforts have a holistic approach. Three industrial metaverse work scenarios were created and assessed from the HF/E point of view. Based on the scenario analysis, new opportunities and challenges were identified related to user experience, usability, usefulness, user acceptance, ergonomics, safety and ethics. This paper is one of the first to start the HF/E discussion related to the metaverse, and its findings can be used both by the research community and the industry when stepping into the era of the industrial metaverse. Copyright © 2024 Inderscience Enterprises Ltd.
KW  - augmented reality
KW  - HF/E
KW  - human factors and ergonomics
KW  - industrial metaverse
KW  - Industry 4.0
KW  - virtual reality
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Fashandi, H.
TI  - Neural module networks: A review
PY  - 2023
T2  - Neurocomputing
VL  - 552
C7  - 126518
DO  - 10.1016/j.neucom.2023.126518
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166471113&doi=10.1016%2fj.neucom.2023.126518&partnerID=40&md5=7c7b8b58e9fcd16cb1fdae7ac36d543d
AB  - The capability of deep neural networks to automatically learn informative features from data is their asset. For instance, a convolutional layer learns the filters based on their placement in the architecture, i.e., the low-level features in the early layers and more abstract features in the higher level. The question is whether we can learn at the sub-task level and automate the process. In other words, can a neural architecture learn to decompose a complex task into sub-tasks (i.e., elemental tasks), solve each sub-task, and aggregate the results? This way, we gain full transparency and explainability of how a complex task has been solved. This is the goal of neural module networks (NMN). Each module represents a sub-task that conveys a symbolic meaning. Each module learns the assigned sub-task based on its placement in the modules’ layout, internal architecture, or both. The NMN re-shapes itself for each sample by choosing the sample-specific modules (i.e., sub-tasks) and placing them into an appropriate layout. This review provides a comprehensive overview of neural module networks and their applications and assumes little prior knowledge. We showcased different applications of NMNs and compared their various implementations. To better compare the performance of each application, we also chose a few non-modular approaches for the completeness of the comparisons. We hope this review and the added benefit of NMN's explainability attract more researchers to solve the current challenges. © 2023 Elsevier B.V.
KW  - Explainable AI
KW  - Neural module networks
KW  - Task decomposition
KW  - Deep neural networks
KW  - Network architecture
KW  - Complex task
KW  - Explainable AI
KW  - Filter-based
KW  - Learn+
KW  - Low-level features
KW  - Module networks
KW  - Neural module network
KW  - Subtask
KW  - Task decomposition
KW  - Task levels
KW  - artificial intelligence
KW  - artificial neural network
KW  - automation
KW  - computer aided design
KW  - evolutionary algorithm
KW  - human
KW  - process design
KW  - reinforcement learning (machine learning)
KW  - Short Survey
KW  - Complex networks
M3  - Short survey
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Sharma, A.
AU  - Sharma, L.
AU  - Krezel, J.
TI  - Exploring the Use of Metaverse for Collaborative Learning in Higher Education: A Scoping Review
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14060 LNCS
SP  - 240
EP  - 251
DO  - 10.1007/978-3-031-48060-7_19
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178521264&doi=10.1007%2f978-3-031-48060-7_19&partnerID=40&md5=3d450cc66182d9775973d668c16f368b
AB  - Student engagement in higher education is strongly associated with positive learning outcomes; however, not all learning methods are equally engaging or stimulating. Recent technological developments hold the potential to make learning more exciting and attractive, especially through the use of Virtual Reality (VR) and Augmented Reality (AR) technologies. These two technologies, blending the real and virtual worlds, create a digital space called the ‘Metaverse’. In the Metaverse, people can interact in a virtual environment with lifelike avatars, providing an immersive learning experience. Several studies have explored the potential of Metaverse technology as a learning tool, highlighting its ability to make learning more engaging, interactive, and interesting. Other advantages of Metaverse include the visualisation of learning materials and allowing teachers to innovate learning processes. This research extensively reviews the literature from designated databases such as Scopus, ProQuest, and Google Scholar to explore the possibilities, effectiveness, and advantages of using Metaverse and AR/VR technologies to facilitate collaborative learning in higher education sectors. Finally, the paper concludes by acknowledging the limitations of using Metaverse and AR/VR technologies, such as the costs associated with their implementation and the skills required in the industry. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Augmented Reality
KW  - Collaborative Learning
KW  - Higher Education
KW  - Metaverse
KW  - Virtual Reality
KW  - Augmented reality
KW  - Blending
KW  - E-learning
KW  - Engineering education
KW  - Interactive computer graphics
KW  - Learning systems
KW  - Augmented reality technology
KW  - Collaborative learning
KW  - High educations
KW  - Learning methods
KW  - Learning outcome
KW  - Metaverses
KW  - Scoping review
KW  - Student engagement
KW  - Technological development
KW  - Virtual reality technology
KW  - Virtual reality
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Das, S.
AU  - Chatterji, S.
AU  - Mukherjee, I.
TI  - AcKnowledge: Acquired Knowledge Representation by Small Language Model Without Pre-training
PY  - 2024
T2  - KnowLLM 2024 - 1st Workshop on Towards Knowledgeable Language Models, Proceedings of the Workshop
SP  - 83
EP  - 95
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204903519&partnerID=40&md5=d20b6e18fde531fb9a9c1d5487734015
AB  - Large language models (LLMs) are pre-trained on enormous amounts of text data and show acclaimed success in knowledge representation. However, there are two bottlenecks with this approach. (1) Pre-training data cannot be regularly updated once the models are deployed, and it is not very fruitful if the model cannot represent updated knowledge. (2) The consistently increasing size and computational resources make it difficult for noncommercial and individual researchers to fine-tune and scale these language models. Major LLMs with external knowledge are also proprietary. In this paper, we propose AcKnowledge, a framework wrapped around a small, non-pre-trained language model for an open-domain question-answering (QA) experiment. AcKnowledge learns relevant knowledge from the internet via meta-learning based on user questions, and re-learns from user feedback if knowledge is misrepresented. Our efficient knowledge representation framework avoids pre-training overhead while enabling updated information. Benchmarking shows competitive performance against similarly sized state-of-the-art (SoTA) LLMs on gold standard QA datasets, demonstrating the potential of integrating internet search and user feedback for improved performance and general-izability. The repository of the work is available at https://github.com/SouravD-Me/AcKnowledge-KnowledgeLM-ACL-2024. © 2024 Association for Computational Linguistics.
KW  - Computational linguistics
KW  - Question answering
KW  - Computational resources
KW  - External knowledge
KW  - Knowledge-representation
KW  - Language model
KW  - Learn+
KW  - Open domain question answering
KW  - Pre-training
KW  - Text data
KW  - Training data
KW  - User feedback
KW  - Knowledge representation
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Kumar, S.
AU  - Datta, S.
AU  - Singh, V.
AU  - Datta, D.
AU  - Kumar Singh, S.
AU  - Sharma, R.
TI  - Applications, Challenges, and Future Directions of Human-in-the-Loop Learning
PY  - 2024
T2  - IEEE Access
VL  - 12
C7  - 10530996
SP  - 75735
EP  - 75760
DO  - 10.1109/ACCESS.2024.3401547
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193295974&doi=10.1109%2fACCESS.2024.3401547&partnerID=40&md5=30b83d43b739aa6a4ca4b1be90678a82
AB  - Machine learning (ML) has become a popular technique for various automation tasks in the era of Industry 4.0, such as the analysis and synthesis of visual data such as images and videos, natural language and speech, financial data, and biomedical applications. However, ML-based automation techniques are facing difficulties like decision-making, thus incorporating user expertise into the system might be advantageous. The goal of adding human domain expertise with ML-based automation is to provide more accurate prediction models. Human-in-the-loop (HITL) systems that integrate human expertise with ML algorithms are becoming more and more common in various industries. However, there are a number of methodological, technical, and ethical difficulties with the development and application of HITL systems. This paper aims to explore the methodologies, challenges, and opportunities associated with HITL systems implementations. We also discuss a number of issues that must be resolved for HITL systems to be effective, including data quality, bias, and user engagement. Besides, we also explored several approaches that can be utilized to enhance the performance of HITL systems, such as active learning (AL), iterative ML, and reinforcement learning, as well as the current state of the art in HITL systems. We also selectively highlighted the advantages of HITL systems, such as their potential to increase decision-making process accountability and transparency by utilizing human experience to improve ML decision-making capability. The paper will be very useful for researchers, practitioners, and policymakers. © 2023 IEEE.
KW  - accountability
KW  - Human-in-the-loop (HITL)
KW  - machine learning algorithms
KW  - transparency
KW  - Automation
KW  - Decision making
KW  - Iterative methods
KW  - Job analysis
KW  - Learning algorithms
KW  - Medical applications
KW  - Natural language processing systems
KW  - Reinforcement learning
KW  - Accountability
KW  - Annotation
KW  - Human-in-the-loop
KW  - Language processing
KW  - Machine learning algorithms
KW  - Natural language processing
KW  - Natural languages
KW  - Task analysis
KW  - Transparency
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 15
ER  -

TY  - JOUR
AU  - Shi, J.
AU  - Ding, N.
AU  - Wang, H.
AU  - Wang, Y.
TI  - How risk preference affects evacuees’ route choice in buildings: An IVR-based experimental study
PY  - 2025
T2  - Safety Science
VL  - 187
C7  - 106840
DO  - 10.1016/j.ssci.2025.106840
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000777374&doi=10.1016%2fj.ssci.2025.106840&partnerID=40&md5=26922b25389c52ca67b7512609a392dc
AB  - During building evacuations, evacuees often tend to enter areas with smoke and flames, which contradicts established safety principles for evacuation. This paper investigates how individuals with different risk preferences process evacuation information and make route choices. 72 participants were categorized into two groups based on a risk preference questionnaire: one-third were identified as Risk Seeking Group (RSG) and the rest as Risk Averse Group (RAG). Subsequently, eye-tracking technology and immersive virtual reality (IVR) were employed to analyze the variations in behavior between these groups. The findings show that: (1) RAG exhibited a general attention bias toward risk-related information; (2) Significant differences were observed in route choice among RAG based on varying cognitive approaches; (3) While all participants acknowledged the importance of safety factors, approximately 40% behaviorally chose routes involving flames; (4) RSG prioritizes evacuation distance and evacuation efficiency in the evacuation process, achieving an average evacuation time that was 23.85% faster than that of RAG. Conversely, RAG displayed a tendency to avoid harm, even at the cost of evacuation efficiency. This paper deconstructs complex evacuation behaviors from a psychological perspective, providing a more comprehensive understanding of route choices among evacuees with different risk preferences. It serves as a reference for optimizing evacuation strategies and designing building safety features with consideration of psychological factors. © 2025 Elsevier Ltd
KW  - Attention process
KW  - Building safety design
KW  - IVR experiment
KW  - Risk preference
KW  - Route choice
KW  - Attention process
KW  - Building safety
KW  - Building safety design
KW  - Group-based
KW  - Immersive virtual reality
KW  - Immersive virtual reality experiment
KW  - Risk averse
KW  - Risk preference
KW  - Route choice
KW  - Safety design
KW  - adult
KW  - Article
KW  - attentional bias
KW  - avoidance behavior
KW  - building
KW  - cognition
KW  - construction work and architectural phenomena
KW  - decision making
KW  - emergency evacuation
KW  - eye tracking
KW  - flame
KW  - human
KW  - human experiment
KW  - normal human
KW  - psychological aspect
KW  - questionnaire
KW  - risk aversion
KW  - risk behavior
KW  - risk seeking
KW  - safety
KW  - smoke
KW  - time
KW  - virtual reality
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Szadeczky, T.
AU  - Bederna, Z.
TI  - Risk, regulation, and governance: evaluating artificial intelligence across diverse application scenarios
PY  - 2025
T2  - Security Journal
VL  - 38
IS  - 1
C7  - 35
DO  - 10.1057/s41284-025-00495-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007148824&doi=10.1057%2fs41284-025-00495-z&partnerID=40&md5=44bf7fd531c9f7cf2008a0170b9f9e4d
AB  - Understanding the impact of Artificial intelligence (AI) systems, including general purpose AI (GPAI) systems, across varied risk profiles becomes imperative with their pervasive expansion. This study systematically examines AI implementations in environments categorised from minimal to high risk, emphasising the significance of tailored risk management strategies and ethical approaches. In our article we explore how different AI applications influence public health, safety, and security and outline the regulatory and ethical frameworks required to manage the impact effectively. Our analysis reveals distinct operational and ethical challenges AI systems face in high-risk scenarios, necessitating thorough oversight and strict regulatory compliance to mitigate potential adverse outcomes. Furthermore, AI applications in lower-risk contexts also require careful consideration of transparency and accountability to ensure ethical alignment and public trust. This paper adds to the current discussion about AI governance by providing a detailed overview of AI risk factors and mitigation strategies. It proposes a complex approach to AI regulation and attempts to serve as a valuable resource for policymakers, IT professionals, and stakeholders. The goal is to maximise the benefits of AI while protecting against its risks, thereby promoting the responsible development and lawful implementation of AI technologies. © The Author(s) 2025.
KW  - Artificial Intelligence Regulation
KW  - Cybersecurity
KW  - European Union
KW  - Risk Management
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Jaber, J.
AU  - Issa, H.
TI  - Unraveling the unintended consequences of AI in agriculture: A netnographic analysis and tri-phasic framework for enhanced uncertainty management
PY  - 2025
T2  - Technological Forecasting and Social Change
VL  - 218
C7  - 124209
DO  - 10.1016/j.techfore.2025.124209
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006686088&doi=10.1016%2fj.techfore.2025.124209&partnerID=40&md5=e777bbe432f5100ea6b582ea20db8ae0
AB  - The agricultural sector has been a slow adopter of AI technologies, primarily due to concerns over the unpredictability of AI and the inherent uncertainties within the industry itself. This hesitation stems from the sector's reliance on complex, variable conditions that challenge the stability of AI solutions. The convergence of AI's unpredictability and agriculture's inherent uncertainty calls for a closer examination of the unintended consequences of AI decision-making in this domain. This research addresses such a dilemma by employing a netnography design to analyze 15 podcasts. The analysis identified three critical themes: predictive dissonance, techno-indecisiveness, and readiness deficit. This research makes three valuable contributions by pioneering an empirical investigation into the unintended consequences of AI in agriculture at the decision-making level, developing an AI concentric-nested ecosystem at the deployment level, and introducing a quantifiable scale graph that acts as a tangible assessment tool for AI's unintended consequences. © 2025 Elsevier Inc.
KW  - Agriculture
KW  - AI
KW  - Unintended consequences
KW  - Unpredictable decision-making
KW  - Agricultural engineering
KW  - Agricultural products
KW  - Agricultural robots
KW  - Crops
KW  - Farms
KW  - Forestry
KW  - Harvesting
KW  - Irrigation
KW  - Risk perception
KW  - Agricultural sector
KW  - AI Technologies
KW  - Complex variable
KW  - Decisions makings
KW  - Tri-Phasic
KW  - Uncertainty
KW  - Uncertainty management
KW  - Unintended consequences
KW  - Unpredictable decision-making
KW  - Variable conditions
KW  - agricultural management
KW  - agricultural technology
KW  - artificial intelligence
KW  - decision making
KW  - empirical analysis
KW  - Cultivation
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Zhang, R.
AU  - Lee, S.
AU  - Hwang, M.
AU  - Hiranaka, A.
AU  - Wang, C.
AU  - Ai, W.
AU  - Tan, J.J.R.
AU  - Gupta, S.
AU  - Hao, Y.
AU  - Levine, G.
AU  - Gao, R.
AU  - Norcia, A.
AU  - Fei-Fei, L.
AU  - Wu, J.
TI  - NOIR: Neural Signal Operated Intelligent Robots for Everyday Activities
PY  - 2023
T2  - Proceedings of Machine Learning Research
VL  - 229
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184352025&partnerID=40&md5=3cc506885814e2e37fd5142a237f3038
AB  - We present Neural Signal Operated Intelligent Robots (NOIR), a general-purpose, intelligent brain-robot interface system that enables humans to command robots to perform everyday activities through brain signals. Through this interface, humans communicate their intended objects of interest and actions to the robots using electroencephalography (EEG). Our novel system demonstrates success in an expansive array of 20 challenging, everyday household activities, including cooking, cleaning, personal care, and entertainment. The effectiveness of the system is improved by its synergistic integration of robot learning algorithms, allowing for NOIR to adapt to individual users and predict their intentions. Our work enhances the way humans interact with robots, replacing traditional channels of interaction with direct, neural communication. Project website: https://noir-corl.github.io/. © 2023 Proceedings of Machine Learning Research. All Rights Reserved.
KW  - Brain-Robot Interface
KW  - Human-Robot Interaction
KW  - Brain
KW  - Electroencephalography
KW  - Electrophysiology
KW  - Human robot interaction
KW  - Learning algorithms
KW  - Machine learning
KW  - Brain signals
KW  - Brain-robot interface
KW  - Channels of interactions
KW  - Household activities
KW  - Humans-robot interactions
KW  - Interface system
KW  - Neural signals
KW  - Personal care
KW  - Robot interface
KW  - Synergistic integration
KW  - Intelligent robots
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - D’Amato, K.
TI  - ChatGPT: towards AI subjectivity
PY  - 2025
T2  - AI and Society
VL  - 40
IS  - 3
C7  - 102642
SP  - 1627
EP  - 1641
DO  - 10.1007/s00146-024-01898-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002976099&doi=10.1007%2fs00146-024-01898-z&partnerID=40&md5=cfd00928efa460da023c2bd42763e69a
AB  - Motivated by the question of responsible AI and value alignment, I seek to offer a uniquely Foucauldian reconstruction of the problem as the emergence of an ethical subject in a disciplinary setting. This reconstruction contrasts with the strictly human-oriented programme typical to current scholarship that often views technology in instrumental terms. With this in mind, I problematise the concept of a technological subjectivity through an exploration of various aspects of ChatGPT in light of Foucault’s work, arguing that current systems lack the reflexivity and self-formative characteristics inherent in the notion of the subject. By drawing upon a recent dialogue between Foucault and phenomenology, I suggest four techno-philosophical desiderata that would address the gaps in this search for a technological subjectivity: embodied self-care, embodied intentionality, imagination and reflexivity. Thus I propose that advanced AI be reconceptualised as a subject capable of “technical” self-crafting and reflexive self-conduct, opening new pathways to grasp the intertwinement of the human and the artificial. This reconceptualisation holds the potential to render future AI technology more transparent and responsible in the circulation of knowledge, care and power. © The Author(s) 2024.
KW  - Discipline
KW  - Dispositif
KW  - Foucault
KW  - Moral machines
KW  - Responsible AI
KW  - Value alignment
KW  - 'current
KW  - Current system
KW  - Discipline
KW  - Dispositif
KW  - Foucault
KW  - Intentionality
KW  - Moral machine
KW  - Responsible AI
KW  - Self-care
KW  - Value alignment
KW  - Ethical technology
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - CONF
AU  - Li, A.C.
AU  - Chen, Z.
AU  - Klassen, T.Q.
AU  - Vaezipoor, P.
AU  - Icarte, R.T.
AU  - McIlraith, S.A.
TI  - Reward Machines for Deep RL in Noisy and Uncertain Environments
PY  - 2024
T2  - Advances in Neural Information Processing Systems
VL  - 37
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000517986&partnerID=40&md5=57caba238a65ba35aef844de08f467fa
AB  - Reward Machines provide an automaton-inspired structure for specifying instructions, safety constraints, and other temporally extended reward-worthy behaviour. By exposing the underlying structure of a reward function, they enable the decomposition of an RL task, leading to impressive gains in sample efficiency. Although Reward Machines and similar formal specifications have a rich history of application towards sequential decision-making problems, prior frameworks have traditionally ignored ambiguity and uncertainty when interpreting the domain-specific vocabulary forming the building blocks of the reward function. Such uncertainty critically arises in many real-world settings due to factors like partial observability or noisy sensors. In this work, we explore the use of Reward Machines for Deep RL in noisy and uncertain environments. We characterize this problem as a POMDP and propose a suite of RL algorithms that exploit task structure under uncertain interpretation of the domain-specific vocabulary. Through theory and experiments, we expose pitfalls in naive approaches to this problem while simultaneously demonstrating how task structure can be successfully leveraged under noisy interpretations of the vocabulary. © 2024 Neural information processing systems foundation. All rights reserved.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Chanda, R.S.
AU  - Pabalkar, V.
AU  - Sharma, S.
TI  - Attitude and behavioral intention for using metaverse in education: learner’s perspective
PY  - 2024
T2  - Journal of Applied Research in Higher Education
VL  - 16
IS  - 5
SP  - 2168
EP  - 2184
DO  - 10.1108/JARHE-07-2023-0307
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185481880&doi=10.1108%2fJARHE-07-2023-0307&partnerID=40&md5=4a62827d3ef2aac193c0a7da6c939993
AB  - Purpose: This study aims to understand and analyze the aspects influencing students’ attitudes and behavior toward the use of metaverse in education. The metaverse is currently viewed as technology with immense prospects. However, the practice of the metaverse for educational motives is rarely deliberated. Design/methodology/approach: To assess the effect of the metaverse on students' knowledge and use of resources, general interests and attitudes toward the metaverse in education, a survey was conducted. The collected data were analyzed using a confirmatory factor analysis (CFA) in the first phase to address the various validity parameters. In the second phase, path analysis of the model was performed using structural equation modeling (SEM). Findings: The study investigated how students intended to behave while using the metaverse for learning. The attitude toward adopting metaverse as technology is influenced by perceived utility and simplicity of use. This leads to behavioral intention as well. Studies reveal that the aspect of perceived usefulness is considered to be more significant in assessing the intention of use. Research limitations/implications: This quantitative study contributes to the literature on metaverse, which is in the growing stage. In the educational sector, the existing studies are scarce; hence, the addition to the literature on metaverse is quite significant in the education domain. Practical implications: The study benefits the students and the academicians because metaverse is largely considered an integral part of technology platforms, which has to be included in the learning systems eventually. There are few courses where the use of metaverse is already initiated at an introductory level, thus opening a broad spectrum of opportunities at all levels. It can provide scholars access to a massive array of resources, including multimedia presentations, interactive objects that support the delivery of lessons, videos, images and audio recordings. Originality/value: This study adds to the existing literature by examining the impact of metaverse in education. The research focused on the students pursuing higher education who were mostly aware of metaverse and were open to the idea of learning and understanding through technology inclusion. © 2024, Emerald Publishing Limited.
KW  - Artificial intelligence
KW  - Augmented reality
KW  - Education
KW  - Metaverse
KW  - Teaching and learning
KW  - Virtual reality
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 8
ER  -

TY  - CHAP
AU  - Roth, A.M.
AU  - Manocha, D.
AU  - Srira, R.D.
AU  - Tabassi, E.
TI  - Explainable and Interpretable Reinforcement Learning for Robotics
PY  - 2024
T2  - Synthesis Lectures on Artificial Intelligence and Machine Learning
VL  - Part F2459
SP  - 1
EP  - 108
DO  - 10.1007/978-3-031-47518-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214705758&doi=10.1007%2f978-3-031-47518-4&partnerID=40&md5=a3d7c3eacf1629c34e8e8ecf4abba9fd
AB  - This book surveys the state of the art in explainable and interpretable reinforcement learning (RL) as relevant for robotics. While RL in general has grown in popularity and been applied to increasingly complex problems, several challenges have impeded the real-world adoption of RL algorithms for robotics and related areas. These include difficulties in preventing safety constraints from being violated and the issues faced by systems operators who desire explainable policies and actions. Robotics applications present a unique set of considerations and result in a number of opportunities related to their physical, real-world sensory input and interactions. The authors consider classification techniques used in past surveys and papers and attempt to unify terminology across the field. The book provides an in-depth exploration of 12 attributes that can be used to classify explainable/interpretable techniques. These include whether the RL method is model-agnostic or model-specific, self-explainable or post-hoc, as well as additional analysis of the attributes of scope, when-produced, format, knowledge limits, explanation accuracy, audience, predictability, legibility, readability, and reactivity. The book is organized around a discussion of these methods broken down into 42 categories and subcategories, where each category can be classified according to some of the attributes. The authors close by identifying gaps in the current research and highlighting areas for future investigation. © 2024 The Authors.
KW  - Autonomous Robotics
KW  - Explainable AI
KW  - Intelligent Systems
KW  - Interpretable AI
KW  - Learning Algorithms
KW  - Learning Systems
KW  - Robot Learning
KW  - Safe AI
KW  - Contrastive Learning
KW  - Federated learning
KW  - Intelligent systems
KW  - Reinforcement learning
KW  - Robot learning
KW  - Robots
KW  - Autonomous robotics
KW  - Complex problems
KW  - Explainable AI
KW  - Interpretable AI
KW  - Real-world
KW  - Reinforcement learning algorithms
KW  - Reinforcement learnings
KW  - Safe AI
KW  - Safety constraint
KW  - State of the art
KW  - Adversarial machine learning
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Alabdulqader, E.A.
AU  - Umer, M.
AU  - Alnowaiser, K.
AU  - Wang, H.
AU  - Alarfaj, A.A.
AU  - Ashraf, I.
TI  - Image Processing-based Resource-Efficient Transfer Learning Approach for Cancer Detection Employing Local Binary Pattern Features
PY  - 2024
T2  - Mobile Networks and Applications
VL  - 29
IS  - 4
C7  - 103596
SP  - 1351
EP  - 1367
DO  - 10.1007/s11036-024-02331-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001647493&doi=10.1007%2fs11036-024-02331-x&partnerID=40&md5=3f285114821d96e2ccef2117111b9133
AB  - Cancer is a life-threatening disease and has witnessed a substantial increase during the past few years. With a further expected increase in the future, it poses a huge challenge for the medical industry to design accurate detection approaches. Earlier and accurate detection of these cancers increases the surviving chances of patients. Computer-aided diagnosis (CAD) can provide significant help in assisting medical experts to make timely and accurate diagnoses. Deep learning models show great promise but are limited by the need for larger datasets for training and higher computational complexity. This study proposes a resource-efficient EfficienetNetB4 model that incorporates local binary pattern features to enhance the detection accuracy of cancer. The proposed approach integrates histopathological images and texture-based features with EfficientNetB4. Extensive experiments involving several pre-trained convolutional neural network variants are carried out. Results show the superior results of the proposed EfficientNetB4 model with a 99.8% accuracy. In addition, precision, recall, and F1 scores are 99.9% each thereby indicating the exceptional results for cancer detection exceeding the existing state-of-the-art approaches. Using a 5-fold cross-validation provides an average 99.88% accuracy further validating the performance of EfficientNetB4. Furthermore, the use of Shapley additive explanations helps comprehend the results and increases the transparency of the decision-making process. This study potentially contributes to further research in CAD-based resource-efficient cancer detection. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
KW  - Cancer detection
KW  - Computer vision
KW  - Image processing
KW  - Resource-efficient CAD
KW  - Transfer learning
KW  - Computer aided diagnosis
KW  - Convolutional neural networks
KW  - Decision making
KW  - Deep learning
KW  - Diseases
KW  - Feature extraction
KW  - Textures
KW  - Cancer detection
KW  - Detection approach
KW  - Images processing
KW  - Learning approach
KW  - Local binary patterns
KW  - Medical industries
KW  - Pattern features
KW  - Resource-efficient
KW  - Resource-efficient computer-aided diagnose
KW  - Transfer learning
KW  - Local binary pattern
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Ali Syed, F.
AU  - Fang, K.-T.
AU  - Kiani, A.K.
AU  - Shoaib, M.
AU  - Asif Zahoor Raja, M.
TI  - LEVERAGING ON INTELLIGENT COMPUTING NEURO-STRUCTURES FOR POPULATION DYNAMICS OF FINANCIAL BUBBLE MODEL
PY  - 2025
T2  - Singapore Economic Review
DO  - 10.1142/S021759082550002X
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217489284&doi=10.1142%2fS021759082550002X&partnerID=40&md5=94c9dc33d13d0422bf8a7e1bd83589a3
AB  - This study aims to exploit the Artificial intelligence (AI)-based computing paradigm to analyze the economic system to define the price movements of unsustainable expansion, rapid collapse, and eventual equilibrium that characterize financial bubbles represented with differential equations to portray the role of societal contagion and group mentality from a behavioral viewpoint with the market population classified as bull, i.e., optimistic, neutrals, bear, i.e., pessimistic, and quitter categories. The concept of the financial bubble is characterized as an unexpected rise in prices that is rapidly followed by a shrill decline and retrospectively appears as a consequence of such uncertainty in price value. AI-based applications facilitate financial analysts with innovative computational paradigms for gaining deep insights, improving predictive accuracy, and creating sustained vigorous risk management stratagems for the financial bubble framework and solving with supervised nonlinear autoregressive exogenous networks with optimized Bayesian regularization algorithm to accomplish the reasonable predictive accuracy and malleability for the solution of financial bubble behavioral dynamics. The Adams numerical solver accomplishes the acquisition of synthetic data for the execution of a multi-layer structure of exogenous networks to solve for financial bubble parameters termed as contagion rate of optimistic behavior, bearish behavior, pessimist's average time of staying in the bearish group, the pessimist's population effect on the autonomous supply and the rate of optimists conversion to pessimists group while assuming other parameters values to be fixed for demand and supply functions. A consistent overlap between proposed results and synthetic numerical values of a financial bubble model is indicated by negligible error value that verifies the exogenous network's effectiveness and is verified by the enclosure of several evaluation measures of the precision and efficiency, through mean square error objective functions, adaptive amendable parameters, error dispersal, and input-error correlation analyses.  © 2025 World Scientific Publishing Company.
KW  - Adams numerical solver
KW  - autoregressive systems
KW  - Bayesian regularization algorithm
KW  - Dynamic nonlinear systems
KW  - econometrics
KW  - financial bubble
KW  - neural networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Krasowski, H.
AU  - Thumm, J.
AU  - Müller, M.
AU  - Schäfer, L.
AU  - Wang, X.
AU  - Althoff, M.
TI  - Provably Safe Reinforcement Learning: Conceptual Analysis, Survey, and Benchmarking
PY  - 2023
T2  - Transactions on Machine Learning Research
VL  - 2023
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000057681&partnerID=40&md5=d7c0502c01e8fcfb414b25a61e818a32
AB  - Ensuring the safety of reinforcement learning (RL) algorithms is crucial to unlock their potential for many real-world tasks. However, vanilla RL and most safe RL approaches do not guarantee safety. In recent years, several methods have been proposed to provide hard safety guarantees for RL, which is essential for applications where unsafe actions could have disastrous consequences. Nevertheless, there is no comprehensive comparison of these provably safe RL methods. Therefore, we introduce a categorization of existing provably safe RL methods, present the conceptual foundations for both continuous and discrete action spaces, and empirically benchmark existing methods. We categorize the methods based on how they adapt the action: action replacement, action projection, and action masking. Our experiments on an inverted pendulum and a quadrotor stabilization task indicate that action replacement is the best-performing approach for these applications despite its comparatively simple realization. Furthermore, adding a reward penalty, every time the safety verification is engaged, improved training performance in our experiments. Finally, we provide practical guidance on selecting provably safe RL approaches depending on the safety specification, RL algorithm, and type of action space. © 2023, Transactions on Machine Learning Research. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 10
ER  -

TY  - CONF
AU  - Tolstaya, E.
AU  - Butler, L.
AU  - Mox, D.
AU  - Paulos, J.
AU  - Kumar, V.
AU  - Ribeiro, A.
TI  - Learning Connectivity for Data Distribution in Robot Teams
PY  - 2021
T2  - IEEE International Conference on Intelligent Robots and Systems
SP  - 413
EP  - 420
DO  - 10.1109/IROS51168.2021.9636873
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124346899&doi=10.1109%2fIROS51168.2021.9636873&partnerID=40&md5=6cc6b4a345a5d9eae468413891137606
AB  - Many algorithms for control of multi-robot teams operate under the assumption that low-latency, global state information necessary to coordinate agent actions can readily be disseminated among the team. However, in harsh environments with no existing communication infrastructure, robots must form ad-hoc networks, forcing the team to operate in a distributed fashion. To overcome this challenge, we propose a task-agnostic, decentralized, low-latency method for data distribution in ad-hoc networks using Graph Neural Networks (GNN). Our approach enables multi-agent algorithms based on global state information to function by ensuring it is available at each robot. To do this, agents glean information about the topology of the network from packet transmissions and feed it to a GNN running locally which instructs the agent when and where to transmit the latest state information. We train the distributed GNN communication policies via reinforcement learning using the average Age of Information as the reward function and show that it improves training stability compared to task-specific reward functions. Our approach performs favorably compared to industry-standard methods for data distribution such as random flooding and round robin. We also show that the trained policies generalize to larger teams of both static and mobile agents.  © 2021 IEEE.
KW  - Ad hoc networks
KW  - Graph neural networks
KW  - Multi agent systems
KW  - Robots
KW  - Ad-hoc networks
KW  - Coordinate agent
KW  - Data distribution
KW  - Global state information
KW  - Graph neural networks
KW  - Harsh environment
KW  - Low latency
KW  - Multi-robot teams
KW  - Reward function
KW  - Robot teams
KW  - Reinforcement learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Ding, W.
AU  - Lin, H.
AU  - Li, B.
AU  - Zhao, D.
TI  - Semantically Adversarial Scene Generation With Explicit Knowledge Guidance
PY  - 2025
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 26
IS  - 2
SP  - 1510
EP  - 1521
DO  - 10.1109/TITS.2024.3510515
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214821200&doi=10.1109%2fTITS.2024.3510515&partnerID=40&md5=da4737ad9ae0978f570670cef892560e
AB  - Generating adversarial scenes that potentially fail autonomous driving systems provides an effective way to improve their robustness. Extending purely data-driven generative models, recent specialized models satisfy additional controllable requirements such as embedding a traffic sign in a driving scene by manipulating patterns implicitly at the neuron level. In this paper, we introduce a method to incorporate domain knowledge explicitly in the generation process to achieve Semantically Adversarial Generation (SAG). To be consistent with the composition of driving scenes, we first categorize the knowledge into two types, the property of objects and the relationship among objects. We then propose a tree-structured variational auto-encoder (T-VAE) to learn hierarchical scene representation. By imposing semantic rules on the properties of nodes and edges into the tree structure, explicit knowledge integration enables controllable generation. To demonstrate the advantage of structural representation, we construct a synthetic example to illustrate the controllability and explainability of our method in a succinct setting. We further extend to realistic environments for autonomous vehicles, showing that our method efficiently identifies adversarial driving scenes against different state-of-the-art 3D point cloud segmentation models and satisfies the constraints specified as explicit knowledge. © 2025 IEEE. All rights reserved,
KW  - autonomous driving
KW  - safety and robustness
KW  - Scene generation
KW  - Traffic signs
KW  - Autonomous driving
KW  - Data driven
KW  - Driving systems
KW  - Embeddings
KW  - Explicit knowledge
KW  - Generative model
KW  - Knowledge guidances
KW  - Property
KW  - Safety and robustness
KW  - Scene generation
KW  - Generative adversarial networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Choi, S.
AU  - Jung, Y.
TI  - Knowledge Graph Construction: Extraction, Learning, and Evaluation
PY  - 2025
T2  - Applied Sciences (Switzerland)
VL  - 15
IS  - 7
C7  - 3727
DO  - 10.3390/app15073727
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002278861&doi=10.3390%2fapp15073727&partnerID=40&md5=9e7416d94fc0625520f280b25151d81e
AB  - A Knowledge Graph (KG), which structurally represents entities (nodes) and relationships (edges), offers a powerful and flexible approach to knowledge representation in the field of Artificial Intelligence (AI). KGs have been increasingly applied in various domains—such as natural language processing (NLP), recommendation systems, knowledge search, and medical diagnostics—spurring continuous research on effective methods for their construction and maintenance. Recently, efforts to combine large language models (LLMs), particularly those aimed at managing hallucination symptoms, with KGs have gained attention. Consequently, new approaches have emerged in each phase of KG development, including Extraction, Learning Paradigm, and Evaluation Methodology. In this paper, we focus on major publications released after 2022 to systematically examine the process of KG construction along three core dimensions: Extraction, Learning Paradigm, and Evaluation Methodology. Specifically, we investigate (1) large-scale data preprocessing and multimodal extraction techniques in the KG Extraction domain, (2) the refinement of traditional embedding methods and the application of cutting-edge techniques—such as Graph Neural Networks, Transformers, and LLMs—in the KG Learning domain, and (3) both intrinsic and extrinsic metrics in the KG Evaluation domain, as well as various approaches to ensure interpretability and reliability. © 2025 by the authors.
KW  - application
KW  - evaluation
KW  - extraction
KW  - knowledge graph
KW  - learning
KW  - LLM
KW  - specific domain
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Diagnosis
KW  - Domain Knowledge
KW  - Federated learning
KW  - Graph embeddings
KW  - Graph neural networks
KW  - Natural language processing systems
KW  - Network embeddings
KW  - Evaluation
KW  - Evaluation methodologies
KW  - Graph construction
KW  - Knowledge graphs
KW  - Language model
KW  - Large language model
KW  - Learning
KW  - Learning evaluations
KW  - Learning paradigms
KW  - Specific domain
KW  - Knowledge graph
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Hassan, K.
AU  - Thakur, A.K.
AU  - Singh, G.
AU  - Singh, J.
AU  - Gupta, L.R.
AU  - Singh, R.
TI  - Application of Artificial Intelligence in Aerospace Engineering and Its Future Directions: A Systematic Quantitative Literature Review
PY  - 2024
T2  - Archives of Computational Methods in Engineering
VL  - 31
IS  - 7
SP  - 4031
EP  - 4086
DO  - 10.1007/s11831-024-10105-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190496834&doi=10.1007%2fs11831-024-10105-7&partnerID=40&md5=d2765cf3e1b6c24798cb5437eae2db27
AB  - This research aims to comprehensively analyze the most essential uses of artificial intelligence in Aerospace Engineering. We obtained papers initially published in academic journals using a Systematic Quantitative Literature Review (SQLR) methodology. We then used bibliometric methods to examine these articles, including keyword co-occurrences and bibliographic coupling. The findings enable us to provide an up-to-date sketch of the available literature, which is then incorporated into an interpretive framework that enables AI's significant antecedents and effects to be disentangled within the context of innovation. We highlight technological, security, and economic factors as antecedents prompting companies to adopt AI to innovate. As essential outcomes of the deployment of AI, in addition to identifying the disciplinary focuses, we also identify business organizations' product innovation, process innovation, aerospace business model innovation, and national security issues. We provide research recommendations for additional examination in connection to various forms of innovation, drawing on the most critical findings from this study. © The Author(s) under exclusive licence to International Center for Numerical Methods in Engineering (CIMNE) 2024.
KW  - Aerospace engineering
KW  - National security
KW  - Numerical methods
KW  - Academic journal
KW  - Bibliographic couplings
KW  - Bibliometric
KW  - Business organizations
KW  - Co-occurrence
KW  - Economic factors
KW  - Literature reviews
KW  - Product innovation process
KW  - Security factors
KW  - Technological factors
KW  - Artificial intelligence
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Pan, T.
AU  - Shome, R.
AU  - Kavraki, L.E.
TI  - Task and Motion Planning for Execution in the Real
PY  - 2024
T2  - IEEE Transactions on Robotics
VL  - 40
SP  - 3356
EP  - 3371
DO  - 10.1109/TRO.2024.3418550
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197634984&doi=10.1109%2fTRO.2024.3418550&partnerID=40&md5=7c1af295000805637775f057e28dc5f6
AB  - Task and motion planning represents a powerful set of hybrid planning methods that combine reasoning over discrete task domains and continuous motion generation. Traditional reasoning necessitates task domain models and enough information to ground actions to motion planning queries. Gaps in this knowledge often arise from sources such as occlusion or imprecise modeling. This work generates task and motion plans that include actions cannot be fully grounded at planning time. During execution, such an action is handled by a provided human-designed or learned closed-loop behavior. Execution combines offline planned motions and online behaviors till reaching the task goal. Failures of behaviors are fed back as constraints to find new plans. Forty real-robot trials and motivating demonstrations are performed to evaluate the proposed framework and compare it against state-of-the-art. Results show faster execution time, less number of actions, and more success in problems where diverse gaps arise. The experiment data are shared for researchers to simulate these settings. The work shows promise in expanding the applicable class of realistic partially grounded problems that robots can address.  © 2004-2012 IEEE.
KW  - Robust execution
KW  - task and motion planning (TAMP)
KW  - Job analysis
KW  - Robot programming
KW  - Computational modelling
KW  - Continous motion
KW  - Domain motions
KW  - Motion-planning
KW  - Planning method
KW  - Robot sensing system
KW  - Task analysis
KW  - Task and motion planningrobust execution
KW  - Task domain
KW  - Task planning
KW  - Motion planning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Kampik, T.
AU  - Warmuth, C.
AU  - Rebmann, A.
AU  - Agam, R.
AU  - Egger, L.N.P.
AU  - Gerber, A.
AU  - Hoffart, J.
AU  - Kolk, J.
AU  - Herzig, P.
AU  - Decker, G.
AU  - van der Aa, H.
AU  - Polyvyanyy, A.
AU  - Rinderle-Ma, S.
AU  - Weber, I.
AU  - Weidlich, M.
TI  - Large Process Models: A Vision for Business Process Management in the Age of Generative AI
PY  - 2024
T2  - KI - Kunstliche Intelligenz
DO  - 10.1007/s13218-024-00863-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199789505&doi=10.1007%2fs13218-024-00863-8&partnerID=40&md5=897a9034dc28fe98b610cf480fcea52b
AB  - The continued success of Large Language Models (LLMs) and other generative artificial intelligence approaches highlights the advantages that large information corpora can have over rigidly defined symbolic models, but also serves as a proof-point of the challenges that purely statistics-based approaches have in terms of safety and trustworthiness. As a framework for contextualizing the potential, as well as the limitations of LLMs and other foundation model-based technologies, we propose the concept of a Large Process Model (LPM) that combines the correlation power of LLMs with the analytical precision and reliability of knowledge-based systems and automated reasoning approaches. LPMs are envisioned to directly utilize the wealth of process management experience that experts have accumulated, as well as process performance data of organizations with diverse characteristics, e.g., regarding size, region, or industry. In this vision, the proposed LPM would enable organizations to receive context-specific (tailored) process and other business models, analytical deep-dives, and improvement recommendations. As such, it would allow to substantially decrease the time and effort required for business transformation, while also allowing for deeper, more impactful, and more actionable insights than previously possible. We argue that implementing an LPM is feasible, but also highlight limitations and research challenges that need to be solved to implement particular aspects of the LPM vision. © The Author(s) 2024.
KW  - Business process management
KW  - Generative artificial intelligence
KW  - Large language models
M3  - Note
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - CONF
AU  - Kalluraya, S.
AU  - Pappas, G.J.
AU  - Kantaros, Y.
TI  - Resilient Temporal Logic Planning in the Presence of Robot Failures
PY  - 2023
T2  - Proceedings of the IEEE Conference on Decision and Control
SP  - 7520
EP  - 7526
DO  - 10.1109/CDC49753.2023.10383968
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184799830&doi=10.1109%2fCDC49753.2023.10383968&partnerID=40&md5=50eacc41367815747046ce1b1d8a17c8
AB  - Several task and motion planning algorithms have been proposed recently to design paths for mobile robot teams with collaborative high-level missions specified using formal languages, such as Linear Temporal Logic (LTL). However, the designed paths often lack reactivity to failures of robot capabilities (e.g., sensing, mobility, or manipulation) that can occur due to unanticipated events (e.g., human intervention or system malfunctioning) which in turn may compromise mission performance. To address this novel challenge, in this paper, we propose a new resilient mission planning algorithm for teams of heterogeneous robots with collaborative LTL missions. The robots are heterogeneous with respect to their capabilities while the mission requires applications of these skills at certain areas in the environment in a temporal/logical order. The proposed method designs paths that can adapt to unexpected failures of robot capabilities. This is accomplished by re-allocating sub-tasks to the robots based on their currently functioning skills while minimally disrupting the existing team motion plans. We provide experiments and theoretical guarantees demonstrating the efficiency and resiliency of the proposed algorithm.  © 2023 IEEE.
KW  - Computer circuits
KW  - Formal languages
KW  - Machine design
KW  - Motion planning
KW  - Robot programming
KW  - Designed path
KW  - Human intervention
KW  - Human-systems
KW  - Linear temporal logic
KW  - Mission performance
KW  - Mission planning
KW  - Mobile robots teams
KW  - Motion planning algorithms
KW  - Planning algorithms
KW  - Task planning
KW  - Temporal logic
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - BOOK
AU  - Chodak, G.
TI  - The Future of E-commerce: Innovations and Developments
PY  - 2024
T2  - The Future of E-commerce: Innovations and Developments
SP  - 1
EP  - 320
DO  - 10.1007/978-3-031-55225-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201484150&doi=10.1007%2f978-3-031-55225-0&partnerID=40&md5=8ab76dd57cba22ebe708010a529811d7
AB  - The e-commerce industry is growing year by year, with the COVID-19 pandemic having greatly accelerated this process. In response to the massive growth, this book analyses future trends in e-commerce, focusing on its importance in some parts of the economy as well key innovations, which include future logistics solutions such as automated delivery robots. The most extensive part of the book is dedicated to exploring virtual reality in e-commerce, where the author presents research on the usage of VR goggles in online stores and discusses the potential advantages and threats. Also covering key topics such as the future of payment methods, AR as an e-commerce enhancement and the direction of its development, as well as AI methods (such as ChatGPT to generate content in an online shop), this book is a key resource for anyone studying e-business. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - AI
KW  - Delivery Method
KW  - e-business
KW  - E-commerce
KW  - Internet Shop
KW  - Payment Method
KW  - robotics
KW  - the role of e-commerce in the economy
KW  - Virtual Reality
M3  - Book
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 8
ER  -

TY  - JOUR
AU  - Vedavathi, N.
AU  - Anil Kumar, K.M.
TI  - E-learning course recommendation based on sentiment analysis using hybrid Elman similarity
PY  - 2023
T2  - Knowledge-Based Systems
VL  - 259
C7  - 110086
DO  - 10.1016/j.knosys.2022.110086
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142207095&doi=10.1016%2fj.knosys.2022.110086&partnerID=40&md5=40f51c116c099712af16c30b9afa922c
AB  - Online learning is also referred to as E-learning which has gained huge attention and attracted most people during the COVID-19 lockdowns. Due to the excess of online information, users face severe challenges and difficulties realizing the best course that is being competitive in the global market. Therefore, it is necessary to develop an online recommendation system that supports the users in selecting the finest course with E-learning. Thus, the proposed work develops a robust RS model using different approaches. Initially, the pre-processing stage is performed to reduce the presented noise in the website data. Then, the feature extraction stage is done to extract the needed features using Improved TF-IDF, W2V (Word 2 Vector), and Hybrid N-gram. Finally, Elman Minimal Redundancy Maximum Relevance and Enhanced Aquila Optimization (EMRMR_EAO) model is proposed to provide Robust course recommendations. In this work, the ERNN method is used to classify the sentiments based on the similarity measure of the MRMR model. The top course recommendation is afforded depending on the similarity scores like Jaccard similarity, cosine similarity and euclidean similarity. Also, the loss function in the classifier is reduced by optimizing the weight parameters using the EAO approach. The performance analysis shows that the proposed recommendation model obtains improved results in terms of accuracy of 99.98%, recall of 99.81%, precision of 99.65%, and F-measure of 99.95%. The comparative analysis exhibit that the proposed EMRMR_EAO model attains better performance than the other existing works in the literature. © 2022 Elsevier B.V.
KW  - Classification
KW  - E-learning
KW  - Elman Minimal Redundancy Maximum Relevance (EMRMR)
KW  - Feature extraction
KW  - Optimization
KW  - Pre-processing
KW  - Recommendation system
KW  - Sentimental analysis
KW  - Extraction
KW  - Feature extraction
KW  - International trade
KW  - Learning systems
KW  - Recommender systems
KW  - Redundancy
KW  - Sentiment analysis
KW  - E - learning
KW  - E-learning course
KW  - Elman minimal redundancy maximum relevance
KW  - Features extraction
KW  - Minimal redundancy
KW  - Online learning
KW  - Optimisations
KW  - Pre-processing
KW  - Sentiment analysis
KW  - Sentimental analyse
KW  - E-learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 31
ER  -

TY  - CONF
AU  - Garrido, J.S.
AU  - Dold, D.
AU  - Frank, J.
TI  - Machine learning on knowledge graphs for context-aware security monitoring
PY  - 2021
T2  - Proceedings of the 2021 IEEE International Conference on Cyber Security and Resilience, CSR 2021
SP  - 55
EP  - 60
DO  - 10.1109/CSR51186.2021.9527927
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106087093&doi=10.1109%2fCSR51186.2021.9527927&partnerID=40&md5=cd9bd4a4a22901203f7da7fef1c7b274
AB  - Machine learning techniques are gaining attention in the context of intrusion detection due to the increasing amounts of data generated by monitoring tools, as well as the sophistication displayed by attackers in hiding their activity. However, existing methods often exhibit important limitations in terms of the quantity and relevance of the generated alerts. Recently, knowledge graphs are finding application in the cybersecurity domain, showing the potential to alleviate some of these drawbacks thanks to their ability to seamlessly integrate data from multiple domains using human-understandable vocabularies. We discuss the application of machine learning on knowledge graphs for intrusion detection and experimentally evaluate a link-prediction method for scoring anomalous activity in industrial systems. After initial unsupervised training, the proposed method is shown to produce intuitively well-calibrated and interpretable alerts in a diverse range of scenarios, hinting at the potential benefits of relational machine learning on knowledge graphs for intrusion detection purposes. © 2021 IEEE.
KW  - Artificial intelligence
KW  - Cybersecurity
KW  - Industrial control systems
KW  - Knowledge graphs
KW  - Machine learning
KW  - Graphic methods
KW  - Knowledge representation
KW  - Machine learning
KW  - Anomalous activity
KW  - Industrial systems
KW  - Machine learning techniques
KW  - Monitoring tools
KW  - Multiple domains
KW  - Potential benefits
KW  - Security monitoring
KW  - Unsupervised training
KW  - Intrusion detection
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 25
ER  -

TY  - CONF
AU  - Bowden, K.K.
AU  - Fan, Y.
AU  - Chen, W.
AU  - Cui, W.
AU  - Harrison, D.
AU  - Wang, X.E.
AU  - Walker, M.
TI  - Active Listening: Personalized Question Generation in Open-Domain Social Conversation with User Model Based Prompting
PY  - 2024
T2  - EMNLP 2024 - 2024 Conference on Empirical Methods in Natural Language Processing, Findings of EMNLP 2024
SP  - 14120
EP  - 14157
DO  - 10.18653/v1/2024.findings-emnlp.826
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217618803&doi=10.18653%2fv1%2f2024.findings-emnlp.826&partnerID=40&md5=ff72b73f27a663cd8492543c8ac8ccbc
AB  - Large language models (LLMs) capable of casual conversation have recently become widely available. We hypothesize that users of conversational systems want a more personalized experience, and existing work shows that users are highly receptive to personalized questions (PQs). Question Generation tasks, however, focus on factual questions from textual excerpts. To create a PQ generator, we first identify over 400 real user interests by anonymously aggregating ∼39K user models. We then populate prompt templates with these 400 interests and use an LLM to generate PQs customized to user interests. The result is PerQs, a novel corpus of ∼19K question/answer pairs. We evaluate PerQs at scale in the unique context of the Alexa Prize. Our results show significant positive effects on perceived conversation quality. We then fine-tune, deploy, and evaluate PerQy, a neural model that generates PQs in real-time. When evaluated against several competitive LLM baselines, PerQy produced the most natural and engaging responses. © 2024 Association for Computational Linguistics.
KW  - Active listening
KW  - Conversational systems
KW  - Language model
KW  - Model-based OPC
KW  - Neural modelling
KW  - Question-answer pairs
KW  - Real- time
KW  - Social conversations
KW  - User Modelling
KW  - Users' interests
KW  - Computational linguistics
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - BOOK
AU  - Cambria, E.
TI  - Understanding natural language understanding
PY  - 2024
T2  - Understanding Natural Language Understanding
SP  - 1
EP  - 500
DO  - 10.1007/978-3-031-73974-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001667810&doi=10.1007%2f978-3-031-73974-3&partnerID=40&md5=596b9c92923c4e0c31ac9dcf8785a7eb
AB  - About half a century ago, AI pioneers like Marvin Minsky embarked on the ambitious project of emulating how the human mind encodes and decodes meaning. While today we have a better understanding of the brain thanks to neuroscience, we are still far from unlocking the secrets of the mind, especially when it comes to language, the prime example of human intelligence. "Understanding natural language understanding", i.e., understanding how the mind encodes and decodes meaning through language, is a significant milestone in our journey towards creating machines that genuinely comprehend human language. Large language models (LLMs) such as GPT-4 have astounded us with their ability to generate coherent, contextually relevant text, seemingly bridging the gap between human and machine communication. Yet, despite their impressive capabilities, these models operate on statistical patterns rather than true comprehension. This textbook delves into the nuanced differences between these two paradigms and explores the future of AI as we strive to achieve true natural language understanding (NLU). LLMs excel at identifying and replicating patterns within vast datasets, producing responses that appear intelligent and meaningful. They can generate text that mimics human writing styles, provide summaries of complex documents, and even engage in extended dialogues with users. However, their limitations become evident when they encounter tasks that require deeper understanding, reasoning, and contextual knowledge. An NLU system that deconstructs meaning leveraging linguistics and semiotics (on top of statistical analysis) represents a more profound level of language comprehension. It involves understanding context in a manner similar to human cognition, discerning subtle meanings, implications, and nuances that current LLMs might miss or misinterpret. NLU grasps the semantics behind words and sentences, comprehending synonyms, metaphors, idioms, and abstract concepts with precision. This textbook explores the current state of LLMs, their capabilities and limitations, and contrasts them with the aspirational goals of NLU. The author delves into the technical foundations required for achieving true NLU, including advanced knowledge representation, hybrid AI systems, and neurosymbolic integration, while also examining the ethical implications and societal impacts of developing AI systems that genuinely understand human language. Containing exercises, a final assignment and a comprehensive quiz, the textbook is meant as a reference for courses on information retrieval, AI, NLP, data analytics, data mining and more. © Springer Nature Switzerland AG 2025. All rights reserved.
KW  - Anaphora resolution
KW  - Aspect extraction
KW  - Knowledge representation
KW  - Large language models
KW  - Metaphor understanding
KW  - Microtext normalization
KW  - Named entity recognition
KW  - Natural language processing
KW  - Natural language understanding
KW  - Neurosymbolic AI
KW  - Personality recognition
KW  - Responsible AI
KW  - Sarcasm detection
KW  - Sentiment analysis
KW  - Word sense disambiguation
M3  - Book
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 18
ER  -

TY  - JOUR
AU  - Yang, F.
AU  - Zuo, R.
AU  - Kreuzer, O.P.
TI  - Artificial intelligence for mineral exploration: A review and perspectives on future directions from data science
PY  - 2024
T2  - Earth-Science Reviews
VL  - 258
C7  - 104941
DO  - 10.1016/j.earscirev.2024.104941
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205364069&doi=10.1016%2fj.earscirev.2024.104941&partnerID=40&md5=1822ed350a07e78d9837320fc3fb1ed3
AB  - The massive accumulation of available multi-modal mineral exploration data for most metallogenic belts worldwide provides abundant information for the discovery of mineral resources. However, managing and analyzing these ever-growing and multidisciplinary mineral exploration data has become increasingly time-consuming and labor-intensive. Artificial intelligence (AI) has demonstrated powerful prediction and knowledge integration capabilities, enabling geologists to efficiently leverage mineral exploration data. This paper reviews publications on state-of-the-art AI applications for ten mineral exploration tasks ranging from data mining to grade and tonnage estimation. These studies are based on expert systems, fuzzy logic, and various machine learning algorithms designed to optimize and improve the workflow of mineral exploration. We recognize that most AI for mineral exploration is data-driven research for now. However, AI models that couple geological knowledge and mineral exploration data will be increasingly favored in this field in the future. This paper also discusses the challenges of AI in mineral exploration research and the implications of future developments associated with novel technologies and practical deployments. Although AI has not yet been extensively tested for practical deployment in mineral exploration, its study execution exhibits the potential to trigger a fundamental research paradigm shift. © 2024 Elsevier B.V.
KW  - Artificial intelligence
KW  - Big data
KW  - Knowledge integration
KW  - Mineral exploration
KW  - artificial intelligence
KW  - efficiency measurement
KW  - estimation method
KW  - future prospect
KW  - geological survey
KW  - metallogenesis
KW  - mineral exploration
KW  - mineral resource
KW  - ore deposit
KW  - prediction
KW  - source rock
KW  - trigger mechanism
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 11
ER  -

TY  - CONF
AU  - Xu, K.
AU  - Zhang, M.
AU  - Li, J.
AU  - Du, S.S.
AU  - Kawarabayashi, K.-I.
AU  - Jegelka, S.
TI  - HOW NEURAL NETWORKS EXTRAPOLATE: FROM FEEDFORWARD TO GRAPH NEURAL NETWORKS
PY  - 2021
T2  - ICLR 2021 - 9th International Conference on Learning Representations
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139721901&partnerID=40&md5=de066cad4df2330230dbf30de85c09e2
AB  - We study how neural networks trained by gradient descent extrapolate, i.e., what they learn outside the support of the training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not extrapolate well in certain simple tasks, Graph Neural Networks (GNNs) - structured networks with MLP modules - have shown some success in more complex tasks. Working towards a theoretical explanation, we identify conditions under which MLPs and GNNs extrapolate well. First, we quantify the observation that ReLU MLPs quickly converge to linear functions along any direction from the origin, which implies that ReLU MLPs do not extrapolate most nonlinear functions. But, they can provably learn a linear target function when the training distribution is sufficiently “diverse”. Second, in connection to analyzing the successes and limitations of GNNs, these results suggest a hypothesis for which we provide theoretical and empirical evidence: the success of GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or edge weights) relies on encoding task-specific non-linearities in the architecture or features. Our theoretical analysis builds on a connection of over-parameterized networks to the neural tangent kernel. Empirically, our theory holds across different training settings. © 2021 ICLR 2021 - 9th International Conference on Learning Representations. All rights reserved.
KW  - Extrapolation
KW  - Gradient methods
KW  - Graph neural networks
KW  - Complex task
KW  - Feed forward
KW  - Gradient-descent
KW  - Graph neural networks
KW  - Learn+
KW  - Multilayers perceptrons
KW  - Neural-networks
KW  - Simple++
KW  - Structured networks
KW  - Tasks graph
KW  - Multilayer neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 118
ER  -

TY  - JOUR
AU  - Triantafyllopoulos, A.
AU  - Christ, L.
AU  - Gebhard, A.
AU  - Jing, X.
AU  - Kathan, A.
AU  - Milling, M.
AU  - Tsangko, I.
AU  - Amiriparian, S.
AU  - Schuller, B.W.
TI  - Beyond Deep Learning: Charting the Next Frontiers of Affective Computing
PY  - 2024
T2  - Intelligent Computing
VL  - 3
C7  - 0089
DO  - 10.34133/icomputing.0089
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206473741&doi=10.34133%2ficomputing.0089&partnerID=40&md5=10a10864f4bd0d4bfd0af18521cc46be
AB  - Affective computing (AC), like most other areas of computational research, has benefited tremendously from advances in deep learning (DL). These advances have opened up new horizons in AC research and practice. Yet, as DL dominates the community’s attention, there is a danger of overlooking other emerging trends in artificial intelligence (AI) research. Furthermore, over-reliance on one particular technology may lead to stagnating progress. In an attempt to foster the exploration of complementary directions, we provide a concise, easily digestible overview of emerging trends in AI research that stand to play a vital role in solving some of the remaining challenges in AC research. Our overview is driven by the limitations of the current state of the art as it pertains to AC. © 2024 Andreas Triantafyllopoulos et al.
KW  - Adversarial machine learning
KW  - 'current
KW  - Affective Computing
KW  - Artificial intelligence research
KW  - Computational researches
KW  - Computing research
KW  - Emerging trends
KW  - Over reliance
KW  - State of the art
KW  - Contrastive Learning
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Messaoudi, C.
AU  - Guessoum, Z.
AU  - ben Romdhane, L.
TI  - A Deep Learning Model for Opinion mining in Twitter Combining Text and Emojis
PY  - 2022
T2  - Procedia Computer Science
VL  - 207
SP  - 2628
EP  - 2637
DO  - 10.1016/j.procs.2022.09.321
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143373485&doi=10.1016%2fj.procs.2022.09.321&partnerID=40&md5=cde2623ccf06d392e7ec94a8a8849456
AB  - Several approaches have been proposed to study opinions on Social Network Sites (SNS). Unfortunately, those works are not topic-sensitive and do not investigate the impact of emojis on text-based classification. In this paper, we propose a novel approach to predict the users' opinions expressed through textual tweets and emojis. Thus, we construct an emoji sentiment lexicon. Then, we extract opinions from the text before considering both the text and emojis to see how they enhance the expression of opinions in SNS discussions. We conduct a set of benchmarks using several well-known machine learning algorithms, leading to an accuracy of 83, 7%. © 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0) Peer-review under responsibility of the scientific committee of the 26th International Conference on Knowledge-Based and Intelligent Information & Engineering Systems (KES 2022)
KW  - emojis
KW  - machine learning
KW  - Opinion mining
KW  - social networks
KW  - Twitter
KW  - Data mining
KW  - Deep learning
KW  - Knowledge based systems
KW  - Learning algorithms
KW  - Learning systems
KW  - Social networking (online)
KW  - Emojis
KW  - Intelligent information systems
KW  - Knowledge based
KW  - Learning models
KW  - Machine-learning
KW  - Opinion mining
KW  - Peer review
KW  - Social network
KW  - Social Network Sites
KW  - Twitter
KW  - Sentiment analysis
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - JOUR
AU  - Tian, Y.
AU  - Lin, F.
AU  - Li, Y.
AU  - Zhang, T.
AU  - Zhang, Q.
AU  - Fu, X.
AU  - Huang, J.
AU  - Dai, X.
AU  - Wang, Y.
AU  - Tian, C.
AU  - Li, B.
AU  - Lv, Y.
AU  - Kovács, L.
AU  - Wang, F.-Y.
TI  - UAVs meet LLMs: Overviews and perspectives towards agentic low-altitude mobility
PY  - 2025
T2  - Information Fusion
VL  - 122
C7  - 103158
DO  - 10.1016/j.inffus.2025.103158
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002285252&doi=10.1016%2fj.inffus.2025.103158&partnerID=40&md5=5bcb4e0cccd08b4c389aa7cd6128f3f3
AB  - Low-altitude mobility, exemplified by unmanned aerial vehicles (UAVs), has introduced transformative advancements across various domains, like transportation, logistics, and agriculture. Leveraging flexible perspectives and rapid maneuverability, UAVs extend traditional systems’ perception and action capabilities, garnering widespread attention from academia and industry. However, current UAV operations primarily depend on human control, with only limited autonomy in simple scenarios, and lack the intelligence and adaptability needed for more complex environments and tasks. The emergence of large language models (LLMs) demonstrates remarkable problem-solving and generalization capabilities, offering a promising pathway for advancing UAV intelligence. This paper explores the integration of LLMs and UAVs, beginning with an overview of UAV systems’ fundamental components and functionalities, followed by an overview of the state-of-the-art LLM technology. Subsequently, it systematically highlights the multimodal data resources available for UAVs, which provide critical support for training and evaluation. Furthermore, key tasks and application scenarios where UAVs and LLMs converge are categorized and analyzed. Finally, a reference roadmap towards agentic UAVs is proposed to enable UAVs to achieve agentic intelligence through autonomous perception, memory, reasoning, and tool utilization. Related resources are available at https://github.com/Hub-Tian/UAVs_Meet_LLMs. © 2025
KW  - Foundation intelligence
KW  - Large language models
KW  - Low altitude mobility systems
KW  - Unmanned aerial vehicles
KW  - Maneuverability
KW  - Street traffic control
KW  - Aerial vehicle
KW  - Foundation intelligence
KW  - Language model
KW  - Large language model
KW  - Low altitude mobility system
KW  - Low altitudes
KW  - Manoeuvrability
KW  - Mobility systems
KW  - Transportation-logistics
KW  - Unmanned aerial vehicle
KW  - Unmanned aerial vehicles (UAV)
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Li, Q.
AU  - Wu, G.
TI  - Explainable reasoning over temporal knowledge graphs by pre-trained language model
PY  - 2025
T2  - Information Processing and Management
VL  - 62
IS  - 1
C7  - 103903
DO  - 10.1016/j.ipm.2024.103903
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205325447&doi=10.1016%2fj.ipm.2024.103903&partnerID=40&md5=c995c53b0111e30f6195c4134fc7e06a
AB  - Temporal knowledge graph reasoning (TKGR) has been considered as a crucial task for modeling the evolving knowledge, aiming to infer the unknown connections between entities at specific times. Traditional TKGR methods try to aggregate structural information between entities and evolve representations of entities over distinct snapshots, while some other methods attempt to extract temporal logic rules from historical interactions. However, these methods fail to address the continuously emerging unseen entities over time and ignore the historical dependencies between entities and relations. To overcome these limitations, we propose a novel method, termed TPNet, which introduces historical information completion strategy (HICS) and pre-trained language model (PLM) to conduct explainable inductive reasoning over TKGs. Specifically, TPNet extracts reliable temporal logical paths from historical subgraphs using a temporal-correlated search strategy. For unseen entities, we utilize HICS to sample or generate paths to supplement their historical information. Besides, a PLM and a time-aware encoder are introduced to jointly encode the temporal paths, thereby comprehensively capturing dependencies between entities and relations. Moreover, the semantic similarity between the query quadruples and the extracted paths is evaluated to simultaneously optimize the representations of entities and relations. Extensive experiments on entity and relation prediction tasks are conducted to evaluate the performance of TPNet. The experimental results on four benchmark datasets demonstrate the superiority of TPNet over state-of-the-art TKGR methods, achieving improvements of 14.35%, 23.08%, 6.75% and 5.38% on MRR, respectively. © 2024 Elsevier Ltd
KW  - Graph representation learning
KW  - Knowledge graph reasoning
KW  - Logical reasoning
KW  - Multi-hop paths
KW  - Pre-trained language model
KW  - Temporal knowledge graph
KW  - Graph representation
KW  - Graph representation learning
KW  - Knowledge graph reasoning
KW  - Knowledge graphs
KW  - Language model
KW  - Logical reasoning
KW  - Multi-hop path
KW  - Pre-trained language model
KW  - Temporal knowledge
KW  - Temporal knowledge graph
KW  - Knowledge graph
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Wei, Y.
TI  - Backpropagation-based Parameter Tuning and Granular Alignment for Multi-target Domain Adaptation
PY  - 2025
T2  - IEEE Access
DO  - 10.1109/ACCESS.2025.3554101
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001320496&doi=10.1109%2fACCESS.2025.3554101&partnerID=40&md5=642a58e3bb08cc5ae57ad2b5785a82c8
AB  - Domain adaptation has emerged as a crucial technique for transferring knowledge between different data distributions. While significant progress has been made in adapting between single source and target domains, the challenging problem of adapting to multiple target domains simultaneously has received limited attention. This paper addresses this gap by introducing a novel framework that effectively handles multiple target domains through two key innovations: backpropagation-based parameter tuning for key features (BPTF) and progressive granular category-level alignment (PGCA). Our approach uniquely combines adaptive feature weighting with dynamic domain alignment to achieve superior performance across multiple target domains simultaneously. Firstly, we introduce the backpropagation-based parameter tuning for key features (GWCF) technique, which attenuates the detrimental impact of noisy samples and significant distribution discrepancies by prioritizing essential features. Secondly, we present the progressive granular category-level alignment (PGCA) strategy, leveraging Kullback-Leibler (KL) divergence to regulate a gradual adaptation process. This method enables a smooth transition from broad categorizations to precise alignments, thereby improving consistency across the source and multiple target domains. Extensive experimental evaluations on four benchmark datasets underscore the effectiveness of our proposed approach, consistently outperforming state-of-the-art methods in multi-target domain adaptation scenarios. © 2013 IEEE.
KW  - adversarial adaptation
KW  - domain adaptive training
KW  - feature alignment
KW  - Adversarial machine learning
KW  - Domain Knowledge
KW  - Adaptive training
KW  - Adversarial adaptation
KW  - Domain adaptation
KW  - Domain adaptive training
KW  - Feature alignment
KW  - Key feature
KW  - Multi-targets
KW  - Multiple targets
KW  - Parameters tuning
KW  - Target domain
KW  - Generative adversarial networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Loconte, L.
AU  - Sladek, A.M.
AU  - Mengel, S.
AU  - Trapp, M.
AU  - Solin, A.
AU  - Gillis, N.
AU  - Vergari, A.
TI  - SUBTRACTIVE MIXTURE MODELS VIA SQUARING: REPRESENTATION AND LEARNING
PY  - 2024
T2  - 12th International Conference on Learning Representations, ICLR 2024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196755178&partnerID=40&md5=45c2c583b6c04e603a394f2b32fdcf50
AB  - Mixture models are traditionally represented and learned by adding several distributions as components. Allowing mixtures to subtract probability mass or density can drastically reduce the number of components needed to model complex distributions. However, learning such subtractive mixtures while ensuring they still encode a non-negative function is challenging. We investigate how to learn and perform inference on deep subtractive mixtures by squaring them. We do this in the framework of probabilistic circuits, which enable us to represent tensorized mixtures and generalize several other subtractive models. We theoretically prove that the class of squared circuits allowing subtractions can be exponentially more expressive than traditional additive mixtures; and, we empirically show this increased expressiveness on a series of real-world distribution estimation tasks. © 2024 12th International Conference on Learning Representations, ICLR 2024. All rights reserved.
KW  - Learning systems
KW  - Additive mixture
KW  - Distribution estimation
KW  - Learn+
KW  - Mixture modeling
KW  - Model complexes
KW  - Non negatives
KW  - Number of components
KW  - Probabilistics
KW  - Real-world
KW  - Probability distributions
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 12
ER  -

TY  - JOUR
AU  - Geng, L.
AU  - Yin, J.
AU  - Chen, G.
AU  - Jia, Q.
TI  - Pseudo-EV: Enhancing 3D Visual Grounding with Pseudo Embodied Viewpoint
PY  - 2025
T2  - IEEE Transactions on Circuits and Systems for Video Technology
DO  - 10.1109/TCSVT.2025.3547855
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000439865&doi=10.1109%2fTCSVT.2025.3547855&partnerID=40&md5=7a990a60db47c410bdb6f937875cba81
AB  - 3D Visual Grounding based on natural language is a fundamental task in Embodied AI. One of the fundamental challenges in localizing objects in 3D scenes through natural language descriptions arises from the variable perception of spatial relationships among objects when viewed from different perspectives. To address this issue, we introduce a model named Pseudo-EV, which decomposes the problem of 3D visual grounding into two stages: (1) predicting an embodied viewpoint and (2) determining the target object within that viewpoint, thereby eliminating viewpoint ambiguity. Given the scarcity of annotations for embodied viewpoint prediction, we employ a large language model (LLM) to generate pseudolabels for existing datasets as intermediate training targets. However, directly predicting viewpoints in continuous Euclidean space proves inefficient, leading to weaker alignment with textual queries and scene semantics, as well as higher training overhead. To overcome these limitations, we introduce two streamlined strategies: an Embodied Viewpoint with Semantic Structure and a Decoupled Target Prediction Strategy. Extensive experiments demonstrate that predicting intermediate embodied viewpoints substantially boosts the performance of 3D visual grounding, achieving state-of-the-art results on both ScanRefer and Nr3D/Sr3D. Moreover, our framework significantly reduces computational cost compared to other viewpoint-aware approaches. © 2025 IEEE. All rights reserved.
KW  - Embodied Cognitive Science
KW  - Human-Centered Robotics
KW  - Human-Robot Collaboration
KW  - Intention Recognition
KW  - Semantic Scene Understanding
KW  - Digital elevation model
KW  - Human robot interaction
KW  - Microrobots
KW  - Prediction models
KW  - Visual languages
KW  - 3D scenes
KW  - Cognitive science
KW  - Embodied cognitive science
KW  - Human centered robotics
KW  - Human-robot collaboration
KW  - Intention recognition
KW  - Language description
KW  - Natural languages
KW  - Scene understanding
KW  - Semantic scene understanding
KW  - Semantics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Pal, N.
AU  - Johnson, T.T.
TI  - Formal Verification of Long Short-Term Memory based Audio Classifiers: A Star based Approach
PY  - 2023
T2  - Electronic Proceedings in Theoretical Computer Science, EPTCS
VL  - 395
SP  - 162
EP  - 179
DO  - 10.4204/EPTCS.395.12
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179002371&doi=10.4204%2fEPTCS.395.12&partnerID=40&md5=39a27da4d762368fd12bf825d874563e
AB  - Formally verifying audio classification systems is essential to ensure accurate signal classification across real-world applications like surveillance, automotive voice commands, and multimedia content management, preventing potential errors with serious consequences. Drawing from recent research, this study advances the utilization of star-set-based formal verification, extended through reachability analysis, tailored explicitly for Long Short-Term Memory architectures and their Convolutional variations within the audio classification domain. By conceptualizing the classification process as a sequence of set operations, the star set-based reachability approach streamlines the exploration of potential operational states attainable by the system. The paper serves as an encompassing case study, validating and verifying sequence audio classification analytics within real-world contexts. It accentuates the necessity for robustness verification to ensure precise and dependable predictions, particularly in light of the impact of noise on the accuracy of output classifications. © 2023 Open Publishing Association. All rights reserved.
KW  - Audio acoustics
KW  - Audio systems
KW  - Brain
KW  - Classification (of information)
KW  - Formal verification
KW  - Memory architecture
KW  - Audio classification
KW  - Automotives
KW  - Classification system
KW  - Multimedia contents management
KW  - Potential errors
KW  - Reachability analysis
KW  - Real-world
KW  - Recent researches
KW  - Signal classification
KW  - Voice command
KW  - Stars
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Pandelea, V.
AU  - Ragusa, E.
AU  - Gastaldo, P.
AU  - Cambria, E.
TI  - Selecting Language Models Features VIA Software-Hardware Co-Design
PY  - 2023
T2  - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings
VL  - 2023-June
DO  - 10.1109/ICASSP49357.2023.10097191
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000382999&doi=10.1109%2fICASSP49357.2023.10097191&partnerID=40&md5=37f8252363b008b898318cca4322d2f9
AB  - The availability of new datasets and deep learning techniques have led to a surge of effort directed towards the creation of new models that can exploit the large amount of data. However, little attention has been given to the development of models that are not only accurate, but also suitable for user-specific use or geared towards resource-constrained devices. Fine-tuning deep models on edge devices is impractical and, often, user customization stands on the sub-optimal feature-extractor/classifier paradigm. Here, we propose a method to fully utilize the intermediate outputs of the popular large pre-trained models in natural language processing when used as frozen feature extractors, and further close the gap between their fine-tuning and more computationally efficient solutions. We reach this goal exploiting the concept of software-hardware co-design and propose a methodical procedure, inspired by Neural Architecture Search, to select the most desirable model taking into consideration application constraints.  © 2023 IEEE.
KW  - Edge Computing
KW  - Evaluation Methodologies
KW  - Language Models
KW  - Opinion Mining / Sentiment Analysis
KW  - Application programs
KW  - Deep learning
KW  - Edge computing
KW  - Large dataset
KW  - Learning systems
KW  - Software design
KW  - Edge computing
KW  - Evaluation methodologies
KW  - Feature extractor
KW  - Fine tuning
KW  - Language model
KW  - Modeling features
KW  - Opinion mining
KW  - Opinion mining / sentiment analyse
KW  - Sentiment analysis
KW  - Software/hardware co designs
KW  - Sentiment analysis
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Kabir, H.M.D.
AU  - Mondal, S.K.
AU  - Alam, S.B.
AU  - Acharya, U.R.
TI  - Transfer learning with spinally shared layers
PY  - 2024
T2  - Applied Soft Computing
VL  - 163
C7  - 111908
DO  - 10.1016/j.asoc.2024.111908
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197385655&doi=10.1016%2fj.asoc.2024.111908&partnerID=40&md5=f7a52a88005c2549f7c9065f86febb6e
AB  - Transfer-learned models have achieved promising performance in numerous fields. However, high-performing transfer-learned models contain a large number of parameters. In this paper, we propose a transfer learning approach with parameter reduction and potential high performance. Although the high performance depends on the nature of the dataset, we ensure the parameter reduction. In the proposed SpinalNet shared parameters, all intermediate-split-incoming parameters except the first-intermediate-split contain a shared value. Therefore, the SpinalNet shared parameters network contains three parameter groups: (1) first input-split to intermediate-split parameters, (2) shared intermediate-split-incoming parameters, and (3) intermediate-split-to-output-split parameters. The total number of parameters becomes lower than the SpinalNet and traditional fully connected layers due to parameter sharing. Besides the overall accuracy, this paper compares the precision, recall, and F1-score of each class as performance criteria. As a result, both parameter reduction and potential performance improvement become possible for the ResNet-type models, VGG-type traditional models, and Vision Transformers. We applied the proposed model to MNIST, STL-10, and COVID-19 datasets to validate our claims. We also provided a posterior plot of the sample from different models for medical practitioners to understand the uncertainty. Example model training scripts of the proposed model are also shared to GitHub. © 2024 The Author(s)
KW  - COVID
KW  - ResNet
KW  - SpinalNet
KW  - Transformer
KW  - Uncertainty
KW  - VGG
KW  - COVID-19
KW  - Learning systems
KW  - COVID
KW  - Learning approach
KW  - Parameter reduction
KW  - Performance
KW  - Resnet
KW  - Spinalnet
KW  - Transfer learning
KW  - Transformer
KW  - Uncertainty
KW  - VGG
KW  - Transfer learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Graves, S.J.
AU  - Chowdhry, R.
AU  - Zhou, M.
AU  - Harmon, I.
AU  - Weinstein, B.
AU  - Ernest, S.K.M.
AU  - Zare, A.
AU  - White, E.P.
AU  - Bohlman, S.A.
TI  - Facilitating macrosystem biology with organismal-scale airborne remote sensing: Challenges and opportunities
PY  - 2025
T2  - Functional Ecology
DO  - 10.1111/1365-2435.70083
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007451369&doi=10.1111%2f1365-2435.70083&partnerID=40&md5=a2693f187f4eef05a3cc67125015fabe
AB  - Emergent ecosystem properties, such as population and trait distributions, biodiversity and energy and water fluxes, occur because of the dynamic interactions of individuals in their environment. Remote sensing, where image data is collected over large areas, can provide information about individual organisms that reveals important ecosystem patterns and processes that are critical for macrosystems scale biology. In this review, we summarize the primary challenges of conducting organismal-scale remote sensing, such as the detection, delineation and characterization of organisms including trees, birds and mammals. For each, we highlight existing and emerging solutions that directly address these challenges. Algorithmic advancements in the realm of deep learning are one solution to addressing the challenges of limited field data, particularly for applications that require models to generalize across ecosystems and transfer to new environments and sensors. Ecological knowledge can be integrated into novel data processing pipelines such as characterizing organisms from a different perspective, translating ecological rules to mathematical expressions and casting uncertainty. To realize the potential of organismal remote sensing requires deliberate interdisciplinary collaboration with the shared goal of developing methods to produce useful ecological data products. Read the free Plain Language Summary for this article on the Journal blog. © 2025 The Author(s). Functional Ecology published by John Wiley & Sons Ltd on behalf of British Ecological Society.
KW  - animal ecology
KW  - classification
KW  - deep learning
KW  - delineation
KW  - detection
KW  - forest ecology
KW  - individual tree
KW  - species identification
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Pagliarini, G.
AU  - Sciavicco, G.
TI  - Interpretable land cover classification with modal decision trees
PY  - 2023
T2  - European Journal of Remote Sensing
VL  - 56
IS  - 1
C7  - 2262738
DO  - 10.1080/22797254.2023.2262738
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180366476&doi=10.1080%2f22797254.2023.2262738&partnerID=40&md5=71bea98e6964d31db1cbbaca5bc83ee7
AB  - Land cover classification (LCC) refers to the task of classifying each pixel in satellite/aerial imagery by predicting a label carrying information about its nature. Despite the importance of having transparent, symbolic decision models, in the recent literature, LCC has been mainly approached with black-box functional models, that are able to leverage the spatial dimensions within the data. In this article, we argue that standard symbolic decision models can be extended to perform a form of spatial reasoning that is adequate for LCC. We propose a generalization of a classical decision tree learning model, based on replacing propositional logic with a modal spatial logic, and provide a CART-like learning algorithm for it. We evaluate its performance at five different LCC tasks, showing that this technique leads to classification models whose performances are superior to those of their propositional counterpart, and at least comparable with those of non-symbolic ones. Ultimately, we show that spatial decision trees and random forests are able to extract complex, but interpretable spatial patterns. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.
KW  - decision tree learning
KW  - hyperspectral image classification
KW  - Interpretable machine learning
KW  - land cover
KW  - land use
KW  - modal logic
KW  - Classification (of information)
KW  - Computer circuits
KW  - Formal logic
KW  - Image classification
KW  - Land use
KW  - Learning algorithms
KW  - Learning systems
KW  - Machine learning
KW  - Satellite imagery
KW  - Decision modeling
KW  - Decision tree learning
KW  - Hyperspectral image classification
KW  - Interpretable machine learning
KW  - Land cover
KW  - Land cover classification
KW  - Machine-learning
KW  - Modal decision
KW  - Modal logic
KW  - Performance
KW  - algorithm
KW  - image classification
KW  - land cover
KW  - land use
KW  - machine learning
KW  - pixel
KW  - satellite imagery
KW  - Decision trees
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 8
ER  -

TY  - CONF
AU  - Zheng, W.
AU  - Guo, Q.
AU  - Yang, H.
AU  - Wang, P.
AU  - Wang, Z.
TI  - Delayed Propagation Transformer: A Universal Computation Engine towards Practical Control in Cyber-Physical Systems
PY  - 2021
T2  - Advances in Neural Information Processing Systems
VL  - 15
SP  - 12141
EP  - 12153
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127064199&partnerID=40&md5=f63dc93b3f32f01bf6830946e466e64b
AB  - Multi-agent control is a central theme in the Cyber-Physical Systems (CPS). However, current control methods either receive non-Markovian states due to insufficient sensing and decentralized design, or suffer from poor convergence. This paper presents the Delayed Propagation Transformer (DePT), a new transformer-based model that specializes in the global modeling of CPS while taking into account the immutable constraints from the physical world. DePT induces a cone-shaped spatial-temporal attention prior, which injects the information propagation and aggregation principles and enables a global view. With physical constraint inductive bias baked into its design, our DePT is ready to plug and play for a broad class of multi-agent systems. The experimental results on one of the most challenging CPS - network-scale traffic signal control system in the open world - show that our model outperformed the state-of-the-art expert methods on synthetic and real-world datasets. Our codes are released at: https://github.com/VITA-Group/DePT. © 2021 Neural information processing systems foundation. All rights reserved.
KW  - Cyber Physical System
KW  - Embedded systems
KW  - Information dissemination
KW  - Traffic signals
KW  - Computation engine
KW  - Cone-shaped
KW  - Current-control method
KW  - Decentralized design
KW  - Global models
KW  - Multiagent control
KW  - Non-Markovian
KW  - Physical world
KW  - Practical controls
KW  - Universal computations
KW  - Multi agent systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 10
ER  -

TY  - CONF
AU  - Cha, S.
AU  - Lee, M.
AU  - Lee, S.
AU  - Oh, H.
TI  - SYMTUNER: Maximizing the Power of Symbolic Execution by Adaptively Tuning External Parameters
PY  - 2022
T2  - Proceedings - International Conference on Software Engineering
VL  - 2022-May
SP  - 2068
EP  - 2079
DO  - 10.1145/3510003.3510185
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133514638&doi=10.1145%2f3510003.3510185&partnerID=40&md5=4268464eb6a64226a04bbd50025bf111
AB  - We present SYMTUNER, a novel technique to automatically tune external parameters of symbolic execution. Practical symbolic execution tools have important external parameters (e.g., symbolic arguments, seed input) that critically affect their performance. Due to the huge parameter space, however, manually customizing those parameters is notoriously difficult even for experts. As a consequence, symbolic execution tools have typically been used in a suboptimal manner that, for example, simply relies on the default parameter settings of the tools and loses the opportunity for better performance. In this paper, we aim to change this situation by automatically configuring symbolic execution parameters. With Symtuner that takes parameter spaces to be tuned, symbolic executors are run without manual parameter configurations; instead, appropriate parameter values are learned and adjusted during symbolic execution. To achieve this, we present a learning algorithm that observes the behavior of symbolic execution and accordingly updates the sampling probability of each parameter space. We evaluated Symtuner with KLEE on 12 open-source C programs. The results show that Symtuner increases branch coverage of KLEE by 56% on average and finds 8 more bugs than KLEE with its default parameters over the latest releases of the programs. © 2022 ACM.
KW  - Software Testing
KW  - Symbolic Execution
KW  - C (programming language)
KW  - Model checking
KW  - Open source software
KW  - Program debugging
KW  - Default parameters
KW  - Novel techniques
KW  - Open-source
KW  - Parameter spaces
KW  - Parameter-setting
KW  - Parameters configuration
KW  - Performance
KW  - Power
KW  - Software testings
KW  - Symbolic execution
KW  - Software testing
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - CONF
AU  - Milkowski, P.
AU  - Karanowski, K.
AU  - Wielopolski, P.
AU  - Kocon, J.
AU  - Kazienko, P.
AU  - Zieba, M.
TI  - Modeling Uncertainty in Personalized Emotion Prediction with Normalizing Flows
PY  - 2023
T2  - IEEE International Conference on Data Mining Workshops, ICDMW
SP  - 757
EP  - 766
DO  - 10.1109/ICDMW60847.2023.00103
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186137865&doi=10.1109%2fICDMW60847.2023.00103&partnerID=40&md5=2b1835e428c881bd2402b70dcb547fa8
AB  - Designing predictive models for subjective problems in natural language processing (NLP) remains challenging. This is mainly due to its non-deterministic nature and different perceptions of the content by different humans. It may be solved by Personalized Natural Language Processing (PNLP), where the model exploits additional information about the reader to make more accurate predictions. However, current approaches require complete information about the recipients to be straight embedded. Besides, the recent methods focus on deterministic inference or simple frequency-based estimations of the probabilities. In this work, we overcome this limitation by proposing a novel approach to capture the uncertainty of the forecast using conditional Normalizing Flows. This allows us to model complex multimodal distributions and to compare various models using negative log-likelihood (NLL). In addition, the new solution allows for various interpretations of possible reader perception thanks to the available sampling function. We validated our method on three challenging, subjective NLP tasks, including emotion recognition and hate speech. The comparative analysis of generalized and personalized approaches revealed that our personalized solutions significantly outperform the baseline and provide more precise uncertainty estimates. The impact on the text interpretability and uncertainty studies are presented as well. The information brought by the developed methods makes it possible to build hybrid models whose effectiveness surpasses classic solutions. In addition, an analysis and visualization of the probabilities of the given decisions for texts with high entropy of annotations and annotators with mixed views were carried out. © 2023 IEEE.
KW  - artificial neural networks
KW  - human profile modelling
KW  - natural language processing
KW  - probabilistic technique
KW  - Emotion Recognition
KW  - Forecasting
KW  - Frequency estimation
KW  - Modeling languages
KW  - Speech recognition
KW  - Uncertainty analysis
KW  - Accurate prediction
KW  - Deterministics
KW  - Emotion predictions
KW  - Human profile modeling
KW  - Language processing
KW  - Modeling uncertainties
KW  - Natural language processing
KW  - Natural languages
KW  - Predictive models
KW  - Probabilistic technique
KW  - Neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - JOUR
AU  - Feng, S.
AU  - Xu, X.
AU  - Li, S.
AU  - Li, Z.
AU  - Gibson, D.
TI  - Is metaverse a buzzword in education? Insights from a systematic review: Is metaverse a buzzword in education?: S. Feng et al.
PY  - 2024
T2  - Educational Technology Research and Development
VL  - 72
IS  - 6
SP  - 3349
EP  - 3390
DO  - 10.1007/s11423-024-10398-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197665948&doi=10.1007%2fs11423-024-10398-2&partnerID=40&md5=b91ef5eb5103478d168ac28bbe2e0ee0
AB  - Although the metaverse is a trending topic in several fields, it is not a new concept within the field of education. In this study, we followed the PRISMA framework and identified 37 articles since 2008 that researched the metaverse in education. We critically reviewed these articles, aiming to examine the evolution of the field’s conceptual understanding of the metaverse in education, identify its applications and effects, as well as synthesize the technical solutions and adoption challenges for implementing metaverse systems in schools. We found that the early empirical implementation of metaverse concepts in education mainly emphasized the characteristics of 3D virtual environments and avatars using the Second Life and OpenSim platforms. These traditional applications were found to be effective in supporting various teaching methods and enhancing students’ learning experiences and outcomes. In recent studies, more advanced technologies that pursue the fusion of physical and virtual environments (e.g. AI techniques, VR/AR devices, cloud platforms, wearable devices) have been incorporated into metaverse systems. However, the extent to which physical and virtual environments were fused in metaverse applications in education needs to be further clarified. We suggest that the conceptual clarity of the metaverse in education will keep evolving along with the technology development, and teacher preparedness for this new technical revolution needs more attention. © Association for Educational Communications and Technology 2024.
KW  - Emerging technologies
KW  - Immersive learning environments
KW  - Metaverse in education
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Devi, M.S.
AU  - Sangeetha, V.
AU  - Reshmi, R.
AU  - Saima Nooreen, S.
AU  - Rajeshwari, C.
AU  - Sai Pranavi, N.
TI  - Contour Edge Mask Filtered Residual Network based Egg Classification
PY  - 2024
T2  - 8th IEEE International Conference on Computational System and Information Technology for Sustainable Solutions, CSITSS 2024
DO  - 10.1109/CSITSS64042.2024.10816958
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216935243&doi=10.1109%2fCSITSS64042.2024.10816958&partnerID=40&md5=eac890fa8adf2e163d775a99b3ce2ea4
AB  - In agricultural and food safety, classifying eggs is a crucial activity that requires great precision in distinguishing various kinds of egg. Traditional approaches can be expensive and error-prone since they frequently rely on manual examination or simple image processing techniques. In order to improve classification performance, this research proposes Contour Edge Mask Filtered ResNet (CEM-ResNet), which combines advanced deep learning techniques with edge-detection methods. The Egg Dataset containing 2000 egg images that was used for implementation. The suggested CEM-ResNet model uses contour edge masking to eliminate extraneous background noise and highlights key structural information while utilizing ResNet architecture to capture essential details of eggs. The suggested CEM-ResNet model uses contour edge masking to eliminate extraneous background noise and highlights key structural information while utilizing ResNet architecture to capture essential details of eggs. Initially, the CEM-ResNet model organizes the egg into two groups as Chicken egg and Duck egg. The organized eggs are performed with labeling and then subjected to data augmentation to end up with 42,000 images. The augmented egg images are converted to grayscale images. The grayscale images are processed with edge detection model to finalize the contour filtered egg images and ResNet model. The contour filtered egg images are refined to create the edges and then the mask was created to generate Contour Edge Mask Filtered (CEM) egg images. The ResNet model was refined to process the CEM egg images. With a high accuracy of 99.64%, the implementation reveals that the proposed CEM-ResNet model outperforms towards the classification task.  © 2024 IEEE.
KW  - accuracy
KW  - augmentation
KW  - classification
KW  - CNN
KW  - DL
KW  - filtering
KW  - kernel
KW  - ResNet
KW  - Accuracy
KW  - Augmentation
KW  - Background noise
KW  - Contour edges
KW  - DL
KW  - Gray-scale images
KW  - Kernel
KW  - Model use
KW  - Network-based
KW  - Structural information
KW  - Deep learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Kumar, A.
AU  - Bhushan, B.
TI  - AI Driven Sentiment Analysis for Social Media Data
PY  - 2023
T2  - Proceedings - 4th IEEE 2023 International Conference on Computing, Communication, and Intelligent Systems, ICCCIS 2023
SP  - 1201
EP  - 1206
DO  - 10.1109/ICCCIS60361.2023.10425434
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186490536&doi=10.1109%2fICCCIS60361.2023.10425434&partnerID=40&md5=35c6bb86802cd2327f0da319573ce500
AB  - Sentiment analysis (SA) is a subject of ongoing text mining research. The subjectivity, emotions, and viewpoints of a text are handled algorithmically by sentiment analysis. This survey research examines the most recent development in this field in great detail. This paper examines and provides a quick overview of various recently suggested algorithm enhancements. Based on their contributions to the various sentiment analysis approaches, these articles are categorized into various categories. Sentiment analysis may be utilised to extract information related to thoughts and feelings from human-generated textual data. Users have posted a significant quantity of unprocessed material to social networking sites in the shape of speech, videos, photographs, and audio. Global catastrophes including heatwaves, earthquakes, cyclones, floods and bushfires are having an extraordinary impact on social media users' life. They frequently write how pessimistic they find the catastrophic scenarios at their target area to be. Politicians and strategic planners must prioritise comprehending location-specific attitudes towards crisis situations. Data may be turned into valuable knowledge by using sentiment analysis. The primary goal of the questionnaire is to provide a concise, almost complete picture of Sentiment Analysis methods and associated topics. The comprehensive categories of several recently published papers and the explanation of the present state of research in sentiment evaluation as well as related fields are the key contributions made by this study. © 2023 IEEE.
KW  - Building resources
KW  - Emotion detection
KW  - Feature selection
KW  - Sentiment analysis
KW  - Sentiment classifification
KW  - Transfer learning
KW  - Feature extraction
KW  - Petroleum reservoir evaluation
KW  - Social networking (online)
KW  - Storms
KW  - Analysis approach
KW  - Building resource
KW  - Emotion detection
KW  - Features selection
KW  - Sentiment analysis
KW  - Sentiment classifification
KW  - Social media datum
KW  - Survey research
KW  - Text-mining
KW  - Transfer learning
KW  - Sentiment analysis
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - BOOK
AU  - Wang, W.
TI  - Principles of Machine Learning: The Three Perspectives
PY  - 2024
T2  - Principles of Machine Learning: the Three Perspectives
SP  - 1
EP  - 527
DO  - 10.1007/978-981-97-5333-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004618318&doi=10.1007%2f978-981-97-5333-8&partnerID=40&md5=45071bdbe84aee19dc67b64863f536c6
AB  - Conducting an in-depth analysis of machine learning, this book proposes three perspectives for studying machine learning: the learning frameworks, learning paradigms, and learning tasks. With this categorization, the learning frameworks reside within the theoretical perspective, the learning paradigms pertain to the methodological perspective, and the learning tasks are situated within the problematic perspective. Throughout the book, a systematic explication of machine learning principles from these three perspectives is provided, interspersed with some examples. The book is structured into four parts, encompassing a total of fifteen chapters. The inaugural part, titled “Perspectives,” comprises two chapters: an introductory exposition and an exploration of the conceptual foundations. The second part, “Frameworks”: subdivided into five chapters, each dedicated to the discussion of five seminal frameworks: probability, statistics, connectionism, symbolism, and behaviorism. Continuing further, the third part, “Paradigms,” encompasses four chapters that explain the three paradigms of supervised learning, unsupervised learning, and reinforcement learning, and narrating several quasi-paradigms emerged in machine learning. Finally, the fourth part, “Tasks”: comprises four chapters, delving into the prevalent learning tasks of classification, regression, clustering, and dimensionality reduction. This book provides a multi-dimensional and systematic interpretation of machine learning, rendering it suitable as a textbook reference for senior undergraduates or graduate students pursuing studies in artificial intelligence, machine learning, data science, computer science, and related disciplines. Additionally, it serves as a valuable reference for those engaged in scientific research and technical endeavors within the realm of machine learning. The translation was done with the help of artificial intelligence. A subsequent human revision was done primarily in terms of content. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.
KW  - deep learning
KW  - machine learning
KW  - reinforcement learning
KW  - supervised learning
KW  - unsupervised learning
KW  - Adversarial machine learning
KW  - Backpropagation
KW  - Cluster analysis
KW  - Contrastive Learning
KW  - Deep learning
KW  - Deep reinforcement learning
KW  - Dimensionality reduction
KW  - Federated learning
KW  - Multi-task learning
KW  - Reinforcement learning
KW  - Self-supervised learning
KW  - Semi-supervised learning
KW  - Students
KW  - Support vector machines
KW  - Conceptual foundations
KW  - Connectionism
KW  - Deep learning
KW  - In-depth analysis
KW  - Learning frameworks
KW  - Learning paradigms
KW  - Learning tasks
KW  - Machine-learning
KW  - Probability statistic
KW  - Reinforcement learnings
KW  - Unsupervised learning
M3  - Book
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Gianola, A.
AU  - Montali, M.
AU  - Papini, M.
TI  - Automated reasoning for reinforcement learning agents in structured environments
PY  - 2021
T2  - CEUR Workshop Proceedings
VL  - 2987
SP  - 43
EP  - 48
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118209959&partnerID=40&md5=27db7fe31757dd924bd054c0f5b2d801
AB  - Designing agents that are both adaptive and trustworthy is a long-standing problem at the intersection of symbolic AI and Machine Learning. In this position paper, we discuss several benefits of combining automated reasoning and reinforcement learning techniques to formally verify agents’ behavior in structured environments, both during and after the learning process. These are systems where agents have access to an explicit structure representing what they know about the world. Since we care both about the verifiability and the efficiency of the learning process, we argue why it is crucial to efficiently integrate complex structures in the learning algorithms themselves. © 2021 Copyright for this paper by its authors.
KW  - Automated reasoning
KW  - Data-aware processes
KW  - Formal methods
KW  - Reinforcement learning
KW  - Verification
KW  - Automation
KW  - Formal verification
KW  - Intelligent agents
KW  - Learning algorithms
KW  - Automated reasoning
KW  - Data-aware process
KW  - Designing agents
KW  - Learning process
KW  - Machine-learning
KW  - Position papers
KW  - Reinforcement learning agent
KW  - Reinforcement learning techniques
KW  - Standing problems
KW  - Structured environment
KW  - Reinforcement learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CHAP
AU  - Belle, V.
TI  - Toward Robots That Reason: Logic, Probability & Causal Laws
PY  - 2023
T2  - Synthesis Lectures on Artificial Intelligence and Machine Learning
SP  - 1
EP  - 10
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149448280&partnerID=40&md5=d040965c06f18c3423020425bcb312dc
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Jaiswal, G.
AU  - Sharma, A.
AU  - Yadav, S.K.
TI  - Critical insights into modern hyperspectral image applications through deep learning
PY  - 2021
T2  - Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery
VL  - 11
IS  - 6
C7  - e1426
DO  - 10.1002/widm.1426
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110935372&doi=10.1002%2fwidm.1426&partnerID=40&md5=db8bb647f1849b52ffc45b57bad6cc67
AB  - Hyperspectral imaging has shown tremendous growth over the past three decades. Hyperspectral imaging was evolved through remote sensing. Along, with the technological enhancements hyperspectral imaging has outgrown, conquering over other various application areas. In addition to it, data enriched data cubes with abundant spectral and spatial information works as perk for capturing, analyzing, reviewing, and interpreting results from data. This review concentrates on emerging application areas of hyperspectral imaging. Emerging application areas are selected in ways where there is a vast scope for future enhancements by exploiting cutting edge technology, that is, deep learning. Applications of hyperspectral imaging techniques in some selected areas (remote sensing, document forgery, history and archaeology conservation, surveillance and security, machine vision for fruit quality inspection, medical imaging) are focused. The review pivots around the publicly available datasets and features used domain wise. This review can act as a baseline for deep learning and machine vision experts, historical geographers, and scholars by providing them a view of how hyperspectral imaging is implemented in multiple domains along with future research prospects. This article is categorized under: Technologies > Machine Learning Technologies > Prediction. © 2021 Wiley Periodicals LLC.
KW  - document forgery
KW  - history and archaeology
KW  - hyperspectral imaging
KW  - machine vision
KW  - remote sensing
KW  - Computer vision
KW  - Deep learning
KW  - Engineering education
KW  - Learning systems
KW  - Medical imaging
KW  - Remote sensing
KW  - Spectroscopy
KW  - Application area
KW  - Cutting edge technology
KW  - Emerging applications
KW  - Fruit quality inspections
KW  - Machine learning technology
KW  - Multiple domains
KW  - Spatial informations
KW  - Technological enhancement
KW  - Hyperspectral imaging
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 37
ER  -

TY  - JOUR
AU  - Saadi, A.A.
AU  - Bhuyan, B.P.
AU  - Ramdane-Cherif, A.
TI  - Power consumption model for Unmanned Aerial Vehicles using Recurrent Neural Network techniques
PY  - 2025
T2  - Aerospace Science and Technology
VL  - 157
C7  - 109819
DO  - 10.1016/j.ast.2024.109819
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211231962&doi=10.1016%2fj.ast.2024.109819&partnerID=40&md5=91174e107c75b25869858b3d7856f68f
AB  - Unmanned Aerial Vehicles (UAVs) have become increasingly integral across diverse sectors, necessitating accurate power consumption modeling to optimize flight operations and ensure reliability. Traditional approaches often fail to capture the intricate, non-linear dynamics between operational parameters and power usage. This study introduces deep learning techniques, including RNN, GRU, LSTM, Bi-LSTM, and SA-Bi-LSTM, with various activation functions and optimizers for predicting UAV power consumption using an extensive dataset. Additionally, the influence of activation functions and optimization algorithms on model performance is assessed. Bi-LSTM demonstrates superior predictive accuracy, as evidenced by RMSE and MAE metrics. © 2024 Elsevier Masson SAS
KW  - Activation functions
KW  - Deep learning
KW  - Machine learning
KW  - Power consumption modeling
KW  - Self-attention mechanism
KW  - Unmanned Aerial Vehicles (UAVs)
KW  - Contrastive Learning
KW  - Recurrent neural networks
KW  - Activation functions
KW  - Aerial vehicle
KW  - Attention mechanisms
KW  - Deep learning
KW  - Flight operation
KW  - Machine-learning
KW  - Neural network techniques
KW  - Power consumption model
KW  - Self-attention mechanism
KW  - Unmanned aerial vehicle
KW  - Unmanned aerial vehicles (UAV)
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Mell, S.
AU  - Bastani, F.
AU  - Zdancewic, S.
AU  - Bastani, O.
TI  - Synthesizing Trajectory Queries from Examples
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 13964 LNCS
SP  - 459
EP  - 484
DO  - 10.1007/978-3-031-37706-8_23
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169034948&doi=10.1007%2f978-3-031-37706-8_23&partnerID=40&md5=58bae255bc11bf845d1a6c4e63109312
AB  - Data scientists often need to write programs to process predictions of machine learning models, such as object detections and trajectories in video data. However, writing such queries can be challenging due to the fuzzy nature of real-world data; in particular, they often include real-valued parameters that must be tuned by hand. We propose a novel framework called Quivr that synthesizes trajectory queries matching a given set of examples. To efficiently synthesize parameters, we introduce a novel technique for pruning the parameter space and a novel quantitative semantics that makes this more efficient. We evaluate Quivr on a benchmark of 17 tasks, including several from prior work, and show both that it can synthesize accurate queries for each task and that our optimizations substantially reduce synthesis time. © 2023, The Author(s).
KW  - Object detection
KW  - Semantics
KW  - Machine learning models
KW  - Novel techniques
KW  - Object trajectories
KW  - Objects detection
KW  - Optimisations
KW  - Parameter spaces
KW  - Process prediction
KW  - Query matching
KW  - Real-world
KW  - Video data
KW  - Trajectories
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Wan, Z.
AU  - Shen, J.
AU  - Chuang, J.
AU  - Xia, X.
AU  - Garcia, J.
AU  - Ma, J.
AU  - Chen, Q.A.
TI  - Too Afraid to Drive: Systematic Discovery of Semantic DoS Vulnerability in Autonomous Driving Planning under Physical-World Attacks
PY  - 2022
T2  - 29th Annual Network and Distributed System Security Symposium, NDSS 2022
DO  - 10.14722/ndss.2022.24177
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179454134&doi=10.14722%2fndss.2022.24177&partnerID=40&md5=296e6c6f5cac473b3b5faa5af01e6ecd
AB  - In high-level Autonomous Driving (AD) systems, behavioral planning is in charge of making high-level driving decisions such as cruising and stopping, and thus highly security-critical. In this work, we perform the first systematic study of semantic security vulnerabilities specific to overly-conservative AD behavioral planning behaviors, i.e., those that can cause failed or significantly-degraded mission performance, which can be critical for AD services such as robo-taxi/delivery. We call them semantic Denial-of-Service (DoS) vulnerabilities, which we envision to be most generally exposed in practical AD systems due to the tendency for conservativeness to avoid safety incidents. To achieve high practicality and realism, we assume that the attacker can only introduce seemingly-benign external physical objects to the driving environment, e.g., off-road dumped cardboard boxes. To systematically discover such vulnerabilities, we design PlanFuzz, a novel dynamic testing approach that addresses various problem-specific design challenges. Specifically, we propose and identify planning invariants as novel testing oracles, and design new input generation to systematically enforce problem-specific constraints for attacker-introduced physical objects. We also design a novel behavioral planning vulnerability distance metric to effectively guide the discovery. We evaluate PlanFuzz on 3 planning implementations from practical open-source AD systems, and find that it can effectively discover 9 previously-unknown semantic DoS vulnerabilities without false positives. We find all our new designs necessary, as without each design, statistically significant performance drops are generally observed. We further perform exploitation case studies using simulation and real-vehicle traces. We discuss root causes and potential fixes. © 2022 29th Annual Network and Distributed System Security Symposium, NDSS 2022. All Rights Reserved.
KW  - Design
KW  - Distance
KW  - Driving
KW  - Performance
KW  - Planning
KW  - Systems
KW  - Testing
KW  - Vulnerability
KW  - Automobile drivers
KW  - Autonomous vehicles
KW  - Crime
KW  - Denial-of-service attack
KW  - Dynamic analysis
KW  - Network security
KW  - Taxicabs
KW  - Autonomous driving
KW  - Behavioral planning
KW  - Denial of Service
KW  - Driving systems
KW  - Physical objects
KW  - Physical world
KW  - Security vulnerabilities
KW  - Security-critical
KW  - Semantic security
KW  - Systematic study
KW  - Semantics
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 20
ER  -

TY  - JOUR
AU  - Wang, X.
AU  - Yi, P.
AU  - Hong, Y.
TI  - A Hierarchical Deep Reinforcement Learning Strategy for Collective Pursuit-Evasion Game with Partial Observations
PY  - 2025
T2  - IEEE Transactions on Artificial Intelligence
DO  - 10.1109/TAI.2025.3566069
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004585756&doi=10.1109%2fTAI.2025.3566069&partnerID=40&md5=c0de92515c58dfc9b9e64d603a455e07
AB  - This paper addresses the problem of Collective Pursuit-Evasion Game (C-PEG) with partial observation, aiming to enhance cooperation among cluster pursuers, reduce the game space, and optimize the overall pursuer strategy efficiency in complex dynamic environments. Firstly, we consider a distributed communication model suitable for cluster collaboration and model the multi-agent cooperative task as a Collective Decentralized Partially Observable Markov Decision Process (C-Dec POMDP). Then we propose a Hierarchical Regularization Game Multi-agent Deep Deterministic Policy Gradient (HRG-MADDPG) algorithm, which includes High-Level Strategy (HLS) and Low-Level Strategy (LLS). The HLS takes the current observation from the pursuers’ sensors and the pursuers’ status as inputs, and outputs target allocation strategies for the coalitions and individuals to guide the LLS in executing specific pursuit tasks. The LLS is further divided into centralized training and decentralized execution phases. In the centralized training phase, the guiding strategy provided by the HLS and the introduced regularization auxiliary term are combined to promote decision-making through the fusion of favorable situations and auxiliary terms. In the decentralized execution phase, a reliable policy improvement method based on partially observable information is designed. All in all, the HRG-MADDPG algorithm provides a reliable method for collective pursuit-evasion. It is trained in a single environment and further validated in multiple different test environments. Simulation results confirm the effectiveness of the proposed method, showing the adaptability, scalability, and rapid responsiveness of the proposed framework in various practical applications. © 2020 IEEE.
KW  - Collective Pursuit-Evasion Games
KW  - Deep Reinforcement Learning
KW  - Hierarchical Strategies
KW  - Multi-agent Systems
KW  - Partially Observable Markov Decision Process
KW  - Collective pursuit-evasion game
KW  - Decentralised
KW  - Hierarchical strategies
KW  - Multi agent
KW  - Multiagent systems (MASs)
KW  - Partial observation
KW  - Partially observable Markov decision process
KW  - Pursuit/evasion games
KW  - Regularisation
KW  - Reinforcement learnings
KW  - Hierarchical systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Alonso, S.M.
AU  - Romero, A.
AU  - Becerra, J.A.
AU  - Duro, R.J.
TI  - Autonomous Perceptual Categorization for Robotic Lifelong Learning in Dynamic Domains
PY  - 2024
T2  - Proceedings of the International Joint Conference on Neural Networks
DO  - 10.1109/IJCNN60899.2024.10650284
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204993798&doi=10.1109%2fIJCNN60899.2024.10650284&partnerID=40&md5=f594d10d52fa8a8e54d9cc6cfd583f6b
AB  - Autonomously acquiring grounded information from on-line interaction in continuous and dynamic domains unknown at design time to allow for abstraction and high-level reasoning is still a challenging problem in robotics. The main issues are how to create the appropriate categories from non-directed interaction with the world, to do so in a way that allows for composition so that future learning is facilitated, and to meet the adaptability requirements imposed by ever changing domains. Thus, in this paper we present an approach based on the generation of task-based dynamic perceptual equivalence classes that are constantly updated and adapted during the life of the robot. To provide a real example, the approach was implemented using three different types of algorithms within the e-MDB cognitive architecture on a real robot. We present results of the robot interacting with different domains and demonstrate the adaptability of the approach through a series of experiments in which the domain is changed arbitrarily. We compare the performance of the three algorithms that were implemented and discuss the consequences of this approach and its possible uses within cognitive architectures. These autonomously generated perceptual classes and their appropriate representation within cognitive architectures constitute a path towards more abstract (and even symbolic) processing starting from grounded emergent low-level components. © 2024 IEEE.
KW  - cognitive architectures
KW  - open-ended learning
KW  - perceptual equivalence classes
KW  - robots
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Federated learning
KW  - Microrobots
KW  - Robot learning
KW  - Cognitive architectures
KW  - Continuous domain
KW  - Design time
KW  - Directed interactions
KW  - Dynamic domains
KW  - High-level reasoning
KW  - Life long learning
KW  - Online interaction
KW  - Open-ended learning
KW  - Perceptual equivalence class
KW  - Equivalence classes
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Ma, Y.
AU  - Abbas, T.
AU  - Gadiraju, U.
TI  - ContextBot: Improving Response Consistency in Crowd-Powered Conversational Systems for Affective Support Tasks
PY  - 2023
T2  - HT 2023 - The 34th ACM Conference on Hypertext and Social Media
C7  - 30
DO  - 10.1145/3603163.3609031
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174244797&doi=10.1145%2f3603163.3609031&partnerID=40&md5=14de32531ffbc9c60d7e567bb4923ce6
AB  - Crowd-powered conversational systems (CPCS) solicit the wisdom of crowds to quickly respond to on-demand users' needs. The very factors that make this a viable solution - -such as the availability of diverse crowd workers on-demand - - also lead to great challenges. The ever-changing pool of online workers powering conversations with individual users makes it particularly difficult to generate contextually consistent responses from a single user's standpoint. To tackle this, prior work has employed conversational facts extracted by workers to maintain a global memory, albeit with limited success. Through a controlled experiment, we explored if a conversational agent, dubbed ContextBot, can provide workers with the required context on the fly for successful completion of affective support tasks in CPCS, and explore the impact of ContextBot on the response quality of workers and their interaction experience. To this end, we recruited workers (N=351) from the Prolific crowd-sourcing platform and carried out a 3×3 factorial between-subjects study. Experimental conditions varied based on (i) whether or not context was elicited and informed by motivational interviewing techniques (MI-adherent guidance, general guidance, and no guidance), and (ii) different conversational entry points for workers to produce responses (early, middle, and late). Our findings show that: (a) workers who entered the conversation earliest were more likely to produce highly consistent responses after interacting with ContextBot; (b) showed better user experience after they interacted with ContextBot with a long chat history to surf; (c) produced more professional responses as endorsed by psychologists; (d) and that interacting with ContextBot through task completion did not negatively impact workers' cognitive load. Our findings shed light on the implications of building intelligent interfaces for scaffolding strategies to preserve consistency in dialogue in CPCS. © 2023 Owner/Author.
KW  - Chatbots
KW  - Crowd-powered Conversational Systems
KW  - Dialogue Context
KW  - Motivational Interviewing
KW  - Real-time Crowdsourcing
KW  - Historic preservation
KW  - Real time systems
KW  - Scaffolds
KW  - Chatbots
KW  - Conversational systems
KW  - Crowd-powered conversational system
KW  - Dialog context
KW  - Motivational interviewing
KW  - On demands
KW  - Real- time
KW  - Real-time crowdsourcing
KW  - Wisdom of crowds
KW  - Workers'
KW  - Crowdsourcing
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Kim, J.
AU  - Min, C.
AU  - Kim, B.
AU  - Choi, J.
TI  - Pre-emptive Action Revision by Environmental Feedback for Embodied Instruction Following Agents
PY  - 2024
T2  - Proceedings of Machine Learning Research
VL  - 270
SP  - 2396
EP  - 2428
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000779990&partnerID=40&md5=ab4a55d2c62b6e6081ddfd7b81278cf6
AB  - When we, humans, perform a task, we consider changes in environments such as objects' arrangement due to interactions with objects and other reasons; e.g., when we find a mug to clean, if it is already clean, we skip cleaning it. But even the state-of-the-art embodied agents often ignore changed environments when performing a task, leading to failure to complete the task, executing unnecessary actions, or fixing the mistake after it was made. Here, we propose Pre-emptive Action Revision by Environmental feeDback (PRED) that allows an embodied agent to revise their action in response to the perceived environmental status before it makes mistakes. We empirically validate PRED and observe that it outperforms the prior art on two challenging benchmarks in the virtual environment, TEACh and ALFRED, by noticeable margins in most metrics, including unseen success rates, with shorter execution time, implying an efficiently behaved agent. Furthermore, we demonstrate the effectiveness of the proposed method with real robot experiments. © 2024 Proceedings of Machine Learning Research.
KW  - Brain plasticity
KW  - Embodied AI
KW  - Environmental Feedback
KW  - Replanning
KW  - Cleaner production
KW  - Contrastive Learning
KW  - Federated learning
KW  - Virtual environments
KW  - Brain plasticity
KW  - Embodied agent
KW  - Embodied AI
KW  - Environmental feedback
KW  - Object arrangements
KW  - Prior arts
KW  - Re-planning
KW  - Real robot
KW  - State of the art
KW  - Adversarial machine learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Mishra, A.
AU  - Sharma, S.
AU  - Pandey, S.K.
TI  - The Present State and Potential Applications of Artificial Intelligence in Cancer Diagnosis and Treatment
PY  - 2025
T2  - Recent Patents on Anti-Cancer Drug Discovery
DO  - 10.2174/0115748928361472250123105507
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007601607&doi=10.2174%2f0115748928361472250123105507&partnerID=40&md5=aed7ea24df8449b8c5155593e7b81e95
AB  - An aberrant increase in cancer incidences has demanded extreme attention globally despite advancements in diagnostic and management strategies. The high mortality rate is concerning, and tumour heterogeneity at the genetic, phenotypic, and pathological levels exacerbates the problem. In this context, lack of early diagnostic techniques and therapeutic resistance to drugs, sole awareness among the public, coupled with the unavailability of these modern technologies in developing and low-income countries, negatively impact cancer management. One of the prime necessities of the world today is the enhancement of early detection of cancers. Several independent studies have shown that screening individuals for cancer can improve patient survival but are bogged down by risk classification and major problems in patient selection. Artificial intelligence (AI) has significantly advanced the field of oncology, addressing various medical challenges, particularly in cancer management. Leveraging extensive medical datasets and innovative computational technologies, AI, especially through deep learning (DL), has found applications across multiple facets of oncology research. These applications range from early cancer detection, diagnosis, classification, and grading, molecular characterization of tumours, prediction of patient outcomes and treatment responses, personalized treatment, and novel anti-cancer drug discovery. Over the past decade, AI/ML has emerged as a valuable tool in cancer prognosis, risk assessment, and treatment selection for cancer patients. Several patents have been and are being filed and granted. Some of those inventions were explored and are being explored in clinical settings as well. In this review, we will discuss the current status, recent advancements, clinical trials, challenges, and opportunities associated with AI/ML applications in cancer detection and management. We are optimistic about the potential of AI/ML in improving outcomes for cancer and the need for further research and development in this field. © 2025 Bentham Science Publishers.
KW  - Artificial intelligence
KW  - cancer diagnosis
KW  - cancer treatment
KW  - digital health care
KW  - drug discovery
KW  - machine learning
KW  - antineoplastic agent
KW  - artificial intelligence
KW  - awareness
KW  - cancer diagnosis
KW  - cancer incidence
KW  - cancer patient
KW  - cancer prognosis
KW  - cancer therapy
KW  - deep learning
KW  - diagnosis
KW  - digital health
KW  - early cancer
KW  - early cancer diagnosis
KW  - human
KW  - low income country
KW  - machine learning
KW  - machine learning software
KW  - malignant neoplasm
KW  - mortality rate
KW  - neoplastic cell transformation
KW  - overall survival
KW  - patient selection
KW  - personalized medicine
KW  - phenotype
KW  - prediction
KW  - review
KW  - risk assessment
KW  - therapy
KW  - treatment outcome
KW  - treatment response
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Aslam, M.
TI  - Neutrosophic analysis of variance: addressing uncertainty in statistical analysis for artificial intelligence
PY  - 2025
T2  - International Journal of Data Science and Analytics
C7  - 101397
DO  - 10.1007/s41060-025-00798-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005222455&doi=10.1007%2fs41060-025-00798-9&partnerID=40&md5=5d3b07b4b84d530b1e1fa3fd80d69fe1
AB  - The traditional analysis of variance (ANOVA) in artificial intelligence (AI) is used to test whether group means differ significantly. However, classical ANOVA cannot handle environments where uncertainty exists. In this paper, we introduce a modified version of ANOVA, called neutrosophic analysis of variance (NANOVA), which is applicable in AI when uncertainty is present. NANOVA addresses cases where training and testing data contain imprecise observations. We conducted a detailed simulation study to examine how varying degrees of indeterminacy affect the descriptive statistics and F-values for both training and testing data. The results from the proposed NANOVA are compared with classical ANOVA to demonstrate the impact of uncertainty on analysis outcomes. An example application of NANOVA using AI training and testing data is provided, showcasing its practical relevance. Our findings reveal that the degree of indeterminacy significantly alters the results, affecting the means, variances, and F-values. This highlights the necessity of considering uncertainty in statistical analysis for AI, as traditional methods may not fully capture the complexities of uncertain environments. By incorporating NANOVA, AI researchers can better account for indeterminate data, leading to more accurate and reliable decision-making in uncertain scenarios. © The Author(s), under exclusive licence to Springer Nature Switzerland AG 2025.
KW  - Classical statistics
KW  - Imprecise data
KW  - Simulation
KW  - Testing
KW  - Uncertainty
KW  - Population statistics
KW  - Analyse of variances
KW  - Classical statistics
KW  - F values
KW  - Imprecise data
KW  - Simulation
KW  - Simulation studies
KW  - Testing data
KW  - Training and testing
KW  - Training data
KW  - Uncertainty
KW  - Analysis of variance (ANOVA)
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Liang, P.P.
AU  - Zadeh, A.
AU  - Morency, L.-P.
TI  - Foundations & Trends in Multimodal Machine Learning: Principles, Challenges, and Open Questions
PY  - 2024
T2  - ACM Computing Surveys
VL  - 56
IS  - 10
C7  - 264
DO  - 10.1145/3656580
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196936643&doi=10.1145%2f3656580&partnerID=40&md5=11d74f875f566a78a722c96383617b5f
AB  - Multimodal machine learning is a vibrant multi-disciplinary research field that aims to design computer agents with intelligent capabilities such as understanding, reasoning, and learning through integrating multiple communicative modalities, including linguistic, acoustic, visual, tactile, and physiological messages. With the recent interest in video understanding, embodied autonomous agents, text-to-image generation, and multisensor fusion in application domains such as healthcare and robotics, multimodal machine learning has brought unique computational and theoretical challenges to the machine learning community given the heterogeneity of data sources and the interconnections often found between modalities. However, the breadth of progress in multimodal research has made it difficult to identify the common themes and open questions in the field. By synthesizing a broad range of application domains and theoretical frameworks from both historical and recent perspectives, this article is designed to provide an overview of the computational and theoretical foundations of multimodal machine learning. We start by defining three key principles of modality heterogeneity, connections, and interactions that have driven subsequent innovations, and propose a taxonomy of six core technical challenges: representation, alignment, reasoning, generation, transference, and quantification covering historical and recent trends. Recent technical achievements will be presented through the lens of this taxonomy, allowing researchers to understand the similarities and differences across new approaches. We end by motivating several open problems for future research as identified by our taxonomy.  © 2024 Copyright held by the owner/author(s).
KW  - data heterogeneity
KW  - feature interactions
KW  - language and vision
KW  - multimedia
KW  - Multimodal machine learning
KW  - representation learning
KW  - Autonomous agents
KW  - Computer vision
KW  - Taxonomies
KW  - Applications domains
KW  - Data heterogeneity
KW  - Feature interactions
KW  - Language and vision
KW  - Machine-learning
KW  - Multi-disciplinary research
KW  - Multi-modal
KW  - Multimedium
KW  - Multimodal machine learning
KW  - Representation learning
KW  - Machine learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 57
ER  -

TY  - JOUR
AU  - Degbelo, A.
AU  - Schmidt, B.
AU  - Henzen, C.
AU  - Lechler, S.
AU  - Lubahn, B.
AU  - Zander, F.
TI  - Desiderata for Intelligent Maps: A Multiperspective Compilation
ST  - Desiderata für intelligente Karten: Eine multiperspektivische Zusammenstellung
PY  - 2023
T2  - KN - Journal of Cartography and Geographic Information
VL  - 73
IS  - 3
SP  - 183
EP  - 198
DO  - 10.1007/s42489-023-00142-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162052497&doi=10.1007%2fs42489-023-00142-w&partnerID=40&md5=a782415a71e2ceee2e2a1ebfebe293aa
AB  - Interactive digital maps are useful for illustrating and analyzing geographic data and are used for diverse purposes (e.g., wayfinding, data journalism, data analysis, and citizen engagement). This article discusses the requirements of intelligent maps from three perspectives: the literature, a user survey, and a reverse-brainstorming workshop. The ideas brought forth are relevant to researchers and designers of digital maps as they incorporate innovative features and strive for a good user experience. © 2023, The Author(s).
KW  - Intelligent maps
KW  - Interactive maps
KW  - Smart maps
KW  - User experience
KW  - cartography
KW  - digital map
KW  - innovation
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Sridhar, K.
AU  - Dutta, S.
AU  - Jayaraman, D.
AU  - Weimer, J.
AU  - Lee, I.
TI  - MEMORY-CONSISTENT NEURAL NETWORKS FOR IMITATION LEARNING
PY  - 2024
T2  - 12th International Conference on Learning Representations, ICLR 2024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196564496&partnerID=40&md5=4031ffe0e6efa1918cb532718663467a
AB  - Imitation learning considerably simplifies policy synthesis compared to alternative approaches by exploiting access to expert demonstrations. For such imitation policies, errors away from the training samples are particularly critical. Even rare slip-ups in the policy action outputs can compound quickly over time, since they lead to unfamiliar future states where the policy is still more likely to err, eventually causing task failures. We revisit simple supervised “behavior cloning” for conveniently training the policy from nothing more than pre-recorded demonstrations, but carefully design the model class to counter the compounding error phenomenon. Our “memory-consistent neural network” (MCNN) outputs are hard-constrained to stay within clearly specified permissible regions anchored to prototypical “memory” training samples. We provide a guaranteed upper bound for the sub-optimality gap induced by MCNN policies. Using MCNNs on 10 imitation learning tasks, with MLP, Transformer, and Diffusion backbones, spanning dexterous robotic manipulation and driving, proprioceptive inputs and visual inputs, and varying sizes and types of demonstration data, we find large and consistent gains in performance, validating that MCNNs are better-suited than vanilla deep neural networks for imitation learning applications. © 2024 12th International Conference on Learning Representations, ICLR 2024. All rights reserved.
KW  - Deep neural networks
KW  - Sampling
KW  - Imitation learning
KW  - Memory training
KW  - Network policy
KW  - Neural-networks
KW  - Optimality
KW  - Policy actions
KW  - Simple++
KW  - Task failures
KW  - Training sample
KW  - Upper Bound
KW  - Demonstrations
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Jiang, W.
AU  - Zeller, M.
AU  - Waleffe, R.
AU  - Hoefler, T.
AU  - Alonso, G.
TI  - Chameleon: a Heterogeneous and Disaggregated Accelerator System for Retrieval-Augmented Language Models
PY  - 2024
T2  - Proceedings of the VLDB Endowment
VL  - 18
IS  - 1
SP  - 42
EP  - 52
DO  - 10.14778/3696435.3696439
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213860402&doi=10.14778%2f3696435.3696439&partnerID=40&md5=a3060e63555da8a2dfa4945327845013
AB  - A Retrieval-Augmented Language Model (RALM) combines a large language model (LLM) with a vector database to retrieve contextspecific knowledge during text generation. This strategy facilitates impressive generation quality even with smaller models, thus reducing computational demands by orders of magnitude. To serve RALMs efficiently and flexibly, we propose Chameleon, a heterogeneous accelerator system integrating both LLM and vector search accelerators in a disaggregated architecture. The heterogeneity ensures efficient serving for both inference and retrieval, while the disaggregation allows independent scaling of LLM and vector search accelerators to fulfill diverse RALM requirements. Our Chameleon prototype implements vector search accelerators on FPGAs and assigns LLM inference to GPUs, with CPUs as cluster coordinators. Evaluated on various RALMs, Chameleon exhibits up to 2.16× reduction in latency and 3.18× speedup in throughput compared to the hybrid CPU-GPU architecture. The promising results pave the way for adopting heterogeneous accelerators for not only LLM inference but also vector search in future RALM systems. © 2024, VLDB Endowment. All rights reserved.
KW  - Colliding beam accelerators
KW  - Computer graphics equipment
KW  - Electron ring accelerators
KW  - Graphics processing unit
KW  - Inference engines
KW  - Linear accelerators
KW  - % reductions
KW  - Accelerator system
KW  - Computational demands
KW  - Disaggregation
KW  - Language model
KW  - Model inference
KW  - Model requirements
KW  - Orders of magnitude
KW  - Scalings
KW  - Text generations
KW  - Vectors
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Tao, Z.
AU  - Wang, C.
AU  - Tian, Z.
AU  - Xu, K.
AU  - Guo, Y.
AU  - Li, S.
AU  - Bai, Y.
AU  - Xie, D.
TI  - SIAT: Document-level Event Extraction via Spatiality-Augmented Interaction Model with Adaptive Thresholding
PY  - 2024
T2  - ACM Transactions on Asian and Low-Resource Language Information Processing
VL  - 23
IS  - 10
C7  - 147
DO  - 10.1145/3698261
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208223790&doi=10.1145%2f3698261&partnerID=40&md5=5b98c47528246ec18da67aea8d1890bd
AB  - Document-level event extraction endeavors to automatically extract structural events from a given document. Many existing approaches focus on modeling entity interactions and decoding these interactions into events, assigning each entity as an event argument. However, these approaches encounter two primary limitations: they exclusively capture semantic dependencies to model entity interactions, overlooking the indication of the spatial distribution features of entities; they decode interactions imprecisely with a hard binary-classification boundary, potentially failing to calibrate micro differences in interactions. To overcome these limitations, we introduce a novel approach termed the Spatiality-augmented Interaction Model with Adaptive Thresholding (SIAT). Our method addresses the first limitation by calculating the relative position encoding of entities to represent spatial interaction features. These features are then integrated with multi-granularity semantic interactions, enhancing the modeling of entity interactions for each entity pair. Furthermore, we introduce an adaptive event decoding mechanism, which establishes a more flexible decision boundary for different entity interactions. Additionally, an adaptive loss function for threshold learning is designed to further refine the model. Experimental results demonstrate that our proposed method achieves competitive performance compared to state-of-the-art methods on two public event extraction datasets while maintaining considerable training efficiency.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
KW  - adaptive threshold
KW  - Document-level event extraction
KW  - relative position encoding
KW  - Augmented reality
KW  - Decoding
KW  - Digital elevation model
KW  - Feature extraction
KW  - Text mining
KW  - Adaptive thresholding
KW  - Adaptive thresholds
KW  - Document-level event extraction
KW  - Encodings
KW  - Events extractions
KW  - Interaction modeling
KW  - Model entities
KW  - Relative position encoding
KW  - Relative positions
KW  - Structural events
KW  - Semantics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Grishina, A.
AU  - Liventsev, V.
AU  - Härmä, A.
AU  - Moonen, L.
TI  - Fully Autonomous Programming Using Iterative Multi-Agent Debugging with Large Language Models
PY  - 2025
T2  - ACM Transactions on Evolutionary Learning and Optimization
VL  - 5
IS  - 1
SP  - 1
EP  - 37
DO  - 10.1145/3719351
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003631468&doi=10.1145%2f3719351&partnerID=40&md5=365eeb1fb9cc4c15edc714c3ec64aefb
AB  - Program synthesis with Large Language Models (LLMs) suffers from a "near-miss syndrome": The generated code closely resembles a correct solution but fails unit tests due to minor errors. We address this with a multi-agent framework called Synthesize, Execute, Instruct, Debug, and Repair (SEIDR). Effectively applying SEIDR to instruction-tuned LLMs requires determining (a) optimal prompts for LLMs, (b) what ranking algorithm selects the best programs in debugging rounds, and (c) balancing the repair of unsuccessful programs with the generation of new ones. We empirically explore these tradeoffs by comparing replace-focused, repair-focused, and hybrid debug strategies. We also evaluate lexicase and tournament selection to rank candidates in each generation. On Program Synthesis Benchmark 2 (PSB2), our framework outperforms both conventional use of OpenAI Codex without a repair phase and traditional genetic programming approaches. SEIDR outperforms the use of an LLM alone, solving 18 problems in C++ and 20 in Python on PSB2 at least once across experiments. To assess generalizability, we employ GPT-3.5 and Llama 3 on the PSB2 and HumanEval-X benchmarks. Although SEIDR with these models does not surpass current state-of-the-art methods on the Python benchmarks, the results on HumanEval-C++ are promising. SEIDR with Llama 3-8B achieves an average pass@100 of 84.2%. Across all SEIDR runs, 163 of 164 problems are solved at least once with GPT-3.5 in HumanEval-C++, and 162 of 164 with the smaller Llama 3-8B. We conclude that SEIDR effectively overcomes the near-miss syndrome in program synthesis with LLMs.  © 2025 Copyright held by the owner/author(s).
KW  - automatic programming
KW  - large language models
KW  - program repair
KW  - Automatic programming
KW  - Autonomous agents
KW  - Python
KW  - Correct solution
KW  - Language model
KW  - Large language model
KW  - Multi agent
KW  - Multiagent framework
KW  - Near-misses
KW  - Program repair
KW  - Program synthesis
KW  - Ranking algorithm
KW  - Unit tests
KW  - Program debugging
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Arumugam, C.
AU  - Nallaperumal, K.
TI  - EIAASG: Emotional Intensive Adaptive Aspect-Specific GCN for sentiment classification
PY  - 2023
T2  - Knowledge-Based Systems
VL  - 260
C7  - 110149
DO  - 10.1016/j.knosys.2022.110149
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145587262&doi=10.1016%2fj.knosys.2022.110149&partnerID=40&md5=bd3d443ab2fcfc2d8f7f0e40d56f8211
AB  - Deep learning techniques and attention schemes are used by many researchers for classifying the sentiments. Retrieval of semantic relationship between the aspects with words of context will improve the classification accuracy. This was done by Aspect-Specific Graph Convolutional Networks (ASGCN) which utilises aspect-specific relationships and attention scheme by researchers. Long-range dependencies and sensitive-important words are missing in these methods. This work proposes two novel approaches for improving the effectiveness of sentiment classification. First, we propose a method, Adaptive Aspect-Specific GCN (AASGCN) for enhancing ASGCN by incorporating adaptive weights into ASGCN to better capturing of the semantic meaning of the opinion target. Second, we introduce an Emotional Intensive Sentiment Reasoning (EISR) that incorporates emotional intensive information into the mechanism. We experiment our proposed work along with many existing work's datasets such as LAP14 (Pontiki et al., 2014), TWITTER (Dong et al., 2014), REST14 (Pontiki et al., 2014), REST15 (Pontiki et al., 2015), and REST16 (Pontiki et al., 2016). The results prove that AASGCN performs well than the range of state-of-the-art models and can be substantially improved by incorporating the two approaches. © 2022 Elsevier B.V.
KW  - Aspect-based
KW  - Deep learning
KW  - EIAASG
KW  - GCN
KW  - Sentiment classification
KW  - Deep learning
KW  - Aspect-based
KW  - Classification accuracy
KW  - Convolutional networks
KW  - Deep learning
KW  - EIAASG
KW  - GCN
KW  - Learning techniques
KW  - Long-range dependencies
KW  - Semantic relationships
KW  - Sentiment classification
KW  - Semantics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 10
ER  -

TY  - CONF
AU  - Wang, Y.
AU  - Zhu, H.
TI  - Safe Exploration in Reinforcement Learning by Reachability Analysis over Learned Models
PY  - 2024
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14683 LNCS
SP  - 232
EP  - 255
DO  - 10.1007/978-3-031-65633-0_11
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200781697&doi=10.1007%2f978-3-031-65633-0_11&partnerID=40&md5=0eed20cab234891d10f96ff7d21c33cf
AB  - We introduce VELM, a reinforcement learning (RL) framework grounded in verification principles for safe exploration in unknown environments. VELM ensures that an RL agent systematically explores its environment, adhering to safety properties throughout the learning process. VELM learns environment models as symbolic formulas and conducts formal reachability analysis over the learned models for safety verification. An online shielding layer is then constructed to confine the RL agent’s exploration solely within a state space verified as safe in the learned model, thereby bolstering the overall safety profile of the RL system. Our experimental results demonstrate the efficacy of VELM across diverse RL environments, highlighting its capacity to significantly reduce safety violations in comparison to existing safe learning techniques, all without compromising the RL agent’s reward performance. © The Author(s) 2024.
KW  - Controller Synthesis
KW  - Reinforcement Learning
KW  - Safe Exploration
KW  - Safety Verification
KW  - Learning systems
KW  - Safety engineering
KW  - Controller synthesis
KW  - Learning frameworks
KW  - Learning process
KW  - Reachability analysis
KW  - Reinforcement learning agent
KW  - Reinforcement learnings
KW  - Safe exploration
KW  - Safety property
KW  - Safety verification
KW  - Unknown environments
KW  - Reinforcement learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Chen, J.
AU  - Mashkova, O.
AU  - Zhapa-Camacho, F.
AU  - Hoehndorf, R.
AU  - He, Y.
AU  - Horrocks, I.
TI  - Ontology Embedding: A Survey of Methods, Applications and Resources
PY  - 2025
T2  - IEEE Transactions on Knowledge and Data Engineering
VL  - 37
IS  - 7
SP  - 4193
EP  - 4212
DO  - 10.1109/TKDE.2025.3559023
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002588756&doi=10.1109%2fTKDE.2025.3559023&partnerID=40&md5=abae0a6bd60e2452b025b105b6d09c72
AB  - Ontologies are widely used for representing domain knowledge and meta data, playing an increasingly important role in Information Systems, the Semantic Web, Bioinformatics and many other domains. However, logical reasoning that ontologies can directly support are quite limited in learning, approximation and prediction. One straightforward solution is to integrate statistical analysis and machine learning. To this end, automatically learning vector representation for knowledge of an ontology i.e., ontology embedding has been widely investigated. Numerous papers have been published on ontology embedding, but a lack of systematic reviews hinders researchers from gaining a comprehensive understanding of this field. To bridge this gap, we write this survey paper, which first introduces different kinds of semantics of ontologies and formally defines ontology embedding as well as its property of faithfulness. Based on this, it systematically categorizes and analyses a relatively complete set of over 80 papers, according to the ontologies they aim at and their technical solutions including geometric modeling, sequence modeling and graph propagation. This survey also introduces the applications of ontology embedding in ontology engineering, machine learning augmentation and life sciences, presents a new library mOWL and discusses the challenges and future directions. © 1989-2012 IEEE.
KW  - knowledge graph
KW  - Ontology
KW  - ontology embedding
KW  - representation learning
KW  - web ontology language
KW  - Graph embeddings
KW  - Knowledge graph
KW  - Ontology
KW  - Domain knowledge
KW  - Embeddings
KW  - Knowledge graphs
KW  - Machine-learning
KW  - Meta-data
KW  - Ontology embedding
KW  - Ontology's
KW  - Representation learning
KW  - Web ontology language (OWL)
KW  - Adversarial machine learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Teotia, J.
AU  - Zhang, X.
AU  - Mao, R.
AU  - Cambria, E.
TI  - Evaluating Vision Language Models in Detecting Learning Engagement
PY  - 2024
T2  - IEEE International Conference on Data Mining Workshops, ICDMW
SP  - 496
EP  - 502
DO  - 10.1109/ICDMW65004.2024.00069
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001344392&doi=10.1109%2fICDMW65004.2024.00069&partnerID=40&md5=0ed610489cfad0ce63d3e7f64b1bdce6
AB  - With the advancement of both computer vision and natural language processing, there is growing interest in incorporating Vision Language Models (VLMs) into the classroom to empower students and educators. Despite the VLMs' sophisticated abilities in context-aware emotion recognition, their effectiveness in detecting classroom-specific emotions, e.g., engagement, distraction, and absent-mindedness, remains underexplored. As such, this paper aims to investigate the capabilities of two state-of-the-art VLMs in this domain through an empirical study, focusing on two research questions: 1) Is learning engagement detection more challenging for VLMs compared to conventional emotion detection? 2) What are the key difficulties faced by VLMs in processing learning engagement detection tasks? To address these questions, we perform a series of evaluation experiments by utilizing a classroom behavior detection dataset and an emotion recognition dataset. We conclude that VLMs that perform well on basic emotion recognition struggle with in-context engagement detection, due to the nuanced and context-dependent nature of the task. Specifically, experiments show that VLMs have difficulty distinguishing engaged and distracted classroom behavior, e.g., reading versus bowing the head. It suggests that VLMs still have significant room for improvement in engagement analysis. This issue can potentially be addressed by incorporating more classroom-specific training data or commonsense reasoning frameworks. © 2024 IEEE.
KW  - emotion recognition
KW  - learning engagement detection
KW  - multimodal learning
KW  - vision language models
KW  - Adversarial machine learning
KW  - Emotion Recognition
KW  - Federated learning
KW  - Visual languages
KW  - Context-Aware
KW  - Emotion recognition
KW  - In contexts
KW  - Language model
KW  - Language processing
KW  - Learning engagement detection
KW  - Multi-modal learning
KW  - Natural languages
KW  - Two-state
KW  - Vision language model
KW  - Contrastive Learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Bhattacharya, S.
AU  - Kailas, S.
AU  - Badyal, S.
AU  - Gil, S.
AU  - Bertsekas, D.
TI  - Multiagent Reinforcement Learning: Rollout and Policy Iteration for POMDP With Application to Multirobot Problems
PY  - 2024
T2  - IEEE Transactions on Robotics
VL  - 40
SP  - 2003
EP  - 2023
DO  - 10.1109/TRO.2023.3347128
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181566788&doi=10.1109%2fTRO.2023.3347128&partnerID=40&md5=8ed507a81dc6a2ddd0077d4cceee5ae8
AB  - In this article, we consider the computational and communication challenges of partially observable multiagent sequential decision-making problems. We present algorithms that simultaneously or sequentially optimize the agents' controls by using multistep lookahead, truncated rollout with a known base policy, and a terminal cost function approximation. In particular: 1) we consider multiagent rollout algorithms that dramatically reduce required computation while preserving the key policy improvement property of the standard rollout method. We improve our multiagent rollout policy by incorporating it in an offline approximate policy iteration scheme, and we apply an additional 'online play' scheme enhancing offline approximation architectures; 2) we consider the imperfect communication case and provide various extensions to our rollout methods to deal with this case; and 3) we demonstrate the performance of our methods in extensive simulations by applying our method to a challenging partially observable multiagent sequential repair problem (state space size 10^{37} and control space size 10^{7}). Our extensive simulations demonstrate that our methods produce better policies for large and complex multiagent problems in comparison with existing methods, including POMCP, MADDPG, and work well where other methods fail to scale up. © 2004-2012 IEEE.
KW  - Approximate policy iteration (approximate PI)
KW  - imperfect communication
KW  - multiagent reinforcement learning
KW  - multiagent rollout
KW  - online play policy
KW  - partial observation Markovian decision problem (POMDP)
KW  - Approximation algorithms
KW  - Cost engineering
KW  - Cost functions
KW  - E-learning
KW  - Iterative methods
KW  - Maintenance
KW  - Multi agent systems
KW  - Reinforcement learning
KW  - Aerospace electronics
KW  - Approximate policy iteration
KW  - Decisions makings
KW  - Imperfect communication
KW  - Multi agent
KW  - Multi-agent reinforcement learning
KW  - Multiagent rollout
KW  - On-line play policy
KW  - Policy iteration
KW  - POMDP
KW  - Decision making
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - JOUR
AU  - Pattanayak, P.
AU  - Kumar, V.
AU  - Meher, A.K.
AU  - Akkasali, N.K.
AU  - Satapathy, S.
AU  - Kumar, G.
AU  - Sharma, N.
AU  - Panda, S.K.
TI  - Composite Structural Health Prediction Using Vibroacoustic Responses via Machine Learning Techniques
PY  - 2025
T2  - International Journal of Applied Mechanics
VL  - 17
IS  - 4
C7  - 2550019
DO  - 10.1142/S175882512550019X
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003315071&doi=10.1142%2fS175882512550019X&partnerID=40&md5=7a39936e2ce6ac31818f1f21a2459a88
AB  - This research adopted five different machine learning (ML) algorithms to identify damage in the laminated structure utilizing the vibroacoustic responses obtained via coupled finite element (FE)-boundary element (BE) solutions. Initially, the composite structural model is derived through higher-order midplane kinematics and solved to compute the fluid-structure interactions in terms of vibroacoustic values via in-house computer code. Furthermore, the exactness and effectiveness of the suggested model have been verified with experimental responses of the intact and damaged shell structure. Subsequently, the sound pressure level data have been extracted for different excitation frequencies numerically using various input parameters via the established model. First, the said ML models are trained using 1500 extracted data sets (using the customized MATLAB code) and predicted the damage using 303 datasets by setting the numerals, i.e., '0' and '1'. A total of 1803 datasets (crack: 902 datasets; intact: 901 datasets) have been utilized for the current analysis. The current predicted responses indicate that the Random Forest Classifier is capable of providing higher accuracy (ranges between 81% and 91%) in comparison to all types of ML algorithms (Random Forest Classifier, Logistics Regression, Linear Support Vector Classified, Kernel Support Vector Machines and Artificial Neural Network) adopted. The proposed method detects and forecasts defects in the composite structures early and helps prevent adverse effects. © 2025 World Scientific Publishing Europe Ltd.
KW  - Acoustic emission (AE)
KW  - HSDT
KW  - machine learning model
KW  - MATLAB
KW  - structural health monitoring
KW  - Support vector regression
KW  - Acoustic emission
KW  - Acoustic-emissions
KW  - Health monitoring
KW  - HSDT
KW  - Machine learning algorithms
KW  - Machine learning models
KW  - Machine learning techniques
KW  - Random forest classifier
KW  - Structural health
KW  - Vibro acoustic response
KW  - Acoustic emission testing
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Kovari, A.
TI  - Explainable AI chatbots towards XAI ChatGPT: A review
PY  - 2025
T2  - Heliyon
VL  - 11
IS  - 2
C7  - e42077
DO  - 10.1016/j.heliyon.2025.e42077
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215225446&doi=10.1016%2fj.heliyon.2025.e42077&partnerID=40&md5=21b05468247903acfc4c069c771340b8
AB  - Advances in artificial intelligence (AI) have had a major impact on natural language processing (NLP), even more so with the emergence of large-scale language models like ChatGPT. This paper aims to provide a critical review of explainable AI (XAI) methodologies for AI chatbots, with a particular focus on ChatGPT. Its main objectives are to investigate the applied methods that improve the explainability of AI chatbots, identify the challenges and limitations within them, and explore future research directions. Such goals emphasize the need for transparency and interpretability of AI systems to build trust with users and allow for accountability. While integrating such interdisciplinary methods, such as hybrid methods combining knowledge graphs with ChatGPT, enhancing explainability, they also highlight industry needs for explainability and user-centred design. This will be followed by a discussion of the balance between explainability and performance, then the role of human judgement, and finally the future of verifiable AI. These are the avenues through which insights can be used to guide the development of transparent, reliable and efficient AI chatbots. © 2025 The Author
KW  - AI chatbots
KW  - ChatGPT
KW  - Controllable AI
KW  - Explainable AI (XAI)
KW  - Natural language processing (NLP)
KW  - Transparency
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Rokade, S.
AU  - Aitwade, S.
AU  - Pujari, S.
AU  - Kamble, N.
TI  - Unveiling the Power of Machine Learning: A Benchmark Analysis of Sentiment Analysis Methods and Their Real-World Performance
PY  - 2024
T2  - 15th International Conference on Advances in Computing, Control, and Telecommunication Technologies, ACT 2024
VL  - 2
SP  - 3483
EP  - 3488
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209150763&partnerID=40&md5=2e5fb28b447743dd399ae05f91bbcd64
AB  - The literature review on sentiment analysis provides a thorough exploration of the current state of the field and its wide-ranging applications. Emphasizing the crucial role of machine learning in automating emotion detection from diverse sources like social media, customer feedback, and product reviews, the review delves into existing research, methodologies, and advancements in sentiment analysis. Its primary goal is to synthesize insights, uncover trends, address challenges, and outline future directions. This comprehensive resource is valuable for researchers, practitioners, and decision-makers. Through an examination of diverse sources, the review seeks to compile perspectives on strategies employed in data collection, techniques for feature extraction, and the process of model selection. It also emphasizes the importance of handling imbalanced datasets and considering contextual nuances, such as sarcasm, in sentiment analysis. Serving as a foundational resource, this literature review sheds light on the sentiment analysis landscape, highlighting its crucial role in extracting valuable insights from human emotions and opinions encoded in text. The model's robust learning capabilities are evident through its high training accuracy and commendable validation performance. The testing accuracy of 85.9% signifies the model's capacity to generalize successfully to data it has not encountered before. The decreasing training loss signifies efficient convergence during training, contributing to the model's overall robustness. With reasonable processing time per batch, the model allows for efficient testing on new data. Further analysis and fine-tuning could enhance the model's optimization for specific use cases or challenges. © Grenze Scientific Society, 2024.
KW  - feature extraction
KW  - machine learning
KW  - model training
KW  - performance evaluation
KW  - Sentiment analysis
KW  - Adversarial machine learning
KW  - Emotion Recognition
KW  - Machine learning
KW  - Analysis method
KW  - Benchmark analysis
KW  - Features extraction
KW  - Literature reviews
KW  - Machine-learning
KW  - Model training
KW  - Performances evaluation
KW  - Power
KW  - Real-world performance
KW  - Sentiment analysis
KW  - Contrastive Learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Zakeri, A.
AU  - Zou, Z.
AU  - Chen, H.
AU  - Latapie, H.
AU  - Imani, M.
TI  - Conjunctive block coding for hyperdimensional graph representation
PY  - 2024
T2  - Intelligent Systems with Applications
VL  - 22
C7  - 200353
DO  - 10.1016/j.iswa.2024.200353
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188239191&doi=10.1016%2fj.iswa.2024.200353&partnerID=40&md5=33a6124c1781a66c48e32e99afd5d549
AB  - Knowledge Graphs (KGs) have become a pivotal knowledge representation tool in machine learning, not only providing access to existing knowledge but also enabling the discovery of new knowledge through advanced applications. Among the scalable reasoning methods used for such applications, distributed graph embedding approaches, particularly GNNs, have become popular for large-scale graph-related tasks. However, many of these methods have limitations in their interpretability and fail to take into account structural similarity in their representation. Hyperdimensional Computing (HDC), also known as Vector Symbolic Architecture (VSA), addresses this issue by using well-defined cognitive operations on distributed representations of symbolic concepts. This work proposes and evaluates a new vector symbolic graph representation, CLOG, that preserves approximate structural similarity beyond edge correspondence and fundamentally differs from previous methods. The model's effectiveness in graph representation is evaluated through theoretical analysis, graph reconstruction experiments, and link prediction task, highlighting its efficiency and accuracy. This approach significantly advances the field by enhancing the capabilities of HDC in graph representation, representing a notable improvement over existing methods. © 2024 The Authors
KW  - Cognitive computing
KW  - Graph representation
KW  - Hyperdimensional computing
KW  - Vector symbolic architecture
KW  - Architecture
KW  - Computer architecture
KW  - Advanced applications
KW  - Block coding
KW  - Cognitive Computing
KW  - Graph representation
KW  - Hyperdimensional computing
KW  - Knowledge graphs
KW  - Knowledge-representation
KW  - Machine-learning
KW  - Structural similarity
KW  - Vector symbolic architecture
KW  - Knowledge graph
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Benmamoun, Z.
AU  - Khlie, K.
AU  - Dehghani, M.
AU  - Gherabi, Y.
TI  - WOA: Wombat Optimization Algorithm for Solving Supply Chain Optimization Problems
PY  - 2024
T2  - Mathematics
VL  - 12
IS  - 7
C7  - 1059
DO  - 10.3390/math12071059
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190093123&doi=10.3390%2fmath12071059&partnerID=40&md5=62218e159e9aff2006badf026ee39138
AB  - Supply Chain (SC) Optimization is a key activity in today’s industry with the goal of increasing operational efficiency, reducing costs, and improving customer satisfaction. Traditional optimization methods often struggle to effectively use resources while handling complex and dynamic Supply chain networks. This paper introduces a novel biomimetic metaheuristic algorithm called the Wombat Optimization Algorithm (WOA) for supply chain optimization. This algorithm replicates the natural behaviors observed in wombats living in the wild, particularly focusing on their foraging tactics and evasive maneuvers towards predators. The theory of WOA is described and then mathematically modeled in two phases: (i) exploration based on the simulation of wombat movements during foraging and trying to find food and (ii) exploitation based on simulating wombat movements when diving towards nearby tunnels to defend against its predators. The effectiveness of WOA in addressing optimization challenges is assessed by handling the CEC 2017 test suite across various problem dimensions, including 10, 30, 50, and 100. The findings of the optimization indicate that WOA demonstrates a strong ability to effectively manage exploration and exploitation, and maintains a balance between them throughout the search phase to deliver optimal solutions for optimization problems. A total of twelve well-known metaheuristic algorithms are called upon to test their performance against WOA in the optimization process. The outcomes of the simulations reveal that WOA outperforms the other algorithms, achieving superior results across most benchmark functions and securing the top ranking as the most efficient optimizer. Using a Wilcoxon rank sum test statistical analysis, it has been proven that WOA outperforms other algorithms significantly. WOA is put to the test with twenty-two constrained optimization problems from the CEC 2011 test suite and four engineering design problems to showcase its ability to solve real-world optimization problems. The results of the simulations demonstrate that WOA excels in real-world applications by delivering superior solutions and outperforming its competitors. © 2024 by the authors.
KW  - bio-inspired
KW  - exploitation
KW  - exploration
KW  - metaheuristic
KW  - optimization
KW  - wombat
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 23
ER  -

TY  - JOUR
AU  - Xiang, L.
AU  - Li, G.
AU  - Li, H.
TI  - A Common Data Environment Framework Applied to Structural Life Cycle Assessment: Coordinating Multiple Sources of Information
PY  - 2025
T2  - Buildings
VL  - 15
IS  - 8
C7  - 1315
DO  - 10.3390/buildings15081315
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003723418&doi=10.3390%2fbuildings15081315&partnerID=40&md5=3470414785027f07509d485c5ae1f5bd
AB  - In Building Information Modeling (BIM)-driven collaboration, the workflow for information management utilizes a Common Data Environment (CDE). The core idea of a CDE is to serve as a single source of truth, enabling efficient coordination among diverse stakeholders. Nevertheless, investigations into employing CDEs to manage projects reveal that procuring commercial CDE solutions is too expensive and functionally redundant for small and medium-sized enterprises (SMEs) and small research organizations, and there is a lack of experience in using CDE tools. Consequently, this study aimed to provide a cheap and lightweight alternative. It proposes a three-layered CDE framework: decentralized databases enabling work in distinct software environments; resource description framework (RDF)-based metadata facilitating seamless data communication; and microservices enabling data collection and reorganization via standardized APIs and query languages. We also apply the CDE framework to structural life cycle assessment (LCA). The results show that a lightweight CDE solution is achievable using tools like the bcfOWL ontology, RESTful APIs, and ASP.NET 6 Clean architecture. This paper offers a scalable framework that reduces infrastructure complexity while allowing users the freedom to integrate diverse tools and APIs for customized information management workflows. This paper’s CDE architecture surpasses traditional commercial software in terms of its flexibility and scalability, facilitating broader CDE applications in the construction industry. © 2025 by the authors.
KW  - building information modeling
KW  - common data environment
KW  - information systems/management
KW  - project management
KW  - structural analysis design
KW  - structural life cycle assessment
KW  - Information management
KW  - Model structures
KW  - Query languages
KW  - Structural analysis
KW  - Analysis/design
KW  - Building Information Modelling
KW  - Common data environment
KW  - Data environment
KW  - Information system management
KW  - Multiple source
KW  - Sources of informations
KW  - Structural analyze design
KW  - Structural life cycle assessment
KW  - Work-flows
KW  - Project management
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Sun, J.J.
TI  - Toward collaborative artificial intelligence development for animal well-being
PY  - 2025
T2  - Journal of the American Veterinary Medical Association
VL  - 263
IS  - 4
SP  - 528
EP  - 535
DO  - 10.2460/javma.24.10.0650
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001378361&doi=10.2460%2fjavma.24.10.0650&partnerID=40&md5=a23f064197209d7d92ab754d1798b544
AB  - This review focuses on opportunities and challenges of future AI developments in veterinary medicine, from the perspective of computer science researchers in developing AI systems for animal behavior analysis. We examine the paradigms of supervised learning, self-supervised learning, and foundation models, highlighting their applications and limitations in automating animal behavior analysis. These emerging technologies present future challenges in data, modeling, and evaluation in veterinary medicine. To address this, we advocate for a collaborative approach that integrates the expertise of AI researchers, veterinary professionals, and other stakeholders to navigate the evolving landscape of AI in veterinary medicine. Through cross-domain dialogue and an emphasis on human and animal well-being, we can shape AI development to advance veterinary practice for the benefit of all. ©The author.
KW  - AI for veterinary medicine
KW  - animal behavior
KW  - animal well-being
KW  - artificial intelligence
KW  - foundation models
KW  - Animal Welfare
KW  - Animals
KW  - Artificial Intelligence
KW  - Behavior, Animal
KW  - Humans
KW  - Veterinary Medicine
KW  - animal behavior
KW  - animal experiment
KW  - animal well-being
KW  - artificial intelligence
KW  - computer
KW  - human
KW  - nonhuman
KW  - review
KW  - veterinary clinic
KW  - veterinary medicine
KW  - animal
KW  - animal behavior
KW  - animal welfare
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Diao, Y.
AU  - Su, Y.-S.
TI  - Exploring the Impact of the Metaverse on Promoting Students' Access to Quality Education: A Meta-Analysis
PY  - 2025
T2  - IEEE Transactions on Learning Technologies
VL  - 18
SP  - 321
EP  - 334
DO  - 10.1109/TLT.2025.3550714
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003037657&doi=10.1109%2fTLT.2025.3550714&partnerID=40&md5=375ad013e56e8b23d9213034d0268715
AB  - With technological advancements, the Metaverse is being used to enhance learning effects and learning experience to ensure quality education. However, current empirical studies have produced varying results. Therefore, a meta-analysis was executed, leveraging the capabilities of Version 3 of the Comprehensive Meta-Analysis software to effectively synthesize the data, drawing insights from 34 studies published prior to October 2024. The goal was to analyze the effects of the Metaverse on quality education, and to investigate the moderating influences of four variables: Metaverse tools, educational stages, subject area, and treatment duration. The results showed that the overall effect sizes for learning effects and learning experience were 0.922 and 1.153, respectively, suggesting that the Metaverse substantially influences educational effects and learning experience. The four moderating variables all play a significant role in shaping the influence of the Metaverse on both learning effects and experience. This meta-analysis highlights a striking trend: the Metaverse's effects were especially pronounced for elementary and secondary school students, but less so for university students. In addition, the Metaverse's effects were most significant in science disciplines.  © 2008-2011 IEEE.
KW  - Meta-analysis
KW  - Metaverse
KW  - quality education
KW  - sustainable development
KW  - 'current
KW  - Empirical studies
KW  - Enhance learning
KW  - Learning effects
KW  - Learning experiences
KW  - Meta-analysis
KW  - Metaverses
KW  - Quality education
KW  - Student access
KW  - Technological advancement
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Kumar, A.
AU  - Trueman, T.E.
AU  - Cambria, E.
TI  - Stress Identification in Online Social Networks
PY  - 2022
T2  - IEEE International Conference on Data Mining Workshops, ICDMW
VL  - 2022-November
SP  - 427
EP  - 434
DO  - 10.1109/ICDMW58026.2022.00063
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148440707&doi=10.1109%2fICDMW58026.2022.00063&partnerID=40&md5=23fa62d19eb8463b456611869381ca63
AB  - Online social networks have become one of the primary ways of communication to individuals. It rapidly gen-erates a large volume of textual and non-textual data such as images, audio, and videos. In particular, textual data plays a vital role in detecting mental health-related problems such as stress, depression, anxiety, and emotional and behavioral disorders. In this paper, we identify the mental stress of online users in social networks using a transformers-based RoBERTa model and an autoregressive model, also called XLNet. We implement this model in both a constrained system and an unconstrained system. The constrained system maintains the gold standard datasets such as training, validation, and testing. On the other hand, the unconstrained system divides the given dataset into user-specific training, validation, and test sets. Our results indicate that the proposed transformers-based RoBERTa model achieves a better result in both constrained and unconstrained systems than the state-of-the-art models.  © 2022 IEEE.
KW  - Mental health
KW  - Stress detection
KW  - Transformers
KW  - Statistical tests
KW  - Audio and video
KW  - Constrained systems
KW  - Health-related problems
KW  - Large volumes
KW  - Mental health
KW  - Mental stress
KW  - Stress detection
KW  - Textual data
KW  - Transformer
KW  - Unconstrained systems
KW  - Social networking (online)
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Diwali, A.
AU  - Saeedi, K.
AU  - Dashtipour, K.
AU  - Gogate, M.
AU  - Cambria, E.
AU  - Hussain, A.
TI  - Sentiment Analysis Meets Explainable Artificial Intelligence: A Survey on Explainable Sentiment Analysis
PY  - 2024
T2  - IEEE Transactions on Affective Computing
VL  - 15
IS  - 3
SP  - 837
EP  - 846
DO  - 10.1109/TAFFC.2023.3296373
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165279170&doi=10.1109%2fTAFFC.2023.3296373&partnerID=40&md5=bcdcc3f89b83061efe953c5e6b6106f2
AB  - Sentiment analysis can be used to derive knowledge that is connected to emotions and opinions from textual data generated by people. As computer power has grown, and the availability of benchmark datasets has increased, deep learning models based on deep neural networks have emerged as the dominant approach for sentiment analysis. While these models offer significant advantages, their lack of interpretability poses a major challenge in comprehending the rationale behind their reasoning and prediction processes, leading to complications in the models' explainability. Further, only limited research has been carried out into developing deep learning models that describe their internal functionality and behaviors. In this timely study, we carry out a first of its kind overview of key sentiment analysis techniques and eXplainable artificial intelligence (XAI) methodologies that are currently in use. Furthermore, we provide a comprehensive review of sentiment analysis explainability. © 2010-2012 IEEE.
KW  - deep learning
KW  - explainability
KW  - interpretability
KW  - Sentiment analysis
KW  - Deep neural networks
KW  - Job analysis
KW  - Computational modelling
KW  - Deep learning
KW  - Explainability
KW  - Interpretability
KW  - Learning models
KW  - Predictive models
KW  - Sentiment analysis
KW  - Task analysis
KW  - Sentiment analysis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 19
ER  -

TY  - JOUR
AU  - Büyüközkan, G.
AU  - Mukul, E.
TI  - Metaverse-based education: literature review and a proposed framework
PY  - 2024
T2  - Interactive Learning Environments
VL  - 32
IS  - 10
SP  - 7468
EP  - 7496
DO  - 10.1080/10494820.2024.2324322
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186580631&doi=10.1080%2f10494820.2024.2324322&partnerID=40&md5=6c62826af1aeb79c9a98fb3c252416dd
AB  - In recent years, with the improvement of information and communication technologies and the step towards 5G technology in the Internet infrastructure, the use of technologies in education is increasing day by day. Metaverse is one of the important technologies that contribute to digital education processes. While various studies search the literature to synthesize Metaverse-related findings in education, there are few studies that describe the main features of the Metaverse-based education concept, systematically summarize the findings related to this concept. To fill this gap, this study aims to conduct a systematic literature review on the Metaverse-based education concept and propose a framework for this concept. The search was made in different databases, and both quantitative analysis and qualitative discussion were used to analyze the state of the art. This study contributes a structured overview of Metaverse-based education-related publications and reports on the existing state of literature, categorizes publications, analyzes and links trends, highlights gaps, and accordingly proposes a framework (i.e. characteristics, critical success and risk factors, technologies, and components). This study not only adds to the current Metaverse-based education knowledge body but also offers policymakers and practitioners with references for developing policies and good practices to support Metaverse-based education. © 2024 Informa UK Limited, trading as Taylor & Francis Group.
KW  - Distance education
KW  - literature review
KW  - metaverse-based education
KW  - mobile learning
KW  - online learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Jeyakumar, J.V.
AU  - Sarker, A.
AU  - Garcia, L.A.
AU  - Srivastava, M.
TI  - X-CHAR: A Concept-based Explainable Complex Human Activity Recognition Model
PY  - 2023
T2  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 7
IS  - 1
C7  - 17
DO  - 10.1145/3580804
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152481193&doi=10.1145%2f3580804&partnerID=40&md5=e7b7c5c59507da1a986949c8cce49349
AB  - End-to-end deep learning models are increasingly applied to safety-critical human activity recognition (HAR) applications, e.g., healthcare monitoring and smart home control, to reduce developer burden and increase the performance and robustness of prediction models. However, integrating HAR models in safety-critical applications requires trust, and recent approaches have aimed to balance the performance of deep learning models with explainable decision-making for complex activity recognition. Prior works have exploited the compositionality of complex HAR (i.e., higher-level activities composed of lower-level activities) to form models with symbolic interfaces, such as concept-bottleneck architectures, that facilitate inherently interpretable models. However, feature engineering for symbolic concepts-as well as the relationship between the concepts-requires precise annotation of lower-level activities by domain experts, usually with fixed time windows, all of which induce a heavy and error-prone workload on the domain expert. In this paper, we introduce X-CHAR, an eXplainable Complex Human Activity Recognition model that doesn't require precise annotation of low-level activities, offers explanations in the form of human-understandable, high-level concepts, while maintaining the robust performance of end-to-end deep learning models for time series data. X-CHAR learns to model complex activity recognition in the form of a sequence of concepts. For each classification, X-CHAR outputs a sequence of concepts and a counterfactual example as the explanation. We show that the sequence information of the concepts can be modeled using Connectionist Temporal Classification (CTC) loss without having accurate start and end times of low-level annotations in the training dataset-significantly reducing developer burden. We evaluate our model on several complex activity datasets and demonstrate that our model offers explanations without compromising the prediction accuracy in comparison to baseline models. Finally, we conducted a mechanical Turk study to show that the explanations provided by our model are more understandable than the explanations from existing methods for complex activity recognition.  © 2023 Owner/Author.
KW  - Activity recognition
KW  - Explainable AI
KW  - Interpretability
KW  - Neural networks
KW  - Automation
KW  - Classification (of information)
KW  - Complex networks
KW  - Deep learning
KW  - Learning systems
KW  - Pattern recognition
KW  - Professional aspects
KW  - Safety engineering
KW  - Activity recognition
KW  - Complex activity
KW  - End to end
KW  - Explainable AI
KW  - Human activity recognition
KW  - Interpretability
KW  - Learning models
KW  - Neural-networks
KW  - Performance
KW  - Recognition models
KW  - Decision making
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 25
ER  -

TY  - CONF
AU  - Vidal, M.-E.
AU  - Niazmand, E.
AU  - Rohde, P.D.
AU  - Iglesias, E.
AU  - Sakor, A.
TI  - Challenges for Healthcare Data Analytics Over Knowledge Graphs
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14160 LNCS
SP  - 89
EP  - 118
DO  - 10.1007/978-3-662-68014-8_4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174618837&doi=10.1007%2f978-3-662-68014-8_4&partnerID=40&md5=c66690524e4d56872276b34eaeab7ece
AB  - Over the past decade, the volume of data has experienced a significant increase, and this growth is projected to accelerate in the coming years. Within the healthcare sector, various methods (such as liquid biopsies, medical images, and genome sequencing) generate substantial amounts of data, which can lead to the discovery of new biomarkers. Analyzing big data in healthcare holds the potential to advance precise diagnostics and effective treatments. However, healthcare data faces several complexity challenges, including volume, variety, and veracity, which necessitate innovative techniques for data management and knowledge discovery to ensure accurate insights and informed decision-making. This paper summarizes the results presented in the invited talk at BDA 2022 and addresses these challenges by proposing a knowledge-driven framework able to handle complexity issues associated with big data and their impact on analytics. In particular, we propose the use of Knowledge Graphs (KGs) as data structures that enable the integration of diverse healthcare data and facilitate the merging of data with ontologies that describe their meaning. We show the benefits of leveraging KGs to uncover patterns and associations among entities. Specifically, we illustrate the application of rule mining tasks that enhance the understanding of the role of biomarkers and previous cancers in lung cancer. © 2023, Springer-Verlag GmbH Germany, part of Springer Nature.
KW  - Healthcare Data Analytics
KW  - Knowledge Graphs
KW  - Semantic Data Integration
KW  - Big data
KW  - Biomarkers
KW  - Data Analytics
KW  - Decision making
KW  - Diagnosis
KW  - Diseases
KW  - Health care
KW  - Information management
KW  - Knowledge graph
KW  - Medical imaging
KW  - Semantics
KW  - Data analytics
KW  - Genome sequencing
KW  - Healthcare data analytic
KW  - Healthcare sectors
KW  - Image sequencing
KW  - Innovative techniques
KW  - Knowledge graphs
KW  - Precise diagnostics
KW  - Semantic data
KW  - Semantic data integration
KW  - Data integration
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Dwivedi, Y.K.
AU  - Hughes, L.
AU  - Baabdullah, A.M.
AU  - Ribeiro-Navarrete, S.
AU  - Giannakis, M.
AU  - Al-Debei, M.M.
AU  - Dennehy, D.
AU  - Metri, B.
AU  - Buhalis, D.
AU  - Cheung, C.M.K.
AU  - Conboy, K.
AU  - Doyle, R.
AU  - Dubey, R.
AU  - Dutot, V.
AU  - Felix, R.
AU  - Goyal, D.P.
AU  - Gustafsson, A.
AU  - Hinsch, C.
AU  - Jebabli, I.
AU  - Janssen, M.
AU  - Kim, Y.-G.
AU  - Kim, J.
AU  - Koos, S.
AU  - Kreps, D.
AU  - Kshetri, N.
AU  - Kumar, V.
AU  - Ooi, K.-B.
AU  - Papagiannidis, S.
AU  - Pappas, I.O.
AU  - Polyviou, A.
AU  - Park, S.-M.
AU  - Pandey, N.
AU  - Queiroz, M.M.
AU  - Raman, R.
AU  - Rauschnabel, P.A.
AU  - Shirish, A.
AU  - Sigala, M.
AU  - Spanaki, K.
AU  - Wei-Han Tan, G.
AU  - Tiwari, M.K.
AU  - Viglia, G.
AU  - Wamba, S.F.
TI  - Metaverse beyond the hype: Multidisciplinary perspectives on emerging challenges, opportunities, and agenda for research, practice and policy
PY  - 2022
T2  - International Journal of Information Management
VL  - 66
C7  - 102542
DO  - 10.1016/j.ijinfomgt.2022.102542
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134587952&doi=10.1016%2fj.ijinfomgt.2022.102542&partnerID=40&md5=838a76d17c1fe1d24c66375173ad5915
AB  - The metaverse has the potential to extend the physical world using augmented and virtual reality technologies allowing users to seamlessly interact within real and simulated environments using avatars and holograms. Virtual environments and immersive games (such as, Second Life, Fortnite, Roblox and VRChat) have been described as antecedents of the metaverse and offer some insight to the potential socio-economic impact of a fully functional persistent cross platform metaverse. Separating the hype and “meta…” rebranding from current reality is difficult, as “big tech” paints a picture of the transformative nature of the metaverse and how it will positively impact people in their work, leisure, and social interaction. The potential impact on the way we conduct business, interact with brands and others, and develop shared experiences is likely to be transformational as the distinct lines between physical and digital are likely to be somewhat blurred from current perceptions. However, although the technology and infrastructure does not yet exist to allow the development of new immersive virtual worlds at scale - one that our avatars could transcend across platforms, researchers are increasingly examining the transformative impact of the metaverse. Impacted sectors include marketing, education, healthcare as well as societal effects relating to social interaction factors from widespread adoption, and issues relating to trust, privacy, bias, disinformation, application of law as well as psychological aspects linked to addiction and impact on vulnerable people. This study examines these topics in detail by combining the informed narrative and multi-perspective approach from experts with varied disciplinary backgrounds on many aspects of the metaverse and its transformational impact. The paper concludes by proposing a future research agenda that is valuable for researchers, professionals and policy makers alike. © 2022 The Authors
KW  - Augmented reality
KW  - Avatars
KW  - Extended reality
KW  - Metaverse
KW  - Second life
KW  - Virtual reality
KW  - Virtual world
KW  - Economic and social effects
KW  - Economics
KW  - Interactive computer graphics
KW  - Leisure
KW  - Virtual reality
KW  - Augmented reality technology
KW  - Avatar
KW  - Extended reality
KW  - Immersive
KW  - Metaverses
KW  - Multidisciplinary perspectives
KW  - Physical world
KW  - Second Life
KW  - Social interactions
KW  - Virtual worlds
KW  - Augmented reality
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1660
ER  -

TY  - JOUR
AU  - Liu, H.
AU  - Wei, R.
AU  - Tu, G.
AU  - Lin, J.
AU  - Liu, C.
AU  - Jiang, D.
TI  - Sarcasm driven by sentiment: A sentiment-aware hierarchical fusion network for multimodal sarcasm detection
PY  - 2024
T2  - Information Fusion
VL  - 108
C7  - 102353
DO  - 10.1016/j.inffus.2024.102353
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188177972&doi=10.1016%2fj.inffus.2024.102353&partnerID=40&md5=f0375a9df66b5c1586c7e728d1a799ca
AB  - Sarcasm is a form of sentiment expression that highlights the disparity between a person's true intentions and the content they explicitly present. With the exponential increase in multimodal data on social platforms, the detection of sarcasm across various modes has become a pivotal area of research. Although previous studies have extensively examined multimodal feature extraction, fusion, and the modeling of inter-modal incongruities, they often neglected the subtle sentiment cues inherent in sarcastic multimodal data. Additionally, they did not adequately address the sparse distribution and tenuous connections between sarcastic features both within and cross modalities. To address these gaps, we introduce a hierarchical fusion model that integrates sentiment information for enhanced multimodal sarcasm detection. Specifically, we use attribute-object matching in the image modality, treating it as an auxiliary attribute modality. Sentiment data is then extracted from each modality and combined to achieve a more comprehensive representation within modalities. Moreover, we characterize the relationships of inter-modal incongruities using a crossmodal Transformer. We also implement a sentiment-aware image-text contrastive loss mechanism to synchronize the semantics of images and text better. By intensifying these alignments, our model is better equipped to understand incongruous relationships. Experiments demonstrate that our hierarchical fusion model achieves state-of-the-art performance on the multimodal sarcasm detection task. © 2024 Elsevier B.V.
KW  - Hierarchical fusion network
KW  - Multimodal sarcasm detection
KW  - Sentiment
KW  - Exponential increase
KW  - Fusion model
KW  - Hierarchical fusion network
KW  - Hierarchical fusions
KW  - Multi-modal
KW  - Multi-modal data
KW  - Multimodal feature extractions
KW  - Multimodal sarcasm detection
KW  - Sentiment
KW  - Sparse distribution
KW  - Semantics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 23
ER  -

TY  - JOUR
AU  - Ezzameli, K.
AU  - Mahersia, H.
TI  - Emotion recognition from unimodal to multimodal analysis: A review
PY  - 2023
T2  - Information Fusion
VL  - 99
C7  - 101847
DO  - 10.1016/j.inffus.2023.101847
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162106799&doi=10.1016%2fj.inffus.2023.101847&partnerID=40&md5=5711dda1521303a2501b2d04107d7316
AB  - The omnipresence of numerous information sources in our daily life brings up new alternatives for emotion recognition in several domains including e-health, e-learning, robotics, and e-commerce. Due to the variety of data, the research area of multimodal machine learning poses special problems for computer scientists; how did the field of emotion recognition progress in each modality and what are the most common strategies for recognizing emotions? What part does deep learning play in this? What is multimodality? How did it progress? What are the methods of information fusion? What are the most used datasets in each modality and in multimodal recognition? We can understand and compare the various methods by answering these questions. © 2023 Elsevier B.V.
KW  - Affective computing
KW  - Deep learning
KW  - Emotion recognition
KW  - Fusion
KW  - Modality
KW  - Multimodality
KW  - Deep learning
KW  - Modal analysis
KW  - Speech recognition
KW  - Affective Computing
KW  - Daily lives
KW  - Deep learning
KW  - Ehealth
KW  - Emotion recognition
KW  - Information sources
KW  - Modality
KW  - Multi-modality
KW  - Multimodal analysis
KW  - Unimodal
KW  - Emotion Recognition
M3  - Short survey
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 96
ER  -

TY  - JOUR
AU  - Caccavale, R.
AU  - Finzi, A.
TI  - A Robotic Cognitive Control Framework for Collaborative Task Execution and Learning
PY  - 2022
T2  - Topics in Cognitive Science
VL  - 14
IS  - 2
SP  - 327
EP  - 343
DO  - 10.1111/tops.12587
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119827688&doi=10.1111%2ftops.12587&partnerID=40&md5=98f0ac4dbe963472515a4796d1a1245e
AB  - In social and service robotics, complex collaborative tasks are expected to be executed while interacting with humans in a natural and fluent manner. In this scenario, the robotic system is typically provided with structured tasks to be accomplished, but must also continuously adapt to human activities, commands, and interventions. We propose to tackle these issues by exploiting the concept of cognitive control, introduced in cognitive psychology and neuroscience to describe the executive mechanisms needed to support adaptive responses and complex goal-directed behaviors. Specifically, we rely on a supervisory attentional system to orchestrate the execution of hierarchically organized robotic behaviors. This paradigm seems particularly effective not only for flexible plan execution but also for human–robot interaction, because it directly provides attention mechanisms considered as pivotal for implicit, non-verbal human–human communication. Following this approach, we are currently developing a robotic cognitive control framework enabling collaborative task execution and incremental task learning. In this paper, we provide a uniform overview of the framework illustrating its main features and discussing the potential of the supervisory attentional system paradigm in different scenarios where humans and robots have to collaborate for learning and executing everyday activities. © 2021 Cognitive Science Society LLC.
KW  - Attention
KW  - Cognitive architecture
KW  - Cognitive control
KW  - Cognitive robotics
KW  - Human–robot collaboration
KW  - Cognition
KW  - Humans
KW  - Learning
KW  - Robotics
KW  - cognition
KW  - human
KW  - learning
KW  - robotics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 14
ER  -

TY  - JOUR
AU  - Zhai, Z.
AU  - Han, L.
AU  - Zhang, W.
TI  - Using EEG technology to enhance performance measurement in physical education
PY  - 2025
T2  - Frontiers in Public Health
VL  - 13
C7  - 1551374
DO  - 10.3389/fpubh.2025.1551374
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218168929&doi=10.3389%2ffpubh.2025.1551374&partnerID=40&md5=64a80e444fd3c71abba264acefa699d8
AB  - Introduction: The application of EEG technology in the context of school physical education offers a promising avenue to explore the neural mechanisms underlying the mental health symptom benefits of physical activity in adolescents. Current research methodologies in this domain primarily rely on behavioral and self-reported data, which ack the precision to capture the complex interplay between physical activity and cognitive-emotional outcomes. Traditional approaches often fail to provide real-time, objective insights into individual variations in mental health symptom responses. Methods: To address these gaps, we propose an Adaptive Physical Education Optimization (APEO)model integrated with EEG analysis to monitor and optimize the mental health symptom impacts of physical education programs. APEO combines biomechanical modeling, engagement prediction through recurrent neural networks, and reinforcement learning to tailor physical activity interventions. By incorporating EEG data, our framework captured neural markers of emotional and cognitive states, enabling precise evaluation and personalized adjustments. Results and discussion: Preliminary results indicate that our system enhances both engagement and mental health symptom outcomes, offering a scalable, data-driven solution to optimize adolescent mental wellbeing through physical education. Copyright © 2025 Zhai, Han and Zhang.
KW  - adolescent mental health symptoms
KW  - EEG analysis
KW  - engagement optimization
KW  - neural mechanisms
KW  - physical education
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Wang, Y.
AU  - Zhu, H.
TI  - Verification-guided Programmatic Controller Synthesis
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 13994 LNCS
SP  - 229
EP  - 250
DO  - 10.1007/978-3-031-30820-8_16
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161453355&doi=10.1007%2f978-3-031-30820-8_16&partnerID=40&md5=5346f306e4514a43059b71674c20e5cc
AB  - We present a verification-based learning framework VEL that synthesizes safe programmatic controllers for environments with continuous state and action spaces. The key idea is the integration of program reasoning techniques into controller training loops. VEL performs abstraction-based program verification to reason about a programmatic controller and its environment as a closed-loop system. Based on a novel verification-guided synthesis loop for training, VEL minimizes the amount of safety violation in the proof space of the system, which approximates the worst-case safety loss, using gradient-descent style optimization. Experimental results demonstrate the substantial benefits of leveraging verification feedback for synthesizing provably correct controllers. © 2023, The Author(s).
KW  - Closed loop systems
KW  - Gradient methods
KW  - Action spaces
KW  - Closed-loop system
KW  - Continuous actions
KW  - Continuous State Space
KW  - Controller synthesis
KW  - Learning frameworks
KW  - Program Verification
KW  - Programmatics
KW  - Reasoning techniques
KW  - Safety violations
KW  - Controllers
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Beikmohammadi, A.
AU  - Magnússon, S.
TI  - TA-Explore: Teacher-Assisted Exploration for Facilitating Fast Reinforcement Learning
PY  - 2023
T2  - Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS
VL  - 2023-May
SP  - 2412
EP  - 2414
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171261919&partnerID=40&md5=6bc4be5014c007603240e7ae083c5f4c
AB  - Reinforcement Learning (RL) is crucial for data-driven decision-making but suffers from sample inefficiency. This poses a risk to system safety and can be costly in real-world environments with physical interactions. This paper proposes a human-inspired framework to improve the sample efficiency of RL algorithms, which gradually provides the learning agent with simpler but similar tasks that progress toward the main task. The proposed method does not require pre-training and can be applied to any goal, environment, and RL algorithm, including value-based and policy-based methods, as well as tabular and deep-RL methods. The framework is evaluated on a Random Walk and optimal control problem with constraint, showing good performance in improving the sample efficiency of RL-learning algorithms. © 2023 International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.
KW  - Deep RL
KW  - Exploration
KW  - Policy Optimization
KW  - PPO
KW  - Sample Efficiency
KW  - Autonomous agents
KW  - Decision making
KW  - Deep learning
KW  - Learning algorithms
KW  - Learning systems
KW  - Multi agent systems
KW  - Optimal control systems
KW  - Reinforcement learning
KW  - Data driven decision
KW  - Decisions makings
KW  - Deep reinforcement learning
KW  - Policy optimization
KW  - Real world environments
KW  - Reinforcement learning algorithms
KW  - Reinforcement learnings
KW  - Sample efficiency
KW  - System safety
KW  - Teachers'
KW  - Efficiency
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Zhang, L.
AU  - Yang, A.J.
AU  - Xiong, Y.
AU  - Casas, S.
AU  - Yang, B.
AU  - Ren, M.
AU  - Urtasun, R.
TI  - Towards Unsupervised Object Detection from LiDAR Point Clouds
PY  - 2023
T2  - Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition
VL  - 2023-June
SP  - 9317
EP  - 9328
DO  - 10.1109/CVPR52729.2023.00899
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168725108&doi=10.1109%2fCVPR52729.2023.00899&partnerID=40&md5=ecd6e8853f1a62dfc96813d168b00ae1
AB  - In this paper, we study the problem of unsupervised object detection from 3D point clouds in self-driving scenes. We present a simple yet effective method that exploits (i) point clustering in near-range areas where the point clouds are dense, (ii) temporal consistency to filter out noisy unsupervised detections, (iii) translation equivariance of CNNs to extend the auto-labels to long range, and (iv) self-supervision for improving on its own. Our approach, OYSTER (Object Discovery via Spatio-Temporal Refinement), does not impose constraints on data collection (such as repeated traversals of the same location), is able to detect objects in a zero-shot manner without supervised fine-tuning (even in sparse, distant regions), and continues to self-improve given more rounds of iterative self-training. To better measure model performance in self-driving scenarios, we propose a new planning-centric perception metric based on distance-to-collision. We demonstrate that our unsupervised object detector significantly outperforms unsupervised baselines on PandaSet and Argoverse 2 Sensor dataset, showing promise that self-supervision combined with object priors can enable object discovery in the wild. For more information, visit the project website: https://waabi.ai/research/oyster.  © 2023 IEEE.
KW  - Autonomous driving
KW  - Object detection
KW  - 3D point cloud
KW  - Autonomous driving
KW  - Clusterings
KW  - Near ranges
KW  - Objects detection
KW  - Point-clouds
KW  - Self drivings
KW  - Simple++
KW  - Temporal consistency
KW  - Unsupervised detection
KW  - Spatio-temporal data
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 19
ER  -

TY  - JOUR
AU  - Ali, S.G.
AU  - Yang, X.
AU  - Masood, S.
AU  - Ghazanfar, Z.
AU  - Jung, Y.
AU  - Chen, T.
AU  - Wang, X.
TI  - Revolutionizing diabetic retinopathy and macular edema management: a systematic review on the transformative potential of artificial intelligence
PY  - 2025
T2  - Visual Computer
DO  - 10.1007/s00371-025-04024-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007683558&doi=10.1007%2fs00371-025-04024-2&partnerID=40&md5=2b037d7f5d628092d298560261f46b57
AB  - Diabetic retinopathy (DR) and diabetic macular edema (DME) are leading causes of vision impairment worldwide, necessitating continuous monitoring and timely interventions due to their chronic, progressive nature. This systematic review evaluates the effectiveness, limitations, and economic benefits of adaptive AI models in managing DR/DME (2020–2025 (February)), focusing on their potential to transform static diagnostics into dynamic, personalized care. We analyzed 119 studies following PRISMA guidelines, prioritizing peer-reviewed research on AI models for dynamic monitoring, personalized risk stratification, and teleophthalmology. Key databases included PubMed, IEEE Xplore, and Scopus. Adaptive AI models demonstrated significant clinical and economic impact. Hybrid models integrating electronic health records (EHRs) and genomic data improved DR progression prediction (AUC: 0.93), while LSTM networks reduced treatment costs by 20% through optimized anti-VEGF therapy. Vision Transformers achieved superior accuracy in real-time monitoring (AUC: 0.95), and teleophthalmology systems like EyePACS reduced unnecessary referrals by 30% in underserved regions. Key limitations include inconsistent real-world validation, regulatory delays (e.g., <5% of models are FDA-approved), and biases in generalization across diverse populations. Adaptive AI models show transformative potential for DR and DME management but require robust validation, ethical frameworks, and interoperability improvements. Therefore, to fully realize the transformative potential of adaptive AI models for DR and DME management, future research must prioritize robust validation, ethical frameworks, and interoperability improvements, focusing on federated learning for data privacy, edge computing for real-time analysis, and integration of socioeconomic factors to enhance equity. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2025.
KW  - Diabetic macular edema (DME)
KW  - Diabetic retinopathy (DR)
KW  - Dynamic monitoring
KW  - Personalized risk stratification
KW  - Personalized medicine
KW  - Records management
KW  - Diabetic macular edema
KW  - Diabetic retinopathy
KW  - Dynamic monitoring
KW  - Macular edema
KW  - Personalized risk stratification
KW  - Risk stratification
KW  - Systematic Review
KW  - Teleophthalmology
KW  - Vision impairments
KW  - Risk management
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Qu, C.
AU  - Dai, S.
AU  - Wei, X.
AU  - Cai, H.
AU  - Wang, S.
AU  - Yin, D.
AU  - Xu, J.
AU  - Wen, J.-R.
TI  - Tool learning with large language models: a survey
PY  - 2025
T2  - Frontiers of Computer Science
VL  - 19
IS  - 8
C7  - 198343
DO  - 10.1007/s11704-024-40678-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217667500&doi=10.1007%2fs11704-024-40678-2&partnerID=40&md5=7a7e6cc79c9a9fe43ca95dfdfecc3743
AB  - Recently, tool learning with large language models (LLMs) has emerged as a promising paradigm for augmenting the capabilities of LLMs to tackle highly complex problems. Despite growing attention and rapid advancements in this field, the existing literature remains fragmented and lacks systematic organization, posing barriers to entry for newcomers. This gap motivates us to conduct a comprehensive survey of existing works on tool learning with LLMs. In this survey, we focus on reviewing existing literature from the two primary aspects (1) why tool learning is beneficial and (2) how tool learning is implemented, enabling a comprehensive understanding of tool learning with LLMs. We first explore the “why” by reviewing both the benefits of tool integration and the inherent benefits of the tool learning paradigm from six specific aspects. In terms of “how”, we systematically review the literature according to a taxonomy of four key stages in the tool learning workflow: task planning, tool selection, tool calling, and response generation. Additionally, we provide a detailed summary of existing benchmarks and evaluation methods, categorizing them according to their relevance to different stages. Finally, we discuss current challenges and outline potential future directions, aiming to inspire both researchers and industrial developers to further explore this emerging and promising area. © Higher Education Press 2025.
KW  - agent
KW  - large language models
KW  - tool learning
KW  - Adversarial machine learning
KW  - Federated learning
KW  - Complex problems
KW  - Language model
KW  - Large language model
KW  - Learning paradigms
KW  - Planning tools
KW  - Task planning
KW  - Tool integration
KW  - Tool learning
KW  - Tool selection
KW  - Work-flows
KW  - Contrastive Learning
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Wu, X.
AU  - He, J.
AU  - Huang, L.
AU  - Fu, C.
AU  - Wang, W.
TI  - WBSan: WebAssembly Bug Detection for Sanitization and Binary-Only Fuzzing
PY  - 2025
T2  - WWW 2025 - Proceedings of the ACM Web Conference
SP  - 3311
EP  - 3322
DO  - 10.1145/3696410.3714622
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005156638&doi=10.1145%2f3696410.3714622&partnerID=40&md5=4fbe2be7d6096f9f3e5670c0828c5c71
AB  - With the advancement of WebAssembly, abbreviated as Wasm, various memory bugs and undefined behaviors have emerged, leading to security issues that affect usability and portability. Existing methods struggle to detect these problems in Wasm binaries due to challenges associated with binary instrumentation and the difficulty of defining legal memory bounds. While sanitizers combined with fuzzing are recognized as effective means for identifying bugs, current Wasm sanitizers necessitate compile-time instrumentation, rendering them unsuitable for practical scenarios where only binaries are accessible. In this paper, we propose WBSan, the first Wasm binary sanitizer employing static analysis and Wasm binary instrumentation to detect memory bugs and undefined behaviors. We develop distinct instrumentation patterns tailored for each type of bug and introduce Wasm shadow memory to address complex memory bugs. Our results reveal that WBSan achieves a 16.8% false detection rate, outperforming current Wasm binary checkers and native sanitizers in detecting memory bugs and undefined behaviors. Furthermore, when compared with the binary-only fuzzer, WBSan uncovers more crashes and achieves greater code coverage. © 2025 Copyright held by the owner/author(s).
KW  - Bug detection
KW  - Fuzzing
KW  - Sanitizer
KW  - WebAssembly
KW  - 'current
KW  - Binary instrumentations
KW  - Bug detection
KW  - Compile time
KW  - Fuzzing
KW  - Memory bounds
KW  - Sanitization
KW  - Sanitizer
KW  - Security issues
KW  - Webassembly
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Klampfl, L.
AU  - Wotawa, F.
TI  - Leveraging Answer Set Programming for Continuous Monitoring, Fault Detection, and Explanation of Automated and Autonomous Driving Systems
PY  - 2024
T2  - OpenAccess Series in Informatics
VL  - 125
C7  - 10
DO  - 10.4230/OASIcs.DX.2024.10
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211954200&doi=10.4230%2fOASIcs.DX.2024.10&partnerID=40&md5=edd3bdfea727247bd7255d676aa228b5
AB  - Recent advancements in automated and autonomous driving systems have facilitated their integration into modern vehicles, enabling them to accurately perceive their surroundings and support or even fully undertake complex driving tasks. Given the complexity and unpredictable nature of driving environments and traffic situations, ensuring the correct behavior of such systems is essential to prevent hazardous situations, increase user acceptance, and avoid human harm. However, the increased complexity of these systems and the extensive search space of possible scenarios introduce significant challenges to testing and real-time fault management. Hence, besides rigorous testing during the development phase, there is a need for additional validation and verification during operation. This paper proposes utilizing Answer Set Programming (ASP), a form of declarative programming, for continuous real-time monitoring, fault detection, and explanation to ensure the correct functioning of automated and autonomous driving systems. Our approach aims to enhance the reliability and safety of such systems by detecting violations and providing explanations that can support fault-adaptive control or mitigation strategies. We demonstrate the effectiveness of our methodology across diverse scenarios executed within a simulation environment, discuss the main challenges encountered, and outline future research directions. © Lorenz Klampfl and Franz Wotawa.
KW  - Answer Set Programming
KW  - Autonomous Driving
KW  - Continuous Monitoring
KW  - Acceptance tests
KW  - Continuous time systems
KW  - Fault detection
KW  - Answer set programming
KW  - Automated driving
KW  - Autonomous driving
KW  - Continuous monitoring
KW  - Driving environment
KW  - Driving systems
KW  - Driving tasks
KW  - Faults detection
KW  - Traffic situations
KW  - Users' acceptance
KW  - Adaptive control systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Bouchouras, G.
AU  - Bitilis, P.
AU  - Kotis, K.
AU  - Vouros, G.A.
TI  - LLMs for the Engineering of a Parkinson Disease Monitoring and Alerting Ontology
PY  - 2024
T2  - CEUR Workshop Proceedings
VL  - 3749
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203587310&partnerID=40&md5=6cf0a5bc51abfa68aafd9a5fe1f9d3ea
AB  - This paper investigates the integration of Large Language Models (LLMs) in the engineering of a Parkinson's Disease (PD) monitoring and alerting ontology. The focus is on the ontology engineering methodology which combines the capabilities of LLMs and human expertise to develop more robust and comprehensive domain ontologies, faster than humans do alone. Evaluating models like ChatGPT-3.5, ChatGPT4, Gemini, and Llama2, this study explores various LLM based ontology engineering methods. The findings reveal that the proposed hybrid approach (both LLM and human involvement), namely X-HCOME, consistently excelled in class generation and F-1 score, indicating its efficiency in creating valid and comprehensive ontologies faster than humans do alone. The study underscores the potential of the combined LLMs and human intelligence to enrich PD domain knowledge and enhance expert-generated PD ontologies. In overall, the presented approach exemplifies a promising collaboration between machine capabilities and human expertise in developing ontologies for complex domains.  Copyright © 2024 for this paper by its authors.
KW  - Human-LLM teaming
KW  - LLMs
KW  - Ontology Engineering
KW  - Parkinson Disease
KW  - Disease control
KW  - Human engineering
KW  - Ontology
KW  - Disease monitoring
KW  - Human expertise
KW  - Human-large language model teaming
KW  - Language model
KW  - Large language model
KW  - Ontology engineering
KW  - Ontology Engineering Methodologies
KW  - Ontology's
KW  - Parkinson's disease
KW  - Neurodegenerative diseases
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Samee, N.A.
AU  - Atteia, G.
AU  - Meshoul, S.
AU  - Al-antari, M.A.
AU  - Kadah, Y.M.
TI  - Deep Learning Cascaded Feature Selection Framework for Breast Cancer Classification: Hybrid CNN with Univariate-Based Approach
PY  - 2022
T2  - Mathematics
VL  - 10
IS  - 19
C7  - 3631
DO  - 10.3390/math10193631
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139957914&doi=10.3390%2fmath10193631&partnerID=40&md5=0a3146117e89f374c4658ca7f562165b
AB  - With the help of machine learning, many of the problems that have plagued mammography in the past have been solved. Effective prediction models need many normal and tumor samples. For medical applications such as breast cancer diagnosis framework, it is difficult to gather labeled training data and construct effective learning frameworks. Transfer learning is an emerging strategy that has recently been used to tackle the scarcity of medical data by transferring pre-trained convolutional network knowledge into the medical domain. Despite the well reputation of the transfer learning based on the pre-trained Convolutional Neural Networks (CNN) for medical imaging, several hurdles still exist to achieve a prominent breast cancer classification performance. In this paper, we attempt to solve the Feature Dimensionality Curse (FDC) problem of the deep features that are derived from the transfer learning pre-trained CNNs. Such a problem is raised due to the high space dimensionality of the extracted deep features with respect to the small size of the available medical data samples. Therefore, a novel deep learning cascaded feature selection framework is proposed based on the pre-trained deep convolutional networks as well as the univariate-based paradigm. Deep learning models of AlexNet, VGG, and GoogleNet are randomly selected and used to extract the shallow and deep features from the INbreast mammograms, whereas the univariate strategy helps to overcome the dimensionality curse and multicollinearity issues for the extracted features. The optimized key features via the univariate approach are statistically significant (p-value ≤ 0.05) and have good capability to efficiently train the classification models. Using such optimal features, the proposed framework could achieve a promising evaluation performance in terms of 98.50% accuracy, 98.06% sensitivity, 98.99% specificity, and 98.98% precision. Such performance seems to be beneficial to develop a practical and reliable computer-aided diagnosis (CAD) framework for breast cancer classification. © 2022 by the authors.
KW  - breast cancer
KW  - CAD system
KW  - deep transfer learning
KW  - feature dimensionality curse (FDC)
KW  - feature reduction and selection
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 40
ER  -

TY  - JOUR
AU  - Alvarez-Risco, A.
AU  - Del-Aguila-Arcentales, S.
AU  - Rosen, M.A.
AU  - Yáñez, J.A.
TI  - Social Cognitive Theory to Assess the Intention to Participate in the Facebook Metaverse by Citizens in Peru during the COVID-19 Pandemic
PY  - 2022
T2  - Journal of Open Innovation: Technology, Market, and Complexity
VL  - 8
IS  - 3
C7  - 142
DO  - 10.3390/joitmc8030142
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137655873&doi=10.3390%2fjoitmc8030142&partnerID=40&md5=f36eede8fdf365fe88ada3f53854afc2
AB  - The current study aims to validate and apply an instrument to assess the relationship between institutional support, technological literacy, and self-efficacy on the intention to participate in the Facebook Metaverse using social cognitive theory. We performed a cross-sectional, analytical study of 410 citizens in Peru to assess the influence of institutional support, technological literacy, and self-efficacy on the intention to participate in the Facebook Metaverse during the COVID-19 pandemic. The research model was validated using partial least square structural equation modeling (PLS-SEM) to establish the influence of variables on the model. Institutional support and technological literacy were found to influence the self-efficacy of participating in the metaverse positively by correlations of 0.573 and 0.257, respectively. Self-efficacy of participating positively influenced the intention to participate in the Facebook Metaverse by 0.808. The model explained 65.4% of the intention to participate in the Facebook Metaverse. Bootstrapping demonstrated that the path coefficients of the research model were statistically significant. The research outcomes may help firms to develop planning and investment in the metaverse, as well as understanding the factors that influence a higher intention to participate in the Facebook Metaverse. © 2022 by the authors.
KW  - COVID-19
KW  - Facebook
KW  - institutional support
KW  - intention to participate
KW  - metaverse
KW  - Peru
KW  - self-efficacy
KW  - technology
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 72
ER  -

TY  - JOUR
AU  - Liu, H.
AU  - Wei, R.
AU  - Tu, G.
AU  - Lin, J.
AU  - Jiang, D.
AU  - Cambria, E.
TI  - Knowing What and Why: Causal emotion entailment for emotion recognition in conversations
PY  - 2025
T2  - Expert Systems with Applications
VL  - 274
C7  - 126924
DO  - 10.1016/j.eswa.2025.126924
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218412922&doi=10.1016%2fj.eswa.2025.126924&partnerID=40&md5=003cf19f81dce03618e5d0c7497c5ee9
AB  - The clues for eliciting emotion deserve attention in the realm of Emotion Recognition in Conversations (ERC). In an ideal dialog system, comprehending emotions alone is insufficient, and underlying the causes of emotion is also imperative. However, previous research overlooked the integration of causal emotion entailment for a prolonged period. Therefore, an emotion-cause hybrid framework that utilizes causal emotion entailment (CEE) is proposed to promote the ERC task. Specifically, the presented method integrates the information of the cause clause extracted through the CEE module that triggers emotions into the utterance representations obtained by the ERC model. Moreover, a Bidirectional Reasoning Network (BRN) is designed to extract emotional cues to simulate human complex emotional cognitive behavior. Experimental results demonstrate that our framework achieves a new state-of-the-art performance on different datasets, indicating that the proposed framework can improve the model's ability to emotion understanding. © 2025 Elsevier Ltd
KW  - Causal emotion entailment
KW  - Emotion recognition
KW  - Reasoning network
KW  - Causal emotion entailment
KW  - Cognitive behavior
KW  - Dialogue systems
KW  - Emotion recognition
KW  - Emotion understanding
KW  - Hybrid framework
KW  - Modeling abilities
KW  - Reasoning network
KW  - State-of-the-art performance
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Löwenmark, K.
AU  - Taal, C.
AU  - Schnabel, S.
AU  - Liwicki, M.
AU  - Sandin, F.
TI  - Technical Language Supervision for Intelligent Fault Diagnosis in Process Industry
PY  - 2022
T2  - International Journal of Prognostics and Health Management
VL  - 13
IS  - 2
DO  - 10.36001/ijphm.2022.v13i2.3137
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140639510&doi=10.36001%2fijphm.2022.v13i2.3137&partnerID=40&md5=d990879d46c80d5bf15f123b591d62dc
AB  - In the process industry, condition monitoring systems with automated fault diagnosis methods assist human experts and thereby improve maintenance efficiency, process sustainabil-ity, and workplace safety. Improving the automated fault diagnosis methods using data and machine learning-based models is a central aspect of intelligent fault diagnosis (IFD). A major challenge in IFD is to develop realistic datasets with accurate labels needed to train and validate models, and to transfer models trained with labeled lab data to heterogeneous process industry environments. However, fault descriptions and work-orders written by domain experts are increasingly digi-tised in modern condition monitoring systems, for example in the context of rotating equipment monitoring. Thus, domain-specific knowledge about fault characteristics and severities exists as technical language annotations in industrial datasets. Furthermore, recent advances in natural language processing enable weakly supervised model optimisation using natural language annotations, most notably in the form of natural language supervision (NLS). This creates a timely opportu-nity to develop technical language supervision (TLS) solu-tions for IFD systems grounded in industrial data, for example as a complement to pre-training with lab data to address problems like overfitting and inaccurate out-of-sample gen-eralisation. We surveyed the literature and identify a con-siderable improvement in the maturity of NLS over the last two years, facilitating applications beyond natural language; a rapid development of weak supervision methods; and transfer learning as a current trend in IFD which can benefit from these developments. Finally we describe a general framework for TLS and implement a TLS case study based on Sentence-BERT and contrastive learning based zero-shot inference on annotated industry data. © 2022, Prognostics and Health Management Society. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Akintunde, M.
AU  - Young, V.
AU  - Yazdanpanah, V.
AU  - Salehi Fathabadi, A.
AU  - Leonard, P.
AU  - Butler, M.
AU  - Moreau, L.
TI  - Verifiably Safe and Trusted Human-AI Systems: A Socio-technical Perspective
PY  - 2023
T2  - ACM International Conference Proceeding Series
C7  - 56
DO  - 10.1145/3597512.3599719
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168003649&doi=10.1145%2f3597512.3599719&partnerID=40&md5=780d1f241667dd7b279b70893b94febf
AB  - Replacing human decision-making with machine decision-making results in challenges associated with stakeholders' trust in AI systems that interact with and keep the human user in the loop. We refer to such systems as Human-AI Systems (HAIS) and argue that technical safety and social trustworthiness of a HAIS are key to its wide-spread adoption by society. To develop a verifiably safe and trusted HAIS, it is important to understand how different stakeholders perceive an autonomous system (AS) as trusted, and how the context of application affects their perceptions. Technical approaches to meet trust and safety concerns are widely investigated and under-used in the context of measuring users' trust in autonomous AI systems. Interdisciplinary socio-technical approaches, grounded in social science (trust) and computer science (safety), are less considered in HAIS investigations. This paper aims to elaborate on the need for the application of formal methods, for ensuring safe behaviour of HAIS, based on the real-life understanding of users about trust, and analysing trust dynamics. This work puts forward core challenges in this area and presents a research agenda on verifiably safe and trusted human-AI systems.  © 2023 Owner/Author.
KW  - Human-AI Systems
KW  - Safety
KW  - Trust
KW  - Verification
KW  - Behavioral research
KW  - Formal verification
KW  - AI systems
KW  - Decisions makings
KW  - Human decision-making
KW  - Human users
KW  - Human-AI system
KW  - Machine decisions
KW  - Socio-technical perspective
KW  - Technical safety
KW  - Trust
KW  - Wide spreads
KW  - Decision making
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Brás, G.
AU  - Silva, A.M.
AU  - Wanner, E.F.
TI  - A genetic algorithm for rule extraction in fuzzy adaptive learning control networks
PY  - 2024
T2  - Genetic Programming and Evolvable Machines
VL  - 25
IS  - 1
C7  - 11
DO  - 10.1007/s10710-024-09486-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188935931&doi=10.1007%2fs10710-024-09486-2&partnerID=40&md5=323d74b831284dec71a68c35aa0b66c1
AB  - This paper presents a novel approach, dubbed Falcon-GA, for rule extraction in a Fuzzy Adaptive Learning Control Network (FALCON) using a Genetic Algorithm (GA). The FALCON-GA combines multiple techniques to establish the relationships and connections among fuzzy rules, including the use of a GA for rule extraction and a Gradient-based method for fine-tuning the membership function parameters. The learning algorithm of FALCON-GA incorporates three key components: the ART (Adaptive Resonance Theory) clustering algorithm for initial membership function identification, the Genetic Algorithm for rule extraction, and the Gradient method for adjusting membership function parameters. Moreover, FALCON-GA offers flexibility by allowing the incorporation of different rule types within the FALCON architecture, making it flexible and expansible. The proposed model has been evaluated in various forecasting problems reported in the literature and compared to alternative models. Computational experiments demonstrate the effectiveness of FALCON-GA in forecasting tasks and reveal significant performance improvements compared to the original FALCON. These results indicate that Genetic Algorithms efficiently extract rules for Fuzzy Adaptive Learning Control Networks. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.
KW  - Forecasting
KW  - Fuzzy systems
KW  - Genetic algorithm
KW  - Rule extraction
KW  - Adaptive control systems
KW  - Clustering algorithms
KW  - Extraction
KW  - Forecasting
KW  - Fuzzy inference
KW  - Fuzzy neural networks
KW  - Gradient methods
KW  - Learning algorithms
KW  - Membership functions
KW  - Adaptive learning control
KW  - Adaptive resonance theory
KW  - Algorithm of fuzzy
KW  - Control network
KW  - Fine tuning
KW  - Function parameters
KW  - Fuzzy adaptive
KW  - Gradient-based method
KW  - Memberships function
KW  - Rules extraction
KW  - Genetic algorithms
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Lu, J.
AU  - Wen, G.
AU  - Lu, R.
AU  - Wang, Y.
AU  - Zhang, S.
TI  - Networked Knowledge and Complex Networks: An Engineering View
PY  - 2022
T2  - IEEE/CAA Journal of Automatica Sinica
VL  - 9
IS  - 8
SP  - 1366
EP  - 1383
DO  - 10.1109/JAS.2022.105737
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135754280&doi=10.1109%2fJAS.2022.105737&partnerID=40&md5=72a5b763c62dec8db3f0c5d29b989537
AB  - Along with the development of information technologies such as mobile Internet, information acquisition technology, cloud computing and big data technology, the traditional knowledge engineering and knowledge-based software engineering have undergone fundamental changes where the network plays an increasingly important role. Within this context, it is required to develop new methodologies as well as technical tools for network-based knowledge representation, knowledge services and knowledge engineering. Obviously, the term 'network' has different meanings in different scenarios. Meanwhile, some breakthroughs in several bottleneck problems of complex networks promote the developments of the new methodologies and technical tools for network-based knowledge representation, knowledge services and knowledge engineering. This paper first reviews some recent advances on complex networks, and then, in conjunction with knowledge graph, proposes a framework of networked knowledge which models knowledge and its relationships with the perspective of complex networks. For the unique advantages of deep learning in acquiring and processing knowledge, this paper reviews its development and emphasizes the role that it played in the development of knowledge engineering. Finally, some challenges and further trends are discussed.  © 2014 Chinese Association of Automation.
KW  - Complex network
KW  - knowledge graph
KW  - networked knowledge
KW  - neural network
KW  - Deep learning
KW  - Distributed computer systems
KW  - Knowledge representation
KW  - Software engineering
KW  - Technology transfer
KW  - Information acquisitions
KW  - Internet information
KW  - Knowledge graphs
KW  - Knowledge service
KW  - Knowledge-representation
KW  - Mobile Internet
KW  - Network-based
KW  - Networked knowledge
KW  - Neural-networks
KW  - Technical tools
KW  - Complex networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 35
ER  -

TY  - CHAP
AU  - Malgieri, L.E.
TI  - Ontologies, Machine Learning and Deep Learning in Obstetrics
PY  - 2023
T2  - Practical Guide to Simulation in Delivery Room Emergencies
SP  - 29
EP  - 64
DO  - 10.1007/978-3-031-10067-3_3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173838181&doi=10.1007%2f978-3-031-10067-3_3&partnerID=40&md5=543e6ba4230327ee1e323181176a13a7
AB  - We have all had to deal with Obstetrics at least once in our lives. Obstetrics and gynecology are highly litigious specialties, accounting for a large proportion of indemnity payments (Emin et al, In Vivo, 33(5):1547–1551, 2019). Artificial intelligence is considered the highest priority among all technologies, and healthcare is its most pressing application, with the goal of putting intelligent, advanced solutions, and medical devices assisted in various ways by Artificial Intelligence (AI) in the hands of professionals around the world to drive better decision making and create more meaningful connections. In Sect. 3.1, we will examine the implications of the introduction of AI in the processes of certifying software as a medical device: certifying software that can change over time depending on the data it examines has opened a discussion table with certifying bodies; at the same time, they have raised the possibility of treating some diseases with software. Sections 3.2–3.4 are devoted to the three cornerstones of Artificial Intelligence: reasoning, data management, and image management. Section 3.2 describes what Ontologies are, allowing to synthesize and manage a very rich and powerful map of all the information known about an entire domain, something we usually do in our heads, reconciling slight differences in nomenclature and data representation to form a coherent plan of action. Section 3.3 on Machine Learning describes a series of algorithms that can be used to examine numerical data, or reduced to such data, in order to identify patterns in them, which are useful both for understanding phenomena that have already occurred and for predicting them. Section 3.4 describes Deep Learning, which is that part of Artificial Intelligence mainly dedicated to the processing of images and videos, as well as of spoken language. Section 3.5 is dedicated to the focus on some studies, research, and publications in the field of obstetrics. In all sections, we have given numerous examples of studies and research in the field of obstetrics. Section 3.6 describes how the growing demand for personalized medicine is opening the door to several new players in the world of healthcare big data. In recent years, the world’s top-ten companies, which used to be oil and gas companies, are all companies that have an innovative, almost strategic-visionary vision of the business on the one hand, and on the other have developed and have great support for emerging Information Technologies and Artificial Intelligence. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.
KW  - Artificial Intelligence
KW  - Deep learning
KW  - Disruptive innovation
KW  - Machine learning
KW  - Obstetrics
KW  - Ontologies
KW  - Software as a medical device (SaMD)
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - CONF
AU  - Duong, C.
AU  - Liu, Q.
AU  - Mao, R.
AU  - Cambria, E.
TI  - Saving Earth One Tweet at a Time through the Lens of Artificial Intelligence
PY  - 2022
T2  - Proceedings of the International Joint Conference on Neural Networks
VL  - 2022-July
DO  - 10.1109/IJCNN55064.2022.9892271
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140708881&doi=10.1109%2fIJCNN55064.2022.9892271&partnerID=40&md5=5c76f26a6e7ce9d8e62f51c9b8694a2e
AB  - The impacts of climate change and global warming have become more visible globally because of the increasing frequency of extreme weather events, abnormal heatwaves, and other climate crises. Besides the traditional survey method, it is beneficial to automatically distillate climate change opinions from social platforms to measure public reactions quickly. We investigate how to organize climate change opinions on Twitter into meaningful categories to support perspective summarizing tasks. We find that merely using the available taxonomy for this task is ineffective; hence we must consider the entire text content. We recommend five high-level categories (Root cause, Impact, Mitigation, Politics or Policy, Others) and assemble ClimateTweets, a dataset with category and polarity labels. In addition, we construct category classification and polarity detection tasks with a range of opinion mining baselines. The experimental results show that both tasks are challenging for existing models. We release the ClimateTweets dataset to facilitate investigation in public opinion mining using text content and artificial intelligent methods. We hope this study could pave the way for future studies in the climate change domain. © 2022 IEEE.
KW  - climate change
KW  - opinion mining
KW  - topic modeling
KW  - Artificial intelligence
KW  - Data mining
KW  - Earth (planet)
KW  - Sentiment analysis
KW  - Social aspects
KW  - Category Classification
KW  - Extreme weather events
KW  - Heatwaves
KW  - Impact mitigation
KW  - Opinion mining
KW  - Root cause
KW  - Survey methods
KW  - Text content
KW  - Through the lens
KW  - Topic Modeling
KW  - Global warming
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 16
ER  -

TY  - CONF
AU  - Meyer-Vitali, A.
AU  - Mulder, W.
TI  - Engineering Principles for Building Trusted Human-AI Systems
PY  - 2024
T2  - Lecture Notes in Networks and Systems
VL  - 1066 LNNS
SP  - 468
EP  - 485
DO  - 10.1007/978-3-031-66428-1_30
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201081422&doi=10.1007%2f978-3-031-66428-1_30&partnerID=40&md5=e393c5cdf6be52563b00723dadfbfc25
AB  - In the process engineering reliable and trustworthy AI systems there is significant wisdom to be gained from traditional engineering domains. Extending on earlier work our attention is on topics that stress the principles of building human-AI systems. We plea for a reinforced attention for engineering methods and processes in order to urge the essence for improved scientific progress and industrial AI applications where one can stand on the shoulders of giants. On the one hand, we see their complexity increase on an individual level, as well as on their connected dependency levels, whilst on the other hand, we see a growing lack of experience on the level of their design and engineering. The complexity of current AI models often limits our understanding. The methods and processes to ensure safety, reliability, and transparency are insufficient. This poses serious risks at the level of trustworthiness, particularly when it comes to critical applications with significant social, economic or even physical impact. Future AI systems must adhere to stringent requirements, as mandated, for instance, by the European AI Act, ensuring meticulous design, validation, and certification based on clearly defined criteria. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - Agency
KW  - Agents and multi-agent systems
KW  - Artificial intelligence
KW  - Causality
KW  - Context-aware pervasive systems
KW  - Explainability
KW  - Human computer interaction
KW  - Models
KW  - Modules
KW  - Robustness
KW  - Smart cities
KW  - Software engineering
KW  - Trust
KW  - Intelligent agents
KW  - Multi agent systems
KW  - Robustness (control systems)
KW  - Smart city
KW  - Agency
KW  - Agent and multi-agent system
KW  - AI systems
KW  - Causality
KW  - Context-aware pervasive systems
KW  - Explainability
KW  - Methods and process
KW  - Module
KW  - Robustness
KW  - Trust
KW  - Human computer interaction
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Pezzè, M.
AU  - Abrahão, S.
AU  - Penzenstadler, B.
AU  - Poshyvanyk, D.
AU  - Roychoudhury, A.
AU  - Yue, T.
TI  - A 2030 Roadmap for Software Engineering
PY  - 2025
T2  - ACM Transactions on Software Engineering and Methodology
VL  - 34
IS  - 5
C7  - 118
DO  - 10.1145/3731559
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007514314&doi=10.1145%2f3731559&partnerID=40&md5=55c14db0ae1b0bd608a71c57b85610c0
AB  - The landscape of software engineering has dramatically changed in recent years. The impressive advances of artificial intelligence are just the latest and most disruptive innovation that has remarkably changed the software engineering research and practice. This special issue shares a roadmap to guide the software engineering community in this confused era. This roadmap is the outcome of a 2-day intensive discussion at the 2030 Software Engineering workshop. The roadmap spotlights and discusses seven main landmarks in the new software engineering landscape: artificial intelligence for software engineering, human aspects of software engineering, software security, verification and validation, sustainable software engineering, automatic programming, and quantum software engineering. This editorial summarizes the core aspects discussed in the 37 papers that comprise the seven sections of the special issue and guides the interested readers throughout the issue. This roadmap is a living body that we will refine with follow-up workshops that will update the roadmap for a series of forthcoming ACM TOSEM special issues. © 2025 Copyright held by the owner/author(s).
KW  - A roadmap for software engineering
KW  - AI and software engineering
KW  - AI for verification and validation
KW  - Automatic Programming
KW  - generative AI for software engineering
KW  - Human factor in software engineering
KW  - Large language models for software engineering
KW  - Quantum software engineering
KW  - security and software engineering
KW  - Sustainable software engineering
KW  - Application programs
KW  - Computer aided software engineering
KW  - Computer operating systems
KW  - Computer software maintenance
KW  - Computer software selection and evaluation
KW  - Engineering research
KW  - Human engineering
KW  - Industrial research
KW  - Model checking
KW  - Search engines
KW  - Software packages
KW  - Software prototyping
KW  - Software quality
KW  - Software testing
KW  - Utility programs
KW  - A roadmap for software engineering
KW  - AI and software engineering
KW  - AI for verification and validation
KW  - Generative AI for software engineering
KW  - Human factor in software engineering
KW  - Language model
KW  - Large language model for software engineering
KW  - Quantum software engineering
KW  - Roadmap
KW  - Security and software engineering
KW  - Sustainable softwares
KW  - Verification-and-validation
KW  - Software design
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Kazemeini, A.
AU  - Mehta, Y.
AU  - Cambria, E.
TI  - Multitask learning for emotion and personality traits detection
PY  - 2022
T2  - Neurocomputing
VL  - 493
SP  - 340
EP  - 350
DO  - 10.1016/j.neucom.2022.04.049
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129550717&doi=10.1016%2fj.neucom.2022.04.049&partnerID=40&md5=d9fb3c76293b87f661cd743c16237300
AB  - In recent years, deep learning-based automated personality traits detection has received a lot of attention, especially now, due to the massive digital footprints of an individual. Moreover, many researchers have demonstrated that there is a strong link between personality traits and emotions. In this paper, we build on the known correlation between personality traits and emotional behaviors and propose a novel transferring based multitask learning framework that simultaneously predicts both of them. We also empirically evaluate and discuss different information-sharing mechanisms between the two tasks. To ensure the high quality of the learning process, we adopt a model-agnostic meta-learning-like framework for model optimization. Our computationally efficient multitask learning model achieves the state-of-the-art performance across multiple famous personality and emotion datasets, even outperforming language model-based models. © 2022 Elsevier B.V.
KW  - Emotion detection
KW  - Information sharing gate
KW  - Multitask learning
KW  - Personality traits detection
KW  - Deep learning
KW  - Information dissemination
KW  - Emotion detection
KW  - Emotional behavior
KW  - Emotions and personality
KW  - High quality
KW  - Information sharing
KW  - Information sharing gate
KW  - Information sharing mechanism
KW  - Personality trait detection
KW  - Personality traits
KW  - Strong link
KW  - Agnostic
KW  - article
KW  - emotion
KW  - human
KW  - human experiment
KW  - language
KW  - learning
KW  - personality
KW  - Information analysis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 37
ER  -

TY  - JOUR
AU  - Vatambeti, R.
AU  - Mantena, S.V.
AU  - Kiran, K.V.D.
AU  - Manohar, M.
AU  - Manjunath, C.
TI  - Twitter sentiment analysis on online food services based on elephant herd optimization with hybrid deep learning technique
PY  - 2024
T2  - Cluster Computing
VL  - 27
IS  - 1
SP  - 655
EP  - 671
DO  - 10.1007/s10586-023-03970-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147314813&doi=10.1007%2fs10586-023-03970-7&partnerID=40&md5=7f7c62d98b6fc3a7c357514ebaab4f6c
AB  - Twitter is a social media stage, making it a valuable resource for learning about people’s opinions, feelings, and thoughts. For this reason, experts came up with methods to analyse the tone of tweets and determine whether they were favourable or negative. This article aims to assist businesses, and especially app-based meal delivery businesses, in conducting competitive research on social broadcasting and transforming social broadcasting data into data production for decision-makers. In this analysis, we compared Swiggy, Zomato, and UberEats. Customers’ tweets about all these brands are obtained using R-Studio, and a deep learning-based sentiment examination approach is functional on the retrieved tweets. The pseudo-inverse learning autoencoder is able to provide feature extraction in the form of an analytic solution after pre-processing, without resorting to many iterations. In this research, we suggest framework for combining the Convolutional Neural Network (CNN) and Bi-directional Long Short Term Memory (Bi-LSTM) models. ConvBiLSTM is used, which is a word embedding model that uses numerical values to represent tweets. The CNN layer takes the feature implanting as input and outputs lower features. In this instance, elephant herd optimization is used to fine-tune the Bi-LSTM weights. Among the three firms, the results indicate that Zomato got the most positive feedback (29%), followed by Swiggy (26%), and UberEats (25%). Zomato also had fewer bad reviews than Swiggy and UberEats, with only 11% of users having a poor experience. In addition, tweets were evaluated for unfavourable views against all three meal delivery services, and suggestions for improvement were offered. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.
KW  - Deep learning
KW  - Elephant herd optimization
KW  - Online food service
KW  - Pseudoinverse learning autoencoder
KW  - Swiggy
KW  - Twitter sentiment analysis
KW  - Zomato
KW  - Behavioral research
KW  - Convolutional neural networks
KW  - Decision making
KW  - E-learning
KW  - Learning systems
KW  - Long short-term memory
KW  - Metadata
KW  - Social networking (online)
KW  - Auto encoders
KW  - Deep learning
KW  - Elephant herd optimization
KW  - Foodservices
KW  - Online food service
KW  - Optimisations
KW  - Pseudo-inverses
KW  - Pseudoinverse learning autoencoder
KW  - Sentiment analysis
KW  - Swiggy
KW  - Twitter sentiment analyse
KW  - Zomato
KW  - Sentiment analysis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 36
ER  -

TY  - CONF
AU  - Koopmann, B.
AU  - Trende, A.
AU  - Rothemann, K.
AU  - Feeken, L.
AU  - Suchan, J.
AU  - Johannmeyer, D.
AU  - Bruck, Y.
TI  - Challenges in Achieving Explainability for Cooperative Transportation Systems
PY  - 2022
T2  - Proceedings of the IEEE International Conference on Requirements Engineering
SP  - 114
EP  - 119
DO  - 10.1109/REW56159.2022.00028
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142250289&doi=10.1109%2fREW56159.2022.00028&partnerID=40&md5=794de5278000e85bde262e63010b3ed4
AB  - The anticipated presence of highly automated vehicles and intelligent infrastructure systems in urban traffic will yield new types of demand-driven mobility and value-added services. To provide these services, future transportation systems will consist of large-scale, cooperative ensembles of highly automated and connected systems that operate in mixed traffic and have to interact with human drivers and vulnerable road users while coordinately ensuring traffic efficiency and safety.We posit that the ability to explain processes and decisions is essential for such systems. Adequately addressing the needs of the involved actors will require that explainability and trust-worthiness are handled as core properties in the development of highly automated systems. To support explainability-driven design approaches, we identify a set of explainability challenges in the context of a large-scale ongoing endeavor on cooperative transportation and present approaches to target these challenges. © 2022 IEEE.
KW  - Explainability
KW  - Highly Automated Driving
KW  - Intelligent Transportation Systems
KW  - Trustworthiness
KW  - Automation
KW  - Automated driving
KW  - Automated systems
KW  - Automated vehicles
KW  - Cooperative transportation
KW  - Explainability
KW  - Highly automated driving
KW  - Intelligent transportation systems
KW  - Large-scales
KW  - Transportation system
KW  - Trustworthiness
KW  - Intelligent systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Zhao, Q.
AU  - Zhang, Y.
AU  - Li, X.
TI  - Safe reinforcement learning for dynamical systems using barrier certificates
PY  - 2022
T2  - Connection Science
VL  - 34
IS  - 1
SP  - 2822
EP  - 2844
DO  - 10.1080/09540091.2022.2151567
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143749596&doi=10.1080%2f09540091.2022.2151567&partnerID=40&md5=4acb5cf1cefea6c6f8f5549a24e1086a
AB  - Safety control is a fundamental problem in policy design. Basic reinforcement learning is effective at learning policy with goal-reaching property. However, it does not guarantee safety property of the learned policy. This paper integrates barrier certificates into actor-critic-based reinforcement learning methods in a feedback-driven framework to learn safe policies for dynamical systems. The safe reinforcement learning framework is composed of two interactive parts: Learner and Verifier. Learner trains the policy to satisfy goal-reaching and safety properties. Since the policy is trained on training datasets, the two properties may not be retained on the whole system. Verifier validates the learned policy on the whole system. If the validation fails, Verifier returns the counterexamples to Learner for retraining the policy in the next iteration. We implement a safe policy learning tool SRLBC and evaluate its performance on three control tasks. Experimental results show that SRLBC achieves safety with no more than 0.5× time overhead compared to the baseline reinforcement learning method, showing the feasibility and effectiveness of our framework. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.
KW  - barrier certificates
KW  - dynamical systems
KW  - neural networks
KW  - Safe reinforcement learning
KW  - safety control
KW  - Dynamical systems
KW  - Iterative methods
KW  - Learning systems
KW  - Neural networks
KW  - Safety engineering
KW  - Barrier certificates
KW  - Learning policy
KW  - Neural-networks
KW  - Policy design
KW  - Property
KW  - Reinforcement learning method
KW  - Reinforcement learnings
KW  - Safe reinforcement learning
KW  - Safety controls
KW  - Safety property
KW  - Reinforcement learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Tahir, W.B.
AU  - Khalid, S.
AU  - Almutairi, S.
AU  - Abohashrh, M.
AU  - Memon, S.A.
AU  - Khan, J.
TI  - Depression Detection in Social Media: A Comprehensive Review of Machine Learning and Deep Learning Techniques
PY  - 2025
T2  - IEEE Access
VL  - 13
SP  - 12789
EP  - 12818
DO  - 10.1109/ACCESS.2025.3530862
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215979662&doi=10.1109%2fACCESS.2025.3530862&partnerID=40&md5=86ec10c69092497623f5c65ad4f10b8b
AB  - Depression is a widespread mental health disorder that may remain undiagnosed by conventional clinical methods. The rapidly growing world of social media sites such as Twitter, Reddit, Facebook, Instagram, and Weibo has provided new avenues for depression detection using Machine Learning (ML) as well as Deep Learning (DL), which analyze user behavior patterns and linguistic cues for more accurate detection of depression. Many techniques have been developed for this aim over the years. Identifying relevant publications on this topic using current academic search systems is challenging due to the rapid growth of research publications, unclear or limited search terms, and the complexity of citation networks. Several review papers have been published to ease this task by summarizing the methodologies, key findings, and recommendations for future research. However, most current reviews often do not provide a clear overview of the evolution, latest techniques, and challenges. This paper aims to address that gap by providing a comprehensive review of ML and DL methodologies for detecting depression on social media. We propose a generic architecture for these systems and present a detailed analysis of methodologies and datasets used for evaluation in this field. In addition, we highlight key open research areas, providing a useful starting point for further research and development. By narrowing our focus to social media, this review contributes to advancing the understanding and application of cutting-edge methods for depression detection. While this review highlights advancements in social media-based depression detection, it excludes alternative approaches like graph-based systems and reinforcement learning, and its focus on social media may limit its applicability to other domains.  © 2013 IEEE.
KW  - Deep learning
KW  - depression detection
KW  - machine learning
KW  - natural language processing
KW  - sentiment analysis
KW  - social media
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Federated learning
KW  - Social psychology
KW  - Tweets
KW  - 'current
KW  - Deep learning
KW  - Depression detection
KW  - Language processing
KW  - Learning techniques
KW  - Machine-learning
KW  - Natural language processing
KW  - Natural languages
KW  - Sentiment analysis
KW  - Social media
KW  - Deep reinforcement learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Ma, X.
AU  - Huang, C.
AU  - Huang, X.
AU  - Wu, W.
TI  - Mamba-DQN: Adaptively Tunes Visual SLAM Parameters Based on Historical Observation DQN
PY  - 2025
T2  - Applied Sciences (Switzerland)
VL  - 15
IS  - 6
C7  - 2950
DO  - 10.3390/app15062950
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001012116&doi=10.3390%2fapp15062950&partnerID=40&md5=ddacecd8827025e205f7563343c80e6a
AB  - The parameter configuration of traditional visual SLAM algorithms usually relies on expert experience and extensive experiments, and the parameter configuration needs to be reset as the scene changes, which is a complex and tedious process. To achieve parameter adaptation in visual SLAM, we propose the Mamba-DQN method, which transforms complex parameter adjustment tasks into policy learning assignments for the agent. In this paper, we select the key parameters of visual SLAM to construct the agent action space. The reward function is constructed based on the absolute trajectory error (ATE), and the Mamba history observer is built within the agent to learn the observation trajectory, aiming to improve the quality of the agent’s decisions. Finally, the proposed method was experimented on the EuRoc MAV and TUM-VI datasets. The experimental results show that Mamba-DQN not only enhances the positioning accuracy of visual SLAM and demonstrates good real-time performance but also avoids the tedious parameter adjustment process. © 2025 by the authors.
KW  - historical observer
KW  - Mamba-DQN
KW  - parameter adaptation
KW  - visual SLAM
KW  - History
KW  - SLAM robotics
KW  - Expert experience
KW  - Historical observation
KW  - Historical observer
KW  - Mamba-DQN
KW  - Parameter adaptation
KW  - Parameters adjustment
KW  - Parameters configuration
KW  - Scene change
KW  - SLAM algorithm
KW  - Visual SLAM
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Dunlap, K.
AU  - Mote, M.
AU  - Delsing, K.
AU  - Hobbs, K.L.
TI  - Run Time Assured Reinforcement Learning for Safe Satellite Docking
PY  - 2023
T2  - Journal of Aerospace Information Systems
VL  - 20
IS  - 1
SP  - 25
EP  - 36
DO  - 10.2514/1.I011126
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145970253&doi=10.2514%2f1.I011126&partnerID=40&md5=e55a208542a6eb7f11dd74d4c957c5cc
AB  - Reinforcement learning promises high performance in complex tasks as well as low online storage and computation cost. However, the trial-and-error learning approach of reinforcement learning could explore unsafe behavior in the search for an optimal solution. Run time assurance (RTA) approaches can be applied to monitor behavior and ensure safety constraint satisfaction during reinforcement learning. This paper investigates the effect of RTA on reinforcement learning training performance in terms of training efficiency, safety constraint satisfaction, control efficiency, task efficiency, and training duration. For the purposes of demonstration, a custom reinforcement learning environment is created where the objective is to develop a policy that moves a satellite into docking position with another satellite in a two-dimensional relative-motion reference frame. Six different policies are trained. The first features no RTA, the second features no RTA but a higher penalty for safety violations, and four others use different RTA techniques to enforce a dynamic velocity constraint during training. The trained policies are analyzed with standardized test points. It is shown that the policies trained without RTA do not learn to adhere to the constraint, whereas all policies trained with RTA do learn to adhere to the constraint. Although more complex RTA frameworks can be better for operational use, it is found that a simple RTA framework provides the best overall results for reinforcement learning training. © 2022 by the American Institute of Aeronautics and Astronautics, Inc.
KW  - Computer aided instruction
KW  - Efficiency
KW  - Satellites
KW  - Complex task
KW  - Constraint Satisfaction
KW  - Learn+
KW  - Online computations
KW  - Online storages
KW  - Performance
KW  - Reinforcement learnings
KW  - Runtimes
KW  - Safety constraint
KW  - Storage costs
KW  - Reinforcement learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 17
ER  -

TY  - JOUR
AU  - e Oliveira, E.
AU  - Pereira, M.T.
AU  - Guedes, A.P.
TI  - An analytical framework for evaluating the impact of Artificial Intelligence technologies in supply chains
PY  - 2025
T2  - Supply Chain Analytics
VL  - 11
C7  - 100129
DO  - 10.1016/j.sca.2025.100129
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007813365&doi=10.1016%2fj.sca.2025.100129&partnerID=40&md5=e2bf6639f540a1ee0682ead5faf29bee
AB  - This study introduces a novel framework for analyzing the impact of technologies through their effect and maturity, allowing for a clear presentation of the literature review results. We then conduct a literature review on applying Artificial Intelligence (AI) to Supply Chain (SC), focusing on evaluating the impact of existing technologies. The proposed framework is based on three axes: (1) maturity axis, which evaluates the readiness level of each technology and its current spread of use, (2) effect axis, which measures the disruption it can bring in terms of performance improvement and the number of potential applications, and (3) full axis, which combines the previous two axes. The proposed novel framework allows researchers to look at the existing literature differently. It makes it easier for practitioners to read and understand the impact of such AI technologies on SC. For the literature review that validates the framework, we have analyzed 24 literature review papers and 118 application papers on this topic. We have grouped the application papers into 90 technologies and used the proposed framework to evaluate them. From the analysis and discussion, we confirm some previous conclusions made in the literature as well as discover new gaps, and we suggest research avenues to be explored. © 2025 The Author(s)
KW  - Artificial intelligence
KW  - Disruption potential modeling
KW  - Machine learning
KW  - Performance evaluation
KW  - Supply chain improvement
KW  - Technology maturity assessment
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Sunmola, F.
AU  - Baryannis, G.
TI  - Artificial Intelligence Opportunities for Resilient Supply Chains
PY  - 2024
T2  - IFAC-PapersOnLine
VL  - 58
IS  - 19
SP  - 813
EP  - 818
DO  - 10.1016/j.ifacol.2024.09.195
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208043066&doi=10.1016%2fj.ifacol.2024.09.195&partnerID=40&md5=0828b5da106147b27d1d69e695c11c30
AB  - The need for supply chains to be resilient is increasingly being recognised, following recent disruptions caused by global socioeconomic crises. Supply chain resilience allows for sustainable growth and development through adaptive capabilities, principally including the ability to effectively respond to disruptions to maintain consistent operations. This paper explores the opportunities presented by Artificial Intelligence (AI) in enhancing supply chain resilience. We first conceptualise resilience through a 4-C model: context, capabilities, choices, and contingencies. We then explore a range of AI approaches and develop a research roadmap that attempts to map particular technologies holding potential to the 4-C model.  Copyright © 2024 The Authors.
KW  - artificial intelligence
KW  - explainability
KW  - industry 5.0
KW  - supply chain resilience
KW  - Adaptive capabilities
KW  - C-models
KW  - Consistent operation
KW  - Explainability
KW  - Growth and development
KW  - Industry 5.0
KW  - Model contexts
KW  - Socio-economics
KW  - Supply chain resiliences
KW  - Sustainable growth
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Mao, R.
AU  - Ge, M.
AU  - Han, S.
AU  - Li, W.
AU  - He, K.
AU  - Zhu, L.
AU  - Cambria, E.
TI  - A survey on pragmatic processing techniques
PY  - 2025
T2  - Information Fusion
VL  - 114
C7  - 102712
DO  - 10.1016/j.inffus.2024.102712
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205136260&doi=10.1016%2fj.inffus.2024.102712&partnerID=40&md5=03b96b04b7c6015e69daf94d0b98fe14
AB  - Pragmatics, situated in the domains of linguistics and computational linguistics, explores the influence of context on language interpretation, extending beyond the literal meaning of expressions. It constitutes a fundamental element for natural language understanding in machine intelligence. With the advancement of large language models, the research focus in natural language processing has predominantly shifted toward high-level task processing, inadvertently downplaying the importance of foundational pragmatic processing tasks. Nevertheless, pragmatics serves as a crucial medium for unraveling human language cognition. The exploration of pragmatic processing stands as a pivotal facet in realizing linguistic intelligence. This survey encompasses important pragmatic processing techniques for subjective and emotive tasks, such as personality recognition, sarcasm detection, metaphor understanding, aspect extraction, and sentiment polarity detection. It spans theoretical research, the forefront of pragmatic processing techniques, and downstream applications, aiming to highlight the significance of these low-level tasks in advancing natural language understanding and linguistic intelligence. © 2024 Elsevier B.V.
KW  - Aspect extraction
KW  - Metaphor understanding
KW  - Personality recognition
KW  - Pragmatic processing
KW  - Sarcasm detection
KW  - Sentiment polarity detection
KW  - Natural language processing systems
KW  - Aspect extraction
KW  - Literals
KW  - Machine intelligence
KW  - Metaphor understanding
KW  - Natural language understanding
KW  - Personality recognition
KW  - Pragmatic processing
KW  - Processing technique
KW  - Sarcasm detection
KW  - Sentiment polarity detection
KW  - Computational linguistics
M3  - Short survey
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 8
ER  -

TY  - JOUR
AU  - Sun, X.
AU  - Qi, J.
AU  - Zhu, Z.
AU  - Li, M.
AU  - Pei, H.
AU  - Meng, J.
TI  - SenticNet and Abstract Meaning Representation driven Attention-Gate semantic framework for aspect sentiment triplet extraction
PY  - 2025
T2  - Engineering Applications of Artificial Intelligence
VL  - 139
C7  - 109625
DO  - 10.1016/j.engappai.2024.109625
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208757952&doi=10.1016%2fj.engappai.2024.109625&partnerID=40&md5=6b4f48ca05e1778e5533c4e320260281
AB  - Aspect sentiment triplet extraction aims to analyze aspect-level sentiment in the form of triplets, including extracting aspect-opinion pairs and predicting the sentiment polarities of these pairs. Many recent works rely on syntactic information (e.g. part-of-speech and syntactic dependency relation) to handle this semantic task, which ignores uncommon part-of-speech items and matches semantically unrelated words. To overcome these drawbacks, we propose a SenticNet and Abstract Meaning Representation (AMR) driven Attention-Gate semantic framework (SAAG), which introduces semantic sentiment knowledge SenticNet and semantic structure AMR as semantic information to replace syntactic information. To highlight the affective meanings in words, an affective-driven attention mechanism is designed to emphasizes sentiment intent within word representations. To match semantically related words, the designed AMR-driven gate mechanism balances the word pair expressions under varying semantic contexts. Extensive experiments on two public datasets demonstrate the effectiveness of our approach. © 2024 Elsevier Ltd
KW  - Affective commonsense knowledge
KW  - Aspect sentiment triplet extraction
KW  - Aspect-based sentiment analysis
KW  - Sentiment analysis
KW  - Semantics
KW  - Affective commonsense knowledge
KW  - Aspect sentiment triplet extraction
KW  - Aspect-based sentiment analyze
KW  - Commonsense knowledge
KW  - Part Of Speech
KW  - Semantics framework
KW  - Sentiment analysis
KW  - Syntactic dependencies
KW  - Syntactic information
KW  - Latent semantic analysis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Eappen, J.
AU  - Xiong, Z.
AU  - Patel, D.
AU  - Bera, A.
AU  - Jagannathan, S.
TI  - Scaling Safe Multi-Agent Control for Signal Temporal Logic Specifications
PY  - 2024
T2  - Proceedings of Machine Learning Research
VL  - 270
SP  - 3516
EP  - 3535
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000763532&partnerID=40&md5=8554dbd8834abe225d0b21a75941761c
AB  - Existing methods for safe multi-agent control using logic specifications like Signal Temporal Logic (STL) often face scalability issues. This is because they rely either on single-agent perspectives or on Mixed Integer Linear Programming (MILP)-based planners, which are complex to optimize. These methods have proven to be computationally expensive and inefficient when dealing with a large number of agents. To address these limitations, we present a new scalable approach to multi-agent control in this setting. Our method treats the relationships between agents using a graph structure rather than in terms of a single-agent perspective. Moreover, it combines a multi-agent collision avoidance controller with a Graph Neural Network (GNN) based planner, models the system in a decentralized fashion, and trains on STL-based objectives to generate safe and efficient plans for multiple agents, thereby optimizing the satisfaction of complex temporal specifications while also facilitating multi-agent collision avoidance. Our experiments show that our approach significantly outperforms existing methods that use a state-of-the-art MILP-based planner in terms of scalability and performance. © 2024 Proceedings of Machine Learning Research.
KW  - Collision Avoidance
KW  - Deep Learning Methods
KW  - Multi-Robot Systems
KW  - Path Planning for Multiple Mobile Robots
KW  - Specification-Guided Learning
KW  - Deep learning
KW  - Industrial robots
KW  - Integer linear programming
KW  - Integer programming
KW  - Intelligent robots
KW  - Mixed-integer linear programming
KW  - Mobile robots
KW  - Motion planning
KW  - Multipurpose robots
KW  - Robot applications
KW  - Robot learning
KW  - Robot programming
KW  - Temporal logic
KW  - Collisions avoidance
KW  - Deep learning method
KW  - Learning methods
KW  - Mixed integer linear
KW  - Multi-robot systems
KW  - Multiagent control
KW  - Multiple mobile robot
KW  - Path planning for multiple mobile robot
KW  - Single-agent
KW  - Specification-guided learning
KW  - Graph neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Ge, Y.
AU  - Tang, Y.
AU  - Xu, J.
AU  - Gokmen, C.
AU  - Li, C.
AU  - Ai, W.
AU  - Martinez, B.J.
AU  - Aydin, A.
AU  - Anvari, M.
AU  - Chakravarthy, A.K.
AU  - Yu, H.-X.
AU  - Wong, J.
AU  - Srivastava, S.
AU  - Lee, S.
AU  - Zha, S.
AU  - Itti, L.
AU  - Li, Y.
AU  - Martin-Martin, R.
AU  - Liu, M.
AU  - Zhang, P.
AU  - Zhang, R.
AU  - Fei-Fei, L.
AU  - Wu, J.
TI  - BEHAVIOR Vision Suite: Customizable Dataset Generation via Simulation
PY  - 2024
T2  - Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition
SP  - 22401
EP  - 22412
DO  - 10.1109/CVPR52733.2024.02114
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211768399&doi=10.1109%2fCVPR52733.2024.02114&partnerID=40&md5=6da9f722649bd0999ecbce266e4a3ed5
AB  - The systematic evaluation and understanding of computer vision models under varying conditions require large amounts of data with comprehensive and customized labels, which real-world vision datasets rarely satisfy. While current synthetic data generators offer a promising alternative, particularly for embodied AI tasks, they often fall short for computer vision tasks due to low asset and rendering quality, limited diversity, and unrealistic physical properties. We introduce the BEHAVIOR Vision Suite (BVS), a set of tools and assets to generate fully customized synthetic data for systematic evaluation of computer vision models, based on the newly developed embodied AI benchmark, BEHAVIOR-1 K. BVS supports a large number of adjustable parameters at the scene level (e.g., lighting, object placement), the object level (e.g., joint configuration, attributes such as 'filled' and 'folded'), and the camera level (e.g., field of view, focal length). Researchers can arbitrarily vary these parameters during data generation to perform controlled experiments. We showcase three example application scenarios: systematically evaluating the robustness of models across different continuous axes of domain shift, evaluating scene understanding models on the same set of images, and training and evaluating simulation-to-real transfer for a novel vision task: unary and binary state prediction. Project website: https://behavior-vision-suite.github.io/ © 2024 IEEE.
KW  - benchmarking
KW  - embodied AI
KW  - simulation
KW  - synthetic data generation
KW  - Condition
KW  - Customizable
KW  - Embodied AI
KW  - Large amounts of data
KW  - Real-world
KW  - Simulation
KW  - Synthetic data
KW  - Synthetic data generations
KW  - Systematic evaluation
KW  - Vision model
KW  - Digital elevation model
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - JOUR
AU  - Albattah, W.
AU  - Habib, S.
AU  - Alsharekh, M.F.
AU  - Islam, M.
AU  - Albahli, S.
AU  - Dewi, D.A.
TI  - An Overview of the Current Challenges, Trends, and Protocols in the Field of Vehicular Communication
PY  - 2022
T2  - Electronics (Switzerland)
VL  - 11
IS  - 21
C7  - 3581
DO  - 10.3390/electronics11213581
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141676308&doi=10.3390%2felectronics11213581&partnerID=40&md5=fe1a913d3c58579eeec72cc92ca32b3c
AB  - Intelligent transportation systems (ITS) provides a safe and reliable means of transferring data between vehicles. The document describes the transmission systems, protocols, networks, taxonomy, and applications of Intelligent Systems. Detailed analysis of the existing transmission flow systems is required, including classification, standards, coverage, applications, as well as their advantages and disadvantages. The adaptability of transmission networks, such as ad hoc, hybrid, mobile ad hoc networks (MANET), and Vehicular ad hoc networks (VANETs), has a significant advantage. Described protocols for a variety of communication types, including routing techniques, platforms, structures, and the use of information areas as well. The use of intelligent technology can determine reliable, comfortable, safe, and trustworthy vehicular communication. This paper analyzes the current vehicular communication (VC) research flow and their deployments with indicated areas where further development is necessary. This paper examines how emerging technologies in the upcoming markets will enable the development of high-featured VC technologies. The challenges of improving upon existing VC systems in the development of future systems are discussed in this paper, including medium selection, link and service quality, security, channel characteristics, and mobility. The purpose of this study is to identify the need for the development of improved VC technologies, networks, and protocols for a wide range of applications in the future. © 2022 by the authors.
KW  - intelligent technologies and applications
KW  - networking and taxonomy
KW  - protocols
KW  - vehicular communication
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 18
ER  -

TY  - JOUR
AU  - Ali, A.
AU  - Khan, R.M.I.
AU  - Manzoor, D.
AU  - Mateen, M.A.
AU  - Khan, M.A.
TI  - AI-Powered e-Learning: Innovations, Challenges, and the Future of Education
PY  - 2025
T2  - International Journal of Information and Education Technology
VL  - 15
IS  - 5
SP  - 882
EP  - 890
DO  - 10.18178/ijiet.2025.15.5.2294
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006675852&doi=10.18178%2fijiet.2025.15.5.2294&partnerID=40&md5=fa1eaa21081bb4a3d81b78435564881a
AB  - The present study explores the transformative impact of Artificial Intelligence (AI) on e-learning and its implications for the future of education. It explores recent revolutions in AI-powered educational technologies, such as adaptive learning systems, intelligent tutoring systems, and personalized learning platforms. The study discourses how these advancements increase student engagement, improve learning outcomes, and provide tailored educational experiences. Additionally, it addresses the challenges associated with implementing AI in education, including data privacy concerns, the digital divide, and the need for educator training. Systematic secondary research approach was implemented to gather the data related to the topic of present study. The potential of AI to revolutionize assessment methods, curriculum design, and administrative tasks in educational institutions is also considered. Finally, the study anticipates the future trajectory of AI in education, sightseeing its potential to create more comprehensive, well-organized, and effective learning environments while admitting the importance of sustaining a balance between technological revolution and human-centered pedagogics. © 2025 by the authors.
KW  - Artificial Intelligence (AI)
KW  - e-learning
KW  - education
KW  - machine learning
KW  - Natural Language Processing (NLP)
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Ji, S.
AU  - Zhang, T.
AU  - Ansari, L.
AU  - Fu, J.
AU  - Tiwari, P.
AU  - Cambria, E.
TI  - MentalBERT: Publicly Available Pretrained Language Models for Mental Healthcare
PY  - 2022
T2  - 2022 Language Resources and Evaluation Conference, LREC 2022
SP  - 7184
EP  - 7190
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143699303&partnerID=40&md5=2a656718ff5375288b1375f52e8773af
AB  - Mental health is a critical issue in modern society, and mental disorders could sometimes turn to suicidal ideation without adequate treatment. Early detection of mental disorders and suicidal ideation from social content provides a potential way for effective social intervention. Recent advances in pretrained contextualized language representations have promoted the development of several domain-specific pretrained models and facilitated several downstream applications. However, there are no existing pretrained language models for mental healthcare. This paper trains and releases two pretrained masked language models, i.e., MentalBERT and MentalRoBERTa, to benefit machine learning for the mental healthcare research community. Besides, we evaluate our trained domain-specific models and several variants of pretrained language models on several mental disorder detection benchmarks and demonstrate that language representations pretrained in the target domain improve the performance of mental health detection tasks. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.
KW  - Mental Healthcare
KW  - MentalBERT
KW  - Pretrained Language Models
KW  - Computational linguistics
KW  - Economic and social effects
KW  - Health care
KW  - Critical issues
KW  - Domain specific
KW  - Language model
KW  - Mental disorders
KW  - Mental health
KW  - Mental healthcare
KW  - Mentalbert
KW  - Pretrained language model
KW  - Social contents
KW  - Suicidal ideation
KW  - Benchmarking
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 116
ER  -

TY  - CONF
AU  - Tian, H.
AU  - Hamedmoghadam, H.
AU  - Shorten, R.
AU  - Ferraro, P.
TI  - Reinforcement Learning with Adaptive Regularization for Safe Control of Critical Systems
PY  - 2024
T2  - Advances in Neural Information Processing Systems
VL  - 37
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000498757&partnerID=40&md5=d3ebc9a9172bdcbbae75ee1b34539add
AB  - Reinforcement Learning (RL) is a powerful method for controlling dynamic systems, but its learning mechanism can lead to unpredictable actions that undermine the safety of critical systems. Here, we propose RL with Adaptive Regularization (RL-AR), an algorithm that enables safe RL exploration by combining the RL policy with a policy regularizer that hard-codes the safety constraints. RL-AR performs policy combination via a “focus module,” which determines the appropriate combination depending on the state-relying more on the safe policy regularizer for less-exploited states while allowing unbiased convergence for well-exploited states. In a series of critical control applications, we demonstrate that RL-AR not only ensures safety during training but also achieves a return competitive with the standards of model-free RL that disregards safety. © 2024 Neural information processing systems foundation. All rights reserved.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Lloret, E.
AU  - Barreiro, A.
AU  - Bhatt, M.
AU  - Bugarín-Diz, A.
AU  - Modoni, G.E.
AU  - Silberztein, M.
AU  - Calixto, I.
AU  - Korvel, G.
AU  - Diamantaras, K.
AU  - Katsalis, A.
AU  - Turuta, O.
AU  - Russo, I.
AU  - Erdem, A.
TI  - Multi3Generation: Multitask, Multilingual, and Multimodal Language Generation
PY  - 2023
T2  - Open Research Europe
VL  - 3
C7  - 176
DO  - 10.12688/openreseurope.16307.1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180942557&doi=10.12688%2fopenreseurope.16307.1&partnerID=40&md5=86d9c63f5b98b2fe60aadface06b5d97
AB  - The purpose of this article is to highlight the critical importance of language generation today. In particular, language generation is explored from the following three aspects: multi-modality, multilinguality, and multitask, which all of them play crucial role for Natural Language Generation (NLG) community. We present the activities conducted within the Multi3Generation COST Action (CA18231), as well as current trends and future perspectives for multitask, multilingual and multimodal language generation. Copyright: © 2023 Lloret E et al.
KW  - Language Technologies
KW  - Multi-task
KW  - Multi3Generation
KW  - Multilinguality
KW  - Multimodality
KW  - Natural Language Generation
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Shams Khoozani, Z.
AU  - Sabri, A.Q.M.
AU  - Seng, W.C.
AU  - Seera, M.
AU  - Eg, K.Y.
TI  - Navigating the landscape of concept-supported XAI: Challenges, innovations, and future directions
PY  - 2024
T2  - Multimedia Tools and Applications
VL  - 83
IS  - 25
SP  - 67147
EP  - 67197
DO  - 10.1007/s11042-023-17666-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182636559&doi=10.1007%2fs11042-023-17666-y&partnerID=40&md5=a342d95e2f0c7af6dd3e141e9da157ae
AB  - This comprehensive review of concept-supported interpretation methods in Explainable Artificial Intelligence (XAI) navigates the multifaceted landscape. As machine learning models become more complex, there is a greater need for interpretation methods that deconstruct their decision-making processes. Traditional interpretation techniques frequently emphasise lower-level attributes, resulting in a schism between complex algorithms and human cognition. To bridge this gap, our research focuses on concept-supported XAI, a new line of research in XAI that emphasises higher-level attributes or 'concepts' that are more aligned with end-user understanding and needs. We provide a thorough examination of over twenty-five seminal works, highlighting their respective strengths and weaknesses. A comprehensive list of available concept datasets, as opposed to training datasets, is presented, along with a discussion of sufficiency metrics and the importance of robust evaluation methods. In addition, we identify six key factors that influence the efficacy of concept-supported interpretation: network architecture, network settings, training protocols, concept datasets, the presence of confounding attributes, and standardised evaluation methodology. We also investigate the robustness of these concept-supported methods, emphasising their potential to significantly advance the field by addressing issues like misgeneralization, information overload, trustworthiness, effective human-AI communication, and ethical concerns. The paper concludes with an exploration of open challenges such as the development of automatic concept discovery methods, strategies for expert-AI integration, optimising primary and concept model settings, managing confounding attributes, and designing efficient evaluation processes. © The Author(s) 2024.
KW  - Concept-Supported XAI
KW  - Ethical AI
KW  - Evaluation Methodology
KW  - Explainable AI
KW  - Human-AI Interaction
KW  - Human-Centred XAI
KW  - Interpretation Methods
KW  - Neural Networks
KW  - Artificial intelligence
KW  - Decision making
KW  - Network architecture
KW  - Philosophical aspects
KW  - Concept-supported XAI
KW  - Decision-making process
KW  - Ethical AI
KW  - Evaluation methodologies
KW  - Explainable AI
KW  - Human-AI interaction
KW  - Human-centered XAI
KW  - Interpretation methods
KW  - Machine learning models
KW  - Neural-networks
KW  - Complex networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - JOUR
AU  - Yin, X.
AU  - Gao, B.
AU  - Yu, X.
TI  - Formal synthesis of controllers for safety-critical autonomous systems: Developments and challenges
PY  - 2024
T2  - Annual Reviews in Control
VL  - 57
C7  - 100940
DO  - 10.1016/j.arcontrol.2024.100940
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187231056&doi=10.1016%2fj.arcontrol.2024.100940&partnerID=40&md5=a054628e73f07aee9590ba766bc27857
AB  - In recent years, formal methods have been extensively used in the design of autonomous systems. By employing mathematically rigorous techniques, formal methods can provide fully automated reasoning processes with provable safety guarantees for complex dynamic systems with intricate interactions between continuous dynamics and discrete logics. This paper provides a comprehensive review of formal controller synthesis techniques for safety-critical autonomous systems. Specifically, we categorize the formal control synthesis problem based on diverse system models, encompassing deterministic, non-deterministic, and stochastic, and various formal safety-critical specifications involving logic, real-time, and real-valued domains. The review covers fundamental formal control synthesis techniques, including abstraction-based approaches and abstraction-free methods. We explore the integration of data-driven synthesis approaches in formal control synthesis. Furthermore, we review formal techniques tailored for multi-agent systems (MAS), with a specific focus on various approaches to address the scalability challenges in large-scale systems. Finally, we discuss some recent trends and highlight research challenges in this area. © 2024 Elsevier Ltd
KW  - Autonomous systems
KW  - Correct-by-construction synthesis
KW  - Formal methods
KW  - Safety critical
KW  - Abstracting
KW  - Controllers
KW  - Formal methods
KW  - Large scale systems
KW  - Model checking
KW  - Multi agent systems
KW  - Safety engineering
KW  - Stochastic control systems
KW  - Stochastic models
KW  - Autonomous system
KW  - Control synthesis
KW  - Correct-by-construction
KW  - Correct-by-construction synthesis
KW  - Deterministics
KW  - Formal controls
KW  - Formal synthesis
KW  - Safety critical
KW  - Synthesis techniques
KW  - System development
KW  - Stochastic systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 10
ER  -

TY  - JOUR
AU  - Nicholson, D.N.
AU  - Greene, C.S.
TI  - Constructing knowledge graphs and their biomedical applications
PY  - 2020
T2  - Computational and Structural Biotechnology Journal
VL  - 18
SP  - 1414
EP  - 1428
DO  - 10.1016/j.csbj.2020.05.017
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086821857&doi=10.1016%2fj.csbj.2020.05.017&partnerID=40&md5=cf41004bac64861d82081bda407c1506
AB  - Knowledge graphs can support many biomedical applications. These graphs represent biomedical concepts and relationships in the form of nodes and edges. In this review, we discuss how these graphs are constructed and applied with a particular focus on how machine learning approaches are changing these processes. Biomedical knowledge graphs have often been constructed by integrating databases that were populated by experts via manual curation, but we are now seeing a more robust use of automated systems. A number of techniques are used to represent knowledge graphs, but often machine learning methods are used to construct a low-dimensional representation that can support many different applications. This representation is designed to preserve a knowledge graph's local and/or global structure. Additional machine learning methods can be applied to this representation to make predictions within genomic, pharmaceutical, and clinical domains. We frame our discussion first around knowledge graph construction and then around unifying representational learning techniques and unifying applications. Advances in machine learning for biomedicine are creating new opportunities across many domains, and we note potential avenues for future work with knowledge graphs that appear particularly promising. © 2020 The Author(s)
KW  - knowledge graphs
KW  - Lterature review
KW  - Machine learning
KW  - Natural language processing
KW  - Network embeddings
KW  - Text mining
KW  - Embeddings
KW  - Graphic methods
KW  - Machine learning
KW  - Medical applications
KW  - Natural language processing systems
KW  - Biomedical applications
KW  - Knowledge graphs
KW  - Language processing
KW  - Lterature review
KW  - Machine learning methods
KW  - Machine-learning
KW  - Natural language processing
KW  - Natural languages
KW  - Network embedding
KW  - Text-mining
KW  - biomedicine
KW  - embedding
KW  - human
KW  - machine learning
KW  - mining
KW  - natural language processing
KW  - prediction
KW  - review
KW  - Knowledge graph
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 177
ER  -

TY  - JOUR
AU  - Wu, T.
AU  - Zheng, H.
AU  - Zheng, G.
AU  - Huo, T.
AU  - Han, S.
TI  - Do we empathize humanoid robots and humans in the same way? Behavioral and multimodal brain imaging investigations
PY  - 2024
T2  - Cerebral Cortex
VL  - 34
IS  - 6
C7  - bhae248
DO  - 10.1093/cercor/bhae248
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196458858&doi=10.1093%2fcercor%2fbhae248&partnerID=40&md5=755a49526abf3117f9e73992cf5b7434
AB  - Humanoid robots have been designed to look more and more like humans to meet social demands. How do people empathize humanoid robots who look the same as but are essentially different from humans? We addressed this issue by examining subjective feelings, electrophysiological activities, and functional magnetic resonance imaging signals during perception of pain and neutral expressions of faces that were recognized as patients or humanoid robots. We found that healthy adults reported deceased feelings of understanding and sharing of humanoid robots' compared to patients' pain. Moreover, humanoid robot (vs. patient) identities reduced long-latency electrophysiological responses and blood oxygenation level-dependent signals in the left temporoparietal junction in response to pain (vs. neutral) expressions. Furthermore, we showed evidence that humanoid robot identities inhibited a causal input from the right ventral lateral prefrontal cortex to the left temporoparietal junction, contrasting the opposite effect produced by patient identities. These results suggest a neural model of modulations of empathy by humanoid robot identity through interactions between the cognitive and affective empathy networks, which provides a neurocognitive basis for understanding human-robot interactions. © 2024 The Author(s). Published by Oxford University Press. All rights reserved.
KW  - EEG
KW  - empathy
KW  - fMRI
KW  - human-humanoid robot
KW  - ventral lateral prefrontal cortex
KW  - Adult
KW  - Brain
KW  - Brain Mapping
KW  - Electroencephalography
KW  - Empathy
KW  - Facial Expression
KW  - Female
KW  - Humans
KW  - Magnetic Resonance Imaging
KW  - Male
KW  - Multimodal Imaging
KW  - Pain
KW  - Robotics
KW  - Young Adult
KW  - adult
KW  - Article
KW  - BOLD signal
KW  - brain electrophysiology
KW  - Chinese
KW  - controlled study
KW  - electroencephalogram
KW  - electrooculogram
KW  - empathy
KW  - eyelid reflex
KW  - facial expression
KW  - female
KW  - functional magnetic resonance imaging
KW  - hemodynamics
KW  - human
KW  - human experiment
KW  - lateral prefrontal cortex
KW  - male
KW  - memory
KW  - nerve potential
KW  - neuroimaging
KW  - normal human
KW  - pain
KW  - sex difference
KW  - supplementary motor area
KW  - temporoparietal junction
KW  - young adult
KW  - brain
KW  - brain mapping
KW  - diagnostic imaging
KW  - electroencephalography
KW  - facial expression
KW  - multimodal imaging
KW  - nuclear magnetic resonance imaging
KW  - pathophysiology
KW  - physiology
KW  - procedures
KW  - psychology
KW  - robotics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Zhao, Z.
AU  - Cheng, S.
AU  - Ding, Y.
AU  - Zhou, Z.
AU  - Zhang, S.
AU  - Xu, D.
AU  - Zhao, Y.
TI  - A Survey of Optimization-Based Task and Motion Planning: From Classical to Learning Approaches
PY  - 2024
T2  - IEEE/ASME Transactions on Mechatronics
DO  - 10.1109/TMECH.2024.3452509
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205769654&doi=10.1109%2fTMECH.2024.3452509&partnerID=40&md5=d7c1ad64e652b010d03c81c925c0652d
AB  - Task and motion planning (TAMP) integrates high-level task planning and low-level motion planning to equip robots with the autonomy to effectively reason over long-horizon, dynamic tasks. Optimization-based TAMP focuses on hybrid optimization approaches that define goal conditions via objective functions and are capable of handling open-ended goals, robotic dynamics, and physical interaction between the robot and the environment. Therefore, optimization-based TAMP is particularly suited to solve highly complex, contact-rich locomotion and manipulation problems. This survey provides a comprehensive review on optimization-based TAMP, covering first, planning domain representations, including action description languages and temporal logic, second, individual solution strategies for components of TAMP, including AI planning and trajectory optimization (TO), and finally, the dynamic interplay between logic-based task planning and model-based TO. A particular focus of this survey is to highlight the algorithm structures to efficiently solve TAMP, especially hierarchical and distributed approaches. In addition, the survey emphasizes the synergy between the classical methods and contemporary learning-based innovations, such as large language models. Furthermore, the future research directions for TAMP is discussed in this survey, highlighting both algorithmic and application-specific challenges. © 1996-2012 IEEE.
KW  - AI planning
KW  - large language models (LLMs)
KW  - robot learning
KW  - task and motion planning (TAMP)
KW  - temporal logic
KW  - trajectory optimization (TO)
KW  - Algorithmic languages
KW  - Motion planning
KW  - Robot learning
KW  - Robot programming
KW  - AI planning
KW  - Language model
KW  - Large language model
KW  - Learning approach
KW  - Motion-planning
KW  - Optimisations
KW  - Task and motion planning
KW  - Task planning
KW  - Trajectory optimization
KW  - Temporal logic
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Barnett, A.J.
AU  - Nguyen, M.
AU  - Spargo, J.
AU  - Yadav, R.
AU  - Cohn-Sheehy, B.I.
AU  - Ranganath, C.
TI  - Hippocampal-cortical interactions during event boundaries support retention of complex narrative events
PY  - 2024
T2  - Neuron
VL  - 112
IS  - 2
SP  - 319
EP  - 330.e7
DO  - 10.1016/j.neuron.2023.10.010
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178240931&doi=10.1016%2fj.neuron.2023.10.010&partnerID=40&md5=ebc522a5eeae5a287136d78b209c1325
AB  - According to most memory theories, encoding involves continuous communication between the hippocampus and neocortex, but recent work has shown that key moments at the end of an event, called event boundaries, may be especially critical for memory formation. We sought to determine how communication between the hippocampus and neocortical regions during the encoding of naturalistic events related to subsequent retrieval of those events and whether this was particularly important at event boundaries. Participants encoded and recalled two cartoon movies during fMRI scanning. Higher functional connectivity between the hippocampus and the posterior medial network (PMN) at an event's offset is related to the subsequent successful recall of that event. Furthermore, hippocampal-PMN offset connectivity also predicted the amount of detail retrieved after a 2-day delay. These data demonstrate that the relationship between memory encoding and hippocampal-neocortical interaction is dynamic and biased toward boundaries. © 2023 Elsevier Inc.
KW  - default mode network
KW  - episodic memory
KW  - event cognition
KW  - fMRI
KW  - functional connectivity
KW  - hippocampus
KW  - naturalistic
KW  - Brain Mapping
KW  - Communication
KW  - Hippocampus
KW  - Humans
KW  - Magnetic Resonance Imaging
KW  - Memory, Episodic
KW  - Mental Recall
KW  - Neocortex
KW  - adult
KW  - Article
KW  - connectome
KW  - electroencephalogram
KW  - experience
KW  - female
KW  - functional connectivity
KW  - functional magnetic resonance imaging
KW  - hippocampus
KW  - human
KW  - human experiment
KW  - male
KW  - medial temporal lobe
KW  - memory consolidation
KW  - neocortex
KW  - normal human
KW  - recall
KW  - brain mapping
KW  - diagnostic imaging
KW  - episodic memory
KW  - hippocampus
KW  - interpersonal communication
KW  - nuclear magnetic resonance imaging
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 11
ER  -

TY  - JOUR
AU  - Sahu, S.
AU  - Kumar, R.
AU  - Mohdshafi, P.
AU  - Shafi, J.
AU  - Kim, S.
AU  - Ijaz, M.F.
TI  - A Hybrid Recommendation System of Upcoming Movies Using Sentiment Analysis of YouTube Trailer Reviews
PY  - 2022
T2  - Mathematics
VL  - 10
IS  - 9
C7  - 1568
DO  - 10.3390/math10091568
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130186083&doi=10.3390%2fmath10091568&partnerID=40&md5=c1b836b21fc78c5e50d3753f9febe20e
AB  - Movies are one of the integral components of our everyday entertainment. In today’s world, people prefer to watch movies on their personal devices. Many movies are available on all popular Over the Top (OTT) platforms. Multiple new movies are released onto these platforms every day. The recommendation system is beneficial for guiding the user to a choice from among the overloaded contents. Most of the research on these recommendation systems has been conducted based on existing movies. We need a recommendation system for forthcoming movies in order to help viewers make a personalized decision regarding which upcoming new movies to watch. In this article, we have proposed a framework combining sentiment analysis and a hybrid recommendation system for recommending movies that are not yet released, but the trailer has been released. In the first module, we extracted comments about the movie trailer from the official YouTube channel for Netflix, computed the overall sentiment, and predicted the rating of the upcoming movies. Next, in the second module, our proposed hybrid recommendation system produced a list of preferred upcoming movies for individual users. In the third module, we finally were able to offer recommendations regarding potentially popular forthcoming movies to the user, according to their personal preferences. This method fuses the predicted rating and preferred list of upcoming movies from modules one and two. This study used publicly available data from The Movie Database (TMDb). We also created a dataset of new movies by randomly selecting a list of one hundred movies released between 2020 and 2021 on Netflix. Our experimental results established that the predicted rating of unreleased movies had the lowest error. Additionally, we showed that the proposed hybrid recommendation system recommends movies according to the user’s preferences and potentially promising forthcoming movies. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.
KW  - hybrid recommendation system
KW  - OTT platform
KW  - predicted rating
KW  - recommendation system
KW  - sentiment analysis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 31
ER  -

TY  - JOUR
AU  - Grieve, J.
AU  - Bartl, S.
AU  - Fuoli, M.
AU  - Grafmiller, J.
AU  - Huang, W.
AU  - Jawerbaum, A.
AU  - Murakami, A.
AU  - Perlman, M.
AU  - Roemling, D.
AU  - Winter, B.
TI  - The sociolinguistic foundations of language modeling
PY  - 2024
T2  - Frontiers in Artificial Intelligence
VL  - 7
C7  - 1472411
DO  - 10.3389/frai.2024.1472411
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216260820&doi=10.3389%2ffrai.2024.1472411&partnerID=40&md5=8616aa4429e6ab2e8751c736cfa29ecc
AB  - In this article, we introduce a sociolinguistic perspective on language modeling. We claim that language models in general are inherently modeling varieties of language, and we consider how this insight can inform the development and deployment of language models. We begin by presenting a technical definition of the concept of a variety of language as developed in sociolinguistics. We then discuss how this perspective could help us better understand five basic challenges in language modeling: social bias, domain adaptation, alignment, language change, and scale. We argue that to maximize the performance and societal value of language models it is important to carefully compile training corpora that accurately represent the specific varieties of language being modeled, drawing on theories, methods, and descriptions from the field of sociolinguistics. Copyright © 2025 Grieve, Bartl, Fuoli, Grafmiller, Huang, Jawerbaum, Murakami, Perlman, Roemling and Winter.
KW  - AI ethics
KW  - artificial intelligence
KW  - computational sociolinguistics
KW  - corpus linguistics
KW  - large language models
KW  - natural language processing
KW  - varieties of language
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Papadimitriou, O.
AU  - Kanavos, A.
AU  - Vonitsanos, G.
AU  - Maragoudakis, M.
AU  - Karkazis, P.
AU  - Mylonas, P.
TI  - Enhancing Emotion Classification with a Hybrid BERT and CNN Architecture
PY  - 2024
T2  - Proceedings - 2024 19th International Workshop on Semantic and Social Media Adaptation and Personalization, SMAP 2024
SP  - 156
EP  - 161
DO  - 10.1109/SMAP63474.2024.00037
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218428050&doi=10.1109%2fSMAP63474.2024.00037&partnerID=40&md5=d37ba33602cee1a7a1eef4846c16aa90
AB  - In computational linguistics, effectively encoding and systematizing emotional expressions in language is a significant challenge. Existing machine learning (ML) models for text analysis often only recognize primary emotional states such as anger, happiness, and sadness, missing the more nuanced spectrum of human emotions. These models frequently overlook the complex semantic interplays and fail to capture the full diversity of emotional expressions, focusing instead on simplistic categorization. This paper proposes a robust ML framework that enhances emotion classification by discriminating among nuanced emotion categories - Anger, Joy, and Fear. Leveraging a sophisticated combination of Convolutional Neural Networks (CNNs) and the Bidirectional Encoder Representations from Transformers (BERT) architecture, our framework demonstrates exceptional accuracy in emotion detection. Evaluating a diverse dataset of text samples, each meticulously tagged with its expressed emotion, confirms the model's superior performance in recognizing and classifying a broad range of emotional states.  © 2024 IEEE.
KW  - Computational Linguistics
KW  - Data Analysis
KW  - Emotion Classification
KW  - Machine Learning
KW  - Social Media Text Analysis
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Emotion Recognition
KW  - Network coding
KW  - Semantics
KW  - Convolutional neural network
KW  - Emotion classification
KW  - Emotional expressions
KW  - Emotional state
KW  - Encodings
KW  - Machine-learning
KW  - Neural network architecture
KW  - Social media
KW  - Social medium text analyze
KW  - Text analysis
KW  - Convolutional neural networks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Sbai, Z.
TI  - Model checking deep neural networks: opportunities and challenges
PY  - 2025
T2  - Frontiers in Computer Science
VL  - 7
C7  - 1557977
DO  - 10.3389/fcomp.2025.1557977
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004473713&doi=10.3389%2ffcomp.2025.1557977&partnerID=40&md5=4d24c2e141de0fb84ed30cf108447730
AB  - Deep neural networks (DNNs) are extensively used in both current and future manufacturing, transportation, and healthcare sectors. The widespread use of neural networks in highly safety-critical applications has made it necessary to prevent catastrophic issues from arising during prediction processes. In fact, misreading a traffic sign by an autonomous car or performing an incorrect analysis of medical records could put human lives in danger. With this awareness, the number of studies related to deep neural network verification has increased dramatically in recent years. In particular, formal guarantees regarding the behavior of a DNN under particular settings are provided by model checking, which is crucial in safety-critical applications where network output errors could have disastrous effects. Model checking is an effective approach for confirming that neural networks perform as planned by comparing them to clearly stated qualities. This paper aims to highlight the critical need for and present challenges associated with using model-checking verification techniques to verify deep neural networks before relying on them in real-world applications. It examines state-of-the-art research and draws the most prominent future directions in the model checking of neural networks. Copyright © 2025 Sbai.
KW  - consistency
KW  - deep neural network
KW  - formal models
KW  - model checking
KW  - robustness
KW  - safety
KW  - specification
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Krakowski, S.
TI  - Human-AI agency in the age of generative AI
PY  - 2025
T2  - Information and Organization
VL  - 35
IS  - 1
C7  - 100560
DO  - 10.1016/j.infoandorg.2025.100560
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219252757&doi=10.1016%2fj.infoandorg.2025.100560&partnerID=40&md5=201fd21e548dc6a5e20f52599ff8798c
AB  - The rapid emergence of generative artificial intelligence (GenAI) is profoundly transforming the nature of work and organizations, challenging prevalent views of AI as primarily enabling prediction and optimization. This paper argues that GenAI represents a qualitative shift that necessitates a fundamental reassessment of AI's role in management and organizations. By identifying and analyzing four critical dimensions [sbnd] (i) GenAI's broad applicability as a general-purpose technology; (ii) its ability to catalyze exploratory and combinatorial innovation; (iii) its capacity to enhance cognitive diversity and decision-making; and (iv) its democratizing effect on AI adoption and value creation [sbnd] the paper highlights GenAI's potential to augment and scale human creativity, learning, and innovation. Building on insights from the AI and management literature, as well as on theory of human-AI agency, the paper develops a novel perspective that challenges the dominant efficiency-oriented narrative. It proposes that a human-complementary approach to GenAI development and implementation, leveraging it as a generative catalyst for exploration, can enable radically increased creativity, innovation, and growth. GenAI's democratizing aspects can amplify these mechanisms, promoting widely shared growth when combined with appropriate policy and managerial choices. Implications for theory, practice, and future research directions are discussed, drawing attention to the need for approaches in GenAI development and deployment that are complementary rather than competitive to human beings. The paper concludes by discussing the theoretical, practical, and policy implications of this transformative technology. It outlines future research directions, emphasizing the critical role of human agency in determining the organizational, societal, and ethical outcomes associated with AI adoption and implementation. © 2025 The Author
KW  - Augmentation
KW  - Automation
KW  - Generative artificial intelligence
KW  - Human-AI agency
KW  - Innovation management
KW  - Machine learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Garg, S.
AU  - Parikh, S.
AU  - Garg, S.
TI  - Navigating Healthcare Insights: A Bird s Eye View of Explainability with Knowledge Graphs
PY  - 2023
T2  - Proceedings - 2023 IEEE 6th International Conference on Artificial Intelligence and Knowledge Engineering, AIKE 2023
SP  - 54
EP  - 61
DO  - 10.1109/AIKE59827.2023.00016
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183596638&doi=10.1109%2fAIKE59827.2023.00016&partnerID=40&md5=e5663ff0ff1a40feae2a32aa93a7020c
AB  - Knowledge graphs (KGs) are gaining prominence in Healthcare AI, especially in drug discovery and pharmaceutical research as they provide a structured way to integrate diverse information sources, enhancing AI system interpretability. This interpretability is crucial in healthcare, where trust and transparency matter, and eXplainable AI (XAI) supports decisionmaking for healthcare professionals. This overview summarizes recent literature on the impact of KGs in healthcare and their role in developing explainable AI models. We cover KG workflow, including construction, relationship extraction, reasoning, and their applications in areas like Drug-Drug Interactions (DDI), Drug Target Interactions (DTI), Drug Development (DD), Adverse Drug Reactions (ADR), and bioinformatics. We emphasize the importance of making KGs more interpretable through knowledge-infused learning in healthcare. Finally, we highlight research challenges and provide insights for future directions.  © 2023 IEEE.
KW  - AI Healthcare
KW  - Drug Discovery
KW  - eXplainable AI (XAI)
KW  - Interpretability
KW  - Knowledge Graphs
KW  - Knowledge-infused learning (K-iL)
KW  - Drug interactions
KW  - Health care
KW  - AI healthcare
KW  - AI systems
KW  - Drug discovery
KW  - Drug discovery researches
KW  - Explainable AI (XAI)
KW  - Information sources
KW  - Interpretability
KW  - Knowledge graphs
KW  - Knowledge-infused learning
KW  - Pharmaceutical research
KW  - Knowledge graph
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Thakkar, A.
AU  - Mungra, D.
AU  - Agrawal, A.
AU  - Chaudhari, K.
TI  - Improving the Performance of Sentiment Analysis Using Enhanced Preprocessing Technique and Artificial Neural Network
PY  - 2022
T2  - IEEE Transactions on Affective Computing
VL  - 13
IS  - 4
SP  - 1771
EP  - 1782
DO  - 10.1109/TAFFC.2022.3206891
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139444976&doi=10.1109%2fTAFFC.2022.3206891&partnerID=40&md5=29ef7f881dfa754e14323acd6418fd97
AB  - With the presence of a massive amount of digitally recorded data, an automated computation can be preferable over the manual approach to evaluate sentiments within given textual fragments. Artificial neural network (ANN) is preferred for sentiment analysis (SA) because of its learning ability and adaptive nature towards diverse data. Handling negation in SA is a challenging task, and to address the same, we propose a specific order of preprocessing (PPR) steps to enhance the performance of SA using ANN. Typically, ANN weights are randomly initialized (R-ANN), which may not give the desired performance. As a potential solution, we propose a novel approach named Matching features with output label based Advanced Technique (MAT) to initialize the ANN weights (MAT-ANN). Simulation results conclude the superiority of the proposed approach PPR+MAT-ANN compared to the existing approach EPR+R-ANN i.e., integrating existing preprocessing (EPR) steps with R-ANN. Moreover, PPR+MAT-ANN architecture is significantly simpler than the existing deep learning-based approach named the NeuroSent tool and gives better performance when evaluated upon the Dranziera protocol.  © 2010-2012 IEEE.
KW  - Artificial neural network
KW  - bernoulli naÃ¯ve bayes
KW  - convolutional neural network
KW  - dranziera
KW  - linear support vector classifier
KW  - logistic regression
KW  - neurosent
KW  - order of preprocessing
KW  - sentiment analysis
KW  - weight initialization
KW  - Data handling
KW  - Deep learning
KW  - Job analysis
KW  - Motion pictures
KW  - Network architecture
KW  - Sentiment analysis
KW  - Support vector machines
KW  - Bernoulli
KW  - Bernoulli naive baye
KW  - Convolutional neural network
KW  - Dranziera
KW  - Features extraction
KW  - Linear support vector classifier
KW  - Logistics regressions
KW  - Naive bayes
KW  - Neurosend
KW  - Order of preprocessing
KW  - Sentiment analysis
KW  - Social networking (online)
KW  - Support vector classifiers
KW  - Support vectors machine
KW  - Task analysis
KW  - Weight initialization
KW  - Neural networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 26
ER  -

TY  - JOUR
AU  - Almeman, K.
AU  - EL Ayeb, F.
AU  - Berrima, M.
AU  - Issaoui, B.
AU  - Morsy, H.
TI  - The Integration of AI and Metaverse in Education: A Systematic Literature Review
PY  - 2025
T2  - Applied Sciences (Switzerland)
VL  - 15
IS  - 2
C7  - 863
DO  - 10.3390/app15020863
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215804434&doi=10.3390%2fapp15020863&partnerID=40&md5=4c9d504099898d1ca5f30e43e035cbab
AB  - The use of the metaverse in educational environments has grown significantly in recent years, particularly following the shift of major tech companies towards virtual worlds and immersive technologies. Virtual reality and augmented reality technologies are employed to construct immersive learning environments. The metaverse is generally understood as a vast digital ecosystem or virtual space, facilitating the transition of individuals from physical to virtual environments, and is applicable to educational domains where practical experiments are challenging or fraught with risks, such as space exploration, chemical experimentation, and flight simulation training. In addition, the integration of artificial intelligence with the metaverse within educational contexts has significantly enriched the learning environment, giving rise to AI-driven teaching systems tailored to each student’s individual pace and learning modalities. As a result, a number of research articles have been conducted to explore the applications of the metaverse and artificial intelligence in education. This paper provides a systematic literature review following the PRISMA methodology to analyze and investigate the significance and impact of the metaverse in education, with a specific focus on the integration of AI with the metaverse. We address inquiries regarding the applications, challenges, academic disciplines, and effects of integrating AI and the metaverse in education that have not yet been explored in most research articles. Additionally, we study the AI techniques used in the metaverse in education and their roles. The review affirms that the integration of the metaverse in education, with the utilization of AI applications, will enrich education by improving students’ understanding and comprehension across diverse academic disciplines. © 2025 by the authors.
KW  - artificial intelligence
KW  - chatbot
KW  - education
KW  - machine learning
KW  - metaverse
KW  - NLP
KW  - Adversarial machine learning
KW  - Augmented reality
KW  - Contrastive Learning
KW  - Digital elevation model
KW  - Flight simulators
KW  - Space research
KW  - Space simulators
KW  - Students
KW  - Teaching
KW  - Virtual reality
KW  - Augmented reality technology
KW  - Chatbots
KW  - Educational environment
KW  - Immersive learning
KW  - Immersive technologies
KW  - Learning environments
KW  - Machine-learning
KW  - Metaverses
KW  - Systematic literature review
KW  - Virtual worlds
KW  - Virtual environments
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - JOUR
AU  - Wang, K.
AU  - Shen, T.
AU  - Wei, J.
AU  - Liu, J.
AU  - Hu, W.
TI  - An intelligent framework for deriving formulas of aerodynamic forces between high-rise buildings under interference effects using symbolic regression algorithms
PY  - 2025
T2  - Journal of Building Engineering
VL  - 99
C7  - 111614
DO  - 10.1016/j.jobe.2024.111614
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212923350&doi=10.1016%2fj.jobe.2024.111614&partnerID=40&md5=c5c686cc360992e00cd674914b52d66c
AB  - Numerous high-rise buildings in megacities create complex interference effects, significantly impacting aerodynamic forces and leading to severe wind-induced disasters. While current machine learning applications predominantly use black-box models with SHapley Additive exPlanations (SHAP) to study these effects, they fall short in providing explicit formulas for practical engineering use. This study pioneers an intelligent framework designed to derive explicit formulas for evaluating interference effects on high-rise buildings. The framework utilizes multiple symbolic regression algorithms based on genetic programming to generate these formulas, which are then evaluated for accuracy and complexity. Sensitivity and physical trend analyses were performed on the most accurate expressions. In addition, a combination of Extreme Gradient Boosting (XGBoost) and SHAP was used to verify the consistency of the results. The study found that the Offspring Selection Genetic Programming (OS-GP) symbolic regression model excelled in both accuracy and complexity. Sensitivity analysis confirmed the influence of contributing factors on aerodynamic forces, consistent with the results from XGBoost and SHAP, thus further validating the accuracy and interpretability of the OS-GP model. Physical trend analysis revealed that formulas derived from OS-GP align more closely with wind tunnel results compared to those obtained from XGBoost. Overall, the proposed symbolic regression expressions offer significant advantages for engineering applications due to their simplicity and high accuracy, providing valuable guidance for wind-resistant design and urban planning. © 2024 Elsevier Ltd
KW  - Genetic programming
KW  - High-rise buildings
KW  - Interference effects
KW  - Machine learning
KW  - Sensitivity analysis
KW  - Symbolic regression
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Genetic programming
KW  - Regression analysis
KW  - Tall buildings
KW  - Wind tunnels
KW  - Aerodynamic forces
KW  - Explicit formula
KW  - High rise building
KW  - Interference effects
KW  - Machine-learning
KW  - Regression algorithms
KW  - Sensitivity analyzes
KW  - Shapley
KW  - Symbolic regression
KW  - Trend analysis
KW  - Sensitivity analysis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Arora, S.
AU  - Thota, S.R.
AU  - Gupta, S.
TI  - Artificial Intelligence-Driven Big Data Analytics for Business Intelligence in SaaS Products
PY  - 2024
T2  - 1st International Conference on Pioneering Developments in Computer Science and Digital Technologies, IC2SDT 2024 - Proceedings
SP  - 164
EP  - 169
DO  - 10.1109/IC2SDT62152.2024.10696409
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207086828&doi=10.1109%2fIC2SDT62152.2024.10696409&partnerID=40&md5=db9e07eaaa516a06fe2400bd03aab52a
AB  - The prevalence and gravity of data-related issues facing modern businesses have propelled the field of business intelligence and analytics (BI&A) to the forefront of academic and professional discourse. A paradigm change is occurring in the way businesses make decisions and prepare for the future, and this paper explores AI and data analytics are changing the face of BI. An aim of the study was to look at BI from every angle, particularly how it has changed with the addition of AI and sophisticated data analytics, and to see where these technologies are headed in the corporate world. The combined use of BI, AI, and BDA in SaaS products is the topic of this review. It describes big data analytics, lists its essential elements, and talks about how it relates to business intelligence. The review examines AI trends in BI, examines successful sector-specific applications, suggests a Big Data Analytics Service-Oriented Architecture (BASOA), and examines SaaS adoption in BI. Further research areas encompass the AI frameworks, optimising the scalability and performance of business intelligence applications built on SaaS platforms. © 2024 IEEE.
KW  - artificial intelligence (AI)
KW  - BASOA
KW  - Big Data Analytics (BDA)
KW  - Business intelligence (BI)
KW  - Machine learning
KW  - NLP
KW  - Software as a Service (SaaS)
KW  - Artificial intelligence
KW  - Big data analytic
KW  - Big data analytic service-oriented architecture
KW  - Business intelligence
KW  - Business-intelligence
KW  - Data analytics
KW  - Machine-learning
KW  - Soa (serviceoriented architecture)
KW  - Software as a service (saa)
KW  - Software-as-a- Service (SaaS)
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Navigli, R.
AU  - Bevilacqua, M.
AU  - Conia, S.
AU  - Montagnini, D.
AU  - Cecconi, F.
TI  - Ten Years of BabelNet: A Survey
PY  - 2021
T2  - IJCAI International Joint Conference on Artificial Intelligence
SP  - 4559
EP  - 4567
DO  - 10.24963/ijcai.2021/620
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125494425&doi=10.24963%2fijcai.2021%2f620&partnerID=40&md5=51c35ed19bddf85fb61fc964fe4ac3c6
AB  - The intelligent manipulation of symbolic knowledge has been a long-sought goal of AI. However, when it comes to Natural Language Processing (NLP), symbols have to be mapped to words and phrases, which are not only ambiguous but also language-specific: multilinguality is indeed a desirable property for NLP systems, and one which enables the generalization of tasks where multiple languages need to be dealt with, without translating text. In this paper we survey BabelNet, a popular wide-coverage lexical-semantic knowledge resource obtained by merging heterogeneous sources into a unified semantic network that helps to scale tasks and applications to hundreds of languages. Over its ten years of existence, thanks to its promise to interconnect languages and resources in structured form, BabelNet has been employed in countless ways and directions. We first introduce the BabelNet model, its components and statistics, and then overview its successful use in a wide range of tasks in NLP as well as in other fields of AI. © 2021 International Joint Conferences on Artificial Intelligence. All rights reserved.
KW  - Natural language processing systems
KW  - Semantics
KW  - Surveys
KW  - Generalisation
KW  - Intelligent manipulation
KW  - Language processing
KW  - Lexical semantics
KW  - Multilinguality
KW  - Multiple languages
KW  - Natural languages
KW  - Property
KW  - Semantics knowledge
KW  - Symbolic knowledge
KW  - Artificial intelligence
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 57
ER  -

TY  - JOUR
AU  - Hassan, M.
AU  - Zhang, H.
AU  - Fateh, A.A.
AU  - Ma, S.
AU  - Liang, W.
AU  - Shang, D.
AU  - Deng, J.
AU  - Zhang, Z.
AU  - Lam, T.K.
AU  - Xu, M.
AU  - Huang, Q.
AU  - Yu, D.
AU  - Zhang, C.
AU  - You, Z.
AU  - Pang, W.
AU  - Yang, C.
AU  - Qin, P.
TI  - Retinal disease projection conditioning by biological traits
PY  - 2024
T2  - Complex and Intelligent Systems
VL  - 10
IS  - 1
SP  - 257
EP  - 271
DO  - 10.1007/s40747-023-01141-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165126717&doi=10.1007%2fs40747-023-01141-0&partnerID=40&md5=3c3ad67228d3744ed2e62ac76953ed57
AB  - Fundus image captures rear of an eye which has been studied for disease identification, classification, segmentation, generation, and biological traits association using handcrafted, conventional, and deep learning methods. In biological traits estimation, most of the studies have been carried out for the age prediction and gender classification with convincing results. The current study utilizes the cutting-edge deep learning (DL) algorithms to estimate biological traits in terms of age and gender together with associating traits to retinal visuals. For the trait’s association, we embed aging as the label information into the proposed DL model to learn knowledge about the effected regions with aging. Our proposed DL models named FAG-Net and FGC-Net, which correspondingly estimates biological traits (age and gender) and generates fundus images. FAG-Net can generate multiple variants of an input fundus image given a list of ages as conditions. In this study, we analyzed fundus images and their corresponding association in terms of aging and gender. Our proposed models outperform randomly selected state-of-the-art DL models. © The Author(s) 2023.
KW  - Age
KW  - Aging effects
KW  - Biological traits
KW  - FAG-Net
KW  - FGC-Net
KW  - Fundus images
KW  - GAN
KW  - Gender
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Fu, B.
AU  - Chen, T.
AU  - Xu, F.
AU  - Zhu, L.
AU  - Li, B.
AU  - Xue, X.
TI  - Circuit Boards Anomaly Detection Based on Background-Foreground Compositional Modeling
ST  - 基于背景-前景组成式建模的电路板异常检测
PY  - 2025
T2  - Jisuanji Yanjiu yu Fazhan/Computer Research and Development
VL  - 62
IS  - 1
SP  - 144
EP  - 159
DO  - 10.7544/issn1000-1239.202330565
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215401359&doi=10.7544%2fissn1000-1239.202330565&partnerID=40&md5=265b9b361cda2a2904ff082aeef893e9
AB  - Anomaly detection aims to detect abnormal samples among many normal samples. In the era of big data, how to apply anomaly detection to real-world scenarios has become one of the most critical problems to consider. Currently, the existing models can hardly cope with dynamic interference such as occlusion, lighting, and color difference in real-world scenarios and cannot quickly migrate application scenarios. We propose a deep learning model based on background-foreground modeling for anomaly detection tasks. Our model first reconstructs the input image into a clean background image without abnormal objects through the feature extraction network and preserves the possible dynamic interference of the image through skip-connection. After obtaining the reconstructed background, this model extracts the position information of abnormal objects through the spatial transformation network, uses an autoencoder to extract latent space representations of the appearance, shape, and presence information of abnormal objects, and reconstructs them. Finally, this model combines the reconstructed abnormal objects and the background image to obtain an overall reconstructed image and realizes anomaly detection by setting a threshold for the presence information of abnormal objects. To validate the effectiveness of the method, we collect data from a real circuit board assembly environment and simulate a scenario with limited annotations in actual production, resulting in the creation of a foreign object in circuit board (FO-CB) dataset for analysis. Additionally, we also conduct experimental validation on the foreign object debris in airport (FOD-A) dataset. The experimental results show that our proposed method performs well on the synthetic dataset and detects all anomalous objects in 9 actual scene data, with a miss rate of down to 0%, and can be applied to real-world circuit board assembly scenarios. © 2025 Science Press. All rights reserved.
KW  - anomaly detection
KW  - compositional modeling
KW  - generative model
KW  - multi-stage training
KW  - synthetic dataset
KW  - Anomaly detection
KW  - Deep learning
KW  - Image analysis
KW  - Image annotation
KW  - Anomaly detection
KW  - Background image
KW  - Circuit boards
KW  - Compositional models
KW  - Generative model
KW  - Multi-stage training
KW  - Multi-stages
KW  - Presence information
KW  - Real-world scenario
KW  - Synthetic datasets
KW  - Image reconstruction
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Safron, A.
AU  - Çatal, O.
AU  - Verbelen, T.
TI  - Generalized Simultaneous Localization and Mapping (G-SLAM) as unification framework for natural and artificial intelligences: towards reverse engineering the hippocampal/entorhinal system and principles of high-level cognition
PY  - 2022
T2  - Frontiers in Systems Neuroscience
VL  - 16
C7  - 787659
DO  - 10.3389/fnsys.2022.787659
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140956675&doi=10.3389%2ffnsys.2022.787659&partnerID=40&md5=fbf8795bf052c8a3abe97fae4761c1a1
AB  - Simultaneous localization and mapping (SLAM) represents a fundamental problem for autonomous embodied systems, for which the hippocampal/entorhinal system (H/E-S) has been optimized over the course of evolution. We have developed a biologically-inspired SLAM architecture based on latent variable generative modeling within the Free Energy Principle and Active Inference (FEP-AI) framework, which affords flexible navigation and planning in mobile robots. We have primarily focused on attempting to reverse engineer H/E-S “design” properties, but here we consider ways in which SLAM principles from robotics may help us better understand nervous systems and emergent minds. After reviewing LatentSLAM and notable features of this control architecture, we consider how the H/E-S may realize these functional properties not only for physical navigation, but also with respect to high-level cognition understood as generalized simultaneous localization and mapping (G-SLAM). We focus on loop-closure, graph-relaxation, and node duplication as particularly impactful architectural features, suggesting these computational phenomena may contribute to understanding cognitive insight (as proto-causal-inference), accommodation (as integration into existing schemas), and assimilation (as category formation). All these operations can similarly be describable in terms of structure/category learning on multiple levels of abstraction. However, here we adopt an ecological rationality perspective, framing H/E-S functions as orchestrating SLAM processes within both concrete and abstract hypothesis spaces. In this navigation/search process, adaptive cognitive equilibration between assimilation and accommodation involves balancing tradeoffs between exploration and exploitation; this dynamic equilibrium may be near optimally realized in FEP-AI, wherein control systems governed by expected free energy objective functions naturally balance model simplicity and accuracy. With respect to structure learning, such a balance would involve constructing models and categories that are neither too inclusive nor exclusive. We propose these (generalized) SLAM phenomena may represent some of the most impactful sources of variation in cognition both within and between individuals, suggesting that modulators of H/E-S functioning may potentially illuminate their adaptive significances as fundamental cybernetic control parameters. Finally, we discuss how understanding H/E-S contributions to G-SLAM may provide a unifying framework for high-level cognition and its potential realization in artificial intelligences. Copyright © 2022 Safron, Çatal and Verbelen.
KW  - active inference
KW  - artificial intelligence
KW  - free energy principle
KW  - hierarchical generative models
KW  - hippocampal and entorhinal systems
KW  - robotics
KW  - SLAM
KW  - adult
KW  - article
KW  - artificial intelligence
KW  - cognition
KW  - control system
KW  - exploration exploitation tradeoff
KW  - female
KW  - hippocampus
KW  - human
KW  - human experiment
KW  - learning
KW  - leisure
KW  - male
KW  - reverse engineering
KW  - robotics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 11
ER  -

TY  - BOOK
AU  - Tamò-Larrieux, A.
AU  - Guitton, C.
AU  - Mayer, S.
TI  - AI and law: How automation is changing the law
PY  - 2025
T2  - AI and Law: How Automation is Changing the Law
SP  - 1
EP  - 194
DO  - 10.1201/9781003386919
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215353387&doi=10.1201%2f9781003386919&partnerID=40&md5=c01bb93abddc45bffd456a16ffce65bc
AB  - This book provides insights into how AI is changing legal practice, government processes, and individuals' access to those processes, encouraging each of us to consider how technological advances are changing the legal system. Particularly, and distinct from current debates on how to regulate AI, this books focuses on how the progressive merger between computational methods and legal rules changes the very structure and application of the law itself. We investigate how automation is changing the legal analysis, legal rulemaking, legal rule extraction, and application of legal rules and how this impacts individuals, policymakers, civil servants, and society at large. We show through many examples that a debate on how automation is changing the law is needed, which must revolve around the democratic legitimacy of the automation of legal processes, and be informed by the technical feasibility and tradeoffs of specific endeavors. © 2025 Aurelia Tamò-Larrieux, Clement Guitton, and Simon Mayer. All rights reserved.
M3  - Book
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Camilleri, M.A.
TI  - Metaverse applications in education: a systematic review and a cost-benefit analysis
PY  - 2024
T2  - Interactive Technology and Smart Education
VL  - 21
IS  - 2
SP  - 245
EP  - 269
DO  - 10.1108/ITSE-01-2023-0017
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161510328&doi=10.1108%2fITSE-01-2023-0017&partnerID=40&md5=e3be033531fa9912390488ecd8ac82a9
AB  - Purpose: Many educators are increasingly acquainting themselves and becoming adept with interactive technologies like augmented reality and virtual reality. Some of them are also looking forward to using Metaverse applications, as they want to benefit from its immersive three-dimensional capabilities. Therefore, the purpose of this study is to critically review the extant literature to investigate how, why, where and when the Metaverse can be used for educational purposes. This study also discusses opportunities, challenges and risks related to this disruptive technology. Design/methodology/approach: A Preferred Reporting Items for Systematic Reviews and Meta-Analyses rigorous protocol is used to search, extract, scrutinize and synthesize content from high-impact articles focused on the use of the Metaverse technology in the realms of education. Afterwards, this study theorizes on the costs and benefits of using this interactive technology with students. Findings: A number of researchers are already experimenting with virtual technologies that are very similar to the Metaverse, in different contexts. This research indicates that most students are lured by immersive multi-sensory three-dimensional environments as well as by virtual reality applications that could simulate real-life situations and provide engaging experiences with virtual representations of people, places and objects. On the other hand, this study reveals that educators ought to consider the potential pitfalls of the Metaverse, including privacy breaches and security risks, as well as possible addictions and the development of mental health issues, among others. Practical implications: Students and educators can use the Metaverse to catapult themselves in a simulated digital universe that could reconfigure their sensory inputs, definitions of space, time and points of access to information. This research calls for the development of regulatory instruments, including sound principles, guidelines and procedures that are intended to safeguard and protect Metaverse users. Originality/value: This contribution implies that there is scope for educators to continue developing the Metaverse’s virtual spaces to improve their students’ motivations, aptitudes and learning outcomes. This study clarifies that the use of the Metaverse in education can create infinite possibilities to enhance their knowledge, competences and abilities through its immersive applications. Yet this paper also raises awareness about possible challenges in the short term as well on other risks associated to the prolonged use of this captivating technology. © 2023, Emerald Publishing Limited.
KW  - Augmented reality
KW  - Education
KW  - Immersive technologies
KW  - Learning
KW  - Metaverse
KW  - Virtual reality
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 39
ER  -

TY  - CONF
AU  - Mlodzian, L.
AU  - Sun, Z.
AU  - Berkemeyer, H.
AU  - Monka, S.
AU  - Wang, Z.
AU  - Dietze, S.
AU  - Halilaj, L.
AU  - Luettin, J.
TI  - nuScenes Knowledge Graph - A comprehensive semantic representation of traffic scenes for trajectory prediction
PY  - 2023
T2  - Proceedings - 2023 IEEE/CVF International Conference on Computer Vision Workshops, ICCVW 2023
SP  - 42
EP  - 52
DO  - 10.1109/ICCVW60793.2023.00011
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182932239&doi=10.1109%2fICCVW60793.2023.00011&partnerID=40&md5=a479c1c7bbd5cdf6b6afae9d24ea0488
AB  - Trajectory prediction in traffic scenes involves accurately forecasting the behaviour of surrounding vehicles. To achieve this objective it is crucial to consider contextual information, including the driving path of vehicles, road topology, lane dividers, and traffic rules. Although studies demonstrated the potential of leveraging heterogeneous context for improving trajectory prediction, state-of-the-art deep learning approaches still rely on a limited subset of this information. This is mainly due to the limited availability of comprehensive representations. This paper presents an approach that utilizes knowledge graphs to model the diverse entities and their semantic connections within traffic scenes. Further, we present nuScenes Knowledge Graph (nSKG), a knowledge graph for the nuScenes dataset, that models explicitly all scene participants and road elements, as well as their semantic and spatial relationships. To facilitate the usage of the nSKG via graph neural networks for trajectory prediction, we provide the data in a format, ready-to-use by the PyGlibrary. All artefacts can be found here: https://tinyurl.com/5t2vv9yu. © 2023 IEEE.
KW  - Deep learning
KW  - Forecasting
KW  - Graph neural networks
KW  - Roads and streets
KW  - Semantics
KW  - Trajectories
KW  - Contextual information
KW  - Driving paths
KW  - Knowledge graphs
KW  - Learning approach
KW  - Road elements
KW  - Semantic representation
KW  - State of the art
KW  - Traffic rules
KW  - Traffic scene
KW  - Trajectory prediction
KW  - Knowledge graph
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Odriozola-Olalde, H.
AU  - Zamalloa, M.
AU  - Arana-Arexolaleiba, N.
AU  - Perez-Cerrolaza, J.
TI  - Towards robust shielded reinforcement learning through adaptive constraints and exploration: The fear field framework
PY  - 2025
T2  - Engineering Applications of Artificial Intelligence
VL  - 144
C7  - 110055
DO  - 10.1016/j.engappai.2025.110055
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215439921&doi=10.1016%2fj.engappai.2025.110055&partnerID=40&md5=a685fffbe1dec6ebad5eb18b88e4f915
AB  - Machine Learning (ML) techniques, including Reinforcement Learning (RL), demonstrate potential as decision-making controllers. However, enhancing the robustness required for real-world deployment remains imperative. Within the realm of Safe RL, Shielded RL emerges as a solution, employing shields to block actions leading to unsafe states and offering safe alternatives through known policies. Yet, many Shielded RL methods rely on dynamic environment models, which may inaccurately predict future states, compromising controller robustness. We introduce the Fear Field framework to mitigate this issue for discrete Markov Decision Process-based (MDP) shields with strictly connected unsafe state spaces and fully observable states, which adjusts safe operation constraints based on disparities between model predictions and actual environmental dynamics. We employ parallel learning and Curriculum Learning (CL) strategies to mitigate lengthy training times in high state-space size environments. Additionally, an adaptive exploration algorithm enhances convergence rates amidst significant environmental dynamic shifts. In our case study, integrating CL and the adaptive exploration algorithm with the Fear Field framework reduces unsafe state occurrences by two orders of magnitude while enhancing convergence time following sudden environmental changes. The Fear Field framework significantly reduces unsafe states in the Frozen Lake Gridworld environment at low computational expense when model predictions deviate from reality, with negligible costs otherwise. © 2025
KW  - Adaptive exploration
KW  - Curriculum learning
KW  - Fear Field
KW  - Robustness
KW  - Safety constraints
KW  - Shielded reinforcement learning
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Curricula
KW  - Markov processes
KW  - Robustness (control systems)
KW  - Adaptive explorations
KW  - Curriculum learning
KW  - Environmental dynamics
KW  - Fear field
KW  - Model prediction
KW  - Reinforcement learnings
KW  - Robustness
KW  - Safety constraint
KW  - Shielded reinforcement learning
KW  - State-space
KW  - Reinforcement learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Olszewski, D.
AU  - Lu, A.
AU  - Stillman, C.
AU  - Warren, K.
AU  - Kitroser, C.
AU  - Pascual, A.
AU  - Ukirde, D.
AU  - Butler, K.
AU  - Traynor, P.
TI  - "Get in Researchers; We're Measuring Reproducibility": A Reproducibility Study of Machine Learning Papers in Tier 1 Security Conferences
PY  - 2021
T2  - CCS 2023 - Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security
SP  - 3433
EP  - 3459
DO  - 10.1145/3576915.3623130
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179843040&doi=10.1145%2f3576915.3623130&partnerID=40&md5=a231c9a58a429612acfacf57df3c2757
AB  - Reproducibility is crucial to the advancement of science; it strengthens confidence in seemingly contradictory results and expands the boundaries of known discoveries. Computer Security has the natural benefit of creating artifacts that should facilitate computational reproducibility, the ability for others to use someone else's code and data to independently recreate results, in a relatively straightforward fashion. While the Security community has recently increased its attention on reproducibility, an independent and comprehensive measurement of the current state of reproducibility has not been conducted. In this paper, we perform the first such study, targeting reproducible artifacts generated specifically by papers on machine learning security (one of the most popular areas in academic research) published in Tier 1 security conferences over the past ten years (2013-2022). We perform our measurement study of indirect and direct reproducibility over nearly 750 papers, their codebases, and datasets. Our analysis shows that there is no statistically significant difference between the availability of artifacts before and after the introduction of Artifact Evaluation Committees in Tier 1 conferences. However, based on three years of results, artifacts that pass through this process work at a higher rate than those that do not. From our collected findings, we offer data-driven suggestions for improving reproducibility in our community, including five common problems observed in our study. In so doing, we demonstrate that significant progress still needs to be made in computational reproducibility in Computer Security research. © 2023 Copyright held by the owner/author(s).
KW  - machine learning
KW  - meta-science
KW  - reproducibility
KW  - security
KW  - Security of data
KW  - Security systems
KW  - 'current
KW  - Comprehensive measurement
KW  - Computational reproducibility
KW  - Independent measurement
KW  - Machine-learning
KW  - Measurements of
KW  - Meta-science
KW  - Reproducibilities
KW  - Security
KW  - Security community
KW  - Machine learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 8
ER  -

TY  - JOUR
AU  - Feng, X.
AU  - Wang, X.
AU  - Su, Y.
TI  - An analysis of the current status of metaverse research based on bibliometrics
PY  - 2024
T2  - Library Hi Tech
VL  - 42
IS  - 1
SP  - 284
EP  - 308
DO  - 10.1108/LHT-10-2022-0467
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143809256&doi=10.1108%2fLHT-10-2022-0467&partnerID=40&md5=ddc72e0189ffda067edfcb5e04a2ccf9
AB  - Purpose: The rise of the metaverse has brought profound changes to the economic and social operation models and injected new vitality into academic research. Although a large number of studies have emerged, there are few quantitative analyses of development frontiers and trends. Design/methodology/approach: From a bibliometric perspective, this paper selects 183 pieces of metaverse-related literature in the WoS core database since 2000 as the object of analysis. This paper sums up the characteristics of the literature using the methods of descriptive statistical analysis, keywords analysis, thematic evolution analysis and summarizes the core themes and the laws of metaverse development in each stage. Findings: The digital economy vision brought by the metaverse has led to an increasing number of researchers and achievements in this field. But the depth and breadth of research are still insufficient and unevenly distributed in the region, and the cross-fertilization fields need to be expanded. From the industry's point of view, VR games represented by Second Life and My World have contributed to the popularity of the metaverse. As technology progresses, the research hotspots in the field of metaverse gradually develop from conceptual research to artificial intelligence, blockchain, NFT and other technical applications. However, academic research has not yet caught up with the industry's pace and stays more in the concept discussion and preliminary application stage. Originality/value: A systematic overview of the current status, knowledge structure and hot issues of metaverse research is shown, which provides a thematic axis for this field, enriches and improves the quantitative analysis of its literature and provides a clear picture for researchers to continuously promote the development of this field. At the same time, it is necessary to warn that technological development is a double-edged sword. The process of metaverse development should return to rationality, respect the laws of its development and guarantee the healthy development of the metaverse by strengthening legal regulation and the ethical review of science and technology. © 2022, Emerald Publishing Limited.
KW  - Bibliometrics
KW  - Knowledge graph
KW  - Metaverse
KW  - Research status
KW  - Theme evolution
KW  - Virtual world
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 36
ER  -

TY  - CONF
AU  - Cao, C.
AU  - Fu, Y.
AU  - Xu, S.
AU  - Zhang, R.
AU  - Li, S.
TI  - ENHANCING HUMAN-AI COLLABORATION THROUGH LOGIC-GUIDED REASONING
PY  - 2024
T2  - 12th International Conference on Learning Representations, ICLR 2024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196871357&partnerID=40&md5=e2e4c6936a0ed0a834345deb825a7ea0
AB  - We present a systematic framework designed to enhance human-robot perception and collaboration through the integration of logical rules and Theory of Mind (ToM). Logical rules provide interpretable predictions and generalize well across diverse tasks, making them valuable for learning and decision-making. Leveraging the ToM for understanding others' mental states, our approach facilitates effective collaboration. In this paper, we employ logic rules derived from observational data to infer human goals and guide human-like agents. These rules are treated as latent variables, and a rule encoder is trained alongside a multi-agent system in the robot's mind. We assess the posterior distribution of latent rules using learned embeddings, representing entities and relations. Confidence scores for each rule indicate their consistency with observed data. Then, we employ a hierarchical reinforcement learning model with ToM to plan robot actions for assisting humans. Extensive experiments validate each component of our framework, and results on multiple benchmarks demonstrate that our model outperforms the majority of existing approaches. © 2024 12th International Conference on Learning Representations, ICLR 2024. All rights reserved.
KW  - Computer circuits
KW  - Decision making
KW  - Reinforcement learning
KW  - Robots
KW  - Decisions makings
KW  - Human robots
KW  - Logic rules
KW  - Logical rules
KW  - Logical theories
KW  - Mental state
KW  - Observational data
KW  - Robot perception
KW  - Systematic framework
KW  - Theory of minds
KW  - Multi agent systems
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Cabral, R.C.
AU  - Luo, S.
AU  - Poon, J.
AU  - Han, S.C.
TI  - 3M-Health: Multimodal Multi-Teacher Knowledge Distillation for Mental Health Detection
PY  - 2024
T2  - International Conference on Information and Knowledge Management, Proceedings
SP  - 152
EP  - 162
DO  - 10.1145/3627673.3679635
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210037930&doi=10.1145%2f3627673.3679635&partnerID=40&md5=c3d7364c6d228bdcf9f115f945a08af9
AB  - The significance of mental health classification is paramount in contemporary society, where digital platforms serve as crucial sources for monitoring individuals' well-being. However, existing social media mental health datasets primarily consist of text-only samples, potentially limiting the efficacy of models trained on such data. Recognising that humans utilise cross-modal information to comprehend complex situations or issues, we present a novel approach to address the limitations of current methodologies. In this work, we introduce a Multimodal and Multi-Teacher Knowledge Distillation model for Mental Health Classification, leveraging insights from cross-modal human understanding. Unlike conventional approaches that often rely on simple concatenation to integrate diverse features, our model addresses the challenge of appropriately representing inputs of varying natures (e.g., texts and sounds). To mitigate the computational complexity associated with integrating all features into a single model, we employ a multimodal and multi-teacher architecture. By distributing the learning process across multiple teachers, each specialising in a particular feature extraction aspect, we enhance the overall mental health classification performance. Through experimental validation, we demonstrate the efficacy of our model in achieving improved performance.  © 2024 Owner/Author.
KW  - knowledge distillation
KW  - mental health classification
KW  - multimodal
KW  - mHealth
KW  - Teaching
KW  - Cross-modal
KW  - Digital platforms
KW  - Knowledge distillation
KW  - Mental health
KW  - Mental health classification
KW  - Multi-modal
KW  - Social media
KW  - Teachers'
KW  - Teachers' knowledge
KW  - Well being
KW  - Electronic health record
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Ren, L.
AU  - Yang, F.
AU  - Gu, C.
AU  - Sun, J.
AU  - Liu, Y.
TI  - A study of factors influencing Chinese college students’ intention of using metaverse technology for basketball learning: Extending the technology acceptance model
PY  - 2022
T2  - Frontiers in Psychology
VL  - 13
C7  - 1049972
DO  - 10.3389/fpsyg.2022.1049972
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145455302&doi=10.3389%2ffpsyg.2022.1049972&partnerID=40&md5=0e3c8e03908241f66b0f5d9188e46a47
AB  - Introduction: Based on the expansion of flow constructs based on the TAM model, this study assesses the impact of metaverse technology in college basketball courses. Methods: We surveyed 849 effective samples using an online questionnaire survey, verified our analysis using structural equation modeling, and examined the moderating effect of gender on the path relationship. Results: The perceived ease of use, the flow experience, and the perceived usefulness of the product are important predictors of behavioral intention. According to the study, perceived usefulness, and flow experience influence attitudes significantly. A moderating effect of gender is observed on perceived ease of use on the path to behavioral intention, and the results extend the theoretical research on the use of metaverse technology for basketball instruction and TAM. Discussion: A metaverse-based learning experience can enhance the flow experience of basketball learning, thus increasing the willingness to use and the effectiveness of learning. Copyright © 2022 Ren, Yang, Gu, Sun and Liu.
KW  - attitude
KW  - basketball teaching
KW  - metaverse
KW  - TAM
KW  - virtual
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 34
ER  -

TY  - JOUR
AU  - Zuidberg Dos Martires, P.
AU  - De Raedt, L.
AU  - Kimmig, A.
TI  - Declarative probabilistic logic programming in discrete-continuous domains
PY  - 2024
T2  - Artificial Intelligence
VL  - 337
C7  - 104227
DO  - 10.1016/j.artint.2024.104227
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205363740&doi=10.1016%2fj.artint.2024.104227&partnerID=40&md5=96154b1ff923b01433a724fb87b5ca4e
AB  - Over the past three decades, the logic programming paradigm has been successfully expanded to support probabilistic modeling, inference and learning. The resulting paradigm of probabilistic logic programming (PLP) and its programming languages owes much of its success to a declarative semantics, the so-called distribution semantics. However, the distribution semantics is limited to discrete random variables only. While PLP has been extended in various ways for supporting hybrid, that is, mixed discrete and continuous random variables, we are still lacking a declarative semantics for hybrid PLP that not only generalizes the distribution semantics and the modeling language but also the standard inference algorithm that is based on knowledge compilation. We contribute the measure semantics together with the hybrid PLP language DC-ProbLog (where DC stands for distributional clauses) and its inference engine infinitesimal algebraic likelihood weighting (IALW). These have the original distribution semantics, standard PLP languages such as ProbLog, and standard inference engines for PLP based on knowledge compilation as special cases. Thus, we generalize the state of the art of PLP towards hybrid PLP in three different aspects: semantics, language and inference. Furthermore, IALW is the first inference algorithm for hybrid probabilistic programming based on knowledge compilation. © 2024 The Author(s)
KW  - Algebraic model counting
KW  - Declarative semantics
KW  - Discrete-continuous distributions
KW  - Knowledge compilation
KW  - Likelihood weighting
KW  - Logic programming
KW  - Probabilistic programming
KW  - Inference engines
KW  - Probabilistic logics
KW  - Algebraic model counting
KW  - Algebraic models
KW  - Continuous distribution
KW  - Declarative semantics
KW  - Discrete-continuous distribution
KW  - Discrete/continuous
KW  - Knowledge compilation
KW  - Likelihood weighting
KW  - Logic-programming
KW  - Model Counting
KW  - Probabilistic programming
KW  - Semantics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - El Gharbaoui, O.
AU  - El Boukhari, H.
AU  - Mazouz, Y.
TI  - Analyzing the evolution of artificial intelligence (AI) in supply chain management: A bibliometric analysis
PY  - 2024
T2  - 2024 International Conference on Circuit, Systems and Communication, ICCSC 2024
DO  - 10.1109/ICCSC62074.2024.10617358
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201317092&doi=10.1109%2fICCSC62074.2024.10617358&partnerID=40&md5=4562949324d4f59f7e3eb5ce0579ff55
AB  - The environment of supply chain management (SCM) has changed dramatically between 2010 and 2024, owing to the incorporation of Artificial intelligence (AI) technology. As a result of the dynamic character of contemporary supply chains, which is driven by economic climate that is highly competitive, the use of new technologies has become necessary in order to successfully navigate the rising complexity of the situation. An exhaustive literature search was conducted for this bibliometric review, which focuses on studies that investigate the use of (AI) in (SCM) The bibliometric analysis revealed the following features: (1) word cloud); (2) Source growth (3)the main authors discuss AI and (SCM); (4) the main articles discuss the application of artificial intelligence (AI) in supply chain management (SCM and (5) the topics that are currently trending in SCM related to AI.  © 2024 IEEE.
KW  - Artificial intelligence (AI)
KW  - Bibliometric analysis
KW  - Supply chain management(SCM)
KW  - Supply chain management
KW  - Artificial intelligence
KW  - Artificial intelligence technologies
KW  - Bibliometric
KW  - Bibliometrics analysis
KW  - Chain management
KW  - Dynamic character
KW  - Economic climates
KW  - Literature search
KW  - Word clouds
KW  - Supply chains
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Song, H.
AU  - Park, B.-Y.
AU  - Park, H.
AU  - Shim, W.M.
TI  - Cognitive and neural state dynamics of narrative comprehension
PY  - 2021
T2  - Journal of Neuroscience
VL  - 41
IS  - 43
SP  - 8972
EP  - 8990
DO  - 10.1523/JNEUROSCI.0037-21.2021
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119021961&doi=10.1523%2fJNEUROSCI.0037-21.2021&partnerID=40&md5=05d0dc224cd68d85519508fcc1d405e6
AB  - Narrative comprehension involves a constant interplay of the accumulation of incoming events and their integration into a coherent structure. This study characterizes cognitive states during narrative comprehension and the network-level reconfiguration occurring dynamically in the functional brain. We presented movie clips of temporally scrambled sequences to human participants (male and female), eliciting fluctuations in the subjective feeling of comprehension. Comprehension occurred when processing events that were highly causally related to the previous events, suggesting that comprehension entails the integration of narratives into a causally coherent structure. The functional neuroimaging results demonstrated that the integrated and efficient brain state emerged during the moments of narrative integration with the increased level of activation and across-modular connections in the default mode network. Underlying brain states were synchronized across individuals when comprehending novel narratives, with increased occurrences of the default mode network state, integrated with sensory processing network, during narrative integration. A model based on time-resolved functional brain connectivity predicted changing cognitive states related to comprehension that are general across narratives. Together, these results support adaptive reconfiguration and interaction of the functional brain networks on causal integration of the narratives. Copyright © 2021 the authors
KW  - Causality
KW  - Cognitive neuroscience
KW  - Default mode network
KW  - FMRI
KW  - Functional connectivity
KW  - Narrative comprehension
KW  - Brain
KW  - Cognition
KW  - Comprehension
KW  - Female
KW  - Humans
KW  - Magnetic Resonance Imaging
KW  - Male
KW  - Motion Pictures
KW  - Narration
KW  - Nerve Net
KW  - Photic Stimulation
KW  - Young Adult
KW  - adult
KW  - Article
KW  - cognition
KW  - cognitive neuroscience
KW  - comprehension
KW  - default mode network
KW  - female
KW  - functional connectivity
KW  - functional magnetic resonance imaging
KW  - functional neuroimaging
KW  - human
KW  - male
KW  - narrative
KW  - nerve cell network
KW  - prediction
KW  - young adult
KW  - brain
KW  - cognition
KW  - comprehension
KW  - diagnostic imaging
KW  - movie
KW  - nuclear magnetic resonance imaging
KW  - photostimulation
KW  - physiology
KW  - procedures
KW  - verbal communication
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 23
ER  -

TY  - JOUR
AU  - Cai, M.
AU  - Zhou, Z.
AU  - Li, L.
AU  - Xiao, S.
AU  - Kan, Z.
TI  - Reinforcement learning with soft temporal logic constraints using limit-deterministic generalized Büchi automaton
PY  - 2025
T2  - Journal of Automation and Intelligence
VL  - 4
IS  - 1
SP  - 39
EP  - 51
DO  - 10.1016/j.jai.2024.12.005
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001071750&doi=10.1016%2fj.jai.2024.12.005&partnerID=40&md5=17d1bb20486dab2340e5ff06e5abed1e
AB  - This paper investigates control synthesis for motion planning under conditions of uncertainty, specifically in robot motion and environmental properties, which are modeled using a probabilistic labeled Markov decision process (PL-MDP). To address this, a model-free reinforcement learning (RL) approach is designed to produce a finite-memory control policy that meets complex tasks specified by linear temporal logic (LTL) formulas. Recognizing the presence of uncertainties and potentially conflicting objectives, this study centers on addressing infeasible LTL specifications. A relaxed LTL constraint enables the agent to adapt its motion plan, allowing for partial satisfaction by accounting for necessary task violations. Additionally, a new automaton structure is introduced to increase the density of accepting rewards, facilitating deterministic policy outcomes. The proposed RL framework is rigorously analyzed and prioritizes two key objectives: (1) satisfying the acceptance condition of the relaxed product MDP, and (2) minimizing long-term violation costs. Simulation and experimental results are presented to demonstrate the framework's effectiveness and robustness. © 2024 The Authors
KW  - Formal methods in robotics and automation
KW  - Linear temporal logic
KW  - Motion planning
KW  - Optimal control
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Francis, J.
AU  - Kitamura, N.
AU  - Labelle, F.
AU  - Lu, X.
AU  - Navarro, I.
AU  - Oh, J.
TI  - Core Challenges in Embodied Vision-Language Planning
PY  - 2022
T2  - Journal of Artificial Intelligence Research
VL  - 74
SP  - 459
EP  - 515
DO  - 10.1613/jair.1.13646
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130468732&doi=10.1613%2fjair.1.13646&partnerID=40&md5=eeef23f9abe8f3abbcff6c30c7f05af8
AB  - Recent advances in the areas of multimodal machine learning and artificial intelligence (AI) have led to the development of challenging tasks at the intersection of Computer Vision, Natural Language Processing, and Embodied AI. Whereas many approaches and previous survey pursuits have characterised one or two of these dimensions, there has not been a holistic analysis at the center of all three. Moreover, even when combinations of these topics are considered, more focus is placed on describing, e.g., current architectural methods, as opposed to also illustrating high-level challenges and opportunities for the field. In this survey paper, we discuss Embodied Vision-Language Planning (EVLP) tasks, a family of prominent embodied navigation and manipulation problems that jointly use computer vision and natural language. We propose a taxonomy to unify these tasks and provide an in-depth analysis and comparison of the new and current algorithmic approaches, metrics, simulated environments, as well as the datasets used for EVLP tasks. Finally, we present the core challenges that we believe new EVLP works should seek to address, and we advocate for task construction that enables model generalizability and furthers real-world deployment. ©2022 AI Access Foundation. All rights reserved.
KW  - Artificial intelligence
KW  - Computer vision
KW  - Learning algorithms
KW  - Natural language processing systems
KW  - 'current
KW  - Algorithmic approach
KW  - Architectural methods
KW  - Embodied artificial intelligence
KW  - Holistic analysis
KW  - In-depth analysis
KW  - Multi-modal
KW  - Natural languages
KW  - Planning tasks
KW  - Simulated environment
KW  - Surveys
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 20
ER  -

TY  - CONF
AU  - Henze, F.
AU  - Fasbender, D.
AU  - Stiller, C.
TI  - How Can Automated Vehicles Explain Their Driving Decisions? Generating Clarifying Summaries Automatically
PY  - 2022
T2  - IEEE Intelligent Vehicles Symposium, Proceedings
VL  - 2022-June
SP  - 935
EP  - 942
DO  - 10.1109/IV51971.2022.9827197
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135378778&doi=10.1109%2fIV51971.2022.9827197&partnerID=40&md5=e7949d8458baff389d21d332c5a91b21
AB  - One way to increase user acceptance in automated vehicles is to explain their driving decisions, but current methods still involve human interpretations and are thus prone to errors. Therefore, the presented method formulates summaries that clarify the automated vehicle's driving decision by extracting all necessary information automatically from the planning algorithm. This paper shows the generation of three exemplary statement types and their validation with an online survey that investigated users' preferences. The results suggest that participants favor statements describing information that affect the driving decision as well as applicable traffic rules. Additionally, individual information needs should be considered when constructing modular explanations. Although this analysis does not consider sophisticated human machine interfaces nor real traffic scenarios, it does show, for the first time, how satisfying statements can be generated using a planning algorithm without any human-induced bias. This is an important step towards self-contained transparency of automated driving functions and can therefore lay the basis for future human machine interfaces. © 2022 IEEE.
KW  - Automation
KW  - Man machine systems
KW  - 'current
KW  - Automated vehicles
KW  - Human Machine Interface
KW  - Modulars
KW  - Online surveys
KW  - Planning algorithms
KW  - Real traffic
KW  - Traffic rules
KW  - User's preferences
KW  - Users' acceptance
KW  - Vehicles
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Mudavath, T.
AU  - Mamidi, A.
TI  - Object detection challenges: Navigating through varied weather conditions—Acomprehensive survey
PY  - 2025
T2  - Journal of Ambient Intelligence and Humanized Computing
VL  - 16
IS  - 2
SP  - 443
EP  - 457
DO  - 10.1007/s12652-025-04956-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001483013&doi=10.1007%2fs12652-025-04956-6&partnerID=40&md5=392bd506047ba6313295540d5c830d2e
AB  - Detecting objects in computer vision is a challenging task, especially under varied weather conditions such as rain, fog, snow, etc. which degrades the visibility, and illumination changes in the image. These conditions create specific challenges in object detection in recognizing the distinct objects in the image. The influence of changing weather conditions remains the cause for concern although deep learning has revolutionized object detection through multi-stage detectors that offer improved accuracy over one-stage detectors, which allow rapid inference. This survey offers a comprehensive exploration of the various object detection methods, and datasets, and emphasizes the challenges posed under the challenging weather conditions. By analyzing current methodologies in object detection and identifying gaps in existing research, this paper provides the limitations under the weather conditions and highlights the research opportunities under weather conditions for the development of better object detection methods that can be suitable for surveillance applications. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2025.
KW  - And YOLO
KW  - Classification
KW  - Deep learning
KW  - Localization
KW  - Machine learning
KW  - Object detection
KW  - Weather conditions
KW  - Computer vision
KW  - Object detection
KW  - Object recognition
KW  - Security systems
KW  - And YOLO
KW  - Condition
KW  - Deep learning
KW  - Detecting objects
KW  - Illumination changes
KW  - Localisation
KW  - Machine-learning
KW  - Object detection method
KW  - Objects detection
KW  - Weather condition
KW  - Deep learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Safadoust, S.
AU  - Güney, F.
TI  - Multi-Object Discovery by Low-Dimensional Object Motion
PY  - 2023
T2  - Proceedings of the IEEE International Conference on Computer Vision
SP  - 734
EP  - 744
DO  - 10.1109/ICCV51070.2023.00074
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175229239&doi=10.1109%2fICCV51070.2023.00074&partnerID=40&md5=0c8c8440e41102b9d1c80278e7963da9
AB  - Recent work in unsupervised multi-object segmentation shows impressive results by predicting motion from a single image despite the inherent ambiguity in predicting motion without the next image. On the other hand, the set of possible motions for an image can be constrained to a low-dimensional space by considering the scene structure and moving objects in it. We propose to model pixel-wise geometry and object motion to remove ambiguity in reconstructing flow from a single image. Specifically, we divide the image into coherently moving regions and use depth to construct flow bases that best explain the observed flow in each region. We achieve state-of-the-art results in unsupervised multi-object segmentation on synthetic and real-world datasets by modeling the scene structure and object motion. Our evaluation of the predicted depth maps shows reliable performance in monocular depth estimation. © 2023 IEEE.
KW  - Computer vision
KW  - Low dimensional
KW  - Low-dimensional spaces
KW  - Moving objects
KW  - Moving regions
KW  - Multi-object segmentation
KW  - Multiobject
KW  - Object motion
KW  - Scene structure
KW  - Single images
KW  - State of the art
KW  - Image segmentation
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Huang, C.
AU  - Yao, X.
TI  - A Roadmap of Explainable Artificial Intelligence: Explain to Whom, When, What and How?
PY  - 2024
T2  - ACM Transactions on Autonomous and Adaptive Systems
VL  - 19
IS  - 4
DO  - 10.1145/3702004
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210323717&doi=10.1145%2f3702004&partnerID=40&md5=180fb77ee5622c06a98801f616e5c8f5
AB  - Explainable artificial intelligence (XAI) has gained significant attention, especially in AI-powered autonomous and adaptive systems (AASs). However, a discernible disconnect exists among research efforts across different communities. The machine learning community often overlooks "explaining to whom,"while the human-computer interaction community has examined various stakeholders with diverse explanation needs without addressing which XAI methods meet these requirements. Currently, no clear guidance exists on which XAI methods suit which specific stakeholders and their distinct needs. This hinders the achievement of the goal of XAI: providing human users with understandable interpretations. To bridge this gap, this article presents a comprehensive XAI roadmap. Based on an extensive literature review, the roadmap summarizes different stakeholders, their explanation needs at different stages of the AI system lifecycle, the questions they may pose, and existing XAI methods. Then, by utilizing stakeholders' inquiries as a conduit, the roadmap connects their needs to prevailing XAI methods, providing a guideline to assist researchers and practitioners to determine more easily which XAI methodologies can meet the specific needs of stakeholders in AASs. Finally, the roadmap discusses the limitations of existing XAI methods and outlines directions for future research. © 2024 Copyright held by the owner/author(s).
KW  - Explainability
KW  - Explainable artificial intelligence
KW  - Human-computer interaction
KW  - Transparency
KW  - Trustworthy artificial intelligence
KW  - Computer interaction
KW  - Different stages
KW  - Explainability
KW  - Explainable artificial intelligence
KW  - Human users
KW  - Literature reviews
KW  - Machine learning communities
KW  - Research efforts
KW  - Roadmap
KW  - Trustworthy artificial intelligence
KW  - Human computer interaction
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Kolev, M.
AU  - Drenchev, L.
AU  - Petkov, V.
AU  - Dimitrova, R.
AU  - Kolev, K.
AU  - Simeonova, T.
TI  - Fabrication and Dry-Sliding Wear Characterization of Open-Cell AlSn6Cu–Al2O3 Composites with LSTM-Based Coefficient of Friction Prediction
PY  - 2024
T2  - Metals
VL  - 14
IS  - 4
C7  - 428
DO  - 10.3390/met14040428
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191380702&doi=10.3390%2fmet14040428&partnerID=40&md5=ac79faf902e527e4552a2948377813ca
AB  - This study investigates the fabrication, wear characterization, and coefficient of friction (COF) prediction of open-cell AlSn6Cu–Al2O3 composites obtained by a liquid-state processing technique. Focusing on wear behavior under varying loads using the pin-on-disk method, this research characterizes microstructure and phase composition via SEM, EDS, and XRD analyses. A novel aspect of this research is the application of an LSTM recurrent neural network model for the fast and accurate prediction of the COF of the composites, eliminating the need for extensive experimental work. Additionally, feature importance analysis using Random Forest regressors is conducted to ascertain the relative contribution of each input variable to the output variable, enhancing our understanding of the wear mechanisms in these materials. The results demonstrate the effectiveness of the composite’s reinforcement in improving wear resistance, highlighting the critical role of mechanical stress and the reinforcement’s hardness in the wear process. The quantitative findings related to the wear behavior include a mass-wear reduction in the open-cell AlSn6Cu–Al2O3 composite from 8.05 mg to 1.90 mg at 50 N and a decrease from 17.55 mg to 8.10 mg at 100 N, demonstrating the Al2O3 particles’ effectiveness in improving wear resistance under different loads. © 2024 by the authors.
KW  - Al-based metal matrix composites
KW  - AlSn6Cu–Al<sub>2</sub>O<sub>3</sub>
KW  - dry-sliding friction
KW  - long short-term memory model
KW  - wear behavior
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Kuznietsov, A.
AU  - Gyevnar, B.
AU  - Wang, C.
AU  - Peters, S.
AU  - Albrecht, S.V.
TI  - Explainable AI for Safe and Trustworthy Autonomous Driving: A Systematic Review
PY  - 2024
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 25
IS  - 12
SP  - 19342
EP  - 19364
DO  - 10.1109/TITS.2024.3474469
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207766711&doi=10.1109%2fTITS.2024.3474469&partnerID=40&md5=b6d9a2e49f4de2bdeeac474dd431439f
AB  - Artificial Intelligence (AI) shows promising applications for the perception and planning tasks in autonomous driving (AD) due to its superior performance compared to conventional methods. However, highly complex AI systems exacerbate the existing challenge of safety assurance of AD. One way to mitigate this challenge is to utilize explainable AI (XAI) techniques. To this end, we present the first comprehensive systematic literature review of explainable methods for safe and trustworthy AD. We begin by analyzing the requirements for AI in the context of AD, focusing on three key aspects: data, model, and agency. We find that XAI is fundamental to meeting these requirements. Based on this, we explain the sources of explanations in AI and describe a taxonomy of XAI. We then identify five key contributions of XAI for safe and trustworthy AI in AD, which are interpretable design, interpretable surrogate models, interpretable monitoring, auxiliary explanations, and interpretable validation. Finally, we propose a conceptual modular framework called SafeX to integrate the reviewed methods, enabling explanation delivery to users while simultaneously ensuring the safety of AI models.  © 2000-2011 IEEE.
KW  - AI safety
KW  - Autonomous driving
KW  - autonomous vehicle
KW  - explainable AI
KW  - trustworthy AI
KW  - Artificial intelligence safety
KW  - Artificial intelligence systems
KW  - Autonomous driving
KW  - Autonomous Vehicles
KW  - Conventional methods
KW  - Explainable artificial intelligence
KW  - Performance
KW  - Planning tasks
KW  - Systematic Review
KW  - Trustworthy artificial intelligence
KW  - Adversarial machine learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Xu, S.
AU  - Liu, J.
TI  - The neural correlates of logical-mathematical symbol systems processing resemble those of spatial cognition more than language processing
PY  - 2025
T2  - iScience
VL  - 28
IS  - 4
C7  - 112016
DO  - 10.1016/j.isci.2025.112016
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000775226&doi=10.1016%2fj.isci.2025.112016&partnerID=40&md5=6f9f3ce7d20bcb4109523645542748de
AB  - The ability to use logical-mathematical symbols (LMS), encompassing tasks such as calculation, reasoning, and programming, is special to humans with recent emergence. LMS processing was suggested to build upon fundamental cognitive systems through neuronal recycling, with natural language processing and spatial cognition as key candidates. This study used meta-analyses and synthesized neural maps of representative LMS tasks, including reasoning, calculation, and mental programming, to compare their neural correlates with those of the two systems. Our results revealed greater activation overlap and multivariate similarity between LMS and spatial cognition than with language processing. Hierarchical clustering further indicated that LMS tasks were indistinguishable from spatial tasks at the neural level, suggesting an inherent connection. Our findings support the hypothesis that spatial cognition is the basis of LMS processing, shedding light on the logical reasoning limitations of large language models, particularly those lacking explicit spatial representations. © 2025 The Author(s)
KW  - Cognitive neuroscience
KW  - Neuroscience
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Meurie, C.
AU  - Lézoray, O.
TI  - A comprehensive review of on-board action recognition models in public transportation systems
PY  - 2025
T2  - Expert Systems with Applications
VL  - 290
C7  - 128311
DO  - 10.1016/j.eswa.2025.128311
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007498965&doi=10.1016%2fj.eswa.2025.128311&partnerID=40&md5=d716a1ef3994d76e55bc06cda6257cf0
AB  - The emergence of autonomous transportation systems marks a significant milestone in modern mobility, promising enhanced safety, efficiency, and convenience. However, ensuring the safety of passengers remains a paramount concern in the development and deployment of such systems. Monitoring the interior of autonomous vehicles has emerged as a critical aspect to guarantee passenger safety, requiring robust on-board action recognition systems. This paper provides an overview of the challenges and advancements in on-board action recognition for interior monitoring in autonomous vehicles. A comprehensive review of datasets pertinent to interior monitoring is presented, encompassing diverse scenarios and conditions to facilitate the training and evaluation of on-board action recognition models. Furthermore, we explore the methodologies employed in the development of these systems, including traditional computer vision techniques, deep learning architectures, and multimodal approaches. By synthesizing insights from existing research and highlighting key challenges and advancements, this paper aims to contribute to the ongoing discourse on enhancing safety measures in future autonomous transportation systems (bus, metro, train, car) through effective interior monitoring and action recognition technologies. © 2025 The Authors
KW  - Autonomous transportation systems
KW  - Computer vision
KW  - Machine learning
KW  - On-board action recognition
KW  - Transportation datasets
KW  - Bus transportation
KW  - Computer vision
KW  - Deep learning
KW  - Intermodal transportation
KW  - Multimodal transportation
KW  - Navigation
KW  - Railroad transportation
KW  - Action recognition
KW  - Action recognition systems
KW  - Autonomous transportation system
KW  - Autonomous Vehicles
KW  - Machine-learning
KW  - On-board action recognition
KW  - Passenger safety
KW  - Public transportation systems
KW  - Recognition models
KW  - Transportation dataset
KW  - Autonomous vehicles
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Haryanto, C.Y.
AU  - Elvira, A.M.
AU  - Nguyen, T.D.
AU  - Vu, M.H.
AU  - Hartanto, Y.
AU  - Lomempow, E.
AU  - Arakala, A.
TI  - Contextualized AI for Cyber Defense: An Automated Survey Using LLMs
PY  - 2024
T2  - 2024 17th International Conference on Security of Information and Networks, SIN 2024
DO  - 10.1109/SIN63213.2024.10871242
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000027249&doi=10.1109%2fSIN63213.2024.10871242&partnerID=40&md5=2351266a63713ef27427a1869f6be8f5
AB  - This paper surveys the potential of contextualized AI in enhancing cyber defense capabilities, revealing significant research growth from 2015 to 2024. We identify a focus on robustness, reliability, and integration methods, while noting gaps in organizational trust and governance frameworks. Our study employs two LLM-assisted literature survey methodologies: (A) ChatGPT 4 for exploration, and (B) Gemma 2:9b for filtering with Claude 3.5 Sonnet for full-text analysis. We discuss the effectiveness and challenges of using LLMs in academic research, providing insights for future researchers.  © 2024 IEEE.
KW  - artificial intelligence
KW  - cyber defense strategy
KW  - cyber security
KW  - meta-analysis
KW  - retrieval augmented generation
KW  - Terrorism
KW  - Cybe defense strategy
KW  - Cyber security
KW  - Cyber-defense
KW  - Defense capability
KW  - Defense strategy
KW  - Integration method
KW  - Meta-analysis
KW  - Paper surveys
KW  - Reliability methods
KW  - Retrieval augmented generation
KW  - Cyber attacks
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Jovic, A.
AU  - Frid, N.
AU  - Brkic, K.
AU  - Cifrek, M.
TI  - Interpretability and accuracy of machine learning algorithms for biomedical time series analysis – a scoping review
PY  - 2025
T2  - Biomedical Signal Processing and Control
VL  - 110
C7  - 108153
DO  - 10.1016/j.bspc.2025.108153
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006670678&doi=10.1016%2fj.bspc.2025.108153&partnerID=40&md5=a609eca943f2f456346e56c9cdaed9ac
AB  - Current research in biomedical time series (BTS) (e.g., ECG, EEG) analysis focuses on applications of various deep learning approaches to improve classification, prediction, or assessment of states and disorders. When trained on sufficiently large datasets, such approaches mostly lead to highly accurate, yet uninterpretable models, sometimes with a possibility for post-hoc explainability. Since high-stake areas such as healthcare warrant model explanations and, where possible, high interpretability in addition to model efficiency, there is nowadays a surprising scarcity of interpretable machine learning models proposed in this field. Although the machine learning community is aware of the need for interpretable machine learning in BTS analysis, the proposed models do not reflect this need. In this scoping review, we considered over 30,000 studies from the Web of Science database, screened nearly 500 studies, and selected over 50 high-quality studies for detailed analysis. These studies focus on interpretable methods, accurate methods, and approaches bridging the two. Most studies analyzed ECG and EEG signals and concentrated on a limited range of applications, including emotion recognition, heart diseases, epilepsy, and motor imagery, reflecting the scarcity of quality public datasets. K-nearest neighbors and decision trees were the most used interpretable methods, while convolutional neural networks with recurrent or attention layers, achieved the highest accuracy. The methods that balance interpretability and accuracy in BTS analysis include advanced generalized additive models and optimization-based approaches for decision trees, rule learning, and linear models. These approaches warrant further studies, as only a few of them were applied in BTS analysis. © 2025 The Author(s)
KW  - Artificial intelligence
KW  - Biomedical signal processing
KW  - Biomedical time series
KW  - Deep learning
KW  - Interpretable machine learning
KW  - Time series analysis
KW  - Deep neural networks
KW  - k-nearest neighbors
KW  - Medical image processing
KW  - Recurrent neural networks
KW  - Biomedical signals processing
KW  - Biomedical time series
KW  - Deep learning
KW  - Interpretability and accuracy
KW  - Interpretable machine learning
KW  - Machine learning algorithms
KW  - Machine-learning
KW  - Scoping review
KW  - Time-series analysis
KW  - Times series
KW  - artificial intelligence
KW  - convolutional neural network
KW  - decision tree
KW  - deep learning
KW  - diagnosis
KW  - diagnostic test accuracy study
KW  - electrocardiogram
KW  - electrocardiography
KW  - electroencephalogram
KW  - electroencephalography
KW  - epilepsy
KW  - explainable machine learning
KW  - heart disease
KW  - human
KW  - imagery
KW  - k nearest neighbor
KW  - learning
KW  - machine learning
KW  - machine learning algorithm
KW  - prediction
KW  - review
KW  - scoping review
KW  - signal processing
KW  - statistical model
KW  - time series analysis
KW  - Convolutional neural networks
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Martin, H.G.
AU  - Radivojevic, T.
AU  - Zucker, J.
AU  - Bouchard, K.
AU  - Sustarich, J.
AU  - Peisert, S.
AU  - Arnold, D.
AU  - Hillson, N.
AU  - Babnigg, G.
AU  - Marti, J.M.
AU  - Mungall, C.J.
AU  - Beckham, G.T.
AU  - Waldburger, L.
AU  - Carothers, J.
AU  - Sundaram, S.
AU  - Agarwal, D.
AU  - Simmons, B.A.
AU  - Backman, T.
AU  - Banerjee, D.
AU  - Tanjore, D.
AU  - Ramakrishnan, L.
AU  - Singh, A.
TI  - Perspectives for self-driving labs in synthetic biology
PY  - 2023
T2  - Current Opinion in Biotechnology
VL  - 79
C7  - 102881
DO  - 10.1016/j.copbio.2022.102881
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145976987&doi=10.1016%2fj.copbio.2022.102881&partnerID=40&md5=8cc58d2474070c68f29160661c906166
AB  - Self-driving labs (SDLs) combine fully automated experiments with artificial intelligence (AI) that decides the next set of experiments. Taken to their ultimate expression, SDLs could usher a new paradigm of scientific research, where the world is probed, interpreted, and explained by machines for human benefit. While there are functioning SDLs in the fields of chemistry and materials science, we contend that synthetic biology provides a unique opportunity since the genome provides a single target for affecting the incredibly wide repertoire of biological cell behavior. However, the level of investment required for the creation of biological SDLs is only warranted if directed toward solving difficult and enabling biological questions. Here, we discuss challenges and opportunities in creating SDLs for synthetic biology. © 2023 The Authors
KW  - Artificial Intelligence
KW  - Humans
KW  - Synthetic Biology
KW  - Biological cells
KW  - Cell behaviours
KW  - Fully automated
KW  - Material science
KW  - Scientific researches
KW  - Self drivings
KW  - Synthetic biology
KW  - human
KW  - investment
KW  - review
KW  - synthetic biology
KW  - artificial intelligence
KW  - Synthetic biology
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 38
ER  -

TY  - JOUR
AU  - Longo, L.
AU  - Brcic, M.
AU  - Cabitza, F.
AU  - Choi, J.
AU  - Confalonieri, R.
AU  - Ser, J.D.
AU  - Guidotti, R.
AU  - Hayashi, Y.
AU  - Herrera, F.
AU  - Holzinger, A.
AU  - Jiang, R.
AU  - Khosravi, H.
AU  - Lecue, F.
AU  - Malgieri, G.
AU  - Páez, A.
AU  - Samek, W.
AU  - Schneider, J.
AU  - Speith, T.
AU  - Stumpf, S.
TI  - Explainable Artificial Intelligence (XAI) 2.0: A manifesto of open challenges and interdisciplinary research directions
PY  - 2024
T2  - Information Fusion
VL  - 106
C7  - 102301
DO  - 10.1016/j.inffus.2024.102301
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185323737&doi=10.1016%2fj.inffus.2024.102301&partnerID=40&md5=793193eb70c00be6efbec7a3275a0b62
AB  - Understanding black box models has become paramount as systems based on opaque Artificial Intelligence (AI) continue to flourish in diverse real-world applications. In response, Explainable AI (XAI) has emerged as a field of research with practical and ethical benefits across various domains. This paper highlights the advancements in XAI and its application in real-world scenarios and addresses the ongoing challenges within XAI, emphasizing the need for broader perspectives and collaborative efforts. We bring together experts from diverse fields to identify open problems, striving to synchronize research agendas and accelerate XAI in practical applications. By fostering collaborative discussion and interdisciplinary cooperation, we aim to propel XAI forward, contributing to its continued success. We aim to develop a comprehensive proposal for advancing XAI. To achieve this goal, we present a manifesto of 28 open problems categorized into nine categories. These challenges encapsulate the complexities and nuances of XAI and offer a road map for future research. For each problem, we provide promising research directions in the hope of harnessing the collective intelligence of interested stakeholders. © 2024 The Author(s)
KW  - Actionable XAI
KW  - Causality
KW  - Concept-based explanations
KW  - Ethical AI
KW  - Explainable artificial intelligence
KW  - Falsifiability
KW  - Generative AI
KW  - Interdisciplinarity
KW  - Interpretability
KW  - Large language models
KW  - Manifesto
KW  - Multi-faceted explanations
KW  - Open challenges
KW  - Responsible AI
KW  - Trustworthy AI
KW  - XAI
KW  - Artificial intelligence
KW  - Actionable XAI
KW  - Causality
KW  - Concept-based
KW  - Concept-based explanation
KW  - Ethical artificial intelligence
KW  - Explainable artificial intelligence
KW  - Falsifiability
KW  - Generative artificial intelligence
KW  - Interdisciplinarity
KW  - Interpretability
KW  - Language model
KW  - Large language model
KW  - Manifesto
KW  - Multi-faceted explanation
KW  - Open challenge
KW  - Responsible artificial intelligence
KW  - Trustworthy artificial intelligence
KW  - XAI
KW  - Ethical technology
M3  - Short survey
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 169
ER  -

TY  - JOUR
AU  - Daios, A.
AU  - Kladovasilakis, N.
AU  - Kelemis, A.
AU  - Kostavelis, I.
TI  - AI Applications in Supply Chain Management: A Survey
PY  - 2025
T2  - Applied Sciences (Switzerland)
VL  - 15
IS  - 5
C7  - 2775
DO  - 10.3390/app15052775
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000601293&doi=10.3390%2fapp15052775&partnerID=40&md5=5c3211192447dcd732e5bb31e8e6b520
AB  - The advent of Industry 4.0 and the integration of Artificial Intelligence (AI) is transforming supply chain management (SCM), improving efficiency, resilience and strategic decision-making capabilities. This research study provides a comprehensive overview of AI applications in key SCM processes, including customer relationship management, inventory management, transportation networks, procurement, demand forecasting and risk management. AI technologies such as Machine Learning, Natural Language Processing and Generative AI offer transformative solutions to streamline logistics, reduce operational risk and improve demand forecasting. In addition, this study identifies barriers to AI adoption, such as implementation challenges, organizational readiness and ethical concerns, and highlights the critical role of AI in promoting supply chain visibility and resilience in the midst of global crises. Future trends emphasize human-centric AI, increasing digital maturity, and addressing ethical and security concerns. This review concludes by confirming the critical role of AI in shaping sustainable, flexible and resilient supply chains while providing a roadmap for future research and application in SCM. © 2025 by the authors.
KW  - artificial intelligence (AI)
KW  - digital transformation
KW  - industry 4.0
KW  - strategic decision making
KW  - supply chain management (SCM)
KW  - Public relations
KW  - Risk management
KW  - Supply chain management
KW  - Artificial intelligence
KW  - Chain management
KW  - Customer relationship management
KW  - Demand forecasting
KW  - Digital transformation
KW  - Improving efficiency
KW  - Management process
KW  - Research studies
KW  - Strategic decision making
KW  - Supply chain management
KW  - Inventory control
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Isikdemir, Y.E.
AU  - Yavuz, H.S.
TI  - The Scalable Fuzzy Inference-Based Ensemble Method for Sentiment Analysis
PY  - 2022
T2  - Computational Intelligence and Neuroscience
VL  - 2022
C7  - 5186144
DO  - 10.1155/2022/5186144
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139428475&doi=10.1155%2f2022%2f5186144&partnerID=40&md5=f326e6bc932c34239c1ad36db4672a64
AB  - Internet environments such as social networks, news sites, and blogs are the platforms where people can share their ideas and opinions. Many people share their comments instantly on the internet, which results in creating large volumes of entries. It is important for institutions and organizations to analyze this big data in an efficient and rapid manner to produce summary information about the feelings or opinions of individuals. In this study, we propose a scalable framework that makes sentiment classification by evaluating the compound probability scores of the most widely used methods in sentiment analysis through a fuzzy inference mechanism in an ensemble manner. The designed fuzzy inference system makes the sentiment estimation by evaluating the compound scores of valance aware dictionary, word embedding, and count vectorization processes. The difference of the proposed method from the classical ensemble methods is that it allows weighting of base learners and combines the strengths of each algorithm through fuzzy rules. The sentiment estimation process from text data can be managed either as a 2-class (positive and negative) or as a 3-class (positive, neutral, and negative) problem. We performed the experimental work on four available tagged social network data sets for both 2-class and 3-class classifications and observed that the proposed method provides improvements in accuracy.  © 2022 Yunus Emre Isikdemir and Hasan Serhan Yavuz.
KW  - Algorithms
KW  - Emotions
KW  - Humans
KW  - Sentiment Analysis
KW  - Classification (of information)
KW  - Fuzzy inference
KW  - Social networking (online)
KW  - Embeddings
KW  - Ensemble methods
KW  - Fuzzy inference mechanism
KW  - Fuzzy inference systems
KW  - Fuzzy inferencer
KW  - Internet environment
KW  - Large volumes
KW  - Sentiment analysis
KW  - Sentiment classification
KW  - Vectorization
KW  - algorithm
KW  - emotion
KW  - human
KW  - Sentiment analysis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - BOOK
AU  - Yu, C.H.A.
TI  - Data mining and exploration: From traditional statistics to modern data science
PY  - 2022
T2  - Data Mining and Exploration: From Traditional Statistics to Modern Data Science
SP  - 1
EP  - 279
DO  - 10.1201/9781003153658
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136700172&doi=10.1201%2f9781003153658&partnerID=40&md5=836f6c4b67a301440c811e9a2af4d22a
AB  - This book introduces both conceptual and procedural aspects of cutting-edge data science methods, such as dynamic data visualization, artificial neural networks, ensemble methods, and text mining. There are at least two unique elements that can set the book apart from its rivals. © 2022 Taylor and Francis Group, LLC. All rights reserved.
M3  - Book
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - BOOK
AU  - Chang, M.
TI  - Foundation, Architecture, and Prototyping of Humanized AI: A New Constructivist Approach
PY  - 2023
T2  - Foundation, Architecture, and Prototyping of Humanized AI: A New Constructivist Approach
SP  - 1
EP  - 372
DO  - 10.1201/b23355
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163494115&doi=10.1201%2fb23355&partnerID=40&md5=3b65af75064c29a813d84dc577479edb
AB  - Humanized AI (HAI), emerging as the next of the AI waves, refers to artificial social beings that are very close to humans in various aspects, beings who are machine-race humans, not digital slaves. Foundation, Architecture, and Prototyping of HAI deploy a novel smalldata approach to vertically explore the spectrum of HAI. Different from the popular big-data philosophy that is based on the rigid notion that the connotation of each concept is fixed and the same to everyone, this book treats understanding as a process from simple to complex, and uses the similarity principle to effectively deal with novelties. Combining the efficiency of the Behaviorists’ goal-driven approach and the flexibility of a Constructivists’ approach, both the architecture of HAI and the philosophical discussions arising from it are elaborated upon. Advancing a unique approach to the concept of HAI, this book appeals to professors and students of both AI and philosophy, as well as industry professionals looking to stay at the forefront of developments within the field. © 2023 Mark Chang.
M3  - Book
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Muñoz, S.
AU  - Iglesias, C.Á.
TI  - Detection of the Severity Level of Depression Signs in Text Combining a Feature-Based Framework with Distributional Representations
PY  - 2023
T2  - Applied Sciences (Switzerland)
VL  - 13
IS  - 21
C7  - 11695
DO  - 10.3390/app132111695
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192377161&doi=10.3390%2fapp132111695&partnerID=40&md5=926a467b3dc0cfd234bc25aac70c774c
AB  - Depression is a common and debilitating mental illness affecting millions of individuals, diminishing their quality of life and overall well-being. The increasing prevalence of mental health disorders has underscored the need for innovative approaches to detect and address depression. In this context, text analysis has emerged as a promising avenue. Novel solutions for text-based depression detection commonly rely on deep neural networks or transformer-based models. Although these approaches have yielded impressive results, they often come with inherent limitations, such as substantial computational requirements or a lack of interpretability. This work aims to bridge the gap between substantial performance and practicality in the detection of depression signs within digital content. To this end, we introduce a comprehensive feature framework that integrates linguistic signals, emotional expressions, and cognitive patterns. The combination of this framework with distributional representations contributes to fostering the understanding of language patterns indicative of depression and provides a deeper grasp of contextual nuances. We exploit this combination using traditional machine learning methods in an effort to yield substantial performance without compromising interpretability and computational efficiency. The performance and generalizability of our approach have been assessed through experimentation using multiple publicly available English datasets. The results demonstrate that our method yields throughput on par with more complex and resource-intensive solutions, achieving F1-scores above 70%. This accomplishment is notable, as the proposed method simultaneously preserves the virtues of simplicity, interpretability, and reduced computational overhead. In summary, the findings of this research contribute to the field by offering an accessible and scalable solution for the detection of depression in real-world scenarios. © 2023 by the authors.
KW  - affective computing
KW  - depression detection
KW  - depression framework
KW  - distributional representations
KW  - text classification
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Abumalloh, R.A.
AU  - Nilashi, M.
AU  - Ooi, K.B.
AU  - Wei-Han, G.
AU  - Cham, T.-H.
AU  - Dwivedi, Y.K.
AU  - Hughes, L.
TI  - The adoption of metaverse in the retail industry and its impact on sustainable competitive advantage: moderating impact of sustainability commitment
PY  - 2024
T2  - Annals of Operations Research
VL  - 342
IS  - 1
SP  - 5
EP  - 46
DO  - 10.1007/s10479-023-05608-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173050309&doi=10.1007%2fs10479-023-05608-8&partnerID=40&md5=7c74c3b2d125abb53ba759f15f330e11
AB  - The concept of the metaverse involves creating a fully immersive virtual world that allows users to interact with each other and digital objects in a way that is almost indistinguishable from reality. One of the key areas where the metaverse is expected to have an impact is retailing. Although there have been several studies on the use of the metaverse in different industries, this issue is rarely investigated in previous studies in the context of retail companies focusing on users’ perceptions. This study accordingly explores the factors impacting the adoption of a metaverse in the retail industry and develops a new model based on the Resource-Based View (RBV) theory. In addition, the relationship between the usage intention of the metaverse and product innovation, and the relationship between product innovation and sustainable competitive advantage are investigated. Furthermore, as sustainability is a critical issue in the adoption of innovation by industries, this study aims to further investigate whether sustainability commitment will strengthen the impact of attitude toward metaverse on the intention to use. The data was collected from retail companies in Malaysia and analyzed to evaluate the proposed research model. The outcomes of this research indicated that there is a positive impact of product innovation on sustainable competitive advantage through the adoption of a metaverse in retail companies. In addition, our findings stressed that the intention to use metaverse will lead to product innovation in retail companies. Furthermore, the results revealed that sustainability commitment does not moderate the relationship between attitude toward the metaverse and intention to use, but impacts the usage intention of the metaverse directly. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.
KW  - Competitive advantage
KW  - Metaverse
KW  - Resource-Based View
KW  - Retail industry
KW  - Sustainability commitment
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 31
ER  -

TY  - CONF
AU  - Tan, Y.S.
AU  - Teo Huiying, N.A.
AU  - Zhe Ghe, E.E.
AU  - Yi Fong, J.Z.
AU  - Wang, Z.
TI  - Video Sentiment Analysis for Child Safety
PY  - 2023
T2  - IEEE International Conference on Data Mining Workshops, ICDMW
SP  - 783
EP  - 790
DO  - 10.1109/ICDMW60847.2023.00106
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186145958&doi=10.1109%2fICDMW60847.2023.00106&partnerID=40&md5=0f602a51a98f221895626020c6074670
AB  - The proliferation of online video content underscores the critical need for effective sentiment analysis, particularly in safeguarding children from potentially harmful material. This research addresses this concern by presenting a multimodal analysis method for assessing video sentiment, categorizing it as either positive (child-friendly) or negative (potentially harmful). This method leverages three key components: text analysis, facial expression analysis, and audio analysis, including music mood analysis, resulting in a comprehensive sentiment assessment. Our evaluation results validate the effectiveness of this approach, making significant contributions to the field of video sentiment analysis and bolstering child safety measures. This research serves as a valuable resource for those seeking to employ sentiment analysis to protect children from harmful content within the dynamic landscape of video content. Furthermore, our work offers insights into the current state of the art, highlighting the recent advancements, possible improvements, and future directions in video sentiment analysis. © 2023 IEEE.
KW  - audio analysis
KW  - child safety
KW  - facial expression analysis
KW  - text analysis
KW  - video sentiment analysis
KW  - Audio acoustics
KW  - Modal analysis
KW  - Safety engineering
KW  - Video recording
KW  - Analysis method
KW  - Audio analysis
KW  - Child safety
KW  - Facial expressions analysis
KW  - Multimodal analysis
KW  - Online video
KW  - Sentiment analysis
KW  - Text analysis
KW  - Video contents
KW  - Video sentiment analyse
KW  - Sentiment analysis
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Cortinas-Lorenzo, K.
AU  - Lacey, G.
TI  - Toward Explainable Affective Computing: A Review
PY  - 2024
T2  - IEEE Transactions on Neural Networks and Learning Systems
VL  - 35
IS  - 10
SP  - 13101
EP  - 13121
DO  - 10.1109/TNNLS.2023.3270027
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161062825&doi=10.1109%2fTNNLS.2023.3270027&partnerID=40&md5=eb9177fc1d06facb35c370977d5489f9
AB  - Affective computing has an unprecedented potential to change the way humans interact with technology. While the last decades have witnessed vast progress in the field, multimodal affective computing systems are generally black box by design. As affective systems start to be deployed in real-world scenarios, such as education or healthcare, a shift of focus toward improved transparency and interpretability is needed. In this context, how do we explain the output of affective computing models? and how to do so without limiting predictive performance? In this article, we review affective computing work from an explainable AI (XAI) perspective, collecting and synthesizing relevant papers into three major XAI approaches: premodel (applied before training), in-model (applied during training), and postmodel (applied after training). We present and discuss the most fundamental challenges in the field, namely, how to relate explanations back to multimodal and time-dependent data, how to integrate context and inductive biases into explanations using mechanisms such as attention, generative modeling, or graph-based methods, and how to capture intramodal and cross-modal interactions in post hoc explanations. While explainable affective computing is still nascent, existing methods are promising, contributing not only toward improved transparency but, in many cases, surpassing state-of-the-art results. Based on these findings, we explore directions for future research and discuss the importance of data-driven XAI and explanation goals, and explainee needs definition, as well as causability or the extent to which a given method leads to human understanding.  © 2012 IEEE.
KW  - Affective computing
KW  - explainable AI (XAI)
KW  - multimodal machine learning
KW  - review
KW  - Graphic methods
KW  - Job analysis
KW  - Transparency
KW  - Affective Computing
KW  - Computational modelling
KW  - Computing system
KW  - Explainable AI (XAI)
KW  - Machine-learning
KW  - Multi-modal
KW  - Multimodal machine learning
KW  - Predictive models
KW  - Task analysis
KW  - article
KW  - attention
KW  - human
KW  - human experiment
KW  - Learning systems
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 12
ER  -

TY  - CHAP
AU  - Li, Y.
AU  - Chen, K.
AU  - Zhang, J.
TI  - AI-Powered Supply Chain and Operations Management (SCOM): Capabilities and Challenges
PY  - 2025
T2  - International Series in Operations Research and Management Science
VL  - 276
SP  - 139
EP  - 165
DO  - 10.1007/978-3-031-85508-5_7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006938172&doi=10.1007%2f978-3-031-85508-5_7&partnerID=40&md5=db7e4e26cbe4315815fa3623317bd2fb
AB  - Artificial intelligence (AI) has emerged as one of the most transformative technologies that revolutionize various sectors including supply chain and operations management (SCOM). AI’s ability to process large datasets, generate predictions, and optimize decision-making processes offers significant operational advantages. However, the integration of AI also introduces challenges, particularly from the aspects of data management and integration, operational and technical challenges in decision-making, and relational and ethical considerations. The enhanced interconnectedness, when combined with AI-powered automation, also significantly amplifies the ripple effect throughout the supply chain when disruptions occur. This chapter explores the capabilities and challenges of AI in SCOM, focusing on data management, decision-making under uncertainties, and buyer-supplier relationship management in the context of resilience and ripple effect. Through a systematic review of the literature, we aim to provide a comprehensive understanding of AI’s role in SCOM and present frameworks for managing the complexities and risks associated with AI-powered operations. © Springer Nature Switzerland AG 2025.
KW  - Artificial intelligence (AI)
KW  - Capabilities
KW  - Challenges
KW  - Operations management
KW  - Ripple effect
KW  - Supply chain management
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CHAP
AU  - Pinto, J.D.
AU  - Paquette, L.
TI  - Deep Learning for Educational Data Science
PY  - 2024
T2  - Postdigital Science and Education (Netherlands)
VL  - Part F3835
SP  - 111
EP  - 139
DO  - 10.1007/978-3-031-64487-0_6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212483900&doi=10.1007%2f978-3-031-64487-0_6&partnerID=40&md5=195821274fbdb496bcb5e849ec2852ce
AB  - With the ever-growing presence of deep artificial neural networks in every facet of modern life, a growing body of researchers in educational data science—a field consisting of various interrelated research communities—have turned their attention to leveraging these powerful algorithms within the education domain. Use cases range from advanced knowledge tracing models that can leverage open-ended student essays or snippets of code to automatic affect and behavior detectors that can identify when a student is frustrated or aimlessly trying to solve problems unproductively—and much more. This chapter provides a brief introduction to deep learning, describes some of its advantages and limitations, presents a survey of its many uses in education, and discusses how it may further shape the field of educational data science. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.
KW  - AI educational applications
KW  - AI use cases
KW  - Data-driven insights
KW  - Deep learning
KW  - Educational data science
KW  - Machine learning
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Li, Y.
AU  - Guangwen, Z.
TI  - Balancing innovation and accountability: AI’s transformative influence on logistics in G20 nations
PY  - 2025
T2  - Humanities and Social Sciences Communications
VL  - 12
IS  - 1
C7  - 750
DO  - 10.1057/s41599-025-05090-6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007073244&doi=10.1057%2fs41599-025-05090-6&partnerID=40&md5=dc3fe411376531db0585b0d4d961e1dc
AB  - This study examines the impact of artificial intelligence (AI) on the logistics performance of G20 countries from 2010 to 2022, with a focus on the moderating effect of accountability, within the framework of Dynamic Capability Theory. Utilizing panel-corrected standard errors (PCSEs) for benchmark regression and two-step System Generalized Method of Moments (GMM) for robustness checks and endogeneity analysis, we assess the relationship between AI investments and logistics efficiency. Our findings reveal that AI positively influences the logistics performance across different economic contexts, with significant effects observed in both developed and developing countries. The robustness analysis, using the number of AI startups as an alternative measure, confirms these results. Moreover, our heterogeneity analysis highlights that high AI funding levels significantly enhance logistics performance, while the impact is negligible in countries with lower AI investments. The analysis of the moderating effect of accountability indicates that while governance improvements contribute positively to logistics efficiency, they may reduce the direct impact of AI investments due to regulatory challenges. These findings imply that policymakers should focus on fostering AI investments and enhancing governance structures to optimize logistics performance, particularly in regions with low AI penetration. Our study underscores the critical role of AI and accountability in advancing global logistics performance. © The Author(s) 2025.
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Zengeya, T.
AU  - Vincent Fonou-Dombeu, J.
TI  - A Review of State of the Art Deep Learning Models for Ontology Construction
PY  - 2024
T2  - IEEE Access
VL  - 12
SP  - 82354
EP  - 82383
DO  - 10.1109/ACCESS.2024.3406426
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194862756&doi=10.1109%2fACCESS.2024.3406426&partnerID=40&md5=61ebe7a005ff9c3b7a93f27e7ca334e7
AB  - Researchers are working towards automation of ontology construction to manage the ever-growing data on the web. Currently, there is a shift from the use of machine learning techniques towards exploration of deep learning models for ontology construction. Deep learning model are capable of extracting terms, entities, relations, and classifications, and perform axiom learning from the underutilized richness of web-based knowledge. There has been remarkable progress in automatic ontology creation using deep learning models since they can perform word embedding, long-term dependency acquisition, concept extraction from large corpora, and inference of abstracted relationships based on broad corpora. Despite their emerging importance, deep learning models remain underutilized in ontology construction, and there is no comprehensive review of their application in ontology learning. This paper presents a comprehensive review of existing deep-learning models for the construction of ontologies, the strength and the weaknesses presented by the deep learning models for ontology learning as well as promising directions to achieve a more robust deep learning models. The Deep Learning models reviewed include Recurrent Neural Networks (RNNs), Convolutional Neural Networks (CNNs), Long-Short Term Memory (LSTMs), and Gated Recurrent Unit (GRU) as well as their ensembles. While these traditional deep learning models have achieved great success, one of their limitations is that they struggle to understand the meaning and order of data in sequences. CNNs and RNN-based models such as LSTMs and GRUs can be computationally expensive due to their large number of parameters or complex gating mechanisms. Furthermore, RNN models suffer from vanishing gradients, making it difficult to learn long-term relationships in sequences. Additionally, RNN-based models process information sequentially, limiting their ability to take advantage of powerful parallel computing hardware, slowing down training and inference, especially for long sequences. Consequently, there has been a shift towards Generative Pre-Trained (GPT) models and Bidirectional Encoder Representations from Transformers (BERT) models. This paper also reviewed the GPT-3, GPT-4, and the BERT models for extracting terms, entities, relations, and classifications. While GPT models excel in contextual understanding and flexibility, they fall short when handling domain-specific terminology and disambiguating complex relationships. Fine-tuning and domain-specific training data could minimize these shortcomings, and further enhance the performance of GPT in term and relation extraction tasks. On the other hand, the BERT models excel in comprehending context-heavy texts, but struggles with higher-level abstraction and inference tasks due to a lack of explicit semantic knowledge, thus necessitating inference for unspecified relationships. The paper recommends further research on deep learning models for ontology alignment and merging. Also, the ensembling of deep learning models and the use of domain-specific knowledge for ontology learning require further research for ontology construction.  © 2013 IEEE.
KW  - axiom learning
KW  - Deep learning
KW  - ontology construction
KW  - ontology learning
KW  - relation discovery
KW  - term extraction
KW  - Complex networks
KW  - Extraction
KW  - Information retrieval
KW  - Learning algorithms
KW  - Learning systems
KW  - Natural language processing systems
KW  - Ontology
KW  - Recurrent neural networks
KW  - Axiom learning
KW  - Computational modelling
KW  - Deep learning
KW  - Machine assisted indexing
KW  - Machine-learning
KW  - Ontology construction
KW  - Ontology learning
KW  - Ontology's
KW  - Relation discovery
KW  - Term extraction
KW  - Data mining
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Kotsiantis, S.
AU  - Verykios, V.
AU  - Tzagarakis, M.
TI  - AI-Assisted Programming Tasks Using Code Embeddings and Transformers
PY  - 2024
T2  - Electronics (Switzerland)
VL  - 13
IS  - 4
C7  - 767
DO  - 10.3390/electronics13040767
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187279862&doi=10.3390%2felectronics13040767&partnerID=40&md5=0a633ab6517ef2e40906d0eac3176645
AB  - This review article provides an in-depth analysis of the growing field of AI-assisted programming tasks, specifically focusing on the use of code embeddings and transformers. With the increasing complexity and scale of software development, traditional programming methods are becoming more time-consuming and error-prone. As a result, researchers have turned to the application of artificial intelligence to assist with various programming tasks, including code completion, bug detection, and code summarization. The utilization of artificial intelligence for programming tasks has garnered significant attention in recent times, with numerous approaches adopting code embeddings or transformer technologies as their foundation. While these technologies are popular in this field today, a rigorous discussion, analysis, and comparison of their abilities to cover AI-assisted programming tasks is still lacking. This article discusses the role of code embeddings and transformers in enhancing the performance of AI-assisted programming tasks, highlighting their capabilities, limitations, and future potential in an attempt to outline a future roadmap for these specific technologies. © 2024 by the authors.
KW  - AI-assisted programming
KW  - code embeddings
KW  - transformers
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Šola, H.M.
AU  - Qureshi, F.H.
AU  - Khawaja, S.
TI  - Human-Centred Design Meets AI-Driven Algorithms: Comparative Analysis of Political Campaign Branding in the Harris–Trump Presidential Campaigns
PY  - 2025
T2  - Informatics
VL  - 12
IS  - 1
C7  - 30
DO  - 10.3390/informatics12010030
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001167561&doi=10.3390%2finformatics12010030&partnerID=40&md5=0f14f70615abd920b350ecb8290138fb
AB  - This study compared the efficacy of AI neuroscience tools versus traditional design methods in enhancing viewer engagement with political campaign materials from the Harris–Trump presidential campaigns. Utilising a mixed-methods approach, we integrated quantitative analysis employing AI’s eye-tracking consumer behaviour metrics (Predict, trained on 180,000 screenings) with an AI-LLM neuroscience-based marketing assistant (CoPilot), with 67,429 areas of interest (AOIs). The original flyer, from an Al Jazeera article, served as the baseline. Professional graphic designers created three redesigned versions, and one was done using recommendations from CoPilot. Metrics including total attention, engagement, start attention, end attention, and percentage seen were evaluated across 13–14 areas of interest (AOIs) for each design. Results indicated that human-enhanced Design 1 with AI eye-tracking achieved superior overall performance across multiple metrics. While the AI-enhanced Design 3 demonstrated strengths in optimising specific AOIs, it did not consistently outperform human-touched designs, particularly in text-heavy areas. The study underscores the complex interplay between neuroscience AI algorithms and human-centred design in political campaign branding, offering valuable insights for future research in neuromarketing and design communication strategies. Python, Pandas, Matplotlib, Seaborn, Spearman correlation, and the Kruskal–Wallis H-test were employed for data analysis and visualisation. © 2025 by the authors.
KW  - AI eye-tracking
KW  - CoPilot
KW  - Harris vs. Trump
KW  - LLM
KW  - neurodesign
KW  - neuromarketing
KW  - political neurodesign
KW  - predict
KW  - predicting human behaviour
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Muñoz, S.
AU  - Iglesias, C.A.
TI  - A text classification approach to detect psychological stress combining a lexicon-based feature framework with distributional representations
PY  - 2022
T2  - Information Processing and Management
VL  - 59
IS  - 5
C7  - 103011
DO  - 10.1016/j.ipm.2022.103011
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133235759&doi=10.1016%2fj.ipm.2022.103011&partnerID=40&md5=bf505d72594f2ba71d2a41e61441bcdd
AB  - Nowadays, stress has become a growing problem for society due to its high impact on individuals but also on health care systems and companies. In order to overcome this problem, early detection of stress is a key factor. Previous studies have shown the effectiveness of text analysis in the detection of sentiment, emotion, and mental illness. However, existing solutions for stress detection from text are focused on a specific corpus. There is still a lack of well-validated methods that provide good results in different datasets. We aim to advance state of the art by proposing a method to detect stress in textual data and evaluating it using multiple public English datasets. The proposed approach combines lexicon-based features with distributional representations to enhance classification performance. To help organize features for stress detection in text, we propose a lexicon-based feature framework that exploits affective, syntactic, social, and topic-related features. Also, three different word embedding techniques are studied for exploiting distributional representation. Our approach has been implemented with three machine learning models that have been evaluated in terms of performance through several experiments. This evaluation has been conducted using three public English datasets and provides a baseline for other researchers. The obtained results identify the combination of FastText embeddings with a selection of lexicon-based features as the best-performing model, achieving F-scores above 80%. © 2022 The Author(s)
KW  - Affective computing
KW  - Distributional representations
KW  - Stress detection
KW  - Stress framework
KW  - Text classification
KW  - Classification (of information)
KW  - Diseases
KW  - Embeddings
KW  - Feature extraction
KW  - Text processing
KW  - Affective Computing
KW  - Classification approach
KW  - Distributional representation
KW  - Healthcare systems
KW  - High impact
KW  - Lexicon-based
KW  - Psychological stress
KW  - Stress detection
KW  - Stress framework
KW  - Text classification
KW  - Stresses
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 50
ER  -

TY  - JOUR
AU  - Mastropaolo, A.
AU  - Escobar-Velásquez, C.
AU  - Linares-Vásquez, M.
TI  - From Triumph to Uncertainty: The Journey of Software Engineering in the AI Era
PY  - 2025
T2  - ACM Transactions on Software Engineering and Methodology
VL  - 34
IS  - 5
C7  - 131
DO  - 10.1145/3709360
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007504743&doi=10.1145%2f3709360&partnerID=40&md5=943930494791f82c75a56715ff32df82
AB  - Over the last 10 years, the realm of AI has experienced an explosion of revolutionary breakthroughs, transforming what seemed like a far-off dream into a reality that is now deeply embedded in our everyday lives. AI’s widespread impact is revolutionizing virtually all aspects of human life, and software engineering (SE) is no exception. As we explore this changing landscape, we are faced with questions about what the future holds for SE and how AI will reshape the roles, duties, and methodologies within the field. The introduction of these groundbreaking technologies highlights the inevitable shift toward a new paradigm, suggesting a future where AI’s capabilities may redefine the boundaries of SE, potentially even more than human input. In this article, we aim at outlining the key elements that, based on our expertise, are vital for the smooth integration of AI into SE, all while preserving the intrinsic human creativity that has been the driving force behind the field. First, we provide a brief description of SE and AI evolution. Afterward, we delve into the intricate interplay between AI-driven automation and human innovation, exploring how these two components can work together to advance SE practices to new methods and standards. © 2025 Association for Computing Machinery. All rights reserved.
KW  - AI4SE
KW  - Artificial Intelligence
KW  - History
KW  - LLM4Code
KW  - Software engineering
KW  - Application programs
KW  - Embedded software
KW  - Human engineering
KW  - Software design
KW  - Software packages
KW  - Software quality
KW  - Verification
KW  - AI4SE
KW  - Driving forces
KW  - Human creativity
KW  - Human lives
KW  - Key elements
KW  - Llm4code
KW  - Software engineering practices
KW  - Two-component
KW  - Uncertainty
KW  - Computer operating systems
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Du, K.
AU  - Xing, F.
AU  - Cambria, E.
TI  - Incorporating Multiple Knowledge Sources for Targeted Aspect-based Financial Sentiment Analysis
PY  - 2023
T2  - ACM Transactions on Management Information Systems
VL  - 14
IS  - 3
C7  - 23
DO  - 10.1145/3580480
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163219274&doi=10.1145%2f3580480&partnerID=40&md5=fb4f9a2e82dded40e3fdfdffd4ab451d
AB  - Combining symbolic and subsymbolic methods has become a promising strategy as research tasks in AI grow increasingly complicated and require higher levels of understanding. Targeted Aspect-based Financial Sentiment Analysis (TABFSA) is an example of such complicated tasks, as it involves processes like information extraction, information specification, and domain adaptation. However, little is known about the design principles of such hybrid models leveraging external lexical knowledge. To fill this gap, we define anterior, parallel, and posterior knowledge integration and propose incorporating multiple lexical knowledge sources strategically into the fine-Tuning process of pre-Trained transformer models for TABFSA. Experiments on the Financial Opinion mining and Question Answering challenge (FiQA) Task 1 and SemEval 2017 Task 5 datasets show that the knowledge-enabled models systematically improve upon their plain deep learning counterparts, and some outperform state-of-The-Art results reported in terms of aspect sentiment analysis error. We discover that parallel knowledge integration is the most effective and domain-specific lexical knowledge is more important according to our ablation analysis. © 2023 Copyright held by the owner/author(s).
KW  - Additional Key Words and PhrasesFinancial sentiment analysis
KW  - deep learning
KW  - knowledge enabled system
KW  - neural networks
KW  - transformer models
KW  - Deep learning
KW  - Finance
KW  - Knowledge management
KW  - Learning systems
KW  - Additional key word and phrasesfinancial sentiment analyse
KW  - Deep learning
KW  - Key words
KW  - Knowledge enabled system
KW  - Knowledge integration
KW  - Knowledge sources
KW  - Lexical knowledge
KW  - Neural-networks
KW  - Sentiment analysis
KW  - Transformer modeling
KW  - Sentiment analysis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 32
ER  -

TY  - JOUR
AU  - Fu, D.S.
AU  - Huang, J.
AU  - Hazra, D.
AU  - Dwivedi, A.K.
AU  - Gupta, S.K.
AU  - Shivahare, B.D.
AU  - Garg, D.
TI  - Enhancing sports image data classification in federated learning through genetic algorithm-based optimization of base architecture
PY  - 2024
T2  - PLoS ONE
VL  - 19
IS  - 7 July
C7  - e0303462
DO  - 10.1371/journal.pone.0303462
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198602542&doi=10.1371%2fjournal.pone.0303462&partnerID=40&md5=2c451c3a413ff4b7cdab29cbb4bab6bf
AB  - Nowadays, federated learning is one of the most prominent choices for making decisions. A significant benefit of federated learning is that, unlike deep learning, it is not necessary to share data samples with the model owner. The weight of the global model in traditional federated learning is created by averaging the weights of all clients or sites. In the proposed work, a novel method has been discussed to generate an optimized base model without hampering its performance, which is based on a genetic algorithm. Chromosome representation, crossover, and mutation-all the intermediate operations of the genetic algorithm have been illustrated with useful examples. After applying the genetic algorithm, there is a significant improvement in inference time and a huge reduction in storage space. Therefore, the model can be easily deployed on resource-constrained devices. For the experimental work, sports data has been used in balanced and unbalanced scenarios with various numbers of clients in a federated learning environment. In addition, we have used four famous deep learning architectures, such as AlexNet, VGG19, ResNet50, and EfficientNetB3, as the base model. We have achieved 92.34% accuracy with 9 clients in the balanced data set by using EfficientNetB3 as the base model using a GA-based approach. Moreover, after applying the genetic algorithm to optimize EfficientNetB3, there is an improvement in inference time and storage space by 20% and 2.35%, respectively. Copyright: © 2024 Fu et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
KW  - Algorithms
KW  - Deep Learning
KW  - Humans
KW  - Neural Networks, Computer
KW  - Sports
KW  - adult
KW  - article
KW  - clinical article
KW  - controlled study
KW  - data classification
KW  - deep learning
KW  - federated learning
KW  - genetic algorithm
KW  - human
KW  - learning environment
KW  - open access publishing
KW  - sport
KW  - algorithm
KW  - artificial neural network
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Callahan, T.J.
AU  - Tripodi, I.J.
AU  - Pielke-Lombardo, H.
AU  - Hunter, L.E.
TI  - Knowledge-Based Biomedical Data Science
PY  - 2020
T2  - Annual Review of Biomedical Data Science
VL  - 3
SP  - 23
EP  - 41
DO  - 10.1146/annurev-biodatasci-010820-091627
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097131994&doi=10.1146%2fannurev-biodatasci-010820-091627&partnerID=40&md5=459a932cacf64a47dbe29017f319dfaa
AB  - Knowledge-based biomedical data science involves the design and implementation of computer systems that act as if they knew about biomedicine. Such systems depend on formally represented knowledge in computer systems, often in the form of knowledge graphs. Here we survey recent progress in systems that use formally represented knowledge to address data science problems in both clinical and biological domains, as well as progress on approaches for creating knowledge graphs. Major themes include the relationships between knowledge graphs and machine learning, the use of natural language processing to construct knowledge graphs, and the expansion of novel knowledge-based approaches to clinical and biological domains. © Annual Review of Biomedical Data Science. All Rights Reserved.
KW  - knowledge discovery
KW  - knowledge graph
KW  - knowledge graph embeddings
KW  - natural language processing
KW  - ontology
KW  - SemanticWeb
KW  - article
KW  - data science
KW  - embedding
KW  - human
KW  - knowledge discovery
KW  - machine learning
KW  - natural language processing
KW  - ontology
KW  - semantic web
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 36
ER  -

TY  - JOUR
AU  - Barcina-Blanco, M.
AU  - Lobo, J.L.
AU  - Garcia-Bringas, P.
AU  - Del Ser, J.
TI  - Managing the unknown in machine learning: Definitions, related areas, recent advances, and prospects
PY  - 2024
T2  - Neurocomputing
VL  - 599
C7  - 128073
DO  - 10.1016/j.neucom.2024.128073
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196768695&doi=10.1016%2fj.neucom.2024.128073&partnerID=40&md5=920d13552411d4ce172446e92f9b2047
AB  - In the rapidly evolving domain of machine learning, the ability to adapt to unforeseen circumstances and novel data types is of paramount importance. The deployment of Artificial Intelligence is progressively aimed at more realistic and open scenarios where data, tasks, and conditions are variable and not fully predetermined, and therefore where a closed set assumption cannot be hold. In such evolving environments, machine learning is asked to be autonomous, continuous, and adaptive, requiring effective management of uncertainty and the unknown to fulfill expectations. In response, there is a vigorous effort to develop a new generation of models, which are characterized by enhanced autonomy and a broad capacity to generalize, enabling them to perform effectively across a wide range of tasks. The field of machine learning in open set environments poses many challenges and also brings together different paradigms, some traditional but others emerging, where the overlapping and confusion between them makes it difficult to distinguish them or give them the necessary relevance. This work delves into the frontiers of methodologies that thrive in these open set environments, by identifying common practices, limitations, and connections between the paradigms Open-Ended Learning, Open-World Learning, Open Set Recognition, and other related areas such as Continual Learning, Out-of-Distribution detection, Novelty Detection, and Active Learning. We seek to easy the understanding of these fields and their common roots, uncover open problems and suggest several research directions that may motivate and articulate future efforts towards more robust and autonomous systems. © 2024 The Author(s)
KW  - AI alignment
KW  - Open set environments
KW  - Open set recognition
KW  - Open-ended learning
KW  - Open-world learning
KW  - Uncertainty
KW  - AI alignment
KW  - Condition
KW  - Datatypes
KW  - Machine-learning
KW  - Open set environment
KW  - Open set recognition
KW  - Open world
KW  - Open-ended learning
KW  - Open-world learning
KW  - Uncertainty
KW  - artificial intelligence
KW  - controlled study
KW  - learning
KW  - machine learning
KW  - short survey
KW  - uncertainty
KW  - Machine learning
M3  - Short survey
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - CONF
AU  - Meyer-Vitali, A.
AU  - Mulder, W.
TI  - Human-AI Engineering for Adults
PY  - 2024
T2  - Frontiers in Artificial Intelligence and Applications 
VL  - 386
SP  - 228
EP  - 240
DO  - 10.3233/FAIA240197
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198730479&doi=10.3233%2fFAIA240197&partnerID=40&md5=082331af57f0b212d953512b8baee707
AB  - The engineering of reliable and trustworthy AI systems needs to mature. While facing unprecedented challenges, there is much to be learned from other engineering disciplines. We focus on the five pillars of (i) Models & Explanations, (ii) Causality & Grounding, (iii) Modularity & Compositionality, (iv) Human Agency & Oversight, and (v) Maturity Models. Based on these pillars, a new AI engineering discipline might emerge, which we aim to support using corresponding methods and tools for 'Trust by Design'. A use case concerning mobility and energy consumption in an urban context is discussed. © 2024 The Authors.
KW  - Agency
KW  - Artificial Intelligence
KW  - Causality
KW  - Context-Aware Pervasive Systems
KW  - Explainability
KW  - Human-Computer Interaction
KW  - Maturity Model
KW  - Models
KW  - Modules
KW  - Multi-Agent Systems
KW  - Robustness
KW  - Smart Cities
KW  - Software Engineering
KW  - Trust
KW  - Energy utilization
KW  - Intelligent agents
KW  - Multi agent systems
KW  - Robustness (control systems)
KW  - Smart city
KW  - Agency
KW  - AI systems
KW  - Causality
KW  - Context-aware pervasive systems
KW  - Engineering disciplines
KW  - Explainability
KW  - Maturity model
KW  - Module
KW  - Robustness
KW  - Trust
KW  - Human computer interaction
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Verghese, M.
AU  - Atkeson, C.
TI  - Using Memory-Based Learning to Solve Tasks with State-Action Constraints
PY  - 2023
T2  - Proceedings - IEEE International Conference on Robotics and Automation
VL  - 2023-May
SP  - 9558
EP  - 9565
DO  - 10.1109/ICRA48891.2023.10161154
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168710425&doi=10.1109%2fICRA48891.2023.10161154&partnerID=40&md5=bea52d51e5ad02fd451ef9784b5761c0
AB  - Tasks where the set of possible actions depend discontinuously on the state pose a significant challenge for current reinforcement learning algorithms. For example, a locked door must be first unlocked, and then the handle turned before the door can be opened. The sequential nature of these tasks makes obtaining final rewards difficult, and transferring information between task variants using continuous learned values such as weights rather than discrete symbols can be inefficient. Our key insight is that agents that act and think symbolically are often more effective in dealing with these tasks. We propose a memory-based learning approach that leverages the symbolic nature of constraints and temporal ordering of actions in these tasks to quickly acquire and transfer high-level information. We evaluate the performance of memory-based learning on both real and simulated tasks with approximately discontinuous constraints between states and actions, and show our method learns to solve these tasks an order of magnitude faster than both model-based and model-free deep reinforcement learning methods. © 2023 IEEE.
KW  - Learning algorithms
KW  - Learning systems
KW  - Reinforcement learning
KW  - 'current
KW  - Constraint ordering
KW  - High-level information
KW  - Higher-level information
KW  - Learning approach
KW  - Memory-based learning
KW  - Ordering of actions
KW  - Performance
KW  - Reinforcement learning algorithms
KW  - Temporal ordering
KW  - Deep learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Ye, S.
AU  - Chen, D.
AU  - Han, S.
AU  - Liao, J.
TI  - 3D Question Answering
PY  - 2022
T2  - IEEE Transactions on Visualization and Computer Graphics
VL  - 30
IS  - 3
SP  - 1772
EP  - 1786
DO  - 10.1109/TVCG.2022.3225327
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144017012&doi=10.1109%2fTVCG.2022.3225327&partnerID=40&md5=a4f916d07b36e8c929a220eaa20e8fa5
AB  - Visual question answering (VQA) has experienced tremendous progress in recent years. However, most efforts have only focused on 2D image question-answering tasks. In this article, we extend VQA to its 3D counterpart, 3D question answering (3DQA), which can facilitate a machine’s perception of 3D real-world scenarios. Unlike 2D image VQA, 3DQA takes the color point cloud as input and requires both appearance and 3D geometrical comprehension to answer the 3D-related questions. To this end, we propose a novel transformer-based 3DQA framework “3DQA-TR”, which consists of two encoders to exploit the appearance and geometry information, respectively. Finally, the multi-modal information about the appearance, geometry, and linguistic question can attend to each other via a 3D-linguistic Bert to predict the target answers. To verify the effectiveness of our proposed 3DQA framework, we further develop the first 3DQA dataset “ScanQA”, which builds on the ScanNet dataset and contains over 10 K question-answer pairs for 806 scenes. To the best of our knowledge, ScanQA is the first large-scale dataset with natural-language questions and free-form answers in 3D environments that is fully human-annotated. We also use several visualizations and experiments to investigate the astonishing diversity of the collected questions and the significant differences between this task from 2D VQA and 3D captioning. Extensive experiments on this dataset demonstrate the obvious superiority of our proposed 3DQA framework over state-of-the-art VQA frameworks and the effectiveness of our major designs. Our code and dataset will be made publicly available to facilitate research in this direction. © 2022 IEEE.
KW  - Point cloud
KW  - scene understanding
KW  - Geometry
KW  - Large dataset
KW  - Natural language processing systems
KW  - 2D images
KW  - Color points
KW  - Geometry information
KW  - Linguistic questions
KW  - Multi-modal information
KW  - Point-clouds
KW  - Question Answering
KW  - Question Answering Task
KW  - Real-world scenario
KW  - Scene understanding
KW  - article
KW  - comprehension
KW  - geometry
KW  - human
KW  - human experiment
KW  - language
KW  - perception
KW  - three-dimensional imaging
KW  - Linguistics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 18
ER  -

TY  - JOUR
AU  - Mathew, D.E.
AU  - Ebem, D.U.
AU  - Ikegwu, A.C.
AU  - Ukeoma, P.E.
AU  - Dibiaezue, N.F.
TI  - Recent Emerging Techniques in Explainable Artificial Intelligence to Enhance the Interpretable and Understanding of AI Models for Human
PY  - 2025
T2  - Neural Processing Letters
VL  - 57
IS  - 1
C7  - 16
DO  - 10.1007/s11063-025-11732-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000029140&doi=10.1007%2fs11063-025-11732-2&partnerID=40&md5=3a1ed8bd9b042b635ff34b70143627b4
AB  - Recent advancements in Explainable Artificial Intelligence (XAI) aim to bridge the gap between complex artificial intelligence (AI) models and human understanding, fostering trust and usability in AI systems. However, challenges persist in comprehensively interpreting these models, hindering their widespread adoption. This study addresses these challenges by exploring recently emerging techniques in XAI. The primary problem addressed is the lack of transparency and interpretability in AI models to humanity for institution-wide use, which undermines user trust and inhibits their integration into critical decision-making processes. Through an in-depth review, this study identifies the objectives of enhancing the interpretability of AI models and improving human understanding of their decision-making processes. Various methodological approaches, including post-hoc explanations, model transparency methods, and interactive visualization techniques, are investigated to elucidate AI model behaviours. We further present techniques and methods to make AI models more interpretable and understandable to humans including their strengths and weaknesses to demonstrate promising advancements in model interpretability, facilitating better comprehension of complex AI systems by humans. In addition, we provide the application of XAI in local use cases. Challenges, solutions, and open research directions were highlighted to clarify these compelling XAI utilization challenges. The implications of this research are profound, as enhanced interpretability fosters trust in AI systems across diverse applications, from healthcare to finance. By empowering users to understand and scrutinize AI decisions, these techniques pave the way for more responsible and accountable AI deployment. © The Author(s) 2025.
KW  - AI models
KW  - AI use cases
KW  - Artificial intelligence
KW  - Explainable AI
KW  - Interpretable AI
KW  - Review
KW  - Artificial intelligence model
KW  - Artificial intelligence systems
KW  - Artificial intelligence use case
KW  - Decision-making process
KW  - Explainable artificial intelligence
KW  - Human understanding
KW  - Intelligence models
KW  - Interpretability
KW  - Interpretable artificial intelligence
KW  - Model understanding
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - CONF
AU  - Chuganskaya, A.A.
AU  - Kovalev, A.K.
AU  - Panov, A.
TI  - The Problem of Concept Learning and Goals of Reasoning in Large Language Models
PY  - 2023
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
VL  - 14001 LNAI
SP  - 661
EP  - 672
DO  - 10.1007/978-3-031-40725-3_56
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172237038&doi=10.1007%2f978-3-031-40725-3_56&partnerID=40&md5=f32df16282c7177f36ec09120a1a4e07
AB  - Modern large language models (LLMs) show good performance in the zero-shot or few-shot learning. This ability ability is a significant result even on tasks for which the models have not been trained is in part due to the fact that by learning from textual internet-scale data, such models build a semblance of a model of the world. However, the question of whether the entities on which that the model operates are concepts in the psychological sense remains open. Relying on conceptual reasoning schemes allows to increase the safety of models in solving complex problems. To address this question, we propose to use standard psychodiagnostic techniques to assess the quality of conceptual thinking of models. We test this hypothesis, by conducting experiments on a dataset adapted for LLMs from the psychological techniques of Kettel and Rubinstein and comparing the effectiveness of each of them. In this paper, we have shown that it is possible to distinguish several types of model errors in incorrect answers to standard tasks on conceptual thinking and to evaluate the type according to the classifications of distortions of conceptual thinking adopted in cultural and historical approaches in psychology. This makes it possible to use the tool of psychodiagnostic techniques not only to evaluate the effectiveness of models, but also to develop training procedures based on such tasks. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Concept learning
KW  - Large language models
KW  - Psychology of thinking
KW  - Purpose of the activity
KW  - Sign-based world model
KW  - Learning systems
KW  - Statistical tests
KW  - Zero-shot learning
KW  - Complex problems
KW  - Concept learning
KW  - Language model
KW  - Large language model
KW  - Performance
KW  - Psychology of thinking
KW  - Purpose of the activity
KW  - Reasoning schemes
KW  - Sign-based world model
KW  - World model
KW  - Computational linguistics
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - CONF
AU  - Giacobbe, M.
AU  - Kroening, D.
AU  - Parsert, J.
TI  - Neural termination analysis
PY  - 2022
T2  - ESEC/FSE 2022 - Proceedings of the 30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering
SP  - 633
EP  - 645
DO  - 10.1145/3540250.3549120
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143085804&doi=10.1145%2f3540250.3549120&partnerID=40&md5=4b9baf09dec270ff0032bf140c4c9ea7
AB  - We introduce a novel approach to the automated termination analysis of computer programs: we use neural networks to represent ranking functions. Ranking functions map program states to values that are bounded from below and decrease as a program runs; the existence of a ranking function proves that the program terminates. We train a neural network from sampled execution traces of a program so that the network's output decreases along the traces; then, we use symbolic reasoning to formally verify that it generalises to all possible executions. Upon the affirmative answer we obtain a formal certificate of termination for the program, which we call a neural ranking function. We demonstrate that, thanks to the ability of neural networks to represent nonlinear functions, our method succeeds over programs that are beyond the reach of state-of-the-art tools. This includes programs that use disjunctions in their loop conditions and programs that include nonlinear expressions.  © 2022 ACM.
KW  - Artificial Intelligence and Machine Learning for Software Engineering
KW  - Automated Reasoning
KW  - Computer-aided Verification
KW  - Formal Methods
KW  - Ranking Function Synthesis
KW  - Termination Analysis
KW  - Formal verification
KW  - Information retrieval
KW  - Machine learning
KW  - Artificial intelligence and machine learning for software engineering
KW  - Artificial intelligence learning
KW  - Automated reasoning
KW  - Automated termination
KW  - Computer-aided verifications
KW  - Machine-learning
KW  - Neural-networks
KW  - Ranking function synthesis
KW  - Ranking functions
KW  - Termination analysis
KW  - Computer aided analysis
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 15
ER  -

TY  - CHAP
AU  - Jovanović, M.
AU  - Jevremović, A.
AU  - Pejović-Milovančević, M.
TI  - Intelligent Interactive Technologies for Mental Health and Well-Being
PY  - 2021
T2  - Studies in Computational Intelligence
VL  - 973
SP  - 331
EP  - 353
DO  - 10.1007/978-3-030-72711-6_18
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112017854&doi=10.1007%2f978-3-030-72711-6_18&partnerID=40&md5=784580f7035bf4b0fcec51a359636e2a
AB  - Mental healthcare has seen numerous benefits from interactive technologies and artificial intelligence. Various interventions have successfully used intelligent technologies to automate the assessment and evaluation of psychological treatments and mental well-being and functioning. These technologies include different types of robots, video games, and conversational agents. The paper critically analyzes existing solutions with the outlooks for their future. In particular, we: (i) give an overview of the technology for mental health, (ii) critically analyze the technology against the proposed criteria, and (iii) provide the design outlooks for these technologies. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Affective computing
KW  - Chatbots
KW  - Conversational agents
KW  - Digital healthcare
KW  - Human-ai interaction
KW  - Intelligent systems
KW  - Mental health
KW  - Mental well-being
KW  - Review
KW  - Robotic technologies
KW  - Survey
KW  - Video games
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Teern, A.
AU  - Elgendy, N.
AU  - Seppanen, P.
AU  - Paivarinta, T.
TI  - An Evolvable Knowledge Graph Supporting a Hybrid Intelligence Autonomous Driving System
PY  - 2025
T2  - Proceedings - 2025 IEEE 22nd International Conference on Software Architecture, ICSA-C 2025
SP  - 557
EP  - 564
DO  - 10.1109/ICSA-C65153.2025.00083
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007942400&doi=10.1109%2fICSA-C65153.2025.00083&partnerID=40&md5=ae7d0614250e1425e38647463fae0030
AB  - Route planning is influenced by various factors, with speed and distance often prioritized in map services. However, dynamic conditions such as road maintenance, weather, or accidents can significantly impact these routes. By leveraging hybrid intelligence (HI), the collaboration between human intuition and machine efficiency, we focus on supporting decision-making in autonomous and semi-autonomous driving contexts. This study explores integrating knowledge of the dynamic conditions into HI Autonomous Driving Systems (HI-ADS) within the 6G Visible Project. The findings demonstrate the potential of knowledge graphs (KGs) to enhance decision-making by integrating evolving data and ensuring adaptability to real-world driving conditions. Based on the design objectives of learning for evolvable KGs, concrete requirements for the HI-ADS KG are established. © 2025 IEEE.
KW  - autonomous driving system
KW  - hybrid intelligence
KW  - knowledge graph
KW  - route planning
KW  - Knowledge graph
KW  - Autonomous driving
KW  - Autonomous driving system
KW  - Decisions makings
KW  - Driving systems
KW  - Dynamic condition
KW  - Evolvable
KW  - Hybrid intelligence
KW  - Knowledge graphs
KW  - Map service
KW  - Route planning
KW  - Autonomous vehicles
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Zhang, J.
AU  - Li, D.
AU  - Kolesar, J.C.
AU  - Shi, H.
AU  - Piskac, R.
TI  - Automated Feedback Generation for Competition-Level Code
PY  - 2022
T2  - ACM International Conference Proceeding Series
C7  - 13
DO  - 10.1145/3551349.3560425
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146923068&doi=10.1145%2f3551349.3560425&partnerID=40&md5=43197bf36b0e3a4a5268f12c73ada2de
AB  - Competitive programming has become a popular way for programmers to test their skills. Competition-level programming problems are challenging in nature, and participants often fail to solve the problem on their first attempt. Some online platforms for competitive programming allow programmers to practice on competition-level problems, and the standard feedback for an incorrect practice submission is the first test case that the submission fails. Often, the failed test case does not provide programmers with enough information to resolve the errors in their code, and they abandon the problem after making several more unsuccessful attempts. We present Clef, the first data-driven tool that can generate feedback on competition-level code automatically by repairing programmers' incorrect submissions. The key development is that Clef can learn how to generate repairs for incorrect submissions by examining the repairs that other programmers made to their own submissions over time. Since the differences between an incorrect program and a correct program for the same task may be significant, we introduce a new data structure, merge trees, to capture the changes between submissions. Merge trees are versatile: they can encode both large algorithm-level redesigns and small statement-level alterations. We evaluated Clef on six real-world problems from Codeforces, the world's largest platform for competitive programming. Clef achieves accuracy in repairing programmers' incorrect submissions. When given incorrect submissions from programmers who never found the solution to a problem on their own, Clef repairs the users' programs of the time.  © 2022 Owner/Author.
KW  - Automated feedback generation
KW  - competitive programming
KW  - program repair
KW  - programming education
KW  - Codes (symbols)
KW  - Computer programming
KW  - Trees (mathematics)
KW  - Automated feedback
KW  - Automated feedback generation
KW  - Competition levels
KW  - Competitive programming
KW  - Data driven
KW  - Online platforms
KW  - Program repair
KW  - Programming education
KW  - Programming problem
KW  - Test case
KW  - Repair
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 8
ER  -

TY  - JOUR
AU  - Liu, W.
AU  - Daruna, A.
AU  - Patel, M.
AU  - Ramachandruni, K.
AU  - Chernova, S.
TI  - A survey of Semantic Reasoning frameworks for robotic systems
PY  - 2023
T2  - Robotics and Autonomous Systems
VL  - 159
C7  - 104294
DO  - 10.1016/j.robot.2022.104294
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141478565&doi=10.1016%2fj.robot.2022.104294&partnerID=40&md5=d73be9475ccc8bc92883bb61073ea3c3
AB  - Robots are increasingly transitioning from specialized, single-task machines to general-purpose systems that operate in diverse and dynamic environments. To address the challenges associated with operation in real-world domains, robots must effectively generalize knowledge, learn, and be transparent in their decision making. This survey examines Semantic Reasoning techniques for robotic systems, which enable robots to encode and use semantic knowledge, including concepts, facts, ideas, and beliefs about the world. Continually perceiving, understanding, and generalizing semantic knowledge allows a robot to identify the meaningful patterns shared between problems and environments, and therefore more effectively perform a wide range of real-world tasks. We identify the three common components that make up a computational Semantic Reasoning Framework: knowledge sources, computational frameworks, and world representations. We analyze the existing implementations and the key characteristics of these components, highlight the many interactions that occur between them, and examine their integration for solving robotic tasks related to five aspects of the world, including objects, spaces, agents, tasks, and actions. By analyzing the computational formulation and underlying mechanisms of existing methods, we provide a unified view of the wide range of semantic reasoning techniques and identify open areas for future research. © 2022 Elsevier B.V.
KW  - Knowledge bases
KW  - Robotics
KW  - Semantic reasoning
KW  - Decision making
KW  - Semantics
KW  - Surveys
KW  - Dynamic environments
KW  - General-purpose systems
KW  - Knowledge base
KW  - Learn+
KW  - Real world domain
KW  - Reasoning framework
KW  - Reasoning techniques
KW  - Robotic systems
KW  - Semantic reasoning
KW  - Semantics knowledge
KW  - Robots
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 14
ER  -

TY  - JOUR
AU  - Li, Z.
AU  - Wang, Z.
AU  - Wang, W.
AU  - Hung, K.
AU  - Xie, H.
AU  - Wang, F.L.
TI  - Retrieval-augmented generation for educational application: A systematic survey
PY  - 2025
T2  - Computers and Education: Artificial Intelligence
VL  - 8
C7  - 100417
DO  - 10.1016/j.caeai.2025.100417
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005954483&doi=10.1016%2fj.caeai.2025.100417&partnerID=40&md5=44cdab1b4a21b28b5f7ceb5d0dd20124
AB  - Advancements in large language models (LLMs) have transformed AI-driven education, enabling innovative applications across various learning and teaching domains. However, LLMs still face several challenges, including hallucination and static internal knowledge, which hinder their reliability in educational settings. Retrieval-Augmented Generation (RAG) enhances LLMs by retrieving relevant information from an external knowledge base and incorporating it into the LLM's generation process. This approach improves factual accuracy and enables dynamic knowledge updates, making LLMs particularly suitable for educational applications. In this paper, we comprehensively review existing research that integrates RAG into educational scenarios. We first clarify the definition and workflow of RAG, and following the indexing mechanism of RAG, we introduce different types of retrievers and generation optimization methods. As the main focus of this work, we explore the practical applications of RAG in education, covering interactive learning systems, generation and assessment of educational content, and large-scale deployment in educational ecosystems. Based on our comprehensive review, this paper discusses existing challenges and future directions, including mitigating hallucinations, ensuring the completeness and timeliness of retrieved knowledge, reducing computational costs, and enhancing multimodal support for RAG-based educational applications. © 2025 The Author(s)
KW  - Artificial intelligence in education
KW  - Educational applications
KW  - Large language models (LLMs)
KW  - Retrieval-augmented generation (RAG)
KW  - Computer aided instruction
KW  - Domain Knowledge
KW  - Educational robots
KW  - Expert systems
KW  - Interactive computer systems
KW  - Knowledge engineering
KW  - Teaching
KW  - Artificial intelligence in education
KW  - Educational Applications
KW  - Educational settings
KW  - External knowledge
KW  - Generation process
KW  - Knowledge update
KW  - Language model
KW  - Large language model
KW  - Learning and teachings
KW  - Retrieval-augmented generation
KW  - Education computing
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Strzelecki, A.
AU  - Jaciow, M.
AU  - Wolny, R.
TI  - Curiosity in Consumer Behavior: A Systematic Literature Review and Research Agenda
PY  - 2024
T2  - International Journal of Consumer Studies
VL  - 48
IS  - 6
C7  - e70001
DO  - 10.1111/ijcs.70001
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210183320&doi=10.1111%2fijcs.70001&partnerID=40&md5=a22d67ea1ba63ebc645d600e08986d40
AB  - The aim of this study is to conduct a systematic review of the literature on consumer curiosity and its impact on consumer behavior. The “Scientific Procedures and Rationales for Systematic Literature Reviews” (SPAR-4-SLR) methodology and the “Theory, Context, Characteristics, and Methodology” (TCCM) framework were employed to analyze 122 papers published between 1992 and 2024. Articles were selected from the Web of Science database using key terms related to consumer curiosity. Consumer curiosity is a complex phenomenon that influences various aspects of consumer behavior, including purchase decisions, consumer engagement, and adaptation to new technologies. Curiosity serves as a significant moderator and mediator in consumer interactions with the market, especially in the context of new technologies such as AI and VR. The findings of this review indicate a growing interest in studying consumer curiosity in recent years, as reflected by the increasing number of publications. The practical implications of the analysis are significant for various stakeholders. Businesses can leverage these findings to develop more effective marketing strategies that engage consumers by stimulating their curiosity. Understanding how curiosity influences decision-making can also aid in the development of innovative products and services that better meet consumers' unmet needs. Additionally, academic researchers can build on the theoretical frameworks related to consumer curiosity and design future research based on identified gaps. Finally, managers and marketing professionals can apply these insights to personalize shopping experiences and enhance consumer engagement, which can lead to increased brand loyalty and competitive advantage. This review emphasizes the need for further research on the role of curiosity in consumer behavior and its impact on product innovation and marketing strategies and provides recommendations for future research directions that could contribute to a deeper understanding of how curiosity shapes consumer interactions with brands and products. © 2024 The Author(s). International Journal of Consumer Studies published by John Wiley & Sons Ltd.
KW  - consumer behavior
KW  - curiosity
KW  - SPAR-4-SLR
KW  - systematic literature review
KW  - TCCM
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Lee, D.-Y.
AU  - Lee, D.-S.
AU  - Cha, Y.
AU  - Min, J.-H.
AU  - Park, Y.-S.
TI  - Data-driven models for predicting community changes in freshwater ecosystems: A review
PY  - 2023
T2  - Ecological Informatics
VL  - 77
C7  - 102163
DO  - 10.1016/j.ecoinf.2023.102163
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163820053&doi=10.1016%2fj.ecoinf.2023.102163&partnerID=40&md5=6290772e3f156fa7a8dbbe95ea2c0ecc
AB  - Freshwater ecosystems are sensitive to disturbances related to human activities, such as climate and land-use changes. To predict and understand the potential impacts of these disturbances, models can be employed. In this study, we reviewed data-based research employing models over the last three decades to predict the biological elements of freshwater ecosystems at different scales, with a focus on phytoplankton, macroinvertebrates, and fish. Specifically, we investigated existing research trends, evaluated the ability of current models to predict changes in freshwater organisms in response to environmental changes, and suggested future research directions. Among the three aquatic organisms, phytoplankton were the focus of studies related to water quality management, whereas most studies on macroinvertebrates and fish skewed toward modeling community composition changes and habitat suitability. Considering that many studies contained more than two study objects, there was a lack of research modeling future changes, such as climate change and subsequent changes in habitat conditions. Hybrid modeling methods using both correlative and mechanistic models have recently become more important, and are likely to improve modeling performance. Advanced models have the potential to significantly enhance the conservation and management of freshwater ecosystems, while also facilitating the development of effective policies that can better address the challenges faced by these ecosystems. Model uncertainty and sensitivity analysis, as well as the interpretable techniques of machine learning, also have the potential to improve model performance. This study provides valuable insights for modeling and general scientific research based on data-driven models. © 2023
KW  - Aquatic community
KW  - Artificial intelligence
KW  - Deep learning
KW  - Ecosystem management
KW  - Interpretability
KW  - Machine learning model
KW  - aquatic community
KW  - artificial intelligence
KW  - community composition
KW  - ecological modeling
KW  - ecosystem management
KW  - fish
KW  - freshwater ecosystem
KW  - literature review
KW  - machine learning
KW  - macroinvertebrate
KW  - prediction
KW  - water quality
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 16
ER  -

TY  - JOUR
AU  - Shen, Y.-Y.
AU  - Zhang, Y.-M.
AU  - Shen, Y.-F.
TI  - A Survey of Vision-based Motion Quality Assessment
ST  - 基于视觉的人体动作质量评价研究综述
PY  - 2025
T2  - Zidonghua Xuebao/Acta Automatica Sinica
VL  - 51
IS  - 2
SP  - 404
EP  - 426
DO  - 10.16383/j.aas.c230551
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219556878&doi=10.16383%2fj.aas.c230551&partnerID=40&md5=16918e526793908edf023cc498c56732
AB  - Vision-based motion quality assessment utilizes computer vision techniques to analyze the quality of individual movement behavior automatically and provide the corresponding assessments of movement quality. It has gradually become the hot issue at the intersection of the sport science and artificial intelligence, and has widely used in the fields of sporting events, athlete selection, fitness and rehabilitation. This article conducts a retrospective analysis of the involved technologies from three aspects: Data acquisition and annotation, motion feature representation, and motion quality assessment. It categorizes and compares various mainstream methods on three datasets: AQA-7, JIGSAWS, and EPIC-Skills 2018. Finally, potential future research directions are discussed. © 2025 Science Press. All rights reserved.
KW  - assessment
KW  - computer vision
KW  - data acquisition
KW  - feature representation
KW  - loss function
KW  - Motion quality
KW  - Computer vision
KW  - Jigs
KW  - Motion capture
KW  - Sports
KW  - Assessment
KW  - Assessment of movements
KW  - Computer vision techniques
KW  - Feature representation
KW  - Loss functions
KW  - Motion quality
KW  - Movement behaviour
KW  - Quality assessment
KW  - Sport science
KW  - Vision based
KW  - Motion estimation
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Hughes, L.
AU  - Dwivedi, Y.K.
AU  - Malik, T.
AU  - Shawosh, M.
AU  - Albashrawi, M.A.
AU  - Jeon, I.
AU  - Dutot, V.
AU  - Appanderanda, M.
AU  - Crick, T.
AU  - De’, R.
AU  - Fenwick, M.
AU  - Gunaratnege, S.M.
AU  - Jurcys, P.
AU  - Kar, A.K.
AU  - Kshetri, N.
AU  - Li, K.
AU  - Mutasa, S.
AU  - Samothrakis, S.
AU  - Wade, M.
AU  - Walton, P.
TI  - AI Agents and Agentic Systems: A Multi-Expert Analysis
PY  - 2025
T2  - Journal of Computer Information Systems
DO  - 10.1080/08874417.2025.2483832
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003188833&doi=10.1080%2f08874417.2025.2483832&partnerID=40&md5=60701c4db0318a5b29a05e5f0cc1f1d3
AB  - The emergence of AI agents and agentic systems represents a significant milestone in artificial intelligence, enabling autonomous systems to operate, learn, and collaborate in complex environments with minimal human intervention. This paper, drawing on multi-expert perspectives, examines the potential of AI agents and agentic systems to reshape industries by decentralizing decision-making, redefining organizational structures, and enhancing cross-functional collaboration. Specific applications include healthcare systems capable of creating adaptive treatment plans, supply chain agents that predict and address disruptions in real-time, and business process automation that reallocates tasks from humans to AI, improving efficiency and innovation. However, the integration of these systems raises critical challenges, including issues of attribution and shared accountability in decision-making, compatibility with legacy systems, and addressing biases in AI-driven processes. The paper concludes that while agentic systems hold immense promise, robust governance frameworks, cross-industry collaboration, and interdisciplinary research into ethical design are essential. Future research should explore adaptive workforce reskilling strategies, transparent accountability mechanisms, and energy-efficient deployment models to ensure ethical and scalable implementation. © 2025 International Association for Computer Information Systems.
KW  - agentic AI
KW  - agentic system
KW  - AI agents
KW  - autonomous agent
KW  - cognitive agent
KW  - intelligent agent
KW  - OpenAI operator
KW  - smart agent
KW  - virtual assistant
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Bordoloi, M.
AU  - Biswas, S.K.
TI  - Sentiment analysis: A survey on design framework, applications and future scopes
PY  - 2023
T2  - Artificial Intelligence Review
VL  - 56
IS  - 11
SP  - 12505
EP  - 12560
DO  - 10.1007/s10462-023-10442-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150428031&doi=10.1007%2fs10462-023-10442-2&partnerID=40&md5=75cae0ef8bcc4b4481c0033b876554dd
AB  - Sentiment analysis is a solution that enables the extraction of a summarized opinion or minute sentimental details regarding any topic or context from a voluminous source of data. Even though several research papers address various sentiment analysis methods, implementations, and algorithms, a paper that includes a thorough analysis of the process for developing an efficient sentiment analysis model is highly desirable. Various factors such as extraction of relevant sentimental words, proper classification of sentiments, dataset, data cleansing, etc. heavily influence the performance of a sentiment analysis model. This survey presents a systematic and in-depth knowledge of different techniques, algorithms, and other factors associated with designing an effective sentiment analysis model. The paper performs a critical assessment of different modules of a sentiment analysis framework while discussing various shortcomings associated with the existing methods or systems. The paper proposes potential multidisciplinary application areas of sentiment analysis based on the contents of data and provides prospective research directions. © 2023, The Author(s), under exclusive licence to Springer Nature B.V.
KW  - Knowledge representation
KW  - Natural language processing
KW  - Sentiment analysis
KW  - Text analysis
KW  - Classification (of information)
KW  - Data mining
KW  - Extraction
KW  - Factor analysis
KW  - Knowledge representation
KW  - Analysis algorithms
KW  - Analysis models
KW  - Design frameworks
KW  - Knowledge-representation
KW  - Language processing
KW  - Natural language processing
KW  - Natural languages
KW  - Research papers
KW  - Sentiment analysis
KW  - Text analysis
KW  - Sentiment analysis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 69
ER  -

TY  - JOUR
AU  - Maghdid, S.S.
AU  - Rashid, T.A.
AU  - Askar, S.K.
TI  - Graph neural networks: Historical backgrounds, present revolutions, and conventionalization for the future
PY  - 2025
T2  - International Journal of Data Science and Analytics
DO  - 10.1007/s41060-025-00797-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007635662&doi=10.1007%2fs41060-025-00797-w&partnerID=40&md5=b66acb9b75cde1e4cdd4cd96b272f1e1
AB  - Graph neural networks (GNNs) have become a powerful framework for analyzing structured data in the form of graphs, with applications spanning diverse fields such as social networks, biology, and recommender systems. This survey explores methodology, development, and advances in GNN architecture. We methodically survey the major classes of GNNs, including convolutional GNNs (ConvGNNs), spatial–temporal graph neural networks (STGNNs), recurrent-based GNNs (RecGNNs), and graph autoencoders (GAEs). Every model is discussed in terms of underlying mathematical formulations, design principles, and practical applications. This survey aims to provide a comprehensive understanding of GNNs for practitioners, students, and researchers alike, highlighting their versatility and potential for future innovations in graph neural networks. This review is broad, addressing the basic ideas behind GNNs, different architectural designs, training and inference methods, common issues and constraints, the variety of datasets used, and real-world applications across numerous fields. We will furthermore discuss applications of graph neural networks across different fields and exemplify open-source codes, benchmark datasets, and model valuation for graph neural networks. In the end, this survey specifies existing challenges in interpretability, generalization, and scalability and proposes possible future research trends to further promote the performance of GNNs across various graph-based learning missions. © The Author(s), under exclusive licence to Springer Nature Switzerland AG 2025.
KW  - Convolutional GNNs (ConvGNNs)
KW  - Graph autoencoders (GAEs)
KW  - Graph neural networks
KW  - Recurrent-based GNNs (RecGNNs)
KW  - Spatial–temporal graph neural networks (STGNNs)
KW  - Convolutional neural networks
KW  - Economic and social effects
KW  - Graph algorithms
KW  - Network theory (graphs)
KW  - Recurrent neural networks
KW  - Auto encoders
KW  - Convolutional graph neural network
KW  - Graph autoencoder
KW  - Graph neural networks
KW  - Recurrent-based graph neural network
KW  - Spatial temporals
KW  - Spatial–temporal graph neural network
KW  - Temporal graphs
KW  - Graph neural networks
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Ma, Y.
AU  - Ye, W.
AU  - Cui, C.
AU  - Zhang, H.
AU  - Xing, S.
AU  - Ke, F.
AU  - Wang, J.
AU  - Miao, C.
AU  - Chen, J.
AU  - Rezatofighi, H.
AU  - Li, Z.
AU  - Zheng, G.
AU  - Zheng, C.
AU  - He, T.
AU  - Chandraker, M.
AU  - Yaman, B.
AU  - Ye, X.
AU  - Zhao, H.
AU  - Cao, X.
TI  - Position: Prospective of Autonomous Driving - Multimodal LLMs, World Models, Embodied Intelligence, AI Alignment, and Mamba
PY  - 2025
T2  - Proceedings - 2025 IEEE/CVF Winter Conference on Applications of Computer Vision Workshops, WACVW 2025
SP  - 920
EP  - 936
DO  - 10.1109/WACVW65960.2025.00114
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005025953&doi=10.1109%2fWACVW65960.2025.00114&partnerID=40&md5=d43b9c66cbce5af871f3e541085f2c69
AB  - With the emergence of Generative AI, multimodal AI systems that leverage foundation models are beginning to demonstrate enormous potential for perceiving the real world, collecting new data, making decisions, and using tools like humans. In recent years, the use of Large Language Models and World Models in autonomous driving has received widespread attention. However, despite their enormous potential, there is still a lack of comprehensive understanding regarding the key challenges, opportunities, and future applications of these new foundation models in driving systems. In this paper, we provide an outlook on this field, summarizing existing methods and exploring their limitations. In addition, we further discuss the applicability of emerging approaches, such as Reinforcement Learning from Human Feedback and Mamba for applications in autonomous driving. Finally, we highlight open questions and offer insights into promising directions for future research. This paper is part of a living document that will be updated based on the LLVM-AD workshop series to reflect the latest developments in the field.  © 2025 IEEE.
KW  - autonomous driving
KW  - embodied ai
KW  - mamba
KW  - multimodal large language model
KW  - world model
KW  - AI systems
KW  - Autonomous driving
KW  - Embodied ai
KW  - Foundation models
KW  - Language model
KW  - Mamba
KW  - Multi-modal
KW  - Multimodal large language model
KW  - Prospectives
KW  - World model
KW  - Reinforcement learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - BOOK
AU  - Hoffmann, C.H.
TI  - The Quest for a Universal Theory of Intelligence: The Mind, the Machine, and Singularity Hypotheses
PY  - 2022
T2  - The Quest for a Universal Theory of Intelligence: The Mind, the Machine, and Singularity Hypotheses
SP  - 1
EP  - 284
DO  - 10.1515/9783110756166
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123682487&doi=10.1515%2f9783110756166&partnerID=40&md5=7a07d853cac55697dfc48e38d3c3a7bf
AB  - Recent findings about the capabilities of smart animals such as corvids or octopi and novel types of artificial intelligence (AI), from social robots to cognitive assistants, are provoking the demand for new answers for meaningful comparison with other kinds of intelligence. This book fills this need by proposing a universal theory of intelligence which is based on causal learning as the central theme of intelligence. The goal is not just to describe, but mainly to explain queries like why one kind of intelligence is more intelligent than another, whatsoever the intelligence. Shiny terms like "strong AI," "superintelligence," "singularity" or "artificial general intelligence" that have been coined by a Babylonian confusion of tongues are clarified on the way. © 2022 Walter de Gruyter GmbH, Berlin/Boston.
KW  - artificial intelligence
KW  - causality
KW  - intelligence
M3  - Book
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Yano, J.
AU  - Gaffney, K.J.
AU  - Gregoire, J.
AU  - Hung, L.
AU  - Ourmazd, A.
AU  - Schrier, J.
AU  - Sethian, J.A.
AU  - Toma, F.M.
TI  - The case for data science in experimental chemistry: examples and recommendations
PY  - 2022
T2  - Nature Reviews Chemistry
VL  - 6
IS  - 5
SP  - 357
EP  - 370
DO  - 10.1038/s41570-022-00382-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129282924&doi=10.1038%2fs41570-022-00382-w&partnerID=40&md5=1c031065a787df80c282ab44226906b4
AB  - The physical sciences community is increasingly taking advantage of the possibilities offered by modern data science to solve problems in experimental chemistry and potentially to change the way we design, conduct and understand results from experiments. Successfully exploiting these opportunities involves considerable challenges. In this Expert Recommendation, we focus on experimental co-design and its importance to experimental chemistry. We provide examples of how data science is changing the way we conduct experiments, and we outline opportunities for further integration of data science and experimental chemistry to advance these fields. Our recommendations include establishing stronger links between chemists and data scientists; developing chemistry-specific data science methods; integrating algorithms, software and hardware to ‘co-design’ chemistry experiments from inception; and combining diverse and disparate data sources into a data network for chemistry research. [Figure not available: see fulltext.] © 2022, Springer Nature Limited.
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 51
ER  -

TY  - JOUR
AU  - Fountzilas, E.
AU  - Pearce, T.
AU  - Baysal, M.A.
AU  - Chakraborty, A.
AU  - Tsimberidou, A.M.
TI  - Convergence of evolving artificial intelligence and machine learning techniques in precision oncology
PY  - 2025
T2  - npj Digital Medicine
VL  - 8
IS  - 1
C7  - 75
DO  - 10.1038/s41746-025-01471-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218218442&doi=10.1038%2fs41746-025-01471-y&partnerID=40&md5=a1bb1f92a6fd15e45dfce70c10e44900
AB  - The confluence of new technologies with artificial intelligence (AI) and machine learning (ML) analytical techniques is rapidly advancing the field of precision oncology, promising to improve diagnostic approaches and therapeutic strategies for patients with cancer. By analyzing multi-dimensional, multiomic, spatial pathology, and radiomic data, these technologies enable a deeper understanding of the intricate molecular pathways, aiding in the identification of critical nodes within the tumor’s biology to optimize treatment selection. The applications of AI/ML in precision oncology are extensive and include the generation of synthetic data, e.g., digital twins, in order to provide the necessary information to design or expedite the conduct of clinical trials. Currently, many operational and technical challenges exist related to data technology, engineering, and storage; algorithm development and structures; quality and quantity of the data and the analytical pipeline; data sharing and generalizability; and the incorporation of these technologies into the current clinical workflow and reimbursement models. © The Author(s) 2025.
KW  - Oncology
KW  - Radiotherapy
KW  - biological marker
KW  - Artificial intelligence learning
KW  - Critical node
KW  - Diagnostic approach
KW  - Machine learning techniques
KW  - Machine-learning
KW  - Molecular pathways
KW  - Multi dimensional
KW  - Synthetic data
KW  - Therapeutic strategy
KW  - Treatment selection
KW  - Article
KW  - artificial intelligence
KW  - automation
KW  - cancer therapy
KW  - data accuracy
KW  - data privacy
KW  - device approval
KW  - digital pathology
KW  - ethical compliance
KW  - Food and Drug Administration
KW  - generative artificial intelligence
KW  - human
KW  - immunohistochemistry
KW  - integrative medicine
KW  - intersectoral collaboration
KW  - large language model
KW  - machine learning
KW  - malignant neoplasm
KW  - medical ethics
KW  - molecular medicine
KW  - personalized cancer therapy
KW  - radiomics
KW  - regulatory compliance
KW  - reliability
KW  - staining
KW  - trust
KW  - Adversarial machine learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 15
ER  -

TY  - JOUR
AU  - Ali, S.
AU  - Abuhmed, T.
AU  - El-Sappagh, S.
AU  - Muhammad, K.
AU  - Alonso-Moral, J.M.
AU  - Confalonieri, R.
AU  - Guidotti, R.
AU  - Del Ser, J.
AU  - Díaz-Rodríguez, N.
AU  - Herrera, F.
TI  - Explainable Artificial Intelligence (XAI): What we know and what is left to attain Trustworthy Artificial Intelligence
PY  - 2023
T2  - Information Fusion
VL  - 99
C7  - 101805
DO  - 10.1016/j.inffus.2023.101805
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159601901&doi=10.1016%2fj.inffus.2023.101805&partnerID=40&md5=4ab083e2f6a076ba5601fd040b4afa41
AB  - Artificial intelligence (AI) is currently being utilized in a wide range of sophisticated applications, but the outcomes of many AI models are challenging to comprehend and trust due to their black-box nature. Usually, it is essential to understand the reasoning behind an AI model's decision-making. Thus, the need for eXplainable AI (XAI) methods for improving trust in AI models has arisen. XAI has become a popular research subject within the AI field in recent years. Existing survey papers have tackled the concepts of XAI, its general terms, and post-hoc explainability methods but there have not been any reviews that have looked at the assessment methods, available tools, XAI datasets, and other related aspects. Therefore, in this comprehensive study, we provide readers with an overview of the current research and trends in this rapidly emerging area with a case study example. The study starts by explaining the background of XAI, common definitions, and summarizing recently proposed techniques in XAI for supervised machine learning. The review divides XAI techniques into four axes using a hierarchical categorization system: (i) data explainability, (ii) model explainability, (iii) post-hoc explainability, and (iv) assessment of explanations. We also introduce available evaluation metrics as well as open-source packages and datasets with future research directions. Then, the significance of explainability in terms of legal demands, user viewpoints, and application orientation is outlined, termed as XAI concerns. This paper advocates for tailoring explanation content to specific user types. An examination of XAI techniques and evaluation was conducted by looking at 410 critical articles, published between January 2016 and October 2022, in reputed journals and using a wide range of research databases as a source of information. The article is aimed at XAI researchers who are interested in making their AI models more trustworthy, as well as towards researchers from other disciplines who are looking for effective XAI methods to complete tasks with confidence while communicating meaning from data. © 2023 The Author(s)
KW  - AI principles
KW  - Data Fusion
KW  - Deep Learning
KW  - Explainable Artificial Intelligence
KW  - Interpretable machine learning
KW  - Post-hoc explainability
KW  - Trustworthy AI
KW  - XAI assessment
KW  - Decision making
KW  - Deep learning
KW  - Learning systems
KW  - Petroleum reservoir evaluation
KW  - Supervised learning
KW  - Well testing
KW  - Artificial intelligence principle
KW  - Black boxes
KW  - Deep learning
KW  - Explainable artificial intelligence
KW  - Intelligence models
KW  - Interpretable machine learning
KW  - Machine-learning
KW  - Post-hoc explainability
KW  - Trustworthy artificial intelligence
KW  - XAI assessment
KW  - Data fusion
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 683
ER  -

TY  - CHAP
AU  - Lin, B.
TI  - Reinforcement Learning Methods in Speech and Language Technology
PY  - 2025
T2  - Signals and Communication Technology
VL  - Part F3653
SP  - 1
EP  - 200
DO  - 10.1007/978-3-031-53720-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217035034&doi=10.1007%2f978-3-031-53720-2&partnerID=40&md5=f6a89fdf9035e23f180f367bd86ef51d
AB  - This book offers a comprehensive guide to reinforcement learning (RL) and bandits methods, specifically tailored for advancements in speech and language technology. Starting with a foundational overview of RL and bandit methods, the book dives into their practical applications across a wide array of speech and language tasks. Readers will gain insights into how these methods shape solutions in automatic speech recognition (ASR), speaker recognition, diarization, spoken and natural language understanding (SLU/NLU), text-to-speech (TTS) synthesis, natural language generation (NLG), and conversational recommendation systems (CRS). Further, the book delves into cutting-edge developments in large language models (LLMs) and discusses the latest strategies in RL, highlighting the emerging fields of multi-agent systems and transfer learning. Emphasizing real-world applications, the book provides clear, step-by-step guidance on employing RL and bandit methods to address challenges in speech and language technology. It includes case studies and practical tips that equip readers to apply these methods to their own projects. As a timely and crucial resource, this book is ideal for speech and language researchers, engineers, students, and practitioners eager to enhance the performance of speech and language systems and to innovate with new interactive learning paradigms from an interface design perspective. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.
KW  - automatic speech recognition
KW  - natural language processing
KW  - reinforcement learning
KW  - speech and language technology
KW  - speech processing
KW  - Adversarial machine learning
KW  - Chatbots
KW  - Learning systems
KW  - Natural language processing systems
KW  - Reinforcement learning
KW  - Speech enhancement
KW  - Transfer learning
KW  - Automatic speech recognition
KW  - Gain insight
KW  - Language processing
KW  - Language technology
KW  - Natural language processing
KW  - Natural languages
KW  - Reinforcement learning method
KW  - Reinforcement learnings
KW  - Speaker recognition
KW  - Speech technology
KW  - Multi agent systems
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Manes, V.J.M.
AU  - Han, H.
AU  - Han, C.
AU  - Cha, S.K.
AU  - Egele, M.
AU  - Schwartz, E.J.
AU  - Woo, M.
TI  - The Art, Science, and Engineering of Fuzzing: A Survey
PY  - 2021
T2  - IEEE Transactions on Software Engineering
VL  - 47
IS  - 11
SP  - 2312
EP  - 2331
DO  - 10.1109/TSE.2019.2946563
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073569517&doi=10.1109%2fTSE.2019.2946563&partnerID=40&md5=f0b4773f046af619aa62cf9bb0058a5b
AB  - Among the many software testing techniques available today, fuzzing has remained highly popular due to its conceptual simplicity, its low barrier to deployment, and its vast amount of empirical evidence in discovering real-world software vulnerabilities. At a high level, fuzzing refers to a process of repeatedly running a program with generated inputs that may be syntactically or semantically malformed. While researchers and practitioners alike have invested a large and diverse effort towards improving fuzzing in recent years, this surge of work has also made it difficult to gain a comprehensive and coherent view of fuzzing. To help preserve and bring coherence to the vast literature of fuzzing, this paper presents a unified, general-purpose model of fuzzing together with a taxonomy of the current fuzzing literature. We methodically explore the design decisions at every stage of our model fuzzer by surveying the related literature and innovations in the art, science, and engineering that make modern-day fuzzers effective. © 1976-2012 IEEE.
KW  - automated software testing
KW  - fuzz testing
KW  - fuzzing
KW  - Software security
KW  - Computer testing
KW  - Program debugging
KW  - Surveys
KW  - Terminology
KW  - Automated software testing
KW  - Computer bugs
KW  - Fuzz Testing
KW  - fuzzing
KW  - Security
KW  - Software security
KW  - Software testing
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 275
ER  -

TY  - BOOK
AU  - Morik, K.
AU  - Rhode, W.
TI  - Discovery in physics
PY  - 2022
T2  - Discovery in Physics
SP  - 1
EP  - 349
DO  - 10.1515/9783110785968
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147949171&doi=10.1515%2f9783110785968&partnerID=40&md5=93303a5e96dd2a7ab718923bfdd4abef
AB  - Machine Learning under Resource Constraints addresses novel machine learning algorithms that are challenged by high-throughput data, by high dimensions, or by complex structures of the data in three volumes. Resource constraints are given by the relation between the demands for processing the data and the capacity of the computing machinery. The resources are runtime, memory, communication, and energy. Hence, modern computer architectures play a significant role. Novel machine learning algorithms are optimized with regard to minimal resource consumption. Moreover, learned predictions are executed on diverse architectures to save resources. It provides a comprehensive overview of the novel approaches to machine learning research that consider resource constraints, as well as the application of the described methods in various domains of science and engineering. © 2023 Katharina Morik and Wolfgang Rhode. All rights reserved.
KW  - Artificial Intelligence
KW  - Big Data and Machine Learning
KW  - Cyber-physical systems
KW  - Data mining for Ubiquitous System Software
KW  - Embedded Systems and Machine Learning
KW  - Highly Distributed Data
KW  - Machine learning for knowledge discovery
KW  - Machine learning in high-energy physics
KW  - ML on Small devices
KW  - Resource-Aware Machine Learning
KW  - Resource-Constrained Data Analysis
M3  - Book
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Lang, P.
AU  - Fu, X.
AU  - Dong, J.
AU  - Yang, H.
AU  - Yin, J.
AU  - Yang, J.
AU  - Martorella, M.
TI  - Recent Advances in Deep-Learning-Based SAR Image Target Detection and Recognition
PY  - 2025
T2  - IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing
VL  - 18
SP  - 6884
EP  - 6915
DO  - 10.1109/JSTARS.2025.3543531
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001082745&doi=10.1109%2fJSTARS.2025.3543531&partnerID=40&md5=a8624ebf44302ef10c3abcd025c50cf5
AB  - Synthetic aperture radar (SAR) image target detection and recognition (SAR-TDR) tasks have become research hot spots in the remote sensing application. These targets include ships, vehicles, aircraft, oil tanks, bridges, and so on. However, with the rapid development of SAR technology and increasingly complex electromagnetic environment, complex characteristics of SAR images bring severe challenges to the accurate SAR-TDR via traditional physical models or manual feature-extraction-based machine learning methods. In recent years, deep learning (DL), as a powerful automatic feature extraction algorithm, has been widely used in the computer vision domain. More specifically, DL has also been introduced into the SAR-TDR tasks and has effectively achieved good performance in terms of accuracy, real-time processing, etc. With the rapid development of DL, SAR image processing, and practical requirements of SAR-TDR in civilian and military domains, it is crucial to conduct a systematic survey on SAR-TDR in the past few years. In this survey article, we mainly conduct a systematic overview of DL-based SAR-TDR literature on two tasks, i.e., target recognition (e.g., ground vehicles, ships, and aircraft) and target detection (e.g., ships, aircraft, change detection, sea surface oil spills, and oil tanks). More specifically, our related works about these topics are also presented to verify the effectiveness of DL-based methods. First, several DL methods (e.g., convolutional neural networks, recurrent neural networks, autoencoders, and generative adversarial networks), commonly used in SAR-TDR, are briefly introduced. Then, a systematic review of DL-based SAR-TDR (including our related works) is presented. Finally, the current challenges and future possible research directions are deeply analyzed and discussed. © 2025 The Authors.
KW  - Automatic target recognition
KW  - change detection (CD)
KW  - deep learning (DL)
KW  - SAR image interpretation
KW  - target detection
KW  - Aircraft detection
KW  - Change detection
KW  - Magnetic levitation vehicles
KW  - Military photography
KW  - Radar imaging
KW  - Ships
KW  - Change detection
KW  - Deep learning
KW  - Image interpretation
KW  - Related works
KW  - Remote sensing applications
KW  - SAR image interpretation
KW  - SAR Images
KW  - Target detection and recognition
KW  - Target recognition
KW  - Targets detection
KW  - image analysis
KW  - image processing
KW  - machine learning
KW  - pattern recognition
KW  - remote sensing
KW  - synthetic aperture radar
KW  - Oil tanks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Zheng, Y.
AU  - Wang, D.
AU  - Gu, X.
AU  - Zyphur, M.J.
AU  - Xiao, L.
AU  - Liao, S.
AU  - Deng, Y.
TI  - Shedding Light on the Black Box: Integrating Prediction Models and Explainability Using Explainable Machine Learning
PY  - 2025
T2  - Organizational Research Methods
DO  - 10.1177/10944281251323248
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000268678&doi=10.1177%2f10944281251323248&partnerID=40&md5=9c76bb8ae8825b382605391f4bac541a
AB  - In contemporary organizational research, when dealing with large heterogeneous datasets and complex relationships, statistical modeling focused on developing substantive explanations typically results in low predictive accuracy. In contrast, machine learning (ML) exhibits remarkable strength for prediction, but suffers from an unexplainable analytical process and output—thus ML is often known as a “black box” approach. The recent development of explainable machine learning (XML) integrates high predictive accuracy with explainability, which combines the advantages inherent in both statistical modeling and ML paradigms. This paper compares XML with statistical modeling and the traditional ML approaches, focusing on an advanced application of XML known as evolving fuzzy system (EFS), which enhances model transparency by clarifying the unique contribution of each modeled predictor. In an illustrative study, we demonstrate two EFS-based XML models and conduct comparative analyses among XML, ML, and statistical models with a commonly-used database in organizational research. Our study offers a thorough description of analysis procedures for implementing XML in organizational research, along with best-practice recommendations for each step as well as Python code to aid future research using XML. Finally, we discuss the benefits of XML for organizational research and its potential development. © The Author(s) 2025.
KW  - evolving fuzzy system
KW  - explainable machine learning
KW  - machine learning and black box
KW  - predictive model
KW  - statistical modeling
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Weisz, J.D.
AU  - Muller, M.
AU  - He, J.
AU  - Houde, S.
TI  - Toward General Design Principles for Generative AI Applications
PY  - 2023
T2  - CEUR Workshop Proceedings
VL  - 3359
SP  - 130
EP  - 144
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150793829&partnerID=40&md5=aeb8e42a1e39d678b7524361f7446cfd
AB  - Generative AI technologies are growing in power, utility, and use. As generative technologies are being incorporated into mainstream applications, there is a need for guidance on how to design those applications to foster productive and safe use. Based on recent research on human-AI co-creation within the HCI and AI communities, we present a set of seven principles for the design of generative AI applications. These principles are grounded in an environment of generative variability. Six principles are focused on designing for characteristics of generative AI: multiple outcomes & imperfection; exploration & control; and mental models & explanations. In addition, we urge designers to design against potential harms that may be caused by a generative model's hazardous output, misuse, or potential for human displacement. We anticipate these principles to usefully inform design decisions made in the creation of novel human-AI applications, and we invite the community to apply, revise, and extend these principles to their own work. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). CEUR Workshop Proceedings (CEUR-WS.org)
KW  - design principles
KW  - foundation models
KW  - generative AI
KW  - human-centered AI
KW  - AI applications
KW  - AI Technologies
KW  - Design Principles
KW  - Foundation models
KW  - General designs
KW  - Generative AI
KW  - Generative technologies
KW  - Human-centered AI
KW  - Power utility
KW  - Recent researches
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 10
ER  -

TY  - CONF
AU  - Weisz, J.D.
AU  - He, J.
AU  - Muller, M.
AU  - Hoefer, G.
AU  - Miles, R.
AU  - Geyer, W.
TI  - Design Principles for Generative AI Applications
PY  - 2024
T2  - Conference on Human Factors in Computing Systems - Proceedings
C7  - 378
DO  - 10.1145/3613904.3642466
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194865926&doi=10.1145%2f3613904.3642466&partnerID=40&md5=f61767155863e786e9289de025c564f5
AB  - Generative AI applications present unique design challenges. As generative AI technologies are increasingly being incorporated into mainstream applications, there is an urgent need for guidance on how to design user experiences that foster effective and safe use. We present six principles for the design of generative AI applications that address unique characteristics of generative AI UX and offer new interpretations and extensions of known issues in the design of AI applications. Each principle is coupled with a set of design strategies for implementing that principle via UX capabilities or through the design process. The principles and strategies were developed through an iterative process involving literature review, feedback from design practitioners, validation against real-world generative AI applications, and incorporation into the design process of two generative AI applications. We anticipate the principles to usefully inform the design of generative AI applications by driving actionable design recommendations. © 2024 Copyright held by the owner/author(s)
KW  - design principles
KW  - foundation models
KW  - Generative AI
KW  - human-centered AI
KW  - AI applications
KW  - AI Technologies
KW  - Design challenges
KW  - Design Principles
KW  - Design strategies
KW  - Design-process
KW  - Foundation models
KW  - Generative AI
KW  - Human-centered AI
KW  - Users' experiences
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 65
ER  -

TY  - JOUR
AU  - Stone, D.G.
AU  - Bradac, C.
TI  - Machine and quantum learning for diamond-based quantum applications
PY  - 2023
T2  - Materials for Quantum Technology
VL  - 3
IS  - 1
C7  - 012001
DO  - 10.1088/2633-4356/acb30a
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153850396&doi=10.1088%2f2633-4356%2facb30a&partnerID=40&md5=724ff3808da904a6e45f1017a3fc5746
AB  - In recent years, machine and quantum learning have gained considerable momentum sustained by growth in computational power and data availability and have shown exceptional aptness for solving recognition- and classification-type problems, as well as problems that require complex, strategic planning. In this work, we discuss and analyze the role machine and quantum learning are playing in the development of diamond-based quantum technologies. This matters as diamond and its optically addressable spin defects are becoming prime hardware candidates for solid state-based applications in quantum information, computing and metrology. Through a selected number of demonstrations, we show that machine and quantum learning are leading to both practical and fundamental improvements in measurement speed and accuracy. This is crucial for quantum applications, especially for those where coherence time and signal-to-noise ratio are scarce resources. We summarize some of the most prominent machine and quantum learning approaches that have been conducive to the presented advances and discuss their potential, as well as their limits, for proposed and future quantum applications. © 2023 The Author(s). Published by IOP Publishing Ltd.
KW  - artificial intelligence
KW  - color centers
KW  - diamond
KW  - machine learning
KW  - quantum applications
KW  - quantum learning
KW  - Color centers
KW  - Machine learning
KW  - Quantum optics
KW  - Signal to noise ratio
KW  - Colour centers
KW  - Computational data
KW  - Computational power
KW  - Data availability
KW  - Machine-learning
KW  - Quantum applications
KW  - Quantum Computing
KW  - Quantum learning
KW  - Quantum technologies
KW  - State based
KW  - Diamonds
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Jakšić, Z.
TI  - Synergy between AI and Optical Metasurfaces: A Critical Overview of Recent Advances
PY  - 2024
T2  - Photonics
VL  - 11
IS  - 5
C7  - 442
DO  - 10.3390/photonics11050442
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194395285&doi=10.3390%2fphotonics11050442&partnerID=40&md5=e78a7ba26ee1092b8318606e43a0a3a4
AB  - The interplay between two paradigms, artificial intelligence (AI) and optical metasurfaces, nowadays appears obvious and unavoidable. AI is permeating literally all facets of human activity, from science and arts to everyday life. On the other hand, optical metasurfaces offer diverse and sophisticated multifunctionalities, many of which appeared impossible only a short time ago. The use of AI for optimization is a general approach that has become ubiquitous. However, here we are witnessing a two-way process—AI is improving metasurfaces but some metasurfaces are also improving AI. AI helps design, analyze and utilize metasurfaces, while metasurfaces ensure the creation of all-optical AI chips. This ensures positive feedback where each of the two enhances the other one: this may well be a revolution in the making. A vast number of publications already cover either the first or the second direction; only a modest number includes both. This is an attempt to make a reader-friendly critical overview of this emerging synergy. It first succinctly reviews the research trends, stressing the most recent findings. Then, it considers possible future developments and challenges. The author hopes that this broad interdisciplinary overview will be useful both to dedicated experts and a general scholarly audience. © 2024 by the author.
KW  - artificial intelligence
KW  - intelligent metasurfaces
KW  - machine learning
KW  - meta-holograms
KW  - metaheuristics
KW  - nanophotonics
KW  - nanoplasmonics
KW  - optical metasurfaces
KW  - reconfigurable metasurfaces
KW  - tunable metasurfaces
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Sharma, T.
AU  - Kechagia, M.
AU  - Georgiou, S.
AU  - Tiwari, R.
AU  - Vats, I.
AU  - Moazen, H.
AU  - Sarro, F.
TI  - A survey on machine learning techniques applied to source code
PY  - 2024
T2  - Journal of Systems and Software
VL  - 209
C7  - 111934
DO  - 10.1016/j.jss.2023.111934
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181046174&doi=10.1016%2fj.jss.2023.111934&partnerID=40&md5=878c3604b3353452697955130c6a6a77
AB  - The advancements in machine learning techniques have encouraged researchers to apply these techniques to a myriad of software engineering tasks that use source code analysis, such as testing and vulnerability detection. Such a large number of studies hinders the community from understanding the current research landscape. This paper aims to summarize the current knowledge in applied machine learning for source code analysis. We review studies belonging to twelve categories of software engineering tasks and corresponding machine learning techniques, tools, and datasets that have been applied to solve them. To do so, we conducted an extensive literature search and identified 494 studies. We summarize our observations and findings with the help of the identified studies. Our findings suggest that the use of machine learning techniques for source code analysis tasks is consistently increasing. We synthesize commonly used steps and the overall workflow for each task and summarize machine learning techniques employed. We identify a comprehensive list of available datasets and tools useable in this context. Finally, the paper discusses perceived challenges in this area, including the availability of standard datasets, reproducibility and replicability, and hardware resources. Editor's note: Open Science material was validated by the Journal of Systems and Software Open Science Board. © 2023 The Authors
KW  - Datasets
KW  - Deep learning
KW  - Machine learning for software engineering
KW  - Source code analysis
KW  - Tools
KW  - Codes (symbols)
KW  - Computer programming languages
KW  - Learning algorithms
KW  - Learning systems
KW  - Software testing
KW  - 'current
KW  - Dataset
KW  - Deep learning
KW  - Engineering tasks
KW  - Machine learning for software engineering
KW  - Machine learning techniques
KW  - Machine-learning
KW  - On-machines
KW  - Open science
KW  - Source code analysis
KW  - Deep learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 23
ER  -

TY  - JOUR
AU  - Gu, S.
AU  - Yang, L.
AU  - Du, Y.
AU  - Chen, G.
AU  - Walter, F.
AU  - Wang, J.
AU  - Knoll, A.
TI  - A Review of Safe Reinforcement Learning: Methods, Theories, and Applications
PY  - 2024
T2  - IEEE Transactions on Pattern Analysis and Machine Intelligence
VL  - 46
IS  - 12
SP  - 11216
EP  - 11235
DO  - 10.1109/TPAMI.2024.3457538
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204119035&doi=10.1109%2fTPAMI.2024.3457538&partnerID=40&md5=fa63d224ae24d0a4ed7017cd13e37344
AB  - Reinforcement Learning (RL) has achieved tremendous success in many complex decision-making tasks. However, safety concerns are raised during deploying RL in real-world applications, leading to a growing demand for safe RL algorithms, such as in autonomous driving and robotics scenarios. While safe control has a long history, the study of safe RL algorithms is still in the early stages. To establish a good foundation for future safe RL research, in this paper, we provide a review of safe RL from the perspectives of methods, theories, and applications. First, we review the progress of safe RL from five dimensions and come up with five crucial problems for safe RL being deployed in real-world applications, coined as '2H3W'. Second, we analyze the algorithm and theory progress from the perspectives of answering the '2H3W' problems. Particularly, the sample complexity of safe RL algorithms is reviewed and discussed, followed by an introduction to the applications and benchmarks of safe RL algorithms. Finally, we open the discussion of the challenging problems in safe RL, hoping to inspire future research on this thread. To advance the study of safe RL algorithms, we release an open-sourced repository containing major safe RL algorithms at the link. © 1979-2012 IEEE.
KW  - constrained Markov decision processes
KW  - Safe reinforcement learning (RL)
KW  - safety optimisation
KW  - safety problems
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Reinforcement learning
KW  - Complex decision
KW  - Constrained Markov decision process
KW  - Optimisations
KW  - Real-world
KW  - Reinforcement learning algorithms
KW  - Reinforcement learning method
KW  - Reinforcement learnings
KW  - Safe reinforcement learning
KW  - Safety optimization
KW  - Safety problems
KW  - adverse drug reaction
KW  - algorithm
KW  - article
KW  - benchmarking
KW  - clinical article
KW  - decision making task
KW  - drug administration
KW  - drug comparison
KW  - drug therapy
KW  - human
KW  - learning
KW  - nonhuman
KW  - side effect
KW  - therapy
KW  - Markov processes
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 37
ER  -

TY  - JOUR
AU  - Zhang, Y.
AU  - Gao, Z.
AU  - He, K.
AU  - Li, C.
AU  - Mao, R.
TI  - From patches to WSIs: A systematic review of deep Multiple Instance Learning in computational pathology
PY  - 2025
T2  - Information Fusion
VL  - 119
C7  - 103027
DO  - 10.1016/j.inffus.2025.103027
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218262135&doi=10.1016%2fj.inffus.2025.103027&partnerID=40&md5=ae1832c31b0db031f7bd46a767282343
AB  - Clinical decision support systems for pathology, particularly those utilizing computational pathology (CPATH) for whole slide image (WSI) analysis, face significant challenges due to the need for high-quality annotated datasets. Given the vast amount of information contained in WSIs, creating such datasets is often prohibitively expensive and time-consuming. Multiple Instance Learning (MIL) has emerged as a promising alternative, enabling training that relies solely on coarse-grained supervision by the fusion of extensive localized information from large-scale wholes, thereby reducing the dependency on costly pixel-level labeling. As a result, MIL has become a pivotal technique in CPATH, driving a surge in related research, particularly over the past five years. This expanding body of work has catalyzed technological innovation, introduced transformative advancements in the field, and been further accelerated by progress in deep learning architectures, large-scale pretraining strategies, and Large Language Models (LLMs). This paper provides a systematic review of recent developments in deep MIL methods, analyzing technological advancements from multiple perspectives, including encoder backbone architectures, encoder pretraining strategies, and MIL aggregation techniques. We present a comprehensive overview of progress in each domain, catalog specific application scenarios, and highlight pivotal contributions that have shaped the field. Finally, we explore emerging research directions and potential future challenges for MIL-based CPATH. © 2025
KW  - Computational pathology
KW  - Multimodal fusion
KW  - Multiple Instance Learning
KW  - Self-supervised learning
KW  - Whole slide images
KW  - Adversarial machine learning
KW  - Contrastive Learning
KW  - Deep learning
KW  - Federated learning
KW  - Semi-supervised learning
KW  - Clinical decision support systems
KW  - Computational pathology
KW  - Image analyze
KW  - Image-analysis
KW  - Large-scales
KW  - Multi-modal fusion
KW  - Multiple-instance learning
KW  - Pre-training
KW  - Systematic Review
KW  - Whole slide images
KW  - Self-supervised learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Weinzierl, S.
AU  - Zilker, S.
AU  - Dunzer, S.
AU  - Matzner, M.
TI  - Machine learning in business process management: A systematic literature review
PY  - 2024
T2  - Expert Systems with Applications
VL  - 253
C7  - 124181
DO  - 10.1016/j.eswa.2024.124181
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195019864&doi=10.1016%2fj.eswa.2024.124181&partnerID=40&md5=6500f98c8b8ceab92906cd0e4d1e4dab
AB  - Machine learning (ML) provides algorithms to create computer programs based on data without explicitly programming them. In business process management (BPM), ML applications are used to analyse and improve processes efficiently. Three frequent examples of using ML are providing decision support through predictions, discovering accurate process models, and improving resource allocation. This paper organises the body of knowledge on ML in BPM. We extract BPM tasks from different literature streams, summarise them under the phases of a process's lifecycle, explain how ML helps perform these tasks and identify technical commonalities in ML implementations across tasks. This study is the first exhaustive review of how ML has been used in BPM. We hope that it can open the door for a new era of cumulative research by helping researchers to identify relevant preliminary work and then combine and further develop existing approaches in a focused fashion. Our paper helps managers and consultants to find ML applications that are relevant in the current project phase of a BPM initiative, like redesigning a business process. We also offer – as a synthesis of our review – a research agenda that spreads ten avenues for future research, including applying novel ML concepts like federated learning, addressing less regarded BPM lifecycle phases like process identification, and delivering ML applications with a focus on end-users. © 2024 The Author(s)
KW  - BPM lifecycle
KW  - Business process management
KW  - Deep learning
KW  - Literature review
KW  - Machine learning
KW  - Computer programming
KW  - Deep learning
KW  - Enterprise resource management
KW  - Life cycle
KW  - Business Process
KW  - Business process management
KW  - Business process management lifecycle
KW  - Deep learning
KW  - Literature reviews
KW  - Machine learning applications
KW  - Machine-learning
KW  - Process management
KW  - Decision support systems
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 12
ER  -

TY  - JOUR
AU  - Gou, Q.-W.
AU  - Dong, Y.-W.
AU  - Li, Y.-M.
TI  - Advances in Deep Learning-Based Program Synthesis
ST  - 基于深度学习的程序合成研究进展
PY  - 2024
T2  - Jisuanji Xuebao/Chinese Journal of Computers
VL  - 47
IS  - 11
SP  - 2594
EP  - 2628
DO  - 10.11897/SP.J.1016.2024.02594
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210751582&doi=10.11897%2fSP.J.1016.2024.02594&partnerID=40&md5=70e79a63c6f9b80b9020752c929132c9
AB  - With the vigorous rise of software engineering practices, and the thriving development of open-source communities, deep learning-based program synthesis has emerged as a focal point of interest in both academia and industry. This field encompasses a range of disciplines including software engineering, deep learning, data mining, natural language processing, and programming languages. Deep learning-based program synthesis, namely intelligent program synthesis, utilizes deep learning techniques to extract knowledge from vast program repositories, with the goal of creating smart tools that improve the quality and productivity of computer programming. In contrast to traditional synthesis methods reliant on heuristic rules or expert systems, program intelligent synthesis has swiftly gained prominence due to its highly scalable and self-optimizing characteristics, becoming a research focus on both software engineering and artificial intelligence domains. The rapid advancement of pre-training techniques has led to the increasing adoption of large-scale language models in program synthesis, propelling continuous advancements in this domain. For example, GPT-4 has demonstrated human-comparable performance on platforms like LeetCode, while DeepMind's AlphaCode addresses challenges in natural language competitive programming. Simultaneously, the industry has introduced a series of AI programming assistants such as Copilot, Comate, and CodeWhisperer, significantly enhancing development efficiency and drastically reducing the learning curve in programming, thereby enabling broader participation in software development. To foster deeper research and widespread application in this field, this paper systematically explores the latest research progress in program intelligent synthesis from various perspectives. It comprehensively discusses aspects such as user intent understanding, program comprehension, model training, model testing, and evaluation, with detailed subdivisions. User intent understanding aims to locate and understand user intentions by integrating contextual semantics and knowledge swiftly and accurately. The paper introduces methods for understanding users from different angles, including input-output pairs, natural language, programs, and visual aspects. Program comprehension analyzes and extracts critical information from programs at various abstraction levels and perspectives, transforming it into forms understandable by computers. This paper presents program comprehension methods based on text sequences, tree structures, and graph structures. Model training uses this information to generate new code, while model testing and evaluation verify and optimize the quality and performance of generated code. The paper also examines challenges such as uneven dataset quality, low efficiency in user intent understanding and program comprehension, as well as issues regarding model interpretability and robustness. Furthermore, the paper anticipates future trends, including higher-quality datasets, more efficient methods for user intent understanding and program comprehension, more robust model architectures, and improved application of these technologies in practical industrial settings. This research not only aids the academic community in comprehensively understanding the latest developments in the field of intelligent program synthesis but also assists software developers in quickly mastering relevant technologies and strategies to meet industrial demands. Through continuous exploration and innovation, intelligent program synthesis is poised to achieve greater breakthroughs in the future, driving innovation and development across the entire software engineering domain. The integration of these advancements promises to revolutionize software engineering practices, ushering in an era of enhanced efficiency and creativity in programming and development workflows. © 2024 Science Press. All rights reserved.
KW  - deep learning
KW  - intelligent software engineering
KW  - program comprehension
KW  - program synthesis
KW  - user intent understanding
KW  - Ada (programming language)
KW  - Application programs
KW  - Computer software selection and evaluation
KW  - Heuristic programming
KW  - Input output programs
KW  - Integration testing
KW  - Model checking
KW  - Open source software
KW  - Personnel training
KW  - Visual languages
KW  - Deep learning
KW  - Intelligent programs
KW  - Intelligent software
KW  - Intelligent software engineering
KW  - Natural languages
KW  - Performance
KW  - Program comprehension
KW  - Program synthesis
KW  - Software engineering practices
KW  - User intent understanding
KW  - Semantics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Tang, Y.
AU  - Bi, J.
AU  - Xu, S.
AU  - Song, L.
AU  - Liang, S.
AU  - Wang, T.
AU  - Zhang, D.
AU  - An, J.
AU  - Lin, J.
AU  - Zhu, R.
AU  - Vosoughi, A.
AU  - Huang, C.
AU  - Zhang, Z.
AU  - Liu, P.
AU  - Feng, M.
AU  - Zheng, F.
AU  - Zhang, J.
AU  - Luo, P.
AU  - Luo, J.
AU  - Xu, C.
TI  - Video Understanding with Large Language Models: A Survey
PY  - 2025
T2  - IEEE Transactions on Circuits and Systems for Video Technology
DO  - 10.1109/TCSVT.2025.3566695
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004593993&doi=10.1109%2fTCSVT.2025.3566695&partnerID=40&md5=da80b853be5de4c7c7da8b8da186fb0e
AB  - With the rapid growth of online video platforms and the escalating volume of video content, the need for proficient video understanding tools has increased significantly. Given the remarkable capabilities of large language models (LLMs) in language and multimodal tasks, this survey provides a detailed overview of recent advances in video understanding that harness the power of LLMs (Vid-LLMs). The emergent capabilities of Vid-LLMs are surprisingly advanced, particularly their ability for open-ended multi-granularity (abstract, temporal, and spatiotemporal) reasoning combined with common-sense knowledge, suggesting a promising path for future video understanding. We examine the unique characteristics and capabilities of Vid-LLMs, categorizing the approaches into three main types: Video Analyzer × LLM, Video Embedder × LLM, and (Analyzer + Embedder) × LLM. We identify five subtypes based on the functions of LLMs in Vid-LLMs: LLM as Summarizer, LLM as Manager, LLM as Text Decoder, LLM as Regressor, and LLM as Hidden Layer. This survey also presents a comprehensive study of the tasks, datasets, benchmarks, and evaluation methods for Vid-LLMs. Additionally, it explores the extensive applications of Vid-LLMs in various domains, highlighting their remarkable scalability and versatility in real-world video understanding challenges. Additionally, it summarizes the limitations of existing Vid-LLMs and outlines directions for future research. For more information, readers are encouraged to visit the repository at https://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding.  © 1991-2012 IEEE.
KW  - Large Language Model
KW  - Multimodality Learning
KW  - Video Understanding
KW  - Vision-Language Model
KW  - Interactive computer graphics
KW  - Language model
KW  - Large language model
KW  - Multi-modality
KW  - Multimodality learning
KW  - Online video
KW  - Rapid growth
KW  - Video understanding
KW  - Video-platforms
KW  - Vision-language model
KW  - Visual languages
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Kleyko, D.
AU  - Rachkovskij, D.
AU  - Osipov, E.
AU  - Rahimi, A.
TI  - A Survey on Hyperdimensional Computing aka Vector Symbolic Architectures, Part II: Applications, Cognitive Models, and Challenges
PY  - 2023
T2  - ACM Computing Surveys
VL  - 55
IS  - 9
C7  - 3558000
DO  - 10.1145/3558000
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147845869&doi=10.1145%2f3558000&partnerID=40&md5=5400141f938a69dc205aafe43a0707f8
AB  - This is Part II of the two-part comprehensive survey devoted to a computing framework most commonly known under the names Hyperdimensional Computing and Vector Symbolic Architectures (HDC/VSA). Both names refer to a family of computational models that use high-dimensional distributed representations and rely on the algebraic properties of their key operations to incorporate the advantages of structured symbolic representations and vector distributed representations. Holographic Reduced Representations [321, 326] is an influential HDC/VSA model that is well known in the machine learning domain and often used to refer to the whole family. However, for the sake of consistency, we use HDC/VSA to refer to the field.Part I of this survey [222] covered foundational aspects of the field, such as the historical context leading to the development of HDC/VSA, key elements of any HDC/VSA model, known HDC/VSA models, and the transformation of input data of various types into high-dimensional vectors suitable for HDC/VSA. This second part surveys existing applications, the role of HDC/VSA in cognitive computing and architectures, as well as directions for future work. Most of the applications lie within the Machine Learning/Artificial Intelligence domain; however, we also cover other applications to provide a complete picture. The survey is written to be useful for both newcomers and practitioners.  © 2023 Association for Computing Machinery.
KW  - analogical reasoning
KW  - applications
KW  - Artificial intelligence
KW  - binary spatter codes
KW  - cognitive architectures
KW  - cognitive computing
KW  - distributed representations
KW  - geometric analogue of holographic reduced representations
KW  - holographic reduced representations
KW  - hyperdimensional computing
KW  - machine learning
KW  - matrix binding of additive terms
KW  - modular composite representations
KW  - multiply-add-permute
KW  - sparse binary distributed representations
KW  - sparse block codes
KW  - tensor product representations
KW  - vector symbolic architectures
KW  - Architecture
KW  - Codes (symbols)
KW  - Computer architecture
KW  - Holography
KW  - Machine learning
KW  - Metadata
KW  - Analogical reasoning
KW  - Binary spatter code
KW  - Cognitive architectures
KW  - Cognitive Computing
KW  - Composite representations
KW  - Distributed representation
KW  - Geometric analog of holographic reduced representation
KW  - Holographic reduced representations
KW  - Hyperdimensional computing
KW  - Machine-learning
KW  - Matrix binding
KW  - Matrix binding of additive term
KW  - Modular composite representation
KW  - Modulars
KW  - Multiply-add
KW  - Multiply-add-permute
KW  - Product representation
KW  - Sparse binary distributed representation
KW  - Sparse block code
KW  - Tensor product representation
KW  - Tensor products
KW  - Vector symbolic architecture
KW  - Vectors
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 80
ER  -

TY  - JOUR
AU  - Liu, Z.
AU  - Zhou, T.
AU  - Yang, H.
AU  - Huang, Z.
AU  - Zhang, Y.
AU  - Zhang, M.
TI  - A Review of the Resourceful Utilization Status for Decommissioned Power Batteries
PY  - 2023
T2  - Energies
VL  - 16
IS  - 23
C7  - 7869
DO  - 10.3390/en16237869
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178958365&doi=10.3390%2fen16237869&partnerID=40&md5=1c7988e6a1b48a9e714b9f113058813a
AB  - With the rapid development of the new energy vehicle industry, the number of power battery decommissioning is increasing year by year. The recycling of power batteries is of great significance for protecting the ecological environment, improving the efficiency of resource utilization, and ensuring the sustainable and healthy development of the new energy automobile industry. In this study, the chemical compositions of power batteries were introduced, the technical path and development status of the echelon utilization of decommissioned power batteries were discussed, and the specific steps and challenges of regenerative utilization of decommissioned power batteries were described in detail from two aspects of pyrometallurgy and hydrometallurgy. Combined with the relevant research results, the main methods of the direct regeneration of positive electrode materials were analyzed. Finally, the main development direction and related suggestions for the resource utilization of decommissioned power batteries were put forward. © 2023 by the authors.
KW  - decommissioned power battery
KW  - direct regeneration
KW  - echelon utilization
KW  - hydrometallurgy
KW  - pyrometallurgy
KW  - Automotive industry
KW  - Electronic Waste
KW  - Pyrometallurgy
KW  - Chemical compositions
KW  - Decommissioned power battery
KW  - Direct regeneration
KW  - Echela utilization
KW  - Ecological environments
KW  - New energies
KW  - New energy vehicles
KW  - Power batteries
KW  - Resources utilizations
KW  - Vehicle industry
KW  - Hydrometallurgy
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Liu, Z.
AU  - Zhang, T.
AU  - Yang, K.
AU  - Thompson, P.
AU  - Yu, Z.
AU  - Ananiadou, S.
TI  - Emotion detection for misinformation: A review
PY  - 2024
T2  - Information Fusion
VL  - 107
C7  - 102300
DO  - 10.1016/j.inffus.2024.102300
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185834018&doi=10.1016%2fj.inffus.2024.102300&partnerID=40&md5=d94b06a58cc644e59c61b34586ee8ea2
AB  - With the advent of social media, an increasing number of netizens are sharing and reading posts and news online. However, the huge volumes of misinformation (e.g., fake news and rumors) that flood the internet can adversely affect people's lives, and have resulted in the emergence of rumor and fake news detection as a hot research topic. The emotions and sentiments of netizens, as expressed in social media posts and news, constitute important factors that can help to distinguish fake news from genuine news and to understand the spread of rumors. This article comprehensively reviews emotion-based methods for misinformation detection, with a particular focus on advanced fusion methods. We begin by explaining the strong links between emotions and misinformation. We subsequently provide a detailed analysis of a range of misinformation detection methods that employ a variety of emotion, sentiment and stance-based features, and describe their strengths and weaknesses. Finally, we discuss a number of ongoing challenges in emotion-based misinformation detection based on large language models, and suggest future research directions, including data collection (multi-platform, multilingual), annotation, benchmark, multimodality, and interpretability. © 2024 The Author(s)
KW  - Emotion detection
KW  - Fake news
KW  - Misinformation
KW  - Rumor
KW  - Sentiment analysis
KW  - Stance detection
KW  - Fake detection
KW  - Social networking (online)
KW  - Advanced fusion
KW  - Emotion detection
KW  - Fake news
KW  - Hot research topics
KW  - Misinformation
KW  - Netizen
KW  - Rumor
KW  - Sentiment analysis
KW  - Social media
KW  - Stance detection
KW  - Sentiment analysis
M3  - Short survey
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 23
ER  -

TY  - JOUR
AU  - Wu, J.
AU  - He, K.
AU  - Mao, R.
AU  - Shang, X.
AU  - Cambria, E.
TI  - Harnessing the potential of multimodal EHR data: A comprehensive survey of clinical predictive modeling for intelligent healthcare
PY  - 2025
T2  - Information Fusion
VL  - 123
C7  - 103283
DO  - 10.1016/j.inffus.2025.103283
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005410972&doi=10.1016%2fj.inffus.2025.103283&partnerID=40&md5=2f6cb92eb141055aa7be0eb915c2b4a9
AB  - The digitization of healthcare has led to the accumulation of vast amounts of patient data through Electronic Health Records (EHRs) systems, creating significant opportunities for advancing intelligent healthcare. Recent breakthroughs in deep learning and information fusion techniques have enabled the seamless integration of diverse data sources, providing richer insights for clinical decision-making. This review offers a comprehensive analysis of predictive modeling approaches that leverage multimodal EHR data, focusing on the latest methodologies and their practical applications. We classify the current advancements from both task-driven and method-driven perspectives, while distilling key challenges and motivations that have fueled these innovations. This exploration examines the real-world impact of advanced technologies in healthcare, addressing issues from data integration to task formulation, challenges, and method refinement. The role of information fusion in enhancing model performance is also emphasized. Building on the discussions and findings, we highlight promising future research directions critical for advancing multimodal fusion technologies in clinical predictive modeling, addressing the complex challenges of real-world clinical environments, and moving toward universal intelligence in healthcare. © 2025 Elsevier B.V.
KW  - Clinical predictive modeling
KW  - Electronic health records
KW  - Intelligent healthcare
KW  - Medical intelligence
KW  - Clinical research
KW  - mHealth
KW  - Nutrition
KW  - Patient treatment
KW  - Clinical predictive modeling
KW  - Digitisation
KW  - Electronic health
KW  - Health records
KW  - Intelligent healthcare
KW  - Medical intelligence
KW  - Multi-modal
KW  - Patient data
KW  - Predictive models
KW  - Real-world
KW  - Electronic health record
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Ding, W.
AU  - Xu, C.
AU  - Arief, M.
AU  - Lin, H.
AU  - Li, B.
AU  - Zhao, D.
TI  - A Survey on Safety-Critical Driving Scenario Generation - A Methodological Perspective
PY  - 2023
T2  - IEEE Transactions on Intelligent Transportation Systems
VL  - 24
IS  - 7
SP  - 6971
EP  - 6988
DO  - 10.1109/TITS.2023.3259322
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153389003&doi=10.1109%2fTITS.2023.3259322&partnerID=40&md5=9a5f06c76040ab0569f028f7d729ffe6
AB  - Autonomous driving systems have witnessed significant development during the past years thanks to the advance in machine learning-enabled sensing and decision-making algorithms. One critical challenge for their massive deployment in the real world is their safety evaluation. Most existing driving systems are still trained and evaluated on naturalistic scenarios collected from daily life or heuristically-generated adversarial ones. However, the large population of cars, in general, leads to an extremely low collision rate, indicating that safety-critical scenarios are rare in the collected real-world data. Thus, methods to artificially generate scenarios become crucial to measure the risk and reduce the cost. In this survey, we focus on the algorithms of safety-critical scenario generation in autonomous driving. We first provide a comprehensive taxonomy of existing algorithms by dividing them into three categories: data-driven generation, adversarial generation, and knowledge-based generation. Then, we discuss useful tools for scenario generation, including simulation platforms and packages. Finally, we extend our discussion to five main challenges of current works- fidelity, efficiency, diversity, transferability, controllability- and research opportunities lighted up by these challenges. © 2000-2011 IEEE.
KW  - Autonomous vehicles
KW  - deep generative models
KW  - robustness
KW  - safety
KW  - Autonomous vehicles
KW  - Knowledge based systems
KW  - Learning systems
KW  - Machine learning
KW  - Population statistics
KW  - Risk assessment
KW  - Risk perception
KW  - Safety engineering
KW  - Autonomous driving
KW  - Autonomous Vehicles
KW  - Deep generative model
KW  - Generative model
KW  - Heuristics algorithm
KW  - Road
KW  - Robustness
KW  - Scenarios generation
KW  - Vehicle's dynamics
KW  - Heuristic algorithms
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 102
ER  -

TY  - JOUR
AU  - Dalal, S.
AU  - Jain, S.
AU  - Dave, M.
TI  - Review of Advancements in Depression Detection Using Social Media Data
PY  - 2025
T2  - IEEE Transactions on Computational Social Systems
VL  - 12
IS  - 1
SP  - 77
EP  - 100
DO  - 10.1109/TCSS.2024.3448624
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209932322&doi=10.1109%2fTCSS.2024.3448624&partnerID=40&md5=314049bda644f9c4bdda402c2c4b7ad7
AB  - A large population embraced social media to share thoughts, emotions, and daily experiences through text, images, audio, or video posts. This user-generated content (UGC) serves various purposes, including user profiling, sentiment analysis, and disease detection or tracking. Notably, researchers recognized the potential of UGC for assessing mental health due to its unobtrusive and real-time monitoring capabilities. Recent reviews on depression identification from textual UGC using AI models covered tools and techniques but overlooked critical components such as datasets, lexicons, features, and subtasks, which are essential for understanding the progress and tasks undertaken. This survey adopts a systematic approach and formulates five research questions to examine the relevant literature concerning these elements. Additionally, it organizes machine learning and deep learning (ML/DL) training features from textual UGC in a hierarchical manner and maps the literature on depression detection into various subtasks. The review highlights that despite the prevalence studies, datasets are limited in both quantity and size, with many relying on less reliable ground truth collection methods such as self-reported diagnosis statements (SRDS). Furthermore, the review identifies an overemphasis on certain textual features, such as n-grams and affective elements, while others, such as life events, egocentric graphs, and intervention/coping style, remain largely unexplored. It is crucial for practical AI depression detection systems to develop expertise in tasks such as severity, symptom detection, and explainable/interpretable depression analysis to instill confidence and trust among users. © 2014 IEEE.
KW  - Deep learning (DL)
KW  - depression
KW  - machine learning (ML)
KW  - mental health
KW  - psycholinguistics
KW  - sentiment analysis
KW  - textual features
KW  - Deep learning
KW  - Depression
KW  - Machine learning
KW  - Machine-learning
KW  - Mental health
KW  - Psycholinguistic
KW  - Sentiment analysis
KW  - Social media
KW  - Textual features
KW  - User-generated
KW  - Deep learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Cui, J.
AU  - Wang, Z.
AU  - Ho, S.-B.
AU  - Cambria, E.
TI  - Survey on sentiment analysis: evolution of research methods and topics
PY  - 2023
T2  - Artificial Intelligence Review
VL  - 56
IS  - 8
SP  - 8469
EP  - 8510
DO  - 10.1007/s10462-022-10386-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145703048&doi=10.1007%2fs10462-022-10386-z&partnerID=40&md5=6531cf12f9efb268389c79623686402b
AB  - Sentiment analysis, one of the research hotspots in the natural language processing field, has attracted the attention of researchers, and research papers on the field are increasingly published. Many literature reviews on sentiment analysis involving techniques, methods, and applications have been produced using different survey methodologies and tools, but there has not been a survey dedicated to the evolution of research methods and topics of sentiment analysis. There have also been few survey works leveraging keyword co-occurrence on sentiment analysis. Therefore, this study presents a survey of sentiment analysis focusing on the evolution of research methods and topics. It incorporates keyword co-occurrence analysis with a community detection algorithm. This survey not only compares and analyzes the connections between research methods and topics over the past two decades but also uncovers the hotspots and trends over time, thus providing guidance for researchers. Furthermore, this paper presents broad practical insights into the methods and topics of sentiment analysis, while also identifying technical directions, limitations, and future work. © 2023, The Author(s), under exclusive licence to Springer Nature B.V.
KW  - Evolution analysis
KW  - Keyword co-occurrence analysis
KW  - Research methods
KW  - Research topics
KW  - Sentiment analysis
KW  - Co-occurrence analysis
KW  - Evolution analysis
KW  - Hotspots
KW  - Keyword co-occurrence analyse
KW  - Language processing
KW  - Natural languages
KW  - Research method
KW  - Research papers
KW  - Research topics
KW  - Sentiment analysis
KW  - Sentiment analysis
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 110
ER  -

TY  - JOUR
AU  - Anwar, U.
AU  - Saparov, A.
AU  - Rando, J.
AU  - Paleka, D.
AU  - Turpin, M.
AU  - Hase, P.
AU  - Lubana, E.S.
AU  - Jenner, E.
AU  - Casper, S.
AU  - Sourbut, O.
AU  - Edelman, B.L.
AU  - Zhang, Z.
AU  - Günther, M.
AU  - Korinek, A.
AU  - Hernandez-Orallo, J.
AU  - Hammond, L.
AU  - Bigelow, E.
AU  - Pan, A.
AU  - Langosco, L.
AU  - Korbak, T.
AU  - Zhang, H.
AU  - Zhong, R.
AU  - Héigeartaigh, S.Ó.
AU  - Recchia, G.
AU  - Corsi, G.
AU  - Chan, A.
AU  - Anderljung, M.
AU  - Edwards, L.
AU  - Petrov, A.
AU  - de Witt, C.S.
AU  - Motwani, S.R.
AU  - Bengio, Y.
AU  - Chen, D.
AU  - Torr, P.H.S.
AU  - Albanie, S.
AU  - Maharaj, T.
AU  - Foerster, J.
AU  - Tramer, F.
AU  - He, H.
AU  - Kasirzade, A.
AU  - Choi, Y.
AU  - Krueger, D.
TI  - Foundational Challenges in Assuring Alignment and Safety of Large Language Models
PY  - 2024
T2  - Transactions on Machine Learning Research
VL  - 2024
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000284817&partnerID=40&md5=8dcdf2366e210b14f899b266489b78fb
AB  - This work identifies 18 foundational challenges in assuring the alignment and safety of large language models (LLMs). These challenges are organized into three different categories: scientific understanding of LLMs, development and deployment methods, and sociotechnical challenges. Based on the identified challenges, we pose 200+ concrete research questions. © 2024, Transactions on Machine Learning Research. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - CONF
AU  - Zha, S.
AU  - Liu, Y.
AU  - Zheng, C.
AU  - Xu, J.
AU  - Yu, F.
AU  - Gong, J.
AU  - Xu, Y.
TI  - Mentigo: An Intelligent Agent for Mentoring Students in the Creative Problem Solving Process
PY  - 2025
T2  - Conference on Human Factors in Computing Systems - Proceedings 
C7  - 199
DO  - 10.1145/3706598.3713952
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005723033&doi=10.1145%2f3706598.3713952&partnerID=40&md5=4db0b9d2109889209d791fcb801e4d39
AB  - Creative Problem-Solving (CPS) promotes creative and critical thinking while enhancing real-world problem-solving skills, making it essential for middle school education. However, providing personalized mentorship in CPS projects at scale is challenging due to resource constraints and diverse student needs. To address this, we developed Mentigo, an AI-driven mentor agent designed to guide middle school students through the CPS process. Using a dataset of real classroom interactions, we encoded CPS task stages, adaptive guidance strategies, and personalized feedback mechanisms to inform Mentigog's dynamic mentoring framework powered by large language models (LLMs). A comparative experiment with 12 students and evaluations from five expert educators demonstrated improved student engagement, creativity, and task performance. Our findings highlight design implications for using LLM-based AI mentors to enhance CPS learning in educational environments. © 2025 Copyright held by the owner/author(s).
KW  - Agent
KW  - creative problem solving
KW  - Generative AI
KW  - mentor
KW  - Case based reasoning
KW  - Curricula
KW  - Teaching
KW  - Creative problem-solving
KW  - Creative thinking
KW  - Critical thinking
KW  - Generative AI
KW  - Language model
KW  - Mentor
KW  - Middle school educations
KW  - Problem solving process
KW  - Problem solving skills
KW  - Real-world problem solving
KW  - Students
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Xi, Z.
AU  - Chen, W.
AU  - Guo, X.
AU  - He, W.
AU  - Ding, Y.
AU  - Hong, B.
AU  - Zhang, M.
AU  - Wang, J.
AU  - Jin, S.
AU  - Zhou, E.
AU  - Zheng, R.
AU  - Fan, X.
AU  - Wang, X.
AU  - Xiong, L.
AU  - Zhou, Y.
AU  - Wang, W.
AU  - Jiang, C.
AU  - Zou, Y.
AU  - Liu, X.
AU  - Yin, Z.
AU  - Dou, S.
AU  - Weng, R.
AU  - Qin, W.
AU  - Zheng, Y.
AU  - Qiu, X.
AU  - Huang, X.
AU  - Zhang, Q.
AU  - Gui, T.
TI  - The rise and potential of large language model based agents: a survey
PY  - 2025
T2  - Science China Information Sciences
VL  - 68
IS  - 2
C7  - 121101
DO  - 10.1007/s11432-024-4222-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217275699&doi=10.1007%2fs11432-024-4222-0&partnerID=40&md5=6b9d5807539ca56dca58c72ceb4221c6
AB  - For a long time, researchers have sought artificial intelligence (AI) that matches or exceeds human intelligence. AI agents, which are artificial entities capable of sensing the environment, making decisions, and taking actions, are seen as a means to achieve this goal. Extensive efforts have been made to develop AI agents, with a primary focus on refining algorithms or training strategies to enhance specific skills or particular task performance. The field, however, lacks a sufficiently general and powerful model to serve as a foundation for building general agents adaptable to diverse scenarios. With their versatile capabilities, large language models (LLMs) pave a promising path for the development of general AI agents, and substantial progress has been made in the realm of LLM-based agents. In this article, we conduct a comprehensive survey on LLM-based agents, covering their construction frameworks, application scenarios, and the exploration of societies built upon LLM-based agents. We also conclude some potential future directions and open problems in this flourishing field. © Science China Press 2025.
KW  - agent society
KW  - AI agents
KW  - large language models
KW  - LLM-based agents
KW  - natural language processing
KW  - Autonomous agents
KW  - Economic and social effects
KW  - Metabolism
KW  - Modeling languages
KW  - Agent society
KW  - Artificial intelligence agent
KW  - Language model
KW  - Language processing
KW  - Large language model
KW  - Large language model-based agent
KW  - Model-based OPC
KW  - Natural language processing
KW  - Natural languages
KW  - Natural language processing systems
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 24
ER  -

TY  - JOUR
AU  - Barnett, A.J.
AU  - Reilly, W.
AU  - Dimsdale-Zucker, H.R.
AU  - Mizrak, E.
AU  - Reagh, Z.
AU  - Ranganath, C.
TI  - Intrinsic connectivity reveals functionally distinct cortico-hippocampal networks in the human brain
PY  - 2021
T2  - PLoS Biology
VL  - 19
IS  - 6
C7  - e3001275
DO  - 10.1371/journal.pbio.3001275
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107803110&doi=10.1371%2fjournal.pbio.3001275&partnerID=40&md5=39db98c3f6c1b40cec2a0c7b9e75b881
AB  - Episodic memory depends on interactions between the hippocampus : and interconnected neocortical regions. Here, using data-driven analyses of resting-state functional magnetic resonance imaging (fMRI) data, we identified the networks that interact with the hippocampus-the default mode network (DMN) and a “medial temporal network” (MTN) that included regions in the medial temporal lobe (MTL) and precuneus. We observed that the MTN plays a critical role in connecting the visual network to the DMN and hippocampus. The DMN could be further divided into 3 subnetworks: a “posterior medial” (PM) subnetwork comprised of posterior cingulate and lateral parietal cortices; an “anterior temporal” (AT) subnetwork comprised of regions in the temporopolar and dorsomedial prefrontal cortex; and a “medial prefrontal” (MP) subnetwork comprised of regions primarily in the medial prefrontal cortex (mPFC). These networks vary in their functional connectivity (FC) along the hippocampal long axis and represent different kinds of information during memory-guided decision-making. Finally, a Neurosynth meta-analysis of fMRI studies suggests new hypotheses regarding the functions of the MTN and DMN subnetworks, providing a framework to guide future research on the neural architecture of episodic memory. © 2021 Barnett et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
KW  - Hippocampus
KW  - Humans
KW  - Memory
KW  - Nerve Net
KW  - Rest
KW  - Task Performance and Analysis
KW  - Temporal Lobe
KW  - Visual Pathways
KW  - article
KW  - decision making
KW  - default mode network
KW  - dorsomedial prefrontal cortex
KW  - episodic memory
KW  - functional connectivity
KW  - functional magnetic resonance imaging
KW  - hippocampus
KW  - human
KW  - medial temporal lobe
KW  - meta analysis
KW  - parietal cortex
KW  - posterior cingulate
KW  - precuneus
KW  - visual network
KW  - hippocampus
KW  - memory
KW  - nerve cell network
KW  - physiology
KW  - rest
KW  - task performance
KW  - temporal lobe
KW  - visual system
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 62
ER  -

TY  - JOUR
AU  - Liang, K.
AU  - Meng, L.
AU  - Liu, M.
AU  - Liu, Y.
AU  - Tu, W.
AU  - Wang, S.
AU  - Zhou, S.
AU  - Liu, X.
AU  - Sun, F.
AU  - He, K.
TI  - A Survey of Knowledge Graph Reasoning on Graph Types: Static, Dynamic, and Multi-Modal
PY  - 2024
T2  - IEEE Transactions on Pattern Analysis and Machine Intelligence
VL  - 46
IS  - 12
SP  - 9456
EP  - 9478
DO  - 10.1109/TPAMI.2024.3417451
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197053678&doi=10.1109%2fTPAMI.2024.3417451&partnerID=40&md5=dd1a76b3df05b2ba12d776718304c4fa
AB  - Knowledge graph reasoning (KGR), aiming to deduce new facts from existing facts based on mined logic rules underlying knowledge graphs (KGs), has become a fast-growing research direction. It has been proven to significantly benefit the usage of KGs in many AI applications, such as question answering, recommendation systems, and etc. According to the graph types, existing KGR models can be roughly divided into three categories, i.e., static models, temporal models, and multi-modal models. Early works in this domain mainly focus on static KGR, and recent works try to leverage the temporal and multi-modal information, which are more practical and closer to real-world. However, no survey papers and open-source repositories comprehensively summarize and discuss models in this important direction. To fill the gap, we conduct a first survey for knowledge graph reasoning tracing from static to temporal and then to multi-modal KGs. Concretely, the models are reviewed based on bi-level taxonomy, i.e., top-level (graph types) and base-level (techniques and scenarios). Besides, the performances, as well as datasets, are summarized and presented. Moreover, we point out the challenges and potential opportunities to enlighten the readers.  © 1979-2012 IEEE.
KW  - knowledge graph
KW  - Knowledge graph reasoning
KW  - multi-modal knowledge graph
KW  - temporal knowledge graph
KW  - Knowledge graph reasoning
KW  - Knowledge graphs
KW  - Multi-modal
KW  - Multi-modal knowledge graph
KW  - Open source repositories
KW  - Temporal knowledge
KW  - Temporal knowledge graph
KW  - article
KW  - artificial intelligence software
KW  - human
KW  - knowledge
KW  - reasoning
KW  - taxonomy
KW  - Knowledge graph
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 87
ER  -

TY  - BOOK
AU  - Zhu, W.
AU  - Wang, X.
TI  - Automated Machine Learning and Meta-Learning for Multimedia
PY  - 2022
T2  - Automated Machine Learning and Meta-Learning for Multimedia
SP  - 1
EP  - 224
DO  - 10.1007/978-3-030-88132-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159474066&doi=10.1007%2f978-3-030-88132-0&partnerID=40&md5=63f227768e201b501351e75c54f28e99
AB  - This book disseminates and promotes the recent research progress and frontier development on AutoML and meta-learning as well as their applications on computer vision, natural language processing, multimedia and data mining related fields. These are exciting and fast-growing research directions in the general field of machine learning. The authors advocate novel, high-quality research findings, and innovative solutions to the challenging problems in AutoML and meta-learning. This topic is at the core of the scope of artificial intelligence, and is attractive to audience from both academia and industry. This book is highly accessible to the whole machine learning community, including: researchers, students and practitioners who are interested in AutoML, meta-learning, and their applications in multimedia, computer vision, natural language processing and data mining related tasks. The book is self-contained and designed for introductory and intermediate audiences. No special prerequisite knowledge is required to read this book. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2021.
KW  - Adaptive information processing
KW  - Automated machine learning
KW  - Automated multimedia information processing
KW  - AutoML
KW  - AutoML for CV/multimedia and datamining
KW  - Bayesian optimization
KW  - Hyper-parameter optimization
KW  - Learning to learn
KW  - Machine learning
KW  - Meta-learning
KW  - Meta-learning for multimedia and datamining
KW  - Neural architecture search
M3  - Book
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Kotseruba, I.
AU  - Tsotsos, J.K.
TI  - 40 years of cognitive architectures: core cognitive abilities and practical applications
PY  - 2020
T2  - Artificial Intelligence Review
VL  - 53
IS  - 1
SP  - 17
EP  - 94
DO  - 10.1007/s10462-018-9646-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050796728&doi=10.1007%2fs10462-018-9646-y&partnerID=40&md5=528ba995b6e5f99f6badeaa4d87e9b5e
AB  - In this paper we present a broad overview of the last 40 years of research on cognitive architectures. To date, the number of existing architectures has reached several hundred, but most of the existing surveys do not reflect this growth and instead focus on a handful of well-established architectures. In this survey we aim to provide a more inclusive and high-level overview of the research on cognitive architectures. Our final set of 84 architectures includes 49 that are still actively developed, and borrow from a diverse set of disciplines, spanning areas from psychoanalysis to neuroscience. To keep the length of this paper within reasonable limits we discuss only the core cognitive abilities, such as perception, attention mechanisms, action selection, memory, learning, reasoning and metareasoning. In order to assess the breadth of practical applications of cognitive architectures we present information on over 900 practical projects implemented using the cognitive architectures in our list. We use various visualization techniques to highlight the overall trends in the development of the field. In addition to summarizing the current state-of-the-art in the cognitive architecture research, this survey describes a variety of methods and ideas that have been tried and their relative success in modeling human cognitive abilities, as well as which aspects of cognitive behavior need more research with respect to their mechanistic counterparts and thus can further inform how cognitive science might progress. © 2018, The Author(s).
KW  - Attention
KW  - Cognitive abilities
KW  - Cognitive architectures
KW  - Perception
KW  - Practical applications
KW  - Survey
KW  - Sensory perception
KW  - Surveying
KW  - Surveys
KW  - Attention
KW  - Attention mechanisms
KW  - Cognitive ability
KW  - Cognitive architectures
KW  - Cognitive behavior
KW  - Existing architectures
KW  - Human cognitive abilities
KW  - Visualization technique
KW  - Behavioral research
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 299
ER  -

TY  - JOUR
AU  - Bekkemoen, Y.
TI  - Explainable reinforcement learning (XRL): a systematic literature review and taxonomy
PY  - 2024
T2  - Machine Learning
VL  - 113
IS  - 1
SP  - 355
EP  - 441
DO  - 10.1007/s10994-023-06479-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178051880&doi=10.1007%2fs10994-023-06479-7&partnerID=40&md5=8a5a3e37497d50b95590c9e028c76928
AB  - In recent years, reinforcement learning (RL) systems have shown impressive performance and remarkable achievements. Many achievements can be attributed to combining RL with deep learning. However, those systems lack explainability, which refers to our understanding of the system’s decision-making process. In response to this challenge, the new explainable RL (XRL) field has emerged and grown rapidly to help us understand RL systems. This systematic literature review aims to give a unified view of the field by reviewing ten existing XRL literature reviews and 189 XRL studies from the past five years. Furthermore, we seek to organize these studies into a new taxonomy, discuss each area in detail, and draw connections between methods and stakeholder questions (e.g., “how can I get the agent to do _?”). Finally, we look at the research trends in XRL, recommend XRL methods, and present some exciting research directions for future research. We hope stakeholders, such as RL researchers and practitioners, will utilize this literature review as a comprehensive resource to overview existing state-of-the-art XRL methods. Additionally, we strive to help find research gaps and quickly identify methods that answer stakeholder questions. © 2023, The Author(s).
KW  - Explainability
KW  - Explainable artificial intelligence
KW  - Explanation
KW  - Interpretability
KW  - Reinforcement learning
KW  - Decision making
KW  - Deep learning
KW  - Taxonomies
KW  - Decision-making process
KW  - Explainability
KW  - Explainable artificial intelligence
KW  - Explanation
KW  - Interpretability
KW  - Literature reviews
KW  - Performance
KW  - Reinforcement learning systems
KW  - Reinforcement learnings
KW  - Systematic literature review
KW  - Reinforcement learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 9
ER  -

TY  - JOUR
AU  - Mao, R.
AU  - He, K.
AU  - Zhang, X.
AU  - Chen, G.
AU  - Ni, J.
AU  - Yang, Z.
AU  - Cambria, E.
TI  - A survey on semantic processing techniques
PY  - 2024
T2  - Information Fusion
VL  - 101
C7  - 101988
DO  - 10.1016/j.inffus.2023.101988
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172881772&doi=10.1016%2fj.inffus.2023.101988&partnerID=40&md5=76336b2dcb9ae56e7cfdc55ec899240c
AB  - Semantic processing is a fundamental research domain in computational linguistics. In the era of powerful pre-trained language models and large language models, the advancement of research in this domain appears to be decelerating. However, the study of semantics is multi-dimensional in linguistics. The research depth and breadth of computational semantic processing can be largely improved with new technologies. In this survey, we analyzed five semantic processing tasks, e.g., word sense disambiguation, anaphora resolution, named entity recognition, concept extraction, and subjectivity detection. We study relevant theoretical research in these fields, advanced methods, and downstream applications. We connect the surveyed tasks with downstream applications because this may inspire future scholars to fuse these low-level semantic processing tasks with high-level natural language processing tasks. The review of theoretical research may also inspire new tasks and technologies in the semantic processing domain. Finally, we compare the different semantic processing techniques and summarize their technical trends, application trends, and future directions. © 2023 Elsevier B.V.
KW  - Anaphora resolution
KW  - Concept extraction
KW  - Named entity recognition
KW  - Semantic processing
KW  - Subjectivity detection
KW  - Word sense disambiguation
KW  - Extraction
KW  - High level languages
KW  - Natural language processing systems
KW  - Semantics
KW  - Anaphora resolution
KW  - Concept extraction
KW  - Downstream applications
KW  - Language model
KW  - Named entity recognition
KW  - Processing technique
KW  - Semantic processing
KW  - Subjectivity detection
KW  - Theoretical research
KW  - Word Sense Disambiguation
KW  - Computational linguistics
M3  - Short survey
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 37
ER  -

TY  - CONF
AU  - Banerjee, A.
AU  - Rahmani, K.
AU  - Biswas, J.
AU  - Dillig, I.
TI  - Dynamic Model Predictive Shielding for Provably Safe Reinforcement Learning
PY  - 2024
T2  - Advances in Neural Information Processing Systems
VL  - 37
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000491289&partnerID=40&md5=b4743e35f19ec97e5c0d2d7677bf36c1
AB  - Among approaches for provably safe reinforcement learning, Model Predictive Shielding (MPS) has proven effective at complex tasks in continuous, high-dimensional state spaces, by leveraging a backup policy to ensure safety when the learned policy attempts to take unsafe actions. However, while MPS can ensure safety both during and after training, it often hinders task progress due to the conservative and task-oblivious nature of backup policies. This paper introduces Dynamic Model Predictive Shielding (DMPS), which optimizes reinforcement learning objectives while maintaining provable safety. DMPS employs a local planner to dynamically select safe recovery actions that maximize both short-term progress as well as long-term rewards. Crucially, the planner and the neural policy play a synergistic role in DMPS. When planning recovery actions for ensuring safety, the planner utilizes the neural policy to estimate long-term rewards, allowing it to observe beyond its short-term planning horizon. Conversely, the neural policy under training learns from the recovery plans proposed by the planner, converging to policies that are both high-performing and safe in practice. This approach guarantees safety during and after training, with bounded recovery regret that decreases exponentially with planning horizon depth. Experimental results demonstrate that DMPS converges to policies that rarely require shield interventions after training and achieve higher rewards compared to several state-of-the-art baselines. © 2024 Neural information processing systems foundation. All rights reserved.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Zhang, T.
AU  - Yang, K.
AU  - Ji, S.
AU  - Ananiadou, S.
TI  - Emotion fusion for mental illness detection from social media: A survey
PY  - 2023
T2  - Information Fusion
VL  - 92
SP  - 231
EP  - 246
DO  - 10.1016/j.inffus.2022.11.031
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143660071&doi=10.1016%2fj.inffus.2022.11.031&partnerID=40&md5=5fda56e3f4cd7f51d66e54a375485fb0
AB  - Mental illnesses are one of the most prevalent public health problems worldwide, which negatively influence people's lives and society's health. With the increasing popularity of social media, there has been a growing research interest in the early detection of mental illness by analysing user-generated posts on social media. According to the correlation between emotions and mental illness, leveraging and fusing emotion information has developed into a valuable research topic. In this article, we provide a comprehensive survey of approaches to mental illness detection in social media that incorporate emotion fusion. We begin by reviewing different fusion strategies, along with their advantages and disadvantages. Subsequently, we discuss the major challenges faced by researchers working in this area, including issues surrounding the availability and quality of datasets, the performance of algorithms and interpretability. We additionally suggest some potential directions for future research. © 2022 The Author(s)
KW  - Affective computing
KW  - Emotion fusion
KW  - Mental illness detection
KW  - Natural language processing
KW  - Social media
KW  - Natural language processing systems
KW  - Social networking (online)
KW  - Affective Computing
KW  - Emotion fusion
KW  - Language processing
KW  - Mental illness
KW  - Mental illness detection
KW  - Natural language processing
KW  - Natural languages
KW  - Research interests
KW  - Social media
KW  - User-generated
KW  - Diseases
M3  - Short survey
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 51
ER  -

TY  - JOUR
AU  - Tocchetti, A.
AU  - Corti, L.
AU  - Balayn, A.
AU  - Yurrita, M.
AU  - Lippmann, P.
AU  - Brambilla, M.
AU  - Yang, J.
TI  - A.I. Robustness: a Human-Centered Perspective on Technological Challenges and Opportunities
PY  - 2025
T2  - ACM Computing Surveys
VL  - 57
IS  - 6
C7  - 141
DO  - 10.1145/3665926
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208063138&doi=10.1145%2f3665926&partnerID=40&md5=7237617d453259e3a94d37896d0de855
AB  - Despite the impressive performance of Artificial Intelligence (AI) systems, their robustness remains elusive and constitutes a key issue that impedes large-scale adoption. Besides, robustness is interpreted differently across domains and contexts of AI. In this work, we systematically survey recent progress to provide a reconciled terminology of concepts around AI robustness. We introduce three taxonomies to organize and describe the literature both from a fundamental and applied point of view: (1) methods and approaches that address robustness in different phases of the machine learning pipeline; (2) methods improving robustness in specific model architectures, tasks, and systems; and in addition, (3) methodologies and insights around evaluating the robustness of AI systems, particularly the tradeoffs with other trustworthiness properties. Finally, we identify and discuss research gaps and opportunities and give an outlook on the field. We highlight the central role of humans in evaluating and enhancing AI robustness, considering the necessary knowledge they can provide, and discuss the need for better understanding practices and developing supportive tools in the future. © 2025 Copyright held by the owner/author(s)
KW  - Artificial intelligence
KW  - human-centered AI
KW  - robustness
KW  - trustworthy AI
KW  - Adversarial machine learning
KW  - Artificial intelligence systems
KW  - Human-centered artificial intelligence
KW  - Key Issues
KW  - Large-scales
KW  - Performance
KW  - Recent progress
KW  - Robustness
KW  - Technological challenges
KW  - Technological opportunity
KW  - Trustworthy artificial intelligence
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Allouch, M.
AU  - Azaria, A.
AU  - Azoulay, R.
TI  - Conversational agents: Goals, technologies, vision and challenges
PY  - 2021
T2  - Sensors
VL  - 21
IS  - 24
C7  - 8448
DO  - 10.3390/s21248448
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121307475&doi=10.3390%2fs21248448&partnerID=40&md5=58af483342a42b24ac1df1e55594ab43
AB  - In recent years, conversational agents (CAs) have become ubiquitous and are a presence in our daily routines. It seems that the technology has finally ripened to advance the use of CAs in various domains, including commercial, healthcare, educational, political, industrial, and personal domains. In this study, the main areas in which CAs are successful are described along with the main technologies that enable the creation of CAs. Capable of conducting ongoing communication with humans, CAs are encountered in natural-language processing, deep learning, and technologies that integrate emotional aspects. The technologies used for the evaluation of CAs and publicly available datasets are outlined. In addition, several areas for future research are identified to address moral and security issues, given the current state of CA-related technological developments. The uniqueness of our review is that an overview of the concepts and building blocks of CAs is provided, and CAs are categorized according to their abilities and main application domains. In addition, the primary tools and datasets that may be useful for the development and evaluation of CAs of different categories are described. Finally, some thoughts and directions for future research are provided, and domains that may benefit from conversational agents are introduced. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.
KW  - Conversational agents
KW  - Human–agent interaction
KW  - Smart environments
KW  - Communication
KW  - Goals
KW  - Humans
KW  - Natural Language Processing
KW  - Technology
KW  - Vision, Ocular
KW  - Deep learning
KW  - Engineering education
KW  - 'current
KW  - Building blockes
KW  - Conversational agents
KW  - Daily routines
KW  - Emotional aspect
KW  - Human-agent interaction
KW  - Moral issues
KW  - Security issues
KW  - Smart environment
KW  - Technological development
KW  - human
KW  - interpersonal communication
KW  - motivation
KW  - natural language processing
KW  - technology
KW  - vision
KW  - Natural language processing systems
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 88
ER  -

TY  - JOUR
AU  - Islam, S.
AU  - Dash, A.
AU  - Seum, A.
AU  - Raj, A.H.
AU  - Hossain, T.
AU  - Shah, F.M.
TI  - Exploring Video Captioning Techniques: A Comprehensive Survey on Deep Learning Methods
PY  - 2021
T2  - SN Computer Science
VL  - 2
IS  - 2
C7  - 120
DO  - 10.1007/s42979-021-00487-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123196713&doi=10.1007%2fs42979-021-00487-x&partnerID=40&md5=77c6eb33ae901db436088e2fd484a825
AB  - Video captioning is an automated collection of natural language phrases that explains the contents in video frames. Because of the incomparable performance of deep learning in the field of computer vision and natural language processing in recent years, research in this field has been exponentially increased throughout past decades. Numerous approaches, datasets, and measurement metrics have been introduced in the literature, calling for a systematic survey to guide research efforts in this exciting new direction. Through the statistical analysis, this survey paper focuses mostly on state-of-the-art approaches, emphasizing deep learning models, assessing benchmark datasets in several parameters, and classifying the pros and cons of the various evaluation metrics based on the previous works in the deep learning field. This survey shows the most used variants of neural networks for visual and spatio-temporal feature extraction as well as language generation model. The results show that ResNet and VGG as visual feature extractor and 3D convolutional neural network as spatio-temporal feature extractor are mostly used. Besides that, Long Short Term Memory (LSTM) has been mainly used as the language model. However, nowadays, the Gated Recurrent Unit (GRU) and Transformer are slowly replacing LSTM. Regarding dataset usage, so far, MSVD and MSR-VTT are very much dominant due to be part of outstanding results among various captioning models. From 2015 to 2020, with all major datasets, some models such as, Inception-Resnet-v2 + C3D + LSTM, ResNet-101 + I3D + Transformer, ResNet-152 + ResNext-101 (R3D) + (LSTM, GAN) have achieved by far best results in video captioning. Despite rapid advancement, our survey reveals that video captioning research-work still has a lot to develop in accessing the full potential of deep learning for classifying and captioning a large number of activities, as well as creating large datasets covering diversified training video samples. © 2021, The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd. part of Springer Nature.
KW  - Dataset Comparison
KW  - Deep Learning
KW  - Evaluation Metrics
KW  - Feature Extraction
KW  - Spatio-Temporal
KW  - Video captioning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 28
ER  -

TY  - JOUR
AU  - Morales, E.F.
AU  - Murrieta-Cid, R.
AU  - Becerra, I.
AU  - Esquivel-Basaldua, M.A.
TI  - A survey on deep learning and deep reinforcement learning in robotics with a tutorial on deep reinforcement learning
PY  - 2021
T2  - Intelligent Service Robotics
VL  - 14
IS  - 5
SP  - 773
EP  - 805
DO  - 10.1007/s11370-021-00398-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119108562&doi=10.1007%2fs11370-021-00398-z&partnerID=40&md5=575666610325c2149a52dbf59ee59308
AB  - This article is about deep learning (DL) and deep reinforcement learning (DRL) works applied to robotics. Both tools have been shown to be successful in delivering data-driven solutions for robotics tasks, as well as providing a natural way to develop an end-to-end pipeline from the robot’s sensing to its actuation, passing through the generation of a policy to perform the given task. These frameworks have been proven to be able to deal with real-world complications such as noise in sensing, imprecise actuation, variability in the scenarios where the robot is being deployed, among others. Following that vein, and given the growing interest in DL and DRL, the present work starts by providing a brief tutorial on deep reinforcement learning, where the goal is to understand the main concepts and approaches followed in the field. Later, the article describes the main, recent, and most promising approaches of DL and DRL in robotics, with sufficient technical detail to understand the core of the works and to motivate interested readers to initiate their own research in the area. Then, to provide a comparative analysis, we present several taxonomies in which the references can be classified, according to high-level features, the task that the work addresses, the type of system, and the learning techniques used in the work. We conclude by presenting promising research directions in both DL and DRL. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
KW  - Deep learning
KW  - Deep reinforcement learning
KW  - Mobile manipulation
KW  - Mobile robot navigation
KW  - Mobile robotics
KW  - Motion planning
KW  - Mobile robots
KW  - Motion planning
KW  - Reinforcement learning
KW  - Robot programming
KW  - Robotics
KW  - Data driven
KW  - Deep learning
KW  - End to end
KW  - Mobile manipulation
KW  - Mobile Robot Navigation
KW  - Mobile robotic
KW  - Motion-planning
KW  - Real-world
KW  - Robotic tasks
KW  - Technical details
KW  - Deep learning
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 69
ER  -

TY  - JOUR
AU  - Li, J.
AU  - Zhang, M.
AU  - Li, N.
AU  - Weyns, D.
AU  - Jin, Z.
AU  - Tei, K.
TI  - Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap
PY  - 2024
T2  - ACM Transactions on Autonomous and Adaptive Systems
VL  - 19
IS  - 3
C7  - 13
DO  - 10.1145/3686803
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204810253&doi=10.1145%2f3686803&partnerID=40&md5=7dd49ab640eece1c677b47af1109d204
AB  - Self-adaptive systems (SASs) are designed to handle changes and uncertainties through a feedback loop with four core functionalities: monitoring, analyzing, planning, and execution. Recently, generative artificial intelligence (GenAI), especially the area of large language models, has shown impressive performance in data comprehension and logical reasoning. These capabilities are highly aligned with the functionalities required in SASs, suggesting a strong potential to employ GenAI to enhance SASs. However, the specific benefits and challenges of employing GenAI in SASs remain unclear. Yet, providing a comprehensive understanding of these benefits and challenges is complex due to several reasons: limited publications in the SAS field, the technological and application diversity within SASs, and the rapid evolution of GenAI technologies. To that end, this article aims to provide researchers and practitioners a comprehensive snapshot that outlines the potential benefits and challenges of employing GenAI's within SAS. Specifically, we gather, filter, and analyze literature from four distinct research fields and organize them into two main categories to potential benefits: (i) enhancements to the autonomy of SASs centered around the specific functions of the MAPE-K feedback loop, and (ii) improvements in the interaction between humans and SASs within human-on-the-loop settings. From our study, we outline a research roadmap that highlights the challenges of integrating GenAI into SASs. The roadmap starts with outlining key research challenges that need to be tackled to exploit the potential for applying GenAI in the field of SAS. The roadmap concludes with a practical reflection, elaborating on current shortcomings of GenAI and proposing possible mitigation strategies.  © 2024 Copyright held by the owner/author(s).
KW  - diffusion model
KW  - Generative AI
KW  - Large Language Model
KW  - MAPE
KW  - Self-Adaptive Systems
KW  - survey
KW  - Adaptive systems
KW  - Functional programming
KW  - Benefit and challenges
KW  - Diffusion model
KW  - Feedback loops
KW  - Generative AI
KW  - Language model
KW  - Large language model
KW  - Mape
KW  - Potential benefits
KW  - Research roadmap
KW  - Self-adaptive system
KW  - Generative adversarial networks
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 8
ER  -

TY  - BOOK
AU  - Luger, G.F.
TI  - Knowing our world: An artificial intelligence perspective
PY  - 2021
T2  - Knowing our World: An Artificial Intelligence Perspective
SP  - 1
EP  - 256
DO  - 10.1007/978-3-030-71873-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142638891&doi=10.1007%2f978-3-030-71873-2&partnerID=40&md5=cb2ac041cad18faa7d988ac215021ed8
AB  - Knowing our World: An Artificial Intelligence Perspective considers the methodologies of science, computation, and artificial intelligence to explore how we humans come to understand and operate in our world. While humankind's history of articulating ideas and building machines that can replicate the activity of the human brain is impressive, Professor Luger focuses on understanding the skills that enable these goals. Based on insights afforded by the challenges of AI design and program building, Knowing our World proposes a foundation for the science of epistemology. Taking an interdisciplinary perspective, the book demonstrates that AI technology offers many representational structures and reasoning strategies that support clarification of these epistemic foundations. This monograph is organized in three Parts; the first three chapters introduce the reader to the foundations of computing and the philosophical background that supports the AI tradition. These three chapters describe the origins of AI, programming as iterative refinement, and the representations and very high-level language tools that support AI application building. The book's second Part introduces three of the four paradigms that represent research and development in AI over the past seventy years: the symbol-based, connectionist, and complex adaptive systems. Luger presents several introductory programs in each area and demonstrates their use. The final three chapters present the primary theme of the book: bringing together the rationalist, empiricist, and pragmatist philosophical traditions in the context of a Bayesian world view. Luger describes Bayes' theorem with a simple proof to demonstrate epistemic insights. He describes research in model building and refinement and several philosophical issues that constrain the future growth of AI. The book concludes with his proposal of the epistemic stance of an active, pragmatic, model-revising realism. © Springer Nature Switzerland AG 2021. All rights reserved.
KW  - Artificial Intelligence (AI)
KW  - Computational intelligence
KW  - Connectionist approach to AI
KW  - Epistemic stance
KW  - Evolutionary computing
KW  - Historical foundations for AI
M3  - Book
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 12
ER  -

TY  - JOUR
AU  - Park, E.H.
AU  - Storey, V.C.
TI  - Emotion Ontology Studies: A Framework for Expressing Feelings Digitally and its Application to Sentiment Analysis
PY  - 2023
T2  - ACM Computing Surveys
VL  - 55
IS  - 9
C7  - 181
DO  - 10.1145/3555719
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147845860&doi=10.1145%2f3555719&partnerID=40&md5=76e78811c5274a2d2d5ca385087345ef
AB  - Emotion ontologies have been developed to capture affect, a concept that encompasses discrete emotions and feelings, especially for research on sentiment analysis, which analyzes a customer's attitude towards a company or a product. However, there have been limited efforts to adapt and employ these ontologies. This research surveys and synthesizes emotion ontology studies to develop a Framework of Emotion Ontologies that can be used to help a user select or design an appropriate emotion ontology to support sentiment analysis and increase the user's understanding of the roles of affect, context, and behavioral information with respect to sentiment. The framework, which is derived from research on emotion ontologies, psychology, and sentiment analysis, classifies emotion ontologies as discrete emotion or one of two hybrid ontologies that are combinations of the discrete, dimensional, or componential process emotion paradigms. To illustrate its usefulness, the framework is applied to the development of an emotion ontology for a sentiment analysis application.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.
KW  - affect
KW  - componential process ontology
KW  - dimensional emotion ontology
KW  - discrete emotion ontology
KW  - emotion
KW  - Framework of Emotion Ontologies
KW  - Ontology
KW  - sentiment analysis
KW  - Sentiment analysis
KW  - Affect
KW  - Componential process ontology
KW  - Dimensional emotion ontology
KW  - Discrete emotion ontology
KW  - Emotion
KW  - Emotion ontologies
KW  - Framework of emotion ontology
KW  - Ontology's
KW  - Process ontologies
KW  - Sentiment analysis
KW  - Ontology
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 19
ER  -

TY  - JOUR
AU  - Han, P.
AU  - Huang, X.
AU  - Fang, Y.
AU  - Han, G.
TI  - Rethinking Knowledge Distillation in Collaborative Machine Learning: Memory, Knowledge, and Their Interactions
PY  - 2025
T2  - IEEE Transactions on Network Science and Engineering
DO  - 10.1109/TNSE.2025.3572362
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006632962&doi=10.1109%2fTNSE.2025.3572362&partnerID=40&md5=349e744938d9b28510973406d1b78dae
AB  - Collaborative learning has emerged as a key paradigm in large-scale intelligent systems, enabling distributed agents to cooperatively train their models while addressing their privacy concerns. Central to this paradigm is knowledge distillation (KD), a technique that facilitates efficient knowledge transfer among agents. However, the underlying mechanisms by which KD leverages memory and knowledge across agents remain underexplored. This paper aims to bridge this gap by offering a comprehensive review of KD in collaborative learning, with a focus on the roles of memory and knowledge. We define and categorize memory and knowledge within the KD process and explore their interrelationships, providing a clear understanding of how knowledge is extracted, stored, and shared in collaborative settings. We examine various collaborative learning patterns, including distributed, hierarchical, and decentralized structures, and provide insights into how memory and knowledge dynamics shape the effectiveness of KD in collaborative learning. Particularly, we emphasize task heterogeneity in distributed learning pattern covering federated learning (FL), multi-agent domain adaptation (MADA), federated multi-modal learning (FML), federated continual learning (FCL), federated multi-task learning (FMTL), and federated graph knowledge embedding (FKGE). Additionally, we highlight model heterogeneity, data heterogeneity, resource heterogeneity, and privacy concerns of these tasks. Our analysis categorizes existing work based on how they handle memory and knowledge. Finally, we discuss existing challenges and propose future directions for advancing KD techniques in the context of collaborative learning. © 2013 IEEE.
KW  - collaborative learning
KW  - heterogeneity
KW  - Knowledge distillation
KW  - memory mechanism
KW  - Domain Knowledge
KW  - Expert systems
KW  - Hierarchical systems
KW  - Knowledge engineering
KW  - Multi-task learning
KW  - Collaborative learning
KW  - Distributed agents
KW  - Heterogeneity
KW  - Knowledge distillation
KW  - Knowledge transfer
KW  - Large-scales
KW  - Learning memory
KW  - Machine-learning
KW  - Memory mechanism
KW  - Privacy concerns
KW  - Federated learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Babaei, R.
AU  - Cheng, S.
AU  - Duan, R.
AU  - Zhao, S.
TI  - Generative Artificial Intelligence and the Evolving Challenge of Deepfake Detection: A Systematic Analysis
PY  - 2025
T2  - Journal of Sensor and Actuator Networks
VL  - 14
IS  - 1
C7  - 17
DO  - 10.3390/jsan14010017
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218879708&doi=10.3390%2fjsan14010017&partnerID=40&md5=94a0d2213769269e899eefecbbcec4c1
AB  - Deepfake technology, which employs advanced generative artificial intelligence to create hyper-realistic synthetic media, poses significant challenges across various sectors, including security, entertainment, and education. This literature review explores the evolution of deepfake generation methods, ranging from traditional techniques to state-of-the-art models such as generative adversarial networks and diffusion models. We navigate through the effectiveness and limitations of various detection approaches, including machine learning, forensic analysis, and hybrid techniques, while highlighting the critical importance of interpretability and real-time performance in detection systems. Furthermore, we discuss the ethical implications and regulatory considerations surrounding deepfake technology, emphasizing the need for comprehensive frameworks to mitigate risks associated with misinformation and manipulation. Through a systematic review of the existing literature, our aim is to identify research gaps and future directions for the development of robust, adaptable detection systems that can keep pace with rapid advancements in deepfake generation. © 2025 by the authors.
KW  - deepfake detection
KW  - digital forensics
KW  - generative artificial intelligence
KW  - media security
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 4
ER  -

TY  - JOUR
AU  - Schmitt, O.
TI  - Relationships and representations of brain structures, connectivity, dynamics and functions
PY  - 2025
T2  - Progress in Neuro-Psychopharmacology and Biological Psychiatry
VL  - 138
C7  - 111332
DO  - 10.1016/j.pnpbp.2025.111332
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001234372&doi=10.1016%2fj.pnpbp.2025.111332&partnerID=40&md5=96dca038a7b390227390edc0d3eaaef2
AB  - The review explores the complex interplay between brain structures and their associated functions, presenting a diversity of hierarchical models that enhances our understanding of these relationships. Central to this approach are structure-function flow diagrams, which offer a visual representation of how specific neuroanatomical structures are linked to their functional roles. These diagrams are instrumental in mapping the intricate connections between different brain regions, providing a clearer understanding of how functions emerge from the underlying neural architecture. The study details innovative attempts to develop new functional hierarchies that integrate structural and functional data. These efforts leverage recent advancements in neuroimaging techniques such as fMRI, EEG, MEG, and PET, as well as computational models that simulate neural dynamics. By combining these approaches, the study seeks to create a more refined and dynamic hierarchy that can accommodate the brain's complexity, including its capacity for plasticity and adaptation. A significant focus is placed on the overlap of structures and functions within the brain. The manuscript acknowledges that many brain regions are multifunctional, contributing to different cognitive and behavioral processes depending on the context. This overlap highlights the need for a flexible, non-linear hierarchy that can capture the brain's intricate functional landscape. Moreover, the study examines the interdependence of these functions, emphasizing how the loss or impairment of one function can impact others. Another crucial aspect discussed is the brain's ability to compensate for functional deficits following neurological diseases or injuries. The investigation explores how the brain reorganizes itself, often through the recruitment of alternative neural pathways or the enhancement of existing ones, to maintain functionality despite structural damage. This compensatory mechanism underscores the brain's remarkable plasticity, demonstrating its ability to adapt and reconfigure itself in response to injury, thereby ensuring the continuation of essential functions. In conclusion, the study presents a system of brain functions that integrates structural, functional, and dynamic perspectives. It offers a robust framework for understanding how the brain's complex network of structures supports a wide range of cognitive and behavioral functions, with significant implications for both basic neuroscience and clinical applications. © 2024
KW  - Behavior
KW  - Brain theory
KW  - Computational neuroscience
KW  - Connectomics
KW  - Functions
KW  - Hierarchies
KW  - Imaging
KW  - Modeling
KW  - Neuronal dynamics
KW  - Ontologies
KW  - Simulation
KW  - Animals
KW  - Brain
KW  - Brain Mapping
KW  - Humans
KW  - Models, Neurological
KW  - Nerve Net
KW  - Neural Pathways
KW  - adaptation
KW  - brain
KW  - brain function
KW  - brain region
KW  - cognition
KW  - computer model
KW  - connectome
KW  - dynamics
KW  - electroencephalogram
KW  - electroencephalography
KW  - functional magnetic resonance imaging
KW  - motor neuron disease
KW  - nerve tract
KW  - neuroimaging
KW  - neurologic disease
KW  - nonhuman
KW  - ontology
KW  - positron emission tomography
KW  - review
KW  - simulation
KW  - theoretical neuroscience
KW  - animal
KW  - biological model
KW  - brain mapping
KW  - diagnostic imaging
KW  - human
KW  - nerve cell network
KW  - nerve tract
KW  - physiology
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Sahu, R.
AU  - Singh, D.P.
TI  - Conventional and deep learning approaches for glacial lake mapping using remote sensing data: a comprehensive review
PY  - 2025
T2  - International Journal of Remote Sensing
VL  - 46
IS  - 10
SP  - 3992
EP  - 4020
DO  - 10.1080/01431161.2025.2496001
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003881834&doi=10.1080%2f01431161.2025.2496001&partnerID=40&md5=5755e2cb068b1796c2858ebb98e8d1ad
AB  - Mountain lakes are one of the critical indicators of climate change and are also responsible for glacier hazards. Mapping glacial lakes is essential for monitoring them and forecasting glacier-related hazards. Remote sensing images play a crucial role in achieving this by enabling accurate and effective mapping of glacial lakes. This review paper provides a comprehensive analysis of traditional pixel-based and object-based methods, along with machine learning and deep learning methods for glacial lake mapping, complemented by a brief summary of available datasets. Deep learning models offer superior accuracy compared to conventional pixel-based, object-based, and machine learning methods. While other natural resource mapping studies have successfully employed advanced deep learning models such as Swin Transformer, Hybrid CNN-ViT, and HRNet with novel backbone architectures, glacial lake mapping has predominantly relied on a limited number of deep learning models. Therefore, this review recommends to use these models for glacial lake mapping in the future. © 2025 Informa UK Limited, trading as Taylor & Francis Group.
KW  - deep learning
KW  - Glacial lakes
KW  - machine learning
KW  - remote sensing data
KW  - Glacial geology
KW  - Global warming
KW  - Mapping
KW  - Comprehensive analysis
KW  - Deep learning
KW  - Glacial lakes
KW  - Learning approach
KW  - Learning models
KW  - Machine-learning
KW  - Mountain lakes
KW  - Remote sensing data
KW  - Remote sensing images
KW  - Review papers
KW  - glacial lake
KW  - machine learning
KW  - mapping
KW  - pixel
KW  - remote sensing
KW  - Deep learning
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Zhang, Z.
AU  - Chen, C.
AU  - Liu, B.
AU  - Liao, C.
AU  - Gong, Z.
AU  - Yu, H.
AU  - Li, J.
AU  - Wang, R.
TI  - Unifying the Perspectives of NLP and Software Engineering: A Survey on Language Models for Code
PY  - 2024
T2  - Transactions on Machine Learning Research
VL  - 2024
SP  - 1
EP  - 125
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000655240&partnerID=40&md5=74ff896f4ed0d5eb3c7533ab951c0f57
AB  - In this work we systematically review the recent advancements in software engineering with language models, covering 70+ models, 40+ evaluation tasks, 180+ datasets, and 900 related works. Unlike previous works, we integrate software engineering (SE) with natural language processing (NLP) by discussing the perspectives of both sides: SE applies language models for development automation, while NLP adopts SE tasks for language model evaluation. We break down code processing models into general language models represented by the GPT family and specialized models that are specifically pretrained on code, often with tailored objectives. We discuss the relations and differences between these models, and highlight the historical transition of code modeling from statistical models and RNNs to pretrained Transformers and LLMs, which is exactly the same course that had been taken by NLP. We also go beyond programming and review LLMs’ application in other software engineering activities including requirement engineering, testing, deployment, and operations in an endeavor to provide a global view of NLP in SE, and identify key challenges and potential future directions in this domain. We keep the survey open and updated on GitHub at https://github.com/codefuse-ai/Awesome-Code-LLM. © 2024, Transactions on Machine Learning Research. All rights reserved.
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Fici, A.
AU  - Bilucaglia, M.
AU  - Casiraghi, C.
AU  - Rossi, C.
AU  - Chiarelli, S.
AU  - Columbano, M.
AU  - Micheletto, V.
AU  - Zito, M.
AU  - Russo, V.
TI  - From E-Commerce to the Metaverse: A Neuroscientific Analysis of Digital Consumer Behavior
PY  - 2024
T2  - Behavioral Sciences
VL  - 14
IS  - 7
C7  - 596
DO  - 10.3390/bs14070596
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199491830&doi=10.3390%2fbs14070596&partnerID=40&md5=31f1856f449be3d86a17a966f55202e4
AB  - The growing interest in consumer behavior in the digital environment is leading scholars and companies to focus on consumer behavior and choices on digital platforms, such as the metaverse. On this immersive digital shopping platform, consumer neuroscience provides an optimal opportunity to explore consumers’ emotions and cognitions. In this study, neuroscience techniques (EEG, SC, BVP) were used to compare emotional and cognitive aspects of shopping between metaverse and traditional e-commerce platforms. Participants were asked to purchase the same product once on a metaverse platform (Second Life, SL) and once via an e-commerce website (EC). After each task, questionnaires were administered to measure perceived enjoyment, informativeness, ease of use, cognitive effort, and flow. Statistical analyses were conducted to examine differences between SL and EC at the neurophysiological and self-report levels, as well as between different stages of the purchase process. The results show that SL elicits greater cognitive engagement than EC, but it is also more mentally demanding, with a higher workload and more memorization, and fails to elicit a strong positive emotional response, leading to a poorer shopping experience. These findings provide insights not only for digital-related consumer research but also for companies to improve their metaverse shopping experience. Before investing in the platform or creating a digital retail space, companies should thoroughly analyze it, focusing on how to enhance users’ cognition and emotions, ultimately promoting a better consumer experience. Despite its limitations, this pilot study sheds light on the emotional and cognitive aspects of metaverse shopping and suggests potential for further research with a consumer neuroscience approach in the metaverse field. © 2024 by the authors.
KW  - consumer neuroscience
KW  - digital consumer behavior
KW  - EEG
KW  - emotions
KW  - metaverse
KW  - neuromarketing
KW  - Second Life
KW  - shopping experience
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 3
ER  -

TY  - JOUR
AU  - Tung Khuat, T.
AU  - Jacob Kedziora, D.
AU  - Gabrys, B.
TI  - The Roles and Modes of Human Interactions with Automated Machine Learning Systems: A Critical Review and Perspectives
PY  - 2023
T2  - Foundations and Trends in Human-Computer Interaction
VL  - 17
IS  - 3-4
SP  - 195
EP  - 387
DO  - 10.1561/1100000091
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182593414&doi=10.1561%2f1100000091&partnerID=40&md5=b7b95a3283760a6bc7a5526ac820b904
AB  - As automated machine learning (AutoML) systems continue to progress in both sophistication and performance, it becomes important to understand the ‘how’ and ‘why’ of human-computer interaction (HCI) within these frameworks, both current and expected. Such a discussion is necessary for optimal system design, leveraging advanced data-processing capabilities to support decision-making involving humans, but it is also key to identifying the opportunities and risks presented by ever-increasing levels of machine autonomy. Within this context, we focus on the following questions: (i) What does HCI currently look like for state-of-the-art AutoML algorithms, especially during the stages of development, deployment, and maintenance? (ii) Do the expectations of HCI within AutoML frameworks vary for different types of users and stakeholders? (iii) How can HCI be managed so that AutoML solutions acquire human trust and broad acceptance? (iv) As AutoML systems become more autonomous and capable of learning from complex open-ended environments, will the fundamental nature of HCI evolve? To consider these questions, we project existing literature in HCI into the space of AutoML; this connection has, to date, largely been unexplored. In so doing, we review topics including user-interface design, human-bias mitigation, and trust in artificial intelligence (AI). Additionally, to rigorously gauge the future of HCI, we contemplate how AutoML may manifest in effectively open-ended environments. This discussion necessarily reviews projected developmental pathways for AutoML, such as the incorporation of high-level reasoning, although the focus remains on how and why HCI may occur in such a framework rather than on any implementational details. Ultimately, this review serves to identify key research directions aimed at better facilitating the roles and modes of human interactions with both current and future AutoML systems. ©2023 T. T. Khuat et al.
KW  - Data handling
KW  - Decision making
KW  - Machine learning
KW  - User interfaces
KW  - 'current
KW  - Advanced data processing
KW  - Automated machines
KW  - Critical perspectives
KW  - Critical review
KW  - Humaninteraction
KW  - Machine learning systems
KW  - Machine-learning
KW  - Optimal systems design
KW  - Performance
KW  - Human computer interaction
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Mumuni, F.
AU  - Mumuni, A.
TI  - Improving deep learning with prior knowledge and cognitive models: A survey on enhancing explainability, adversarial robustness and zero-shot learning
PY  - 2024
T2  - Cognitive Systems Research
VL  - 84
C7  - 101188
DO  - 10.1016/j.cogsys.2023.101188
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183716435&doi=10.1016%2fj.cogsys.2023.101188&partnerID=40&md5=61aafc6a003c4a9da8d4eef3b24d62b0
AB  - We review current and emerging knowledge-informed and brain-inspired cognitive systems for realizing adversarial defenses, eXplainable Artificial Intelligence (XAI), and zero-shot or few-shot learning. Data-driven machine learning models have achieved remarkable performance and demonstrated capabilities surpassing humans in many applications. Yet, their inability to exploit domain knowledge leads to serious performance limitations in practical applications. In particular, deep learning systems are exposed to adversarial attacks, which can trick them into making glaringly incorrect decisions. Moreover, complex data-driven models typically lack interpretability or explainability, i.e., their decisions cannot be understood by human subjects. Furthermore, models are usually trained on standard datasets with a closed-world assumption. Hence, they struggle to generalize to unseen cases during inference in practical open-world environments, thus, raising the zero- or few-shot generalization problem. Although many conventional solutions exist, explicit domain knowledge, brain-inspired neural networks and cognitive architectures offer powerful new dimensions towards alleviating these problems. Prior knowledge is represented in appropriate forms like mathematical relations, logic rules, knowledge graphs, and large language models (LLMs). and incorporated in deep learning frameworks to improve performance. Brain-inspired cognition methods use computational models that mimic the human brain to enhance intelligent behavior in artificial agents and autonomous robots. Ultimately, these models achieve better explainability, higher adversarial robustness and data-efficient learning, and can, in turn, provide insights for cognitive science and neuroscience—that is, to deepen human understanding on how the brain works in general, and how it handles these problems. © 2023 Elsevier B.V.
KW  - Adversarial attack
KW  - Brain-inspired neural network
KW  - Cognitive architecture
KW  - Domain knowledge
KW  - Explainable AI
KW  - Zero-shot generalization
KW  - Brain
KW  - Cognitive systems
KW  - Computation theory
KW  - Deep learning
KW  - Intelligent robots
KW  - Learning systems
KW  - Network architecture
KW  - Zero-shot learning
KW  - Adversarial attack
KW  - Brain-inspired
KW  - Brain-inspired neural network
KW  - Cognitive architectures
KW  - Domain knowledge
KW  - Explainable AI
KW  - Generalisation
KW  - Learning with prior knowledge
KW  - Neural-networks
KW  - Zero-shot generalization
KW  - Article
KW  - artificial intelligence
KW  - artificial neural network
KW  - back propagation
KW  - cognitive model
KW  - coronavirus disease 2019
KW  - deep learning
KW  - deep neural network
KW  - few shot learning
KW  - functional magnetic resonance imaging
KW  - human
KW  - image reconstruction
KW  - knowledge
KW  - large language model
KW  - machine learning
KW  - man machine interaction
KW  - mathematics
KW  - measurement accuracy
KW  - prediction
KW  - thorax radiography
KW  - zero shot learning
KW  - Domain Knowledge
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 8
ER  -

TY  - JOUR
AU  - Wang, S.
AU  - Huang, L.
AU  - Gao, A.
AU  - Ge, J.
AU  - Zhang, T.
AU  - Feng, H.
AU  - Satyarth, I.
AU  - Li, M.
AU  - Zhang, H.
AU  - Ng, V.
TI  - Machine/Deep Learning for Software Engineering: A Systematic Literature Review
PY  - 2023
T2  - IEEE Transactions on Software Engineering
VL  - 49
IS  - 3
SP  - 1188
EP  - 1231
DO  - 10.1109/TSE.2022.3173346
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132507335&doi=10.1109%2fTSE.2022.3173346&partnerID=40&md5=635eb559263a653bdd90543131162571
AB  - Since 2009, the deep learning revolution, which was triggered by the introduction of ImageNet, has stimulated the synergy between Software Engineering (SE) and Machine Learning (ML)/Deep Learning (DL). Meanwhile, critical reviews have emerged that suggest that ML/DL should be used cautiously. To improve the applicability and generalizability of ML/DL-related SE studies, we conducted a 12-year Systematic Literature Review (SLR) on 1,428 ML/DL-related SE papers published between 2009 and 2020. Our trend analysis demonstrated the impacts that ML/DL brought to SE. We examined the complexity of applying ML/DL solutions to SE problems and how such complexity led to issues concerning the reproducibility and replicability of ML/DL studies in SE. Specifically, we investigated how ML and DL differ in data preprocessing, model training, and evaluation when applied to SE tasks, and what details need to be provided to ensure that a study can be reproduced or replicated. By categorizing the rationales behind the selection of ML/DL techniques into five themes, we analyzed how model performance, robustness, interpretability, complexity, and data simplicity affected the choices of ML/DL models.  © 2022 IEEE.
KW  - deep learning
KW  - machine learning
KW  - Software engineering
KW  - Deep learning
KW  - Engineering education
KW  - Job analysis
KW  - Learning systems
KW  - Software engineering
KW  - Code
KW  - Complexity theory
KW  - Critical review
KW  - Deep learning
KW  - Engineering learning
KW  - Machine-learning
KW  - Predictive models
KW  - Software
KW  - Systematic literature review
KW  - Task analysis
KW  - Data structures
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 39
ER  -

TY  - JOUR
AU  - Zhang, X.
AU  - Mao, R.
AU  - Cambria, E.
TI  - A survey on syntactic processing techniques
PY  - 2023
T2  - Artificial Intelligence Review
VL  - 56
IS  - 6
SP  - 5645
EP  - 5728
DO  - 10.1007/s10462-022-10300-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141670223&doi=10.1007%2fs10462-022-10300-7&partnerID=40&md5=56bbe95e526391fecaee37a23b664701
AB  - Computational syntactic processing is a fundamental technique in natural language processing. It normally serves as a pre-processing method to transform natural language into structured and normalized texts, yielding syntactic features for downstream task learning. In this work, we propose a systematic survey of low-level syntactic processing techniques, namely: microtext normalization, sentence boundary disambiguation, part-of-speech tagging, text chunking, and lemmatization. We summarize and categorize widely used methods in the aforementioned syntactic analysis tasks, investigate the challenges, and yield possible research directions to overcome the challenges in future work. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.
KW  - Lemmatization
KW  - Microtext normalization
KW  - Natural language processing
KW  - Part-of-speech tagging
KW  - Sentence boundary disambiguation
KW  - Syntactic processing
KW  - Text chunking
KW  - Computational linguistics
KW  - Natural language processing systems
KW  - Processing
KW  - Surveys
KW  - Language processing
KW  - Lemmatization
KW  - Microtext normalization
KW  - Natural language processing
KW  - Natural languages
KW  - Normalisation
KW  - Part of speech tagging
KW  - Parts-of-speech tagging
KW  - Sentence boundaries
KW  - Sentence boundary disambiguation
KW  - Syntactic processing
KW  - Text chunking
KW  - Syntactics
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 14
ER  -

TY  - CONF
AU  - Li, J.
AU  - Yang, Y.
AU  - Bai, Y.
AU  - Zhou, X.
AU  - Li, Y.
AU  - Sun, H.
AU  - Liu, Y.
AU  - Si, X.
AU  - Ye, Y.
AU  - Wu, Y.
AU  - Lin, Y.
AU  - Xu, B.
AU  - Ren, B.
AU  - Feng, C.
AU  - Gao, Y.
AU  - Huang, H.
TI  - Fundamental Capabilities of Large Language Models and their Applications in Domain Scenarios: A Survey
PY  - 2024
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
VL  - 1
SP  - 11116
EP  - 11141
DO  - 10.18653/v1/2024.acl-long.599
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204445649&doi=10.18653%2fv1%2f2024.acl-long.599&partnerID=40&md5=f60972599d8fdf3b12773113b879ae31
AB  - Large Language Models (LLMs) demonstrate significant value in domain-specific applications, benefiting from their fundamental capabilities. Nevertheless, it is still unclear which fundamental capabilities contribute to success in specific domains. Moreover, the existing benchmark-based evaluation cannot effectively reflect the performance of real-world applications. In this survey, we review recent advances of LLMs in domain applications, aiming to summarize the fundamental capabilities and their collaboration. Furthermore, we establish connections between fundamental capabilities and specific domains, evaluating the varying importance of different capabilities. Based on our findings, we propose a reliable strategy for domains to choose more robust backbone LLMs for real-world applications. © 2024 Association for Computational Linguistics.
KW  - Domain-specific application
KW  - Language model
KW  - Performance
KW  - Real-world
KW  - Computational linguistics
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 5
ER  -

TY  - JOUR
AU  - Bembenek, A.
AU  - Greenberg, M.
AU  - Chong, S.
TI  - Making Formulog Fast: An Argument for Unconventional Datalog Evaluation
PY  - 2024
T2  - Proceedings of the ACM on Programming Languages
VL  - 8
IS  - OOPSLA2
C7  - 314
DO  - 10.1145/3689754
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206453591&doi=10.1145%2f3689754&partnerID=40&md5=c5d71cba62cbbd80e74f8cfda6a9f7b0
AB  - With its combination of Datalog, SMT solving, and functional programming, the language Formulog provides an appealing mix of features for implementing SMT-based static analyses (e.g., refinement type checking, symbolic execution) in a natural, declarative way. At the same time, the performance of its custom Datalog solver can be an impediment to using Formulog beyond prototyping - a common problem for Datalog variants that aspire to solve large problem instances. In this work we speed up Formulog evaluation, with some surprising results: while 2.2× speedups can be obtained by using the conventional techniques for high-performance Datalog (e.g., compilation, specialized data structures), the big wins come by abandoning the central assumption in modern performant Datalog engines, semi-naive Datalog evaluation. In the place of semi-naive evaluation, we develop eager evaluation, a concurrent Datalog evaluation algorithm that explores the logical inference space via a depth-first traversal order. In practice, eager evaluation leads to an advantageous distribution of Formulog's SMT workload to external SMT solvers and improved SMT solving times: our eager evaluation extensions to the Formulog interpreter and Soufflé's code generator achieve mean 5.2× and 7.6× speedups, respectively, over the optimized code generated by off-the-shelf Soufflé on SMT-heavy Formulog benchmarks. All in all, using compilation and eager evaluation (as appropriate), Formulog implementations of refinement type checking, bottom-up pointer analysis, and symbolic execution achieve speedups on 20 out of 23 benchmarks over previously published, hand-tuned analyses written in Fĝ™¯, Java, and C++, providing strong evidence that Formulog can be the basis of a realistic platform for SMT-based static analysis. Moreover, our experience adds nuance to the conventional wisdom that traditional semi-naive evaluation is the one-size-fits-all best Datalog evaluation algorithm for static analysis workloads. © 2024 Owner/Author.
KW  - compilation
KW  - Datalog
KW  - Formulog
KW  - parallel evaluation
KW  - SMT solving
KW  - Benchmarking
KW  - C++ (programming language)
KW  - Inference engines
KW  - Java programming language
KW  - Program debugging
KW  - Program interpreters
KW  - Compilation
KW  - Datalog
KW  - Evaluation algorithm
KW  - Formulog
KW  - Parallel evaluation
KW  - Performance
KW  - Semi-naive evaluation
KW  - SMT solving
KW  - Symbolic execution
KW  - Typechecking
KW  - Functional programming
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - BOOK
AU  - De Oliveira, T.S.
AU  - Bell, R.W.
TI  - Subsoil Constraints for Crop Production
PY  - 2022
T2  - Subsoil Constraints for Crop Production
SP  - 1
EP  - 450
DO  - 10.1007/978-3-031-00317-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163567077&doi=10.1007%2f978-3-031-00317-2&partnerID=40&md5=98aaa92fbb0258c0b22ad35013f9ebb1
AB  - This book will address the major subsoil physical and chemical constraints and their implications to crop production; Plant growth is often restricted by adverse physical and chemical properties of subsoils yet these limitations are not revealed by testing surface soils and hence their significance in crop management is often overlooked. The major constraints can be physical or chemical. Physical limitations such as poor/nil subsoil structure, sandy subsoils that do not provide adequate water or gravelly subsoils and, etc. On the other hand, chemical constraints include acidity/alkalinity, high extractable Al or Mn, low nutrient availability, salts, boron toxicity and pyritic subsoils. Some of these constraints are inherent properties of the soil profile while others are induced by crop and soil management practices. This aim of this book is to define the constraints and discuss amelioration practices and benefits for crop production. This book will be of interest to readers involved with agriculture and soil sciences in laboratory, applied or classroom settings. © Springer Nature Switzerland AG 2022.
KW  - Abiotic Stress
KW  - Crop Production
KW  - Irrigation Sciences
KW  - Plant Growth
KW  - Soil and Water Sciences
KW  - Soil Constraints
M3  - Book
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 9
ER  -

TY  - CHAP
AU  - Fujii, K.
TI  - Machine Learning in Sports: Open Approach for Next Play Analytics
PY  - 2025
T2  - SpringerBriefs in Computer Science
VL  - Part F295
SP  - 1
EP  - 121
DO  - 10.1007/978-981-96-1445-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004923731&doi=10.1007%2f978-981-96-1445-5&partnerID=40&md5=cf1b65c031e5dcdb8bb42a01a5595fbd
AB  - This open access book provides cutting-edge work on machine learning in sports analytics, emphasizing the integration of computer vision, data analytics, and machine learning to redefine strategic sports analysis. This book not only covers the essential methodologies of capturing and analyzing real sports data but also pioneers the integration of real-world analytics with digital modeling, advancing the field toward sophisticated digital modeling in sports. Through a seamless blend of theoretical frameworks and practical applications, the book illustrates how these integrated technologies can be utilized to predict, evaluate, and suggest next plays in sports. By leveraging the power of machine learning, the book presents cutting-edge approaches to sports analytics, where data from actual games is enhanced with predictive simulations for strategic planning and decision-making. The use of digital modeling in sports opens up new dimensions of interaction between the physical play and its digital analysis, offering a comprehensive understanding that was previously unattainable. This book is an essential read for postgraduates, researchers, and technologists, who are interested in sports analysts. The book consists of five parts: Part I, which comprises a single chapter exploring the fundamentals and scope of learning-based sports analytics; Parts II, III, IV, and V review the various aspects of this field, including data acquisition with computer vision, predictive analysis and play evaluation with machine learning, potential play evaluation with learning-based agent modeling, and future perspectives and ecosystems on the field. This structure provides a comprehensive overview that will engage and inform researchers and practitioners interested in the intersection of analytical research and cutting-edge technology in sports. © The Editor(s) (if applicable) and The Author(s) 2025. This book is an open access publication.
KW  - Artificial intelligence
KW  - Basketball
KW  - Cyber-physical systems
KW  - Deep learning
KW  - Football
KW  - Machine learning
KW  - Modeling
KW  - Open Access
KW  - Prediction
KW  - Real-world data
KW  - Reinforcement learning
KW  - Soccer
KW  - Sports
KW  - Advanced Analytics
KW  - Artificial life
KW  - Decision making
KW  - Deep reinforcement learning
KW  - Intelligent systems
KW  - Multi agent systems
KW  - Reinforcement learning
KW  - Strategic planning
KW  - Cybe-physical systems
KW  - Cyber-physical systems
KW  - Deep learning
KW  - Digital modeling
KW  - Machine-learning
KW  - Modeling
KW  - OpenAccess
KW  - Real-world
KW  - Real-world data
KW  - Reinforcement learnings
KW  - Deep learning
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - CONF
AU  - Tanaka, R.
AU  - Suzuki, T.
AU  - Fujii, K.
TI  - 3D Pose-Based Temporal Action Segmentation for Figure Skating: A Fine-Grained and Jump Procedure-Aware Annotation Approach
PY  - 2024
T2  - MMSports 2024 - Proceedings of the 7th ACM International Workshop on Multimedia Content Analysis in Sports, Co-Located with: MM 2024
SP  - 17
EP  - 26
DO  - 10.1145/3689061.3689077
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210875089&doi=10.1145%2f3689061.3689077&partnerID=40&md5=38f92c210c678894b6062f479fdb1dda
AB  - Understanding human actions from videos is essential in many domains, including sports. In figure skating, technical judgments are performed by watching skaters’ 3D movements, and its part of the judging procedure can be regarded as a Temporal Action Segmentation (TAS) task. TAS tasks in figure skating that automatically assign temporal semantics to video are actively researched. However, there is a lack of datasets and effective methods for TAS tasks requiring 3D pose data. In this study, we first created the FS-Jump3D dataset of complex and dynamic figure skating jumps using optical markerless motion capture. We also propose a new fine-grained figure skating jump TAS dataset annotation method with which TAS models can learn jump procedures. In the experimental results, we validated the usefulness of 3D pose features as input and the fine-grained dataset for the TAS model in figure skating. FS-Jump3D Dataset is available at https://github.com/ryota-skating/FS-Jump3D. © 2024 Copyright held by the owner/author(s).
KW  - Annotation
KW  - Computer vision
KW  - Datasets
KW  - Human pose estimation
KW  - Sports
KW  - Temporal action segmentation
KW  - 3D modeling
KW  - Computer vision
KW  - Image segmentation
KW  - Motion capture
KW  - Three dimensional computer graphics
KW  - Action segmentation
KW  - Annotation
KW  - Dataset
KW  - Figure skating
KW  - Fine grained
KW  - Human actions
KW  - Human pose estimations
KW  - Segmentation models
KW  - Temporal action segmentation
KW  - Temporal semantics
KW  - Spatio-temporal data
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - BOOK
AU  - Wang, X.-J.
TI  - Theoretical neuroscience: Understanding cognition
PY  - 2025
T2  - Theoretical Neuroscience: Understanding Cognition
SP  - 1
EP  - 561
DO  - 10.1201/9781003459361
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216424448&doi=10.1201%2f9781003459361&partnerID=40&md5=88789d85db96051864a253bb184dc031
AB  - This textbook is an introduction to Systems and Theoretical/Computational Neuroscience, with a particular emphasis on cognition. It consists of three parts: Part I covers fundamental concepts and mathematical models in computational neuroscience, along with cutting-edge topics. Part II explores the building blocks of cognition, including working memory (how the brain maintains and manipulates information "online" without external input), decision making (how choices are made among multiple options under conditions of uncertainty and risk) and behavioral flexibility (how we direct attention and control actions). Part III is dedicated to frontier research, covering models of large-scale multi-regional brain systems, Computational Psychiatry and the interface with Artificial Intelligence. The author highlights the perspective of neural circuits as dynamical systems, and emphasizes a cross-level mechanistic understanding of the brain and mind, from genes and cell types to collective neural populations and behavior. Overall, this textbook provides an opportunity for readers to become well versed in this highly interdisciplinary field of the twenty-first century. Key Features • Rooted in the most recent advances in experimental studies of basic cognitive functions • Introduces neurobiological and mathematical concepts so that the book is self-contained • Heavily illustrated with high-quality figures that help to illuminate neurobiological concepts, present experimental findings and explain mathematical models • Concludes with a list of core cognitive behavior tasks, ten take-home messages and three open questions for future research • Computer model codes are available via GitHub for hands-on practice. © 2025 Xiao-Jing Wang. All rights reserved.
M3  - Book
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Paul, R.
AU  - Mishra, S.
AU  - Khatti, J.
TI  - Role of Artificial Intelligence (AI) Techniques in Tunnel Engineering—A Scientific Review
PY  - 2025
T2  - Indian Geotechnical Journal
DO  - 10.1007/s40098-025-01238-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003448161&doi=10.1007%2fs40098-025-01238-y&partnerID=40&md5=856ee491f078bfdb2674ac3797fec1a2
AB  - The design, building, and maintenance of underground structures are being revolutionized by applying Artificial Intelligence (AI) techniques in tunnel engineering, which provide previously unheard-of levels of safety, efficiency, and precision. This scientific investigation looks at the various ways AI may help with the intricate problems of tunnel engineering, especially in geotechnical analysis, construction automation, and long-term performance monitoring. The interpretation of large amounts of geological data, precise subsurface condition forecasts, and design uncertainty reduction are all made possible by AI-powered machine learning algorithms. By improving cutterhead performance, decreasing wear, and limiting downtime, AI enhances the operation of tunnel boring machines during tunnel construction. Real-time monitoring systems powered by AI enable proactive risk management and raise safety standards by detecting irregularities like water intrusion and ground deformations. Additionally, to extend the lifespan of tunnel infrastructure, AI-based predictive maintenance systems examine structural health data to foresee breakdowns and plan prompt repairs. Automation in excavation and lining installation has also been made possible using sophisticated computer vision and robots, decreasing the need for human involvement in dangerous situations. Notwithstanding these developments, many obstacles remain, including the inability to obtain high-quality data, computational complexity, and incorporating AI models into conventional engineering processes. This study highlights essential applications, summarizes recent research, and talks about the potential and limitations of artificial intelligence in tunnel engineering. The results highlight how AI can transform tunneling by promoting safer, more economical, and sustainable engineering methods. Furthermore, this paper proposes new portals to expand the study of AI applications in tunnel engineering, which would benefit academics, engineers, and tunnel designers. © The Author(s), under exclusive licence to Indian Geotechnical Society 2025.
KW  - Artificial intelligence
KW  - Geo-mechanical properties assessment
KW  - Hybrid soft computing
KW  - Neural network
KW  - Tunnel boring machine performance
KW  - Tunnel engineering
KW  - Architectural design
KW  - Boring machines (machine tools)
KW  - Health risks
KW  - Machine design
KW  - Predictive maintenance
KW  - Repair
KW  - Risk assessment
KW  - Tunnel linings
KW  - Tunneling (excavation)
KW  - Tunneling machines
KW  - Underground buildings
KW  - Geo-mechanical property assessment
KW  - Hybrid soft computing
KW  - Machine performance
KW  - Mechanical
KW  - Neural-networks
KW  - Property assessment
KW  - Soft-Computing
KW  - Tunnel boring
KW  - Tunnel boring machine performance
KW  - Tunnel engineering
KW  - Risk management
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Labat, S.
AU  - Demeester, T.
AU  - Hoste, V.
TI  - EmoTwiCS: a corpus for modelling emotion trajectories in Dutch customer service dialogues on Twitter
PY  - 2024
T2  - Language Resources and Evaluation
VL  - 58
IS  - 2
SP  - 505
EP  - 546
DO  - 10.1007/s10579-023-09700-0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178903823&doi=10.1007%2fs10579-023-09700-0&partnerID=40&md5=825a3ff444f1e83d83c3c3b679456630
AB  - Due to the rise of user-generated content, social media is increasingly adopted as a channel to deliver customer service. Given the public character of online platforms, the automatic detection of emotions forms an important application in monitoring customer satisfaction and preventing negative word-of-mouth. This paper introduces EmoTwiCS, a corpus of 9489 Dutch customer service dialogues on Twitter that are annotated for emotion trajectories. In our business-oriented corpus, we view emotions as dynamic attributes of the customer that can change at each utterance of the conversation. The term ‘emotion trajectory’ refers therefore not only to the fine-grained emotions experienced by customers (annotated with 28 labels and valence-arousal-dominance scores), but also to the event happening prior to the conversation and the responses made by the human operator (both annotated with 8 categories). Inter-annotator agreement (IAA) scores on the resulting dataset are substantial and comparable with related research, underscoring its high quality. Given the interplay between the different layers of annotated information, we perform several in-depth analyses to investigate (i) static emotions in isolated tweets, (ii) dynamic emotions and their shifts in trajectory, and (iii) the role of causes and response strategies in emotion trajectories. We conclude by listing the advantages and limitations of our dataset, after which we give some suggestions on the different types of predictive modelling tasks and open research questions to which EmoTwiCS can be applied. The dataset is made publicly available at https://lt3.ugent.be/resources/emotwics. © The Author(s) 2023.
KW  - Customer service
KW  - Dutch resource
KW  - Emotion analysis
KW  - Emotion recognition in conversations (ERC)
KW  - Social media text
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 6
ER  -

TY  - JOUR
AU  - Pashangpour, S.
AU  - Nejat, G.
TI  - The Future of Intelligent Healthcare: A Systematic Analysis and Discussion on the Integration and Impact of Robots Using Large Language Models for Healthcare
PY  - 2024
T2  - Robotics
VL  - 13
IS  - 8
C7  - 112
DO  - 10.3390/robotics13080112
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202627455&doi=10.3390%2frobotics13080112&partnerID=40&md5=453b55b6709a54756400b1dd6ac7c7e0
AB  - The potential use of large language models (LLMs) in healthcare robotics can help address the significant demand put on healthcare systems around the world with respect to an aging demographic and a shortage of healthcare professionals. Even though LLMs have already been integrated into medicine to assist both clinicians and patients, the integration of LLMs within healthcare robots has not yet been explored for clinical settings. In this perspective paper, we investigate the groundbreaking developments in robotics and LLMs to uniquely identify the needed system requirements for designing health-specific LLM-based robots in terms of multi-modal communication through human–robot interactions (HRIs), semantic reasoning, and task planning. Furthermore, we discuss the ethical issues, open challenges, and potential future research directions for this emerging innovative field. © 2024 by the authors.
KW  - healthcare robotics
KW  - large language models
KW  - multi-modal communication
KW  - semantic reasoning
KW  - task planning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 7
ER  -

TY  - JOUR
AU  - Orka, N.A.
AU  - Awal, M.A.
AU  - Liò, P.
AU  - Pogrebna, G.
AU  - Ross, A.G.
AU  - Moni, M.A.
TI  - Quantum deep learning in neuroinformatics: a systematic review
PY  - 2025
T2  - Artificial Intelligence Review
VL  - 58
IS  - 5
C7  - 134
DO  - 10.1007/s10462-025-11136-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218352210&doi=10.1007%2fs10462-025-11136-7&partnerID=40&md5=7213d589ef9b3852778f777c007ef605
AB  - Neuroinformatics involves replicating and detecting intricate brain activities through computational models, where deep learning plays a foundational role. Our systematic review explores quantum deep learning (QDL), an emerging deep learning sub-field, to assess whether quantum-based approaches outperform classical approaches in brain data learning tasks. This review is a pioneering effort to compare these deep learning domains. In addition, we survey neuroinformatics and its various subdomains to understand the current state of the field and where QDL stands relative to recent advancements. Our statistical analysis of tumor classification studies (n = 16) reveals that QDL models achieved a mean accuracy of 0.9701 (95% CI 0.9533–0.9868), slightly outperforming classical models with a mean accuracy of 0.9650 (95% CI 0.9475–0.9825). We observed similar trends across Alzheimer’s diagnosis, stroke lesion detection, cognitive state monitoring, and brain age prediction, with QDL demonstrating better performance in metrics such as F1-score, dice coefficient, and RMSE. Our findings, paired with prior documented quantum advantages, highlight QDL’s promise in healthcare applications as quantum technology evolves. Our discussion outlines existing research gaps with the intent of encouraging further investigation in this developing field. © The Author(s) 2025.
KW  - Neuroinformatics
KW  - PRISMA
KW  - Quantum deep learning
KW  - Quantum machine learning
KW  - Systematic review
KW  - Adversarial machine learning
KW  - Deep learning
KW  - Deep reinforcement learning
KW  - Quantum optics
KW  - Brain activity
KW  - Computational modelling
KW  - Machine-learning
KW  - Neuroinformatics
KW  - PRISMA
KW  - Quantum deep learning
KW  - Quantum machine learning
KW  - Quantum machines
KW  - Sub fields
KW  - Systematic Review
KW  - Contrastive Learning
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - JOUR
AU  - Schulz, S.A.
AU  - Oulton, R.F.
AU  - Kenney, M.
AU  - Alù, A.
AU  - Staude, I.
AU  - Bashiri, A.
AU  - Fedorova, Z.
AU  - Kolkowski, R.
AU  - Koenderink, A.F.
AU  - Xiao, X.
AU  - Yang, J.
AU  - Peveler, W.J.
AU  - Clark, A.W.
AU  - Perrakis, G.
AU  - Tasolamprou, A.C.
AU  - Kafesaki, M.
AU  - Zaleska, A.
AU  - Dickson, W.
AU  - Richards, D.
AU  - Zayats, A.
AU  - Ren, H.
AU  - Kivshar, Y.
AU  - Maier, S.
AU  - Chen, X.
AU  - Ansari, M.A.
AU  - Gan, Y.
AU  - Alexeev, A.
AU  - Krauss, T.F.
AU  - Di Falco, A.
AU  - Gennaro, S.D.
AU  - Santiago-Cruz, T.
AU  - Brener, I.
AU  - Chekhova, M.V.
AU  - Ma, R.-M.
AU  - Vogler-Neuling, V.V.
AU  - Weigand, H.C.
AU  - Talts, I.-L.
AU  - Occhiodori, I.
AU  - Grange, R.
AU  - Rahmani, M.
AU  - Xu, L.
AU  - Kamali, S.M.
AU  - Arababi, E.
AU  - Faraon, A.
AU  - Harwood, A.C.
AU  - Vezzoli, S.
AU  - Sapienza, R.
AU  - Lalanne, P.
AU  - Dmitriev, A.
AU  - Rockstuhl, C.
AU  - Sprafke, A.
AU  - Vynck, K.
AU  - Upham, J.
AU  - Alam, M.Z.
AU  - De Leon, I.
AU  - Boyd, R.W.
AU  - Padilla, W.J.
AU  - Malof, J.M.
AU  - Jana, A.
AU  - Yang, Z.
AU  - Colom, R.
AU  - Song, Q.
AU  - Genevet, P.
AU  - Achouri, K.
AU  - Evlyukhin, A.B.
AU  - Lemmer, U.
AU  - Fernandez-Corbaton, I.
TI  - Roadmap on photonic metasurfaces
PY  - 2024
T2  - Applied Physics Letters
VL  - 124
IS  - 26
C7  - 260701
DO  - 10.1063/5.0204694
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197219045&doi=10.1063%2f5.0204694&partnerID=40&md5=dd840db12129717d20b4a687da5aa093
AB  - Here we present a roadmap on Photonic metasurfaces. This document consists of a number of perspective articles on different applications, challenge areas or technologies underlying photonic metasurfaces. Each perspective will introduce the topic, present a state of the art as well as give an insight into the future direction of the subfield. © 2024 Author(s).
KW  - Metasurface
KW  - Roadmap
KW  - State of the art
KW  - Subfields
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 50
ER  -

TY  - JOUR
AU  - Irfan, B.
AU  - Kuoppamäki, S.
AU  - Hosseini, A.
AU  - Skantze, G.
TI  - Between reality and delusion: challenges of applying large language models to companion robots for open-domain dialogues with older adults
PY  - 2025
T2  - Autonomous Robots
VL  - 49
IS  - 1
C7  - 9
DO  - 10.1007/s10514-025-10190-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000731912&doi=10.1007%2fs10514-025-10190-y&partnerID=40&md5=936f5003cc9f70898edeed87db6c6429
AB  - Throughout our lives, we interact daily in conversations with our friends and family, covering a wide range of topics, known as open-domain dialogue. As we age, these interactions may diminish due to changes in social and personal relationships, leading to loneliness in older adults. Conversational companion robots can alleviate this issue by providing daily social support. Large language models (LLMs) offer flexibility for enabling open-domain dialogue in these robots. However, LLMs are typically trained and evaluated on textual data, while robots introduce additional complexity through multi-modal interactions, which has not been explored in prior studies. Moreover, it is crucial to involve older adults in the development of robots to ensure alignment with their needs and expectations. Correspondingly, using iterative participatory design approaches, this paper exposes the challenges of integrating LLMs into conversational robots, deriving from 34 Swedish-speaking older adults’ (one-to-one) interactions with a personalized companion robot, built on Furhat robot with GPT-3.5. These challenges encompass disruptions in conversations, including frequent interruptions, slow, repetitive, superficial, incoherent, and disengaging responses, language barriers, hallucinations, and outdated information, leading to frustration, confusion, and worry among older adults. Drawing on insights from these challenges, we offer recommendations to enhance the integration of LLMs into conversational robots, encompassing both general suggestions and those tailored to companion robots for older adults. © The Author(s) 2025.
KW  - Companion robot
KW  - Elderly care
KW  - Large language models
KW  - Open-domain dialogue
KW  - Participatory design
KW  - Socially assistive robot
KW  - Economic and social effects
KW  - Industrial robots
KW  - Nanorobots
KW  - Social robots
KW  - Companion robot
KW  - Elderly care
KW  - Language model
KW  - Large language model
KW  - Older adults
KW  - Open-domain dialog
KW  - Participatory design
KW  - Personal relationships
KW  - Social relationships
KW  - Socially assistive robots
KW  - Microrobots
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Minai, A.A.
TI  - Deep Intelligence: What AI Should Learn from Nature’s Imagination
PY  - 2024
T2  - Cognitive Computation
VL  - 16
IS  - 5
SP  - 2389
EP  - 2404
DO  - 10.1007/s12559-023-10124-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149380048&doi=10.1007%2fs12559-023-10124-9&partnerID=40&md5=a21ab449798bfee4c4de8da016909b1e
AB  - Artificial intelligence (AI) has recently seen explosive growth and remarkable successes in several application areas. However, it is becoming clear that the methods that have made this possible are subject to several limitations that might inhibit progress towards replicating the more general intelligence seen in humans and other animals. In contrast to current AI methods that focus on specific tasks and rely on large amounts of offline data and extensive, slow, and mostly supervised learning, this natural intelligence is quick, versatile, agile, and open-ended. This position paper brings together ideas from neuroscience, evolutionary and developmental biology, and complex systems to analyze why such natural intelligence is possible in animals and suggests that AI should exploit the same strategies to move in a different direction. In particular, it argues that integrated embodiment, modularity, synergy, developmental learning, and evolution are key enablers of natural intelligence and should be at the core of AI systems as well. The analysis in the paper leads to the description of a biologically grounded deep intelligence (DI) framework for understanding natural intelligence and developing a new approach to building more versatile, autonomous, and integrated AI. The paper concludes that the dominant paradigm of AI today is unlikely to lead to truly natural general intelligence and that something like the biologically inspired DI framework is needed for that. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.
KW  - Developmental learning
KW  - Embodiment
KW  - Emergence
KW  - Evolution
KW  - Intelligence
KW  - Modularity
KW  - Biomimetics
KW  - Deep learning
KW  - Developmental learning
KW  - Embodiment
KW  - Emergence
KW  - Evolution
KW  - Explosive growth
KW  - General Intelligence
KW  - Intelligence
KW  - Learn+
KW  - Modularity
KW  - Natural intelligence
KW  - Animals
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - CONF
AU  - Capel, T.
AU  - Brereton, M.
TI  - What is Human-Centered about Human-Centered AI? A Map of the Research Landscape
PY  - 2023
T2  - Conference on Human Factors in Computing Systems - Proceedings
C7  - 359
DO  - 10.1145/3544548.3580959
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160009041&doi=10.1145%2f3544548.3580959&partnerID=40&md5=96b3b146d2a683f2d2f5babf0d03d9c1
AB  - The application of Artificial Intelligence (AI) across a wide range of domains comes with both high expectations of its benefits and dire predictions of misuse. While AI systems have largely been driven by a technology-centered design approach, the potential societal consequences of AI have mobilized both HCI and AI researchers towards researching human-centered artificial intelligence (HCAI). However, there remains considerable ambiguity about what it means to frame, design and evaluate HCAI. This paper presents a critical review of the large corpus of peer-reviewed literature emerging on HCAI in order to characterize what the community is defining as HCAI. Our review contributes an overview and map of HCAI research based on work that explicitly mentions the terms 'human-centered artificial intelligence' or 'human-centered machine learning' or their variations, and suggests future challenges and research directions. The map reveals the breadth of research happening in HCAI, established clusters and the emerging areas of Interaction with AI and Ethical AI. The paper contributes a new definition of HCAI, and calls for greater collaboration between AI and HCI research, and new HCAI constructs. © 2023 ACM.
KW  - artificial intelligence
KW  - critical review
KW  - human-centered artificial intelligence
KW  - human-centered machine learning
KW  - machine learning
KW  - Ethical technology
KW  - Artificial intelligence systems
KW  - Community IS
KW  - Critical review
KW  - Design approaches
KW  - Frame design
KW  - Human-centered artificial intelligence
KW  - Human-centered machine learning
KW  - Large corpora
KW  - Machine-learning
KW  - Machine learning
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 88
ER  -

TY  - BOOK
AU  - Sutherland, K.E.
TI  - Artificial Intelligence for Strategic Communication
PY  - 2025
T2  - Artificial Intelligence for Strategic Communication
SP  - 1
EP  - 486
DO  - 10.1007/978-981-96-2575-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004520890&doi=10.1007%2f978-981-96-2575-8&partnerID=40&md5=6147439f2503cbe1350b1e7f56132706
AB  - In an era where AI is revolutionising every aspect of communication, this groundbreaking research monograph provides an essential roadmap for navigating the intersection of artificial intelligence and strategic communication. Drawing on extensive primary research, including interviews with 41 experts and surveys of 400 professionals across three continents and eight countries, this book provides insights from relevant scholars, communication practitioners and AI tool developers. This comprehensive guide combines scholarly rigour with practical application, presenting a data-informed Model for Practice that helps to withstand the constant evolution of AI technology. Each chapter delivers research-informed, actionable tools relating to the multifaceted field of strategic communication including ethical practice, strategy development, content creation, evaluation, and continuous improvement. Bridging the gap between theoretical understanding and practical implementation, AI for Strategic Communication is an invaluable resource for strategic communication scholars, students, and practitioners, essential for advancing careers in the age of AI. This work emerged from the need for a comprehensive source combining scholarly, practitioner and AI developer perspectives on strategic communication from around the globe. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025, corrected publication 2025.
KW  - AI Communication Ethics
KW  - AI Content Creation
KW  - AI in Public Relations
KW  - AI in Strategic Communication
KW  - AI-Driven Marketing
KW  - Artificial Intelligence in Communication
KW  - Ethical AI Communication
KW  - Future-Proof Communication
KW  - Multidisciplinary Communication Guide
KW  - Research-Based Communication Strategies
KW  - Engineering education
KW  - Signaling
KW  - AI communication ethic
KW  - AI content creation
KW  - AI in public relation
KW  - AI in strategic communication
KW  - AI-driven marketing
KW  - Artificial intelligence in communication
KW  - Communication ethics
KW  - Communication strategy
KW  - Content creation
KW  - Ethical AI communication
KW  - Future proofs
KW  - Future-proof communication
KW  - Multidisciplinary communication guide
KW  - Proof communications
KW  - Research-based communication strategy
KW  - Strategic communication
KW  - Ethical technology
M3  - Book
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 0
ER  -

TY  - JOUR
AU  - Ali, H.
AU  - Pham, D.-T.
AU  - Alam, S.
AU  - Schultz, M.
AU  - Li, M.Z.
AU  - Wang, Y.
AU  - Itoh, E.
AU  - Duong, V.N.
TI  - Human-AI Hybrids in Safety-Critical Systems: Concept, definition and perspectives from Air Traffic Management
PY  - 2025
T2  - Advanced Engineering Informatics
VL  - 65
C7  - 103256
DO  - 10.1016/j.aei.2025.103256
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000269413&doi=10.1016%2fj.aei.2025.103256&partnerID=40&md5=de013b57864d140152d5b11459a0dd72
AB  - The recent advancements in Artificial Intelligence (AI) have paved the way for Human-AI Hybrid (HAH) systems, which integrate human and AI capabilities to augment human ingenuity rather than replace it. However, the application of HAH in Safety-Critical Systems (SCS), such as Air Traffic Management (ATM), remains limited due to the high stakes involved and the challenges presented by AI's unpredictable behavior and limitations in complex reasoning tasks. This paper provides an extensive review of the emerging domain of HAH in ATM, defining HAH and examining the fundamental pillars of effective HAH in ATM, including collaboration, adaptation, and trust. By synthesizing interdisciplinary research, this review explores the interaction between humans and AI, identifies obstacles, and recommends strategies for developing effective HAH systems in ATM. Furthermore, by examining real-world ATM applications, this study bridges the gap between theoretical recommendations and practical implementation, offering valuable insights for future efforts in similar contexts. © 2025 Elsevier Ltd
KW  - Adaptation
KW  - Air Traffic Management
KW  - Collaboration
KW  - Human-AI Hybrid
KW  - Safety-Critical Systems
KW  - Trust
KW  - Advanced traffic management systems
KW  - Air navigation
KW  - Air traffic control
KW  - Adaptation
KW  - Air Traffic Management
KW  - Collaboration
KW  - Concept definitions
KW  - Emerging domains
KW  - Human-artificial intelligence hybrid
KW  - Reasoning tasks
KW  - Safety critical systems
KW  - System concepts
KW  - Trust
KW  - Air transportation
M3  - Article
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 1
ER  -

TY  - BOOK
AU  - Mills, S.
TI  - AI for Behavioural Science
PY  - 2022
T2  - AI for Behavioural Science
SP  - 1
EP  - 123
DO  - 10.1201/9781003203315
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148135303&doi=10.1201%2f9781003203315&partnerID=40&md5=eadf777169f1da64d059d334faa8bae1
AB  - This book is a concise introduction to emerging concepts and ideas found at the intersection of contemporary behavioural science and artificial intelligence. The book explores how these disciplines interact, change, and adapt to one another and what the implications of such an interaction are for practice and society. AI for Behavioural Science book begins by exploring the field of machine behaviour, which advocates using behavioural science to investigate artificial intelligence. This perspective is built upon to develop a framework of terminology that treats humans and machines as comparable entities possessing their own motive power. From here, the notion of artificial intelligence systems becoming choice architects is explored through a series of reconceptualisations. The architecting of choices is reconceptualised as a process of selection from a set of choice architectural designs, while human behaviour is reconceptualised in terms of probabilistic outcomes. The material difference between the so-called “manual nudging” and “automatic nudging” (or hypernudging) is then explored. The book concludes with a discussion of who is responsible for autonomous choice architects. © 2023 Stuart Mills.
M3  - Book
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 2
ER  -

TY  - JOUR
AU  - Chen, X.
AU  - Hu, X.
AU  - Huang, Y.
AU  - Jiang, H.
AU  - Ji, W.
AU  - Jiang, Y.
AU  - Jiang, Y.
AU  - Liu, B.
AU  - Liu, H.
AU  - Li, X.
AU  - Lian, X.
AU  - Meng, G.
AU  - Peng, X.
AU  - Sun, H.
AU  - Shi, L.
AU  - Wang, B.
AU  - Wang, C.
AU  - Wang, J.
AU  - Wang, T.
AU  - Xuan, J.
AU  - Xia, X.
AU  - Yang, Y.
AU  - Yang, Y.
AU  - Zhang, L.
AU  - Zhou, Y.
AU  - Zhang, L.
TI  - Deep learning-based software engineering: progress, challenges, and opportunities
PY  - 2025
T2  - Science China Information Sciences
VL  - 68
IS  - 1
C7  - 111102
DO  - 10.1007/s11432-023-4127-5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213975936&doi=10.1007%2fs11432-023-4127-5&partnerID=40&md5=339d64be694274af921581204ad8dd5e
AB  - Researchers have recently achieved significant advances in deep learning techniques, which in turn has substantially advanced other research disciplines, such as natural language processing, image processing, speech recognition, and software engineering. Various deep learning techniques have been successfully employed to facilitate software engineering tasks, including code generation, software refactoring, and fault localization. Many studies have also been presented in top conferences and journals, demonstrating the applications of deep learning techniques in resolving various software engineering tasks. However, although several surveys have provided overall pictures of the application of deep learning techniques in software engineering, they focus more on learning techniques, that is, what kind of deep learning techniques are employed and how deep models are trained or fine-tuned for software engineering tasks. We still lack surveys explaining the advances of subareas in software engineering driven by deep learning techniques, as well as challenges and opportunities in each subarea. To this end, in this study, we present the first task-oriented survey on deep learning-based software engineering. It covers twelve major software engineering subareas significantly impacted by deep learning techniques. Such subareas spread out through the whole lifecycle of software development and maintenance, including requirements engineering, software development, testing, maintenance, and developer collaboration. As we believe that deep learning may provide an opportunity to revolutionize the whole discipline of software engineering, providing one survey covering as many subareas as possible in software engineering can help future research push forward the frontier of deep learning-based software engineering more systematically. For each of the selected subareas, we highlight the major advances achieved by applying deep learning techniques with pointers to the available datasets in such a subarea. We also discuss the challenges and opportunities concerning each of the surveyed software engineering subareas. © The Author(s) 2024.
KW  - deep learning
KW  - software artifact representation
KW  - software benchmark
KW  - software engineering
KW  - survey
KW  - Application programs
KW  - Computer aided software engineering
KW  - Computer software maintenance
KW  - Requirements engineering
KW  - Software design
KW  - Software testing
KW  - Deep learning
KW  - Engineering tasks
KW  - Images processing
KW  - Language processing
KW  - Learning techniques
KW  - Natural languages
KW  - Software artefacts
KW  - Software artifact representation
KW  - Software benchmark
KW  - Sub-areas
KW  - Life cycle
M3  - Review
DB  - Scopus
N1  - Export Date: 20 June 2025; Cited By: 11
ER  -

